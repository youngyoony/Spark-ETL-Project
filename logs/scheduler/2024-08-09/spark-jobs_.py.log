[2024-08-09T13:17:36.893+0000] {processor.py:157} INFO - Started process (PID=3036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:17:36.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:17:36.896+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:36.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:17:36.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:17:37.156+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.156+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-08-09T13:17:37.163+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.163+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-08-09T13:17:37.165+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.165+0000] {manager.py:499} INFO - Created Permission View: %s
[2024-08-09T13:17:37.165+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.165+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-08-09T13:17:37.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:17:37.179+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.179+0000] {dag.py:2937} INFO - Creating ORM DAG for spark_data_processing_pipeline
[2024-08-09T13:17:37.190+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:17:37.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-08T01:00:00+00:00, run_after=2024-08-09T01:00:00+00:00
[2024-08-09T13:17:37.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.313 seconds
[2024-08-09T13:18:07.313+0000] {processor.py:157} INFO - Started process (PID=3046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:07.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:18:07.319+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:07.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:07.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:07.378+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:07.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:18:07.399+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:07.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-08T01:00:00+00:00, run_after=2024-08-09T01:00:00+00:00
[2024-08-09T13:18:07.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-09T13:18:37.773+0000] {processor.py:157} INFO - Started process (PID=3056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:37.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:18:37.783+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:37.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:37.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:18:37.859+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:37.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:18:37.892+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:18:37.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-08T01:00:00+00:00, run_after=2024-08-09T01:00:00+00:00
[2024-08-09T13:18:37.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-09T13:19:08.134+0000] {processor.py:157} INFO - Started process (PID=3066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:08.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:19:08.138+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:08.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:08.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:08.167+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:08.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:19:08.180+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:08.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-08T01:00:00+00:00, run_after=2024-08-09T01:00:00+00:00
[2024-08-09T13:19:08.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T13:19:38.437+0000] {processor.py:157} INFO - Started process (PID=3077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:38.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:19:38.455+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:38.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:38.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:19:38.554+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:38.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:19:38.583+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:19:38.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:19:38.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-09T13:20:09.012+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:09.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:20:09.019+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:09.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:09.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:09.069+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:09.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:20:09.084+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:09.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:20:09.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-09T13:20:39.457+0000] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:39.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:20:39.470+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:39.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:39.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:20:39.551+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:39.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:20:39.581+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:20:39.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:20:39.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-09T13:21:09.752+0000] {processor.py:157} INFO - Started process (PID=3460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:09.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:21:09.758+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:09.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:09.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:09.814+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:09.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:21:09.830+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:09.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:21:09.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-09T13:21:40.177+0000] {processor.py:157} INFO - Started process (PID=3470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:40.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:21:40.185+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:40.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:40.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:21:40.251+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:40.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:21:40.287+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:21:40.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:21:40.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-09T13:22:10.525+0000] {processor.py:157} INFO - Started process (PID=3480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:10.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:22:10.535+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:10.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:10.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:10.590+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:10.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:22:10.607+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:10.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:22:10.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-09T13:22:40.921+0000] {processor.py:157} INFO - Started process (PID=3490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:40.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:22:40.927+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:40.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:40.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:22:40.973+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:40.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:22:40.990+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:22:40.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:22:41.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T13:23:11.243+0000] {processor.py:157} INFO - Started process (PID=3675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:11.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:23:11.258+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:11.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:11.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:11.335+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:11.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:23:11.348+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:11.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:23:11.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-09T13:23:41.608+0000] {processor.py:157} INFO - Started process (PID=3685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:41.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:23:41.614+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:41.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:41.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:23:41.670+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:41.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:23:41.685+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:23:41.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:23:41.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-09T13:24:11.991+0000] {processor.py:157} INFO - Started process (PID=3695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:12.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:24:12.015+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:12.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:12.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:12.064+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:12.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:24:12.080+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:12.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:24:12.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-09T13:24:42.344+0000] {processor.py:157} INFO - Started process (PID=3705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:42.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:24:42.348+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:42.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:42.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:24:42.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:42.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:24:42.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:24:42.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:24:42.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T13:25:12.715+0000] {processor.py:157} INFO - Started process (PID=3715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:12.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:25:12.722+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:12.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:12.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:12.776+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:12.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:25:12.794+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:12.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:25:12.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-09T13:25:43.373+0000] {processor.py:157} INFO - Started process (PID=4102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:43.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:25:43.381+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:43.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:43.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:25:43.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:43.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:25:43.519+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:25:43.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:25:43.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-09T13:26:13.783+0000] {processor.py:157} INFO - Started process (PID=4308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:13.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:26:13.790+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:13.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:13.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:13.831+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:13.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:26:13.844+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:13.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:26:13.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-09T13:26:44.159+0000] {processor.py:157} INFO - Started process (PID=4318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:44.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:26:44.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:44.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:44.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:26:44.213+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:44.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:26:44.237+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:26:44.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:26:44.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-09T13:27:14.487+0000] {processor.py:157} INFO - Started process (PID=4328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:14.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:27:14.506+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:14.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:14.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:14.569+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:14.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:27:14.594+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:14.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:27:14.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-09T13:27:44.842+0000] {processor.py:157} INFO - Started process (PID=4670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:44.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:27:44.857+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:44.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:44.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:27:45.092+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:45.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:27:45.117+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:27:45.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:27:45.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.303 seconds
[2024-08-09T13:28:15.416+0000] {processor.py:157} INFO - Started process (PID=4881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:15.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:28:15.428+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:15.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:15.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:15.470+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:15.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:28:15.483+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:15.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:28:15.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-09T13:28:45.848+0000] {processor.py:157} INFO - Started process (PID=4891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:45.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:28:45.865+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:45.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:45.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:28:45.931+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:45.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:28:45.957+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:28:45.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:28:45.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-09T13:29:16.270+0000] {processor.py:157} INFO - Started process (PID=4901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:16.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:29:16.279+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:16.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:16.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:16.360+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:16.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:29:16.400+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:16.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:29:16.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-09T13:29:46.703+0000] {processor.py:157} INFO - Started process (PID=4911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:46.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:29:46.709+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:46.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:46.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:29:46.769+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:46.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:29:46.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:29:46.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:29:46.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-09T13:30:17.067+0000] {processor.py:157} INFO - Started process (PID=4921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:17.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:30:17.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:17.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:17.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:17.171+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:17.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:30:17.196+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:17.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:30:17.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-09T13:30:47.436+0000] {processor.py:157} INFO - Started process (PID=4931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:47.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:30:47.443+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:47.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:47.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:30:47.480+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:47.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:30:47.493+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:30:47.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:30:47.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T13:31:17.796+0000] {processor.py:157} INFO - Started process (PID=4941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:17.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:31:17.799+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:17.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:17.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:17.850+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:17.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:31:17.861+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:17.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:31:17.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-09T13:31:48.143+0000] {processor.py:157} INFO - Started process (PID=4951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:48.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:31:48.147+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:48.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:48.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:31:48.172+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:48.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:31:48.185+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:31:48.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:31:48.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T13:32:18.463+0000] {processor.py:157} INFO - Started process (PID=4961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:18.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:32:18.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:18.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:18.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:18.497+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:18.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:32:18.507+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:18.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:32:18.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T13:32:48.772+0000] {processor.py:157} INFO - Started process (PID=4971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:48.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:32:48.775+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:48.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:48.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:32:48.801+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:48.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:32:48.818+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:32:48.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:32:48.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T13:33:19.110+0000] {processor.py:157} INFO - Started process (PID=4981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:19.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:33:19.113+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:19.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:19.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:19.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:19.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:33:19.154+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:19.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:33:19.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T13:33:49.463+0000] {processor.py:157} INFO - Started process (PID=4991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:49.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:33:49.469+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:49.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:49.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:33:49.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:49.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:33:49.530+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:33:49.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:33:49.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T13:34:19.795+0000] {processor.py:157} INFO - Started process (PID=5001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:19.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:34:19.797+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:19.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:19.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:19.820+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:19.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:34:19.830+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:19.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:34:19.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-08-09T13:34:50.112+0000] {processor.py:157} INFO - Started process (PID=5011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:50.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:34:50.117+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:50.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:50.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:34:50.148+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:50.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:34:50.162+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:34:50.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:34:50.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T13:35:20.491+0000] {processor.py:157} INFO - Started process (PID=5021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:20.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:35:20.495+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:20.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:20.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:20.524+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:20.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:35:20.536+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:20.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:35:20.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T13:35:50.781+0000] {processor.py:157} INFO - Started process (PID=5031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:50.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:35:50.789+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:50.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:50.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:35:50.915+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:50.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:35:50.935+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:35:50.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:35:50.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-09T13:36:21.221+0000] {processor.py:157} INFO - Started process (PID=5041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:21.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:36:21.228+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:21.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:21.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:21.352+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:21.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:36:21.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:21.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:36:21.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-09T13:36:51.692+0000] {processor.py:157} INFO - Started process (PID=5051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:51.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:36:51.697+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:51.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:51.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:36:51.769+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:51.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:36:51.791+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:36:51.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:36:51.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-09T13:37:22.078+0000] {processor.py:157} INFO - Started process (PID=5061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:22.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:37:22.111+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:22.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:22.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:22.204+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:22.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:37:22.230+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:22.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:37:22.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-09T13:37:52.492+0000] {processor.py:157} INFO - Started process (PID=5071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:52.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:37:52.494+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:52.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:52.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:37:52.527+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:52.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:37:52.564+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:37:52.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:37:52.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-09T13:38:22.852+0000] {processor.py:157} INFO - Started process (PID=5081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:22.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:38:22.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:22.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:22.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:22.895+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:22.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:38:22.914+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:22.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:38:22.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-09T13:38:53.159+0000] {processor.py:157} INFO - Started process (PID=5091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:53.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:38:53.165+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:53.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:53.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:38:53.215+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:53.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:38:53.244+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:38:53.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:38:53.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-09T13:39:23.503+0000] {processor.py:157} INFO - Started process (PID=5101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:23.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:39:23.511+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:23.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:23.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:23.564+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:23.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:39:23.610+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:23.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:39:23.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-09T13:39:53.905+0000] {processor.py:157} INFO - Started process (PID=5111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:53.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:39:53.913+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:53.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:53.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:39:54.002+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:54.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:39:54.042+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:39:54.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:39:54.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-09T13:40:24.314+0000] {processor.py:157} INFO - Started process (PID=5121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:40:24.320+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:24.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:24.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:24.368+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:24.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:40:24.389+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:24.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:40:24.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-09T13:40:54.641+0000] {processor.py:157} INFO - Started process (PID=5131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:54.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:40:54.647+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:54.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:54.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:40:54.691+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:54.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:40:54.707+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:40:54.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:40:54.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T13:41:24.949+0000] {processor.py:157} INFO - Started process (PID=5141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:24.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:41:24.954+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:24.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:24.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:24.996+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:24.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:41:25.017+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:25.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:41:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-09T13:41:55.480+0000] {processor.py:157} INFO - Started process (PID=5151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:55.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:41:55.485+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:55.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:55.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:41:55.539+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:55.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:41:55.559+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:41:55.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:41:55.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-09T13:42:25.890+0000] {processor.py:157} INFO - Started process (PID=5161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:25.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:42:25.893+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:25.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:25.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:25.928+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:25.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:42:25.945+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:25.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:42:25.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T13:42:56.776+0000] {processor.py:157} INFO - Started process (PID=5171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:56.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:42:56.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:56.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:56.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:42:56.860+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:56.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:42:56.884+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:42:56.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:42:56.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-09T13:51:09.200+0000] {processor.py:157} INFO - Started process (PID=5180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:09.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:51:09.203+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:09.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:09.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:09.331+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:09.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:51:09.362+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:09.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:51:09.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-09T13:51:57.361+0000] {processor.py:157} INFO - Started process (PID=5190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:57.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:51:57.367+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:57.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:57.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:51:57.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:57.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:51:57.438+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:51:57.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:51:57.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-09T13:52:27.804+0000] {processor.py:157} INFO - Started process (PID=5201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:52:27.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:52:27.811+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:52:27.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:52:27.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:52:27.879+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:52:27.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:52:27.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:52:27.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:52:27.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-09T13:53:41.274+0000] {processor.py:157} INFO - Started process (PID=5211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:53:41.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:53:41.278+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:53:41.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:53:41.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:53:41.369+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:53:41.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:53:41.391+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:53:41.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:53:41.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-09T13:54:11.611+0000] {processor.py:157} INFO - Started process (PID=5223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:11.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:54:11.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:11.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:11.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:11.672+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:11.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:54:11.694+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:11.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:54:11.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-09T13:54:42.036+0000] {processor.py:157} INFO - Started process (PID=5231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:42.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:54:42.041+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:42.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:42.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:54:42.098+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:42.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:54:42.124+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:54:42.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:54:42.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-09T13:55:12.457+0000] {processor.py:157} INFO - Started process (PID=5242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:12.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:55:12.466+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:12.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:12.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:12.531+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:12.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:55:12.556+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:12.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:55:12.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-09T13:55:42.827+0000] {processor.py:157} INFO - Started process (PID=5252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:42.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:55:42.833+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:42.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:42.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:55:42.891+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:42.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:55:42.919+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:55:42.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:55:42.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-09T13:56:13.183+0000] {processor.py:157} INFO - Started process (PID=5263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:13.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:56:13.188+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:13.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:13.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:13.271+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:13.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:56:13.290+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:13.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:56:13.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-09T13:56:43.694+0000] {processor.py:157} INFO - Started process (PID=5273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:43.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:56:43.701+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:43.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:43.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:56:43.765+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:43.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:56:43.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:56:43.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:56:43.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-09T13:57:14.119+0000] {processor.py:157} INFO - Started process (PID=5283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:14.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:57:14.124+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:14.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:14.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:14.227+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:14.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:57:14.249+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:14.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:57:14.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-09T13:57:44.468+0000] {processor.py:157} INFO - Started process (PID=5293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:44.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:57:44.473+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:44.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:44.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:57:44.532+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:44.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:57:44.549+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:57:44.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:57:44.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-09T13:58:14.870+0000] {processor.py:157} INFO - Started process (PID=5303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:14.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:58:14.875+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:14.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:14.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:14.923+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:14.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:58:14.946+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:14.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:58:14.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-09T13:58:45.169+0000] {processor.py:157} INFO - Started process (PID=5313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:45.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:58:45.176+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:45.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:45.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:58:45.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:45.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:58:45.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:58:45.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:58:45.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-09T13:59:15.600+0000] {processor.py:157} INFO - Started process (PID=5323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:15.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:59:15.625+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:15.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:15.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:15.681+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:15.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:59:15.704+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:15.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:59:15.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-09T13:59:46.057+0000] {processor.py:157} INFO - Started process (PID=5333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:46.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T13:59:46.063+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:46.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:46.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T13:59:46.134+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:46.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T13:59:46.150+0000] {logging_mixin.py:151} INFO - [2024-08-09T13:59:46.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T13:59:46.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-09T14:00:16.349+0000] {processor.py:157} INFO - Started process (PID=5343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:16.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:00:16.357+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:16.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:16.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:16.426+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:16.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:00:16.443+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:16.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:00:16.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-09T14:00:46.838+0000] {processor.py:157} INFO - Started process (PID=5353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:46.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:00:46.843+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:46.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:46.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:00:46.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:46.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:00:46.923+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:00:46.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:00:46.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-09T14:01:17.192+0000] {processor.py:157} INFO - Started process (PID=5363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:17.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:01:17.197+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:17.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:17.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:17.240+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:17.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:01:17.256+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:17.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:01:17.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-09T14:01:47.531+0000] {processor.py:157} INFO - Started process (PID=5373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:47.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:01:47.536+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:47.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:47.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:01:47.578+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:47.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:01:47.593+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:01:47.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:01:47.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-09T14:02:17.959+0000] {processor.py:157} INFO - Started process (PID=5383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:17.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:02:17.965+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:17.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:18.005+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:18.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:02:18.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:18.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:02:18.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-09T14:02:48.367+0000] {processor.py:157} INFO - Started process (PID=5393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:48.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:02:48.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:48.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:48.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:02:48.443+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:48.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:02:48.461+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:02:48.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:02:48.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-09T14:03:18.698+0000] {processor.py:157} INFO - Started process (PID=5403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:18.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:03:18.705+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:18.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:18.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:18.753+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:18.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:03:18.767+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:18.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:03:18.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-09T14:03:49.127+0000] {processor.py:157} INFO - Started process (PID=5413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:49.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:03:49.134+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:49.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:49.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:03:49.192+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:49.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:03:49.210+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:03:49.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:03:49.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-09T14:04:19.451+0000] {processor.py:157} INFO - Started process (PID=5423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:19.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:04:19.458+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:19.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:19.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:19.529+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:19.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:04:19.555+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:19.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:04:19.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-09T14:04:49.865+0000] {processor.py:157} INFO - Started process (PID=5433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:49.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:04:49.870+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:49.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:49.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:04:49.911+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:49.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:04:49.929+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:04:49.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:04:49.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-09T14:05:20.293+0000] {processor.py:157} INFO - Started process (PID=5443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:20.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:05:20.297+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:20.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:20.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:20.355+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:20.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:05:20.367+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:20.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:05:20.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-09T14:05:50.611+0000] {processor.py:157} INFO - Started process (PID=5453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:50.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:05:50.617+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:50.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:50.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:05:50.654+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:50.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:05:50.667+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:05:50.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:05:50.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T14:06:20.982+0000] {processor.py:157} INFO - Started process (PID=5463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:20.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:06:20.987+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:20.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:21.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:21.035+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:21.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:06:21.050+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:21.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:06:21.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T14:06:51.466+0000] {processor.py:157} INFO - Started process (PID=5473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:51.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:06:51.471+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:51.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:51.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:06:51.515+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:51.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:06:51.527+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:06:51.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:06:51.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-09T14:07:21.849+0000] {processor.py:157} INFO - Started process (PID=5483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:21.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:07:21.859+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:21.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:21.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:21.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:21.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:07:21.922+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:21.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:07:21.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-09T14:07:52.292+0000] {processor.py:157} INFO - Started process (PID=5493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:52.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:07:52.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:52.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:52.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:07:52.364+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:52.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:07:52.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:07:52.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:07:52.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-09T14:08:22.716+0000] {processor.py:157} INFO - Started process (PID=5503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:22.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:08:22.722+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:22.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:22.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:22.753+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:22.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:08:22.768+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:22.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:08:22.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T14:08:53.154+0000] {processor.py:157} INFO - Started process (PID=5513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:53.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:08:53.158+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:53.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:53.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:08:53.204+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:53.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:08:53.220+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:08:53.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:08:53.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-09T14:09:23.536+0000] {processor.py:157} INFO - Started process (PID=5523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:23.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:09:23.540+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:23.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:23.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:23.577+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:23.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:09:23.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:23.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:09:23.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T14:09:53.884+0000] {processor.py:157} INFO - Started process (PID=5533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:53.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:09:53.890+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:53.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:53.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:09:53.937+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:53.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:09:53.952+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:09:53.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:09:53.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-09T14:10:24.327+0000] {processor.py:157} INFO - Started process (PID=5543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:24.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:10:24.336+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:24.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:24.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:24.393+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:24.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:10:24.410+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:24.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:10:24.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-09T14:10:54.654+0000] {processor.py:157} INFO - Started process (PID=5553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:54.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:10:54.660+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:54.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:54.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:10:54.702+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:54.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:10:54.718+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:10:54.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:10:54.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-09T14:11:25.023+0000] {processor.py:157} INFO - Started process (PID=5563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:25.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:11:25.030+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:25.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:25.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:25.059+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:25.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:11:25.069+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:25.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:11:25.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T14:11:55.484+0000] {processor.py:157} INFO - Started process (PID=5573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:55.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:11:55.491+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:55.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:55.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:11:55.544+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:55.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:11:55.558+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:11:55.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:11:55.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-09T14:12:25.802+0000] {processor.py:157} INFO - Started process (PID=5583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:25.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:12:25.809+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:25.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:25.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:25.848+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:25.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:12:25.861+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:25.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:12:25.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-09T14:12:56.214+0000] {processor.py:157} INFO - Started process (PID=5593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:56.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:12:56.221+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:56.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:56.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:12:56.267+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:56.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:12:56.281+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:12:56.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:12:56.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-09T14:13:26.558+0000] {processor.py:157} INFO - Started process (PID=5603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:26.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:13:26.565+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:26.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:26.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:26.607+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:26.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:13:26.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:26.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:13:26.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-09T14:13:56.912+0000] {processor.py:157} INFO - Started process (PID=5613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:56.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:13:56.918+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:56.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:56.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:13:56.957+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:56.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:13:56.971+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:13:56.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:13:56.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T14:14:27.279+0000] {processor.py:157} INFO - Started process (PID=5623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:27.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:14:27.282+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:27.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:27.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:27.339+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:27.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:14:27.356+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:27.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:14:27.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-09T14:14:57.587+0000] {processor.py:157} INFO - Started process (PID=5633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:57.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:14:57.592+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:57.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:57.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:14:57.634+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:57.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:14:57.653+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:14:57.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:14:57.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-09T14:15:27.961+0000] {processor.py:157} INFO - Started process (PID=5643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:27.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:15:27.965+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:27.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:27.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:27.995+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:27.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:15:28.010+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:28.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:15:28.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T14:15:58.315+0000] {processor.py:157} INFO - Started process (PID=5653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:58.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:15:58.319+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:58.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:58.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:15:58.384+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:58.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:15:58.396+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:15:58.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:15:58.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-09T14:16:28.679+0000] {processor.py:157} INFO - Started process (PID=5662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:28.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:16:28.686+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:28.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:28.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:28.720+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:28.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:16:28.734+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:28.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:16:28.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T14:16:58.990+0000] {processor.py:157} INFO - Started process (PID=5673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:58.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:16:58.996+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:58.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:59.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:16:59.071+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:59.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:16:59.086+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:16:59.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:16:59.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-09T14:17:29.325+0000] {processor.py:157} INFO - Started process (PID=5683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:29.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:17:29.341+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:29.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:29.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:29.389+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:29.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:17:29.406+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:29.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:17:29.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-09T14:17:59.727+0000] {processor.py:157} INFO - Started process (PID=5692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:59.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:17:59.733+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:59.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:59.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:17:59.780+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:59.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:17:59.799+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:17:59.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:17:59.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-09T14:18:30.279+0000] {processor.py:157} INFO - Started process (PID=5703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:18:30.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:18:30.285+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:18:30.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:18:30.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:18:30.432+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:18:30.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:18:30.460+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:18:30.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:18:30.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-08-09T14:19:00.661+0000] {processor.py:157} INFO - Started process (PID=5713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:00.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:19:00.669+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:00.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:00.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:00.738+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:00.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:19:00.756+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:00.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:19:00.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-09T14:19:31.101+0000] {processor.py:157} INFO - Started process (PID=5723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:31.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:19:31.108+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:31.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:31.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:19:31.179+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:31.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:19:31.198+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:19:31.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:19:31.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-09T14:20:01.438+0000] {processor.py:157} INFO - Started process (PID=5733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:01.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:20:01.446+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:01.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:01.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:01.469+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:01.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:20:01.479+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:01.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:20:01.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T14:20:31.849+0000] {processor.py:157} INFO - Started process (PID=5743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:31.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:20:31.856+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:31.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:31.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:20:31.914+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:31.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:20:31.937+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:20:31.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:20:31.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-09T14:21:02.327+0000] {processor.py:157} INFO - Started process (PID=5753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:02.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:21:02.330+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:02.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:02.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:02.357+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:02.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:21:02.375+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:02.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:21:02.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T14:21:32.706+0000] {processor.py:157} INFO - Started process (PID=5763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:32.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:21:32.711+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:32.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:32.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:21:32.754+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:32.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:21:32.767+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:21:32.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:21:32.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-09T14:22:03.071+0000] {processor.py:157} INFO - Started process (PID=5773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:03.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:22:03.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:03.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:03.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:03.128+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:03.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:22:03.148+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:03.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:22:03.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-09T14:22:33.429+0000] {processor.py:157} INFO - Started process (PID=5783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:33.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:22:33.434+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:33.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:33.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:22:33.461+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:33.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:22:33.472+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:22:33.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:22:33.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T14:23:03.856+0000] {processor.py:157} INFO - Started process (PID=5793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:03.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:23:03.862+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:03.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:03.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:03.910+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:03.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:23:03.923+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:03.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:23:03.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-09T14:23:34.164+0000] {processor.py:157} INFO - Started process (PID=5803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:34.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:23:34.168+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:34.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:34.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:23:34.198+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:34.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:23:34.211+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:23:34.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:23:34.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T14:24:04.559+0000] {processor.py:157} INFO - Started process (PID=5813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:04.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:24:04.572+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:04.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:04.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:04.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:04.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:24:04.648+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:04.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:24:04.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-09T14:24:34.901+0000] {processor.py:157} INFO - Started process (PID=5823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:34.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:24:34.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:34.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:34.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:24:34.964+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:34.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:24:34.980+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:24:34.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:24:34.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-09T14:25:05.243+0000] {processor.py:157} INFO - Started process (PID=5833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:05.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:25:05.254+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:05.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:05.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:05.326+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:05.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:25:05.343+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:05.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:25:05.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-09T14:25:35.583+0000] {processor.py:157} INFO - Started process (PID=5843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:35.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:25:35.585+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:35.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:25:35.612+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:35.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:25:35.622+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:25:35.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:25:35.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T14:26:06.012+0000] {processor.py:157} INFO - Started process (PID=5853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:06.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:26:06.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:06.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:06.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:06.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:06.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:26:06.098+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:06.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:26:06.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-09T14:26:36.321+0000] {processor.py:157} INFO - Started process (PID=5863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:36.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:26:36.324+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:36.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:36.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:26:36.357+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:36.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:26:36.386+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:26:36.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:26:36.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-09T14:27:06.696+0000] {processor.py:157} INFO - Started process (PID=5873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:06.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:27:06.702+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:06.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:06.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:06.769+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:06.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:27:06.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:06.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:27:06.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-09T14:27:37.162+0000] {processor.py:157} INFO - Started process (PID=5883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:37.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:27:37.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:37.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:37.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:27:37.201+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:37.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:27:37.211+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:27:37.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:27:37.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T14:28:07.528+0000] {processor.py:157} INFO - Started process (PID=5893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:07.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:28:07.533+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:07.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:07.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:07.584+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:07.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:28:07.609+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:07.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:28:07.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-09T14:28:37.868+0000] {processor.py:157} INFO - Started process (PID=5903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:37.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:28:37.875+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:37.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:37.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:28:37.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:37.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:28:37.930+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:28:37.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:28:37.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-09T14:29:08.343+0000] {processor.py:157} INFO - Started process (PID=5913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:08.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:29:08.347+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:08.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:08.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:08.389+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:08.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:29:08.403+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:08.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:29:08.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-09T14:29:38.657+0000] {processor.py:157} INFO - Started process (PID=5923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:38.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:29:38.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:38.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:38.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:29:38.711+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:38.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:29:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:29:38.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:29:38.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-09T14:30:08.995+0000] {processor.py:157} INFO - Started process (PID=5933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:08.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:30:09.002+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:09.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:09.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:09.049+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:09.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:30:09.068+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:09.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:30:09.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-09T14:30:39.318+0000] {processor.py:157} INFO - Started process (PID=5943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:39.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:30:39.325+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:39.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:39.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:30:39.367+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:39.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:30:39.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:30:39.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:30:39.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-09T14:31:09.714+0000] {processor.py:157} INFO - Started process (PID=5953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:09.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:31:09.719+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:09.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:09.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:09.764+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:09.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:31:09.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:09.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:31:09.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-09T14:31:40.146+0000] {processor.py:157} INFO - Started process (PID=5963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:40.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:31:40.152+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:40.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:40.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:31:40.190+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:40.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:31:40.207+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:31:40.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:31:40.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T14:32:10.544+0000] {processor.py:157} INFO - Started process (PID=5973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:10.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:32:10.548+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:10.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:10.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:10.580+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:10.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:32:10.593+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:10.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:32:10.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T14:32:41.005+0000] {processor.py:157} INFO - Started process (PID=5983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:41.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:32:41.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:41.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:41.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:32:41.127+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:41.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:32:41.149+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:32:41.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:32:41.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-09T14:33:11.381+0000] {processor.py:157} INFO - Started process (PID=5993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:11.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:33:11.407+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:11.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:11.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:11.590+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:11.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:33:11.619+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:11.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:33:11.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.272 seconds
[2024-08-09T14:33:41.720+0000] {processor.py:157} INFO - Started process (PID=6003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:41.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:33:41.725+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:41.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:41.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:33:41.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:41.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:33:41.801+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:33:41.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:33:41.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-09T14:34:12.182+0000] {processor.py:157} INFO - Started process (PID=6013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:12.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:34:12.190+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:12.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:12.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:12.254+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:12.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:34:12.273+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:12.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:34:12.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-09T14:34:42.634+0000] {processor.py:157} INFO - Started process (PID=6023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:42.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:34:42.642+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:42.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:42.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:34:42.726+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:42.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:34:42.744+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:34:42.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:34:42.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-09T14:35:13.110+0000] {processor.py:157} INFO - Started process (PID=6033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:13.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:35:13.121+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:13.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:13.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:13.189+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:13.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:35:13.207+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:13.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:35:13.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-09T14:35:43.444+0000] {processor.py:157} INFO - Started process (PID=6043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:43.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:35:43.450+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:43.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:43.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:35:43.509+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:43.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:35:43.526+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:35:43.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:35:43.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-09T14:36:13.850+0000] {processor.py:157} INFO - Started process (PID=6053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:13.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:36:13.856+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:13.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:13.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:14.019+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:14.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:36:14.039+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:14.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:36:14.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-08-09T14:36:44.184+0000] {processor.py:157} INFO - Started process (PID=6063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:44.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:36:44.202+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:44.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:44.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:36:44.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:44.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:36:44.323+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:36:44.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:36:44.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-09T14:37:15.041+0000] {processor.py:157} INFO - Started process (PID=6073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:15.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:37:15.051+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:15.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:15.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:15.168+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:15.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:37:15.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:15.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:37:15.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-09T14:37:45.416+0000] {processor.py:157} INFO - Started process (PID=6083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:45.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:37:45.425+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:45.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:45.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:37:45.525+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:45.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:37:45.544+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:37:45.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:37:45.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-09T14:38:15.815+0000] {processor.py:157} INFO - Started process (PID=6093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:15.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:38:15.821+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:15.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:15.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:15.900+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:15.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:38:15.921+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:15.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:38:15.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-09T14:38:46.269+0000] {processor.py:157} INFO - Started process (PID=6103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:46.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:38:46.272+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:46.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:46.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:38:46.300+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:46.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:38:46.311+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:38:46.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:38:46.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T14:39:16.746+0000] {processor.py:157} INFO - Started process (PID=6113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:16.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:39:16.755+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:16.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:16.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:16.865+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:16.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:39:16.894+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:16.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:39:16.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-09T14:39:46.982+0000] {processor.py:157} INFO - Started process (PID=6123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:46.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:39:46.983+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:46.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:46.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:39:47.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:47.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:39:47.025+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:39:47.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:39:47.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T14:40:17.730+0000] {processor.py:157} INFO - Started process (PID=6133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:17.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:40:17.735+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:17.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:17.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:17.786+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:17.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:40:17.798+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:17.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:40:17.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-09T14:40:48.094+0000] {processor.py:157} INFO - Started process (PID=6143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:48.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:40:48.096+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:48.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:48.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:40:48.127+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:48.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:40:48.139+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:40:48.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:40:48.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T14:41:18.473+0000] {processor.py:157} INFO - Started process (PID=6153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:18.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:41:18.478+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:18.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:18.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:18.519+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:18.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:41:18.533+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:18.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:41:18.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T14:41:48.846+0000] {processor.py:157} INFO - Started process (PID=6163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:48.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:41:48.850+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:48.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:48.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:41:48.879+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:48.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:41:48.893+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:41:48.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:41:48.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T14:42:19.214+0000] {processor.py:157} INFO - Started process (PID=6173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:19.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:42:19.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:19.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:19.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:19.244+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:19.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:42:19.254+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:19.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:42:19.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T14:42:49.497+0000] {processor.py:157} INFO - Started process (PID=6183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:49.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:42:49.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:49.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:49.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:42:49.545+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:49.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:42:49.558+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:42:49.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:42:49.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T14:43:19.922+0000] {processor.py:157} INFO - Started process (PID=6193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:19.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:43:19.926+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:19.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:19.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:19.965+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:19.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:43:19.977+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:19.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:43:19.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T14:43:50.243+0000] {processor.py:157} INFO - Started process (PID=6203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:50.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:43:50.247+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:50.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:50.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:43:50.287+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:50.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:43:50.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:43:50.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:43:50.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-09T14:44:20.582+0000] {processor.py:157} INFO - Started process (PID=6213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:20.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:44:20.588+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:20.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:20.641+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:20.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:44:20.656+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:20.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:44:20.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-09T14:44:50.976+0000] {processor.py:157} INFO - Started process (PID=6223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:50.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:44:50.981+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:50.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:51.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:44:51.049+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:51.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:44:51.072+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:44:51.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:44:51.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-09T14:45:21.287+0000] {processor.py:157} INFO - Started process (PID=6233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:21.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:45:21.293+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:21.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:21.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:21.355+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:21.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:45:21.379+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:21.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:45:21.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-09T14:45:51.621+0000] {processor.py:157} INFO - Started process (PID=6242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:51.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:45:51.627+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:51.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:51.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:45:51.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:51.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:45:51.709+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:45:51.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:45:51.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-09T14:46:21.943+0000] {processor.py:157} INFO - Started process (PID=6253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:21.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:46:21.947+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:21.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:21.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:22.002+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:22.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:46:22.019+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:22.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:46:22.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-09T14:46:55.775+0000] {processor.py:157} INFO - Started process (PID=6263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:55.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:46:55.781+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:55.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:55.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:46:55.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:55.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:46:55.924+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:46:55.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:46:55.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-09T14:47:26.114+0000] {processor.py:157} INFO - Started process (PID=6272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:26.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:47:26.120+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:26.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:26.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:26.192+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:26.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:47:26.207+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:26.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:47:26.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-09T14:47:56.399+0000] {processor.py:157} INFO - Started process (PID=6284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:56.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:47:56.405+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:56.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:56.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:47:56.470+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:56.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:47:56.513+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:47:56.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:47:56.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-09T14:48:26.705+0000] {processor.py:157} INFO - Started process (PID=6294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:26.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:48:26.711+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:26.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:26.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:26.747+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:26.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:48:26.772+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:26.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:48:26.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T14:48:57.022+0000] {processor.py:157} INFO - Started process (PID=6304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:57.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:48:57.025+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:57.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:57.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:48:57.056+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:57.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:48:57.068+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:48:57.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:48:57.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T14:49:27.441+0000] {processor.py:157} INFO - Started process (PID=6314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:27.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:49:27.448+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:27.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:27.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:27.485+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:27.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:49:27.496+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:27.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:49:27.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T14:49:57.772+0000] {processor.py:157} INFO - Started process (PID=6324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:57.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:49:57.781+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:57.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:57.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:49:57.802+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:57.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:49:57.811+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:49:57.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:49:57.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T14:50:28.092+0000] {processor.py:157} INFO - Started process (PID=6334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:28.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:50:28.094+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:28.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:28.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:28.127+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:28.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:50:28.140+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:28.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:50:28.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T14:50:58.414+0000] {processor.py:157} INFO - Started process (PID=6344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:58.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:50:58.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:58.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:58.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:50:58.456+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:58.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:50:58.471+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:50:58.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:50:58.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T14:51:28.791+0000] {processor.py:157} INFO - Started process (PID=6354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:28.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:51:28.794+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:28.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:28.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:28.827+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:28.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:51:28.839+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:28.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:51:28.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T14:51:59.196+0000] {processor.py:157} INFO - Started process (PID=6364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:59.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:51:59.200+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:59.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:59.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:51:59.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:59.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:51:59.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:51:59.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:51:59.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T14:52:29.751+0000] {processor.py:157} INFO - Started process (PID=6374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:52:29.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:52:29.757+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:52:29.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:52:29.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:52:29.822+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:52:29.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:52:29.835+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:52:29.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:52:29.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-09T14:53:00.193+0000] {processor.py:157} INFO - Started process (PID=6384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:00.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:53:00.197+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:00.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:00.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:00.256+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:00.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:53:00.268+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:00.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:53:00.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-09T14:53:30.627+0000] {processor.py:157} INFO - Started process (PID=6394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:30.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:53:30.629+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:30.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:30.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:53:30.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:30.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:53:30.674+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:53:30.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:53:30.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T14:54:00.970+0000] {processor.py:157} INFO - Started process (PID=6404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:00.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:54:00.977+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:00.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:00.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:01.001+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:01.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:54:01.011+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:01.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:54:01.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T14:54:31.310+0000] {processor.py:157} INFO - Started process (PID=6414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:31.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:54:31.312+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:31.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:31.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:54:31.340+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:31.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:54:31.350+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:54:31.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:54:31.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T14:55:01.598+0000] {processor.py:157} INFO - Started process (PID=6424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:01.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:55:01.601+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:01.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:01.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:01.627+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:01.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:55:01.637+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:01.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:55:01.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T14:55:31.934+0000] {processor.py:157} INFO - Started process (PID=6434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:31.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:55:31.940+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:31.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:31.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:55:31.967+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:31.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:55:31.977+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:55:31.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:55:31.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T14:56:02.296+0000] {processor.py:157} INFO - Started process (PID=6444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:02.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:56:02.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:02.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:02.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:02.340+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:02.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:56:02.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:02.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:56:02.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T14:56:32.638+0000] {processor.py:157} INFO - Started process (PID=6454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:32.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:56:32.641+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:32.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:32.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:56:32.668+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:32.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:56:32.682+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:56:32.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:56:32.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T14:57:02.967+0000] {processor.py:157} INFO - Started process (PID=6464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:02.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:57:02.971+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:02.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:02.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:02.996+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:02.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:57:03.005+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:03.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:57:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T14:57:33.359+0000] {processor.py:157} INFO - Started process (PID=6474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:33.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:57:33.365+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:33.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:33.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:57:33.407+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:33.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:57:33.418+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:57:33.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:57:33.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T14:58:03.620+0000] {processor.py:157} INFO - Started process (PID=6484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:03.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:58:03.622+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:03.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:03.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:03.649+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:03.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:58:03.660+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:03.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:58:03.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T14:58:34.021+0000] {processor.py:157} INFO - Started process (PID=6494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:34.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:58:34.026+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:34.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:34.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:58:34.051+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:34.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:58:34.061+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:58:34.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:58:34.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T14:59:04.367+0000] {processor.py:157} INFO - Started process (PID=6504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:04.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:59:04.370+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:04.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:04.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:04.394+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:04.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:59:04.406+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:04.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:59:04.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T14:59:34.783+0000] {processor.py:157} INFO - Started process (PID=6514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:34.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T14:59:34.787+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:34.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:34.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T14:59:34.813+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:34.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T14:59:34.823+0000] {logging_mixin.py:151} INFO - [2024-08-09T14:59:34.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T14:59:34.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T15:00:05.210+0000] {processor.py:157} INFO - Started process (PID=6524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:05.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:00:05.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:05.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:05.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:05.256+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:05.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:00:05.268+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:05.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:00:05.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T15:00:35.578+0000] {processor.py:157} INFO - Started process (PID=6534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:35.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:00:35.581+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:35.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:35.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:00:35.611+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:35.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:00:35.623+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:00:35.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:00:35.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:01:05.979+0000] {processor.py:157} INFO - Started process (PID=6544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:05.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:01:05.982+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:05.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:05.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:06.013+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:06.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:01:06.022+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:06.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:01:06.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:01:36.289+0000] {processor.py:157} INFO - Started process (PID=6554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:36.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:01:36.292+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:36.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:36.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:01:36.324+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:36.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:01:36.335+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:01:36.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:01:36.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T15:02:06.627+0000] {processor.py:157} INFO - Started process (PID=6564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:06.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:02:06.630+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:06.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:06.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:06.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:06.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:02:06.667+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:06.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:02:06.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T15:02:37.129+0000] {processor.py:157} INFO - Started process (PID=6574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:37.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:02:37.136+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:37.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:37.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:02:37.169+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:37.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:02:37.180+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:02:37.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:02:37.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:03:07.452+0000] {processor.py:157} INFO - Started process (PID=6584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:07.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:03:07.456+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:07.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:07.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:07.489+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:07.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:03:07.500+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:07.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:03:07.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T15:03:37.800+0000] {processor.py:157} INFO - Started process (PID=6594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:37.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:03:37.803+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:37.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:37.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:03:37.832+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:37.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:03:37.843+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:03:37.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:03:37.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T15:04:08.249+0000] {processor.py:157} INFO - Started process (PID=6604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:08.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:04:08.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:08.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:08.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:08.281+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:08.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:04:08.293+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:08.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:04:08.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:04:38.635+0000] {processor.py:157} INFO - Started process (PID=6614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:38.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:04:38.639+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:38.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:38.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:04:38.666+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:38.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:04:38.679+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:04:38.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:04:38.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:05:09.078+0000] {processor.py:157} INFO - Started process (PID=6624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:09.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:05:09.082+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:09.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:09.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:09.109+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:09.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:05:09.121+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:09.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:05:09.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T15:05:39.472+0000] {processor.py:157} INFO - Started process (PID=6634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:39.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:05:39.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:39.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:39.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:05:39.505+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:39.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:05:39.514+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:05:39.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:05:39.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:06:09.804+0000] {processor.py:157} INFO - Started process (PID=6644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:09.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:06:09.807+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:09.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:09.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:09.837+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:09.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:06:09.850+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:09.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:06:09.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T15:06:40.179+0000] {processor.py:157} INFO - Started process (PID=6654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:40.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:06:40.186+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:40.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:40.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:06:40.225+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:40.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:06:40.237+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:06:40.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:06:40.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T15:07:10.539+0000] {processor.py:157} INFO - Started process (PID=6664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:10.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:07:10.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:10.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:10.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:10.568+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:10.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:07:10.577+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:10.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:07:10.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T15:07:40.878+0000] {processor.py:157} INFO - Started process (PID=6674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:40.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:07:40.880+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:40.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:40.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:07:40.907+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:40.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:07:40.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:07:40.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:07:40.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T15:08:11.270+0000] {processor.py:157} INFO - Started process (PID=6684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:11.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:08:11.273+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:11.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:11.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:11.296+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:11.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:08:11.307+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:11.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:08:11.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T15:08:41.670+0000] {processor.py:157} INFO - Started process (PID=6694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:41.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:08:41.676+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:41.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:41.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:08:41.719+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:41.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:08:41.733+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:08:41.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:08:41.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T15:09:12.044+0000] {processor.py:157} INFO - Started process (PID=6704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:12.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:09:12.049+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:12.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:12.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:12.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:12.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:09:12.088+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:12.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:09:12.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:09:42.346+0000] {processor.py:157} INFO - Started process (PID=6714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:42.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:09:42.350+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:42.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:42.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:09:42.376+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:42.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:09:42.386+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:09:42.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:09:42.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T15:10:12.737+0000] {processor.py:157} INFO - Started process (PID=6724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:12.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:10:12.741+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:12.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:12.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:12.780+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:12.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:10:12.794+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:12.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:10:12.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T15:10:43.293+0000] {processor.py:157} INFO - Started process (PID=6734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:43.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:10:43.298+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:43.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:43.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:10:43.338+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:43.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:10:43.352+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:10:43.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:10:43.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T15:11:13.703+0000] {processor.py:157} INFO - Started process (PID=6744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:13.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:11:13.706+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:13.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:13.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:13.907+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:13.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:11:13.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:13.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:11:13.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-08-09T15:11:44.268+0000] {processor.py:157} INFO - Started process (PID=6754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:44.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:11:44.271+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:44.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:44.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:11:44.312+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:44.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:11:44.322+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:11:44.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:11:44.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:12:14.653+0000] {processor.py:157} INFO - Started process (PID=6764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:14.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:12:14.655+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:14.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:14.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:14.697+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:14.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:12:14.708+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:14.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:12:14.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:12:45.079+0000] {processor.py:157} INFO - Started process (PID=6774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:45.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:12:45.083+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:45.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:45.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:12:45.116+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:45.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:12:45.126+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:12:45.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:12:45.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T15:13:15.462+0000] {processor.py:157} INFO - Started process (PID=6784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:15.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:13:15.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:15.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:15.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:15.511+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:15.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:13:15.522+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:15.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:13:15.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-09T15:13:45.914+0000] {processor.py:157} INFO - Started process (PID=6794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:45.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:13:45.917+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:45.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:45.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:13:45.952+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:45.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:13:45.962+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:13:45.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:13:45.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T15:14:16.283+0000] {processor.py:157} INFO - Started process (PID=6804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:16.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:14:16.286+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:16.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:16.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:16.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:16.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:14:16.328+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:16.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:14:16.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:14:46.639+0000] {processor.py:157} INFO - Started process (PID=6814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:46.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:14:46.642+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:46.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:46.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:14:46.673+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:46.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:14:46.682+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:14:46.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:14:46.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:15:17.004+0000] {processor.py:157} INFO - Started process (PID=6824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:17.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:15:17.007+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:17.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:17.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:17.038+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:17.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:15:17.048+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:17.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:15:17.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:15:47.454+0000] {processor.py:157} INFO - Started process (PID=6833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:47.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:15:47.462+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:47.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:47.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:15:47.525+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:47.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:15:47.538+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:15:47.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:15:47.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-09T15:16:17.750+0000] {processor.py:157} INFO - Started process (PID=6844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:17.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:16:17.753+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:17.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:17.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:17.783+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:17.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:16:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:17.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:16:17.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:16:48.113+0000] {processor.py:157} INFO - Started process (PID=6854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:48.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:16:48.116+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:48.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:48.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:16:48.146+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:48.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:16:48.157+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:16:48.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:16:48.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T15:17:18.418+0000] {processor.py:157} INFO - Started process (PID=6864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:18.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:17:18.421+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:18.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:18.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:18.456+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:18.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:17:18.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:18.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:17:18.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:17:48.740+0000] {processor.py:157} INFO - Started process (PID=6874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:48.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:17:48.745+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:48.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:48.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:17:48.791+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:48.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:17:48.803+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:17:48.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:17:48.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T15:18:19.180+0000] {processor.py:157} INFO - Started process (PID=6883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:19.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:18:19.195+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:19.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:19.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:19.277+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:19.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:18:19.287+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:19.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:18:19.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-09T15:18:49.620+0000] {processor.py:157} INFO - Started process (PID=6894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:49.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:18:49.628+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:49.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:49.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:18:49.650+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:49.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:18:49.660+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:18:49.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:18:49.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:19:19.955+0000] {processor.py:157} INFO - Started process (PID=6904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:19.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:19:19.959+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:19.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:19.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:19.988+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:19.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:19:20.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:20.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:19:20.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T15:19:50.318+0000] {processor.py:157} INFO - Started process (PID=6914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:50.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:19:50.322+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:50.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:50.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:19:50.348+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:50.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:19:50.363+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:19:50.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:19:50.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T15:20:20.677+0000] {processor.py:157} INFO - Started process (PID=6924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:20.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:20:20.680+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:20.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:20.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:20.706+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:20.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:20:20.715+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:20.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:20:20.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T15:20:51.033+0000] {processor.py:157} INFO - Started process (PID=6934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:51.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:20:51.035+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:51.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:51.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:20:51.068+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:51.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:20:51.076+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:20:51.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:20:51.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:21:21.377+0000] {processor.py:157} INFO - Started process (PID=6944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:21.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:21:21.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:21.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:21.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:21.408+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:21.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:21:21.420+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:21.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:21:21.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:21:51.819+0000] {processor.py:157} INFO - Started process (PID=6954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:51.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:21:51.823+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:51.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:51.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:21:51.854+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:51.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:21:51.864+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:21:51.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:21:51.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:22:22.218+0000] {processor.py:157} INFO - Started process (PID=6964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:22.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:22:22.229+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:22.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:22.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:22.255+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:22.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:22:22.264+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:22.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:22:22.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T15:22:52.542+0000] {processor.py:157} INFO - Started process (PID=6974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:52.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:22:52.547+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:52.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:52.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:22:52.643+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:52.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:22:52.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:22:52.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:22:52.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-09T15:23:22.849+0000] {processor.py:157} INFO - Started process (PID=6984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:22.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:23:22.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:22.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:22.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:22.885+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:22.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:23:22.895+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:22.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:23:22.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:23:53.116+0000] {processor.py:157} INFO - Started process (PID=6994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:53.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:23:53.119+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:53.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:53.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:23:53.148+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:53.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:23:53.158+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:23:53.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:23:53.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:24:23.573+0000] {processor.py:157} INFO - Started process (PID=7004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:23.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:24:23.576+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:23.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:23.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:23.602+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:23.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:24:23.613+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:23.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:24:23.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T15:24:53.973+0000] {processor.py:157} INFO - Started process (PID=7014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:53.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:24:53.976+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:53.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:53.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:24:54.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:54.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:24:54.010+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:24:54.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:24:54.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T15:25:24.395+0000] {processor.py:157} INFO - Started process (PID=7024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:24.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:25:24.399+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:24.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:24.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:24.426+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:24.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:25:24.436+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:24.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:25:24.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T15:25:54.834+0000] {processor.py:157} INFO - Started process (PID=7034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:54.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:25:54.839+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:54.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:54.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:25:54.868+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:54.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:25:54.881+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:25:54.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:25:54.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:26:25.184+0000] {processor.py:157} INFO - Started process (PID=7044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:25.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:26:25.192+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:25.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:25.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:25.214+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:25.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:26:25.224+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:25.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:26:25.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T15:26:55.567+0000] {processor.py:157} INFO - Started process (PID=7054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:55.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:26:55.572+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:55.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:55.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:26:55.607+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:55.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:26:55.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:26:55.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:26:55.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:27:25.936+0000] {processor.py:157} INFO - Started process (PID=7064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:25.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:27:25.940+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:25.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:25.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:25.969+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:25.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:27:25.979+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:25.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:27:25.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T15:27:56.273+0000] {processor.py:157} INFO - Started process (PID=7074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:27:56.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:56.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:56.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:27:56.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:56.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:27:56.327+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:27:56.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:27:56.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T15:28:26.551+0000] {processor.py:157} INFO - Started process (PID=7084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:26.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:28:26.554+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:26.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:26.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:26.579+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:26.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:28:26.588+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:26.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:28:26.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T15:28:56.868+0000] {processor.py:157} INFO - Started process (PID=7094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:56.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:28:56.870+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:56.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:56.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:28:56.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:56.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:28:56.910+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:28:56.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:28:56.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:29:27.206+0000] {processor.py:157} INFO - Started process (PID=7104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:27.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:29:27.210+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:27.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:27.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:27.241+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:27.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:29:27.249+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:27.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:29:27.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:29:57.681+0000] {processor.py:157} INFO - Started process (PID=7114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:57.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:29:57.684+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:57.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:57.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:29:57.712+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:57.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:29:57.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:29:57.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:29:57.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:30:28.108+0000] {processor.py:157} INFO - Started process (PID=7124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:28.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:30:28.112+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:28.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:28.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:28.140+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:28.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:30:28.151+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:28.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:30:28.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T15:30:58.569+0000] {processor.py:157} INFO - Started process (PID=7134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:58.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:30:58.575+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:58.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:58.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:30:58.608+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:58.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:30:58.619+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:30:58.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:30:58.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:31:28.883+0000] {processor.py:157} INFO - Started process (PID=7144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:28.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:31:28.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:28.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:28.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:28.915+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:28.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:31:28.925+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:28.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:31:28.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T15:31:59.296+0000] {processor.py:157} INFO - Started process (PID=7154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:59.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:31:59.299+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:59.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:59.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:31:59.328+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:59.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:31:59.341+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:31:59.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:31:59.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:32:29.653+0000] {processor.py:157} INFO - Started process (PID=7164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:32:29.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:32:29.656+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:32:29.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:32:29.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:32:29.688+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:32:29.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:32:29.699+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:32:29.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:32:29.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:33:00.129+0000] {processor.py:157} INFO - Started process (PID=7174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:00.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:33:00.135+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:00.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:00.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:00.182+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:00.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:33:00.193+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:00.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:33:00.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-09T15:33:30.427+0000] {processor.py:157} INFO - Started process (PID=7184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:30.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:33:30.436+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:30.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:30.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:33:30.461+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:30.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:33:30.473+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:33:30.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:33:30.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:34:00.855+0000] {processor.py:157} INFO - Started process (PID=7194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:00.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:34:00.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:00.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:00.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:00.886+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:00.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:34:00.895+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:00.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:34:00.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T15:34:31.275+0000] {processor.py:157} INFO - Started process (PID=7204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:31.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:34:31.279+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:31.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:31.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:34:31.305+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:31.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:34:31.316+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:34:31.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:34:31.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T15:35:01.644+0000] {processor.py:157} INFO - Started process (PID=7214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:01.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:35:01.646+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:01.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:01.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:01.676+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:01.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:35:01.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:01.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:35:01.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:35:32.044+0000] {processor.py:157} INFO - Started process (PID=7224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:32.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:35:32.047+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:32.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:32.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:35:32.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:32.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:35:32.088+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:35:32.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:35:32.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T15:36:02.463+0000] {processor.py:157} INFO - Started process (PID=7234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:02.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:36:02.468+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:02.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:02.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:02.499+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:02.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:36:02.510+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:02.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:36:02.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:36:32.869+0000] {processor.py:157} INFO - Started process (PID=7244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:32.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:36:32.874+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:32.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:32.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:36:32.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:32.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:36:32.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:36:32.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:36:32.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T15:37:03.198+0000] {processor.py:157} INFO - Started process (PID=7254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:03.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:37:03.202+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:03.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:03.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:03.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:03.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:37:03.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:03.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:37:03.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T15:37:33.572+0000] {processor.py:157} INFO - Started process (PID=7264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:33.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:37:33.575+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:33.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:33.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:37:33.602+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:33.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:37:33.614+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:37:33.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:37:33.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:38:26.817+0000] {processor.py:157} INFO - Started process (PID=7276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:26.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:38:26.825+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:26.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:26.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:26.871+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:26.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:38:26.885+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:26.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:38:26.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-09T15:38:57.126+0000] {processor.py:157} INFO - Started process (PID=7286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:57.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:38:57.130+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:57.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:57.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:38:57.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:57.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:38:57.176+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:38:57.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:38:57.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:54:28.469+0000] {processor.py:157} INFO - Started process (PID=7296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:28.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:54:28.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:28.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:28.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:28.640+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:28.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:54:28.711+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:28.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:54:28.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-08-09T15:54:58.822+0000] {processor.py:157} INFO - Started process (PID=7305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:58.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:54:58.845+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:58.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:58.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:54:58.923+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:58.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:54:58.937+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:54:58.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:54:58.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-09T15:55:29.126+0000] {processor.py:157} INFO - Started process (PID=7316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:29.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:55:29.129+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:29.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:29.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:29.161+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:29.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:55:29.174+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:29.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:55:29.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T15:55:59.504+0000] {processor.py:157} INFO - Started process (PID=7325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:59.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:55:59.511+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:59.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:59.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:55:59.569+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:59.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:55:59.582+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:55:59.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:55:59.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-09T15:56:29.910+0000] {processor.py:157} INFO - Started process (PID=7336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:56:29.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:56:29.913+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:56:29.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:56:29.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:56:29.940+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:56:29.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:56:29.950+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:56:29.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:56:29.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T15:57:00.285+0000] {processor.py:157} INFO - Started process (PID=7346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:00.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:57:00.291+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:00.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:00.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:00.330+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:00.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:57:00.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:00.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:57:00.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T15:57:30.653+0000] {processor.py:157} INFO - Started process (PID=7356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:30.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:57:30.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:30.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:30.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:57:30.686+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:30.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:57:30.697+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:57:30.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:57:30.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:58:00.933+0000] {processor.py:157} INFO - Started process (PID=7366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:00.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:58:00.936+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:00.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:00.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:00.964+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:00.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:58:00.975+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:00.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:58:00.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:58:34.005+0000] {processor.py:157} INFO - Started process (PID=7376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:34.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:58:34.009+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:34.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:34.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:58:34.047+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:34.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:58:34.059+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:58:34.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:58:34.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T15:59:04.314+0000] {processor.py:157} INFO - Started process (PID=7386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:04.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:59:04.318+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:04.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:04.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:04.346+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:04.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:59:04.356+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:04.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:59:04.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T15:59:34.734+0000] {processor.py:157} INFO - Started process (PID=7396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:34.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T15:59:34.737+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:34.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:34.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T15:59:34.767+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:34.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T15:59:34.777+0000] {logging_mixin.py:151} INFO - [2024-08-09T15:59:34.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T15:59:34.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:00:05.145+0000] {processor.py:157} INFO - Started process (PID=7406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:05.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:00:05.150+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:05.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:05.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:05.189+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:05.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:00:05.203+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:05.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:00:05.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T16:00:35.514+0000] {processor.py:157} INFO - Started process (PID=7416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:35.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:00:35.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:35.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:00:35.541+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:35.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:00:35.550+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:00:35.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:00:35.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T16:01:05.872+0000] {processor.py:157} INFO - Started process (PID=7426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:05.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:01:05.874+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:05.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:05.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:05.902+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:05.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:01:05.913+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:05.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:01:05.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:01:36.299+0000] {processor.py:157} INFO - Started process (PID=7436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:36.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:01:36.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:36.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:36.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:01:36.329+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:36.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:01:36.340+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:01:36.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:01:36.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:02:06.633+0000] {processor.py:157} INFO - Started process (PID=7446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:06.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:02:06.635+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:06.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:06.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:06.663+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:06.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:02:06.675+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:06.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:02:06.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:02:36.971+0000] {processor.py:157} INFO - Started process (PID=7456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:36.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:02:36.973+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:36.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:36.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:02:37.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:37.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:02:37.011+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:02:37.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:02:37.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:03:07.331+0000] {processor.py:157} INFO - Started process (PID=7466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:07.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:03:07.333+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:07.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:07.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:07.361+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:07.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:03:07.372+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:07.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:03:07.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:03:37.661+0000] {processor.py:157} INFO - Started process (PID=7476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:37.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:03:37.664+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:37.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:37.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:03:37.697+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:37.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:03:37.710+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:03:37.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:03:37.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T16:04:08.026+0000] {processor.py:157} INFO - Started process (PID=7486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:08.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:04:08.029+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:08.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:08.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:08.054+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:08.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:04:08.063+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:08.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:04:08.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T16:04:38.462+0000] {processor.py:157} INFO - Started process (PID=7496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:38.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:04:38.466+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:38.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:38.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:04:38.500+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:38.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:04:38.512+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:04:38.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:04:38.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T16:05:08.823+0000] {processor.py:157} INFO - Started process (PID=7506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:08.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:05:08.827+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:08.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:08.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:08.857+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:08.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:05:08.867+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:08.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:05:08.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:05:39.227+0000] {processor.py:157} INFO - Started process (PID=7516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:39.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:05:39.230+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:39.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:39.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:05:39.260+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:39.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:05:39.271+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:05:39.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:05:39.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:06:09.621+0000] {processor.py:157} INFO - Started process (PID=7526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:09.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:06:09.625+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:09.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:09.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:09.653+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:09.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:06:09.663+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:09.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:06:09.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:06:39.986+0000] {processor.py:157} INFO - Started process (PID=7536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:39.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:06:39.989+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:39.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:40.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:06:40.016+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:40.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:06:40.027+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:06:40.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:06:40.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:07:10.323+0000] {processor.py:157} INFO - Started process (PID=7546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:10.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:07:10.325+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:10.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:10.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:10.352+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:10.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:07:10.362+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:10.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:07:10.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T16:07:40.685+0000] {processor.py:157} INFO - Started process (PID=7556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:40.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:07:40.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:40.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:40.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:07:40.723+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:40.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:07:40.732+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:07:40.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:07:40.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T16:08:11.087+0000] {processor.py:157} INFO - Started process (PID=7566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:11.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:08:11.092+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:11.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:11.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:11.130+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:11.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:08:11.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:11.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:08:11.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T16:08:41.497+0000] {processor.py:157} INFO - Started process (PID=7576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:41.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:08:41.499+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:41.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:41.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:08:41.530+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:41.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:08:41.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:08:41.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:08:41.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:09:11.877+0000] {processor.py:157} INFO - Started process (PID=7586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:11.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:09:11.881+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:11.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:11.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:11.919+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:11.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:09:11.931+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:11.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:09:11.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T16:09:42.236+0000] {processor.py:157} INFO - Started process (PID=7596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:42.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:09:42.239+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:42.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:42.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:09:42.265+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:42.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:09:42.275+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:09:42.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:09:42.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:10:12.591+0000] {processor.py:157} INFO - Started process (PID=7606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:12.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:10:12.594+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:12.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:12.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:12.627+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:12.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:10:12.637+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:12.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:10:12.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T16:10:42.907+0000] {processor.py:157} INFO - Started process (PID=7616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:42.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:10:42.909+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:42.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:42.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:10:42.932+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:42.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:10:42.944+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:10:42.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:10:42.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T16:11:13.258+0000] {processor.py:157} INFO - Started process (PID=7626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:13.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:11:13.261+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:13.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:13.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:13.291+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:13.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:11:13.304+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:13.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:11:13.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T16:11:43.640+0000] {processor.py:157} INFO - Started process (PID=7636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:43.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:11:43.645+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:43.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:43.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:11:43.680+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:43.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:11:43.692+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:11:43.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:11:43.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T16:12:13.993+0000] {processor.py:157} INFO - Started process (PID=7646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:13.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:12:13.996+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:13.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:14.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:14.025+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:14.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:12:14.035+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:14.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:12:14.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:12:44.286+0000] {processor.py:157} INFO - Started process (PID=7656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:44.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:12:44.288+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:44.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:44.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:12:44.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:44.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:12:44.327+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:12:44.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:12:44.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:13:14.633+0000] {processor.py:157} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:14.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:13:14.641+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:14.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:14.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:14.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:14.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:13:14.674+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:14.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:13:14.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:13:44.996+0000] {processor.py:157} INFO - Started process (PID=7676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:44.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:13:45.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:45.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:45.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:13:45.029+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:45.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:13:45.039+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:13:45.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:13:45.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T16:14:15.318+0000] {processor.py:157} INFO - Started process (PID=7686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:15.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:14:15.324+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:15.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:15.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:15.360+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:15.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:14:15.372+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:15.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:14:15.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T16:14:45.652+0000] {processor.py:157} INFO - Started process (PID=7696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:45.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:14:45.656+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:45.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:45.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:14:45.687+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:45.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:14:45.699+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:14:45.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:14:45.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T16:15:16.028+0000] {processor.py:157} INFO - Started process (PID=7706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:16.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:15:16.033+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:16.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:16.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:16.064+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:16.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:15:16.075+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:16.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:15:16.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T16:15:46.307+0000] {processor.py:157} INFO - Started process (PID=7716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:46.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:15:46.310+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:46.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:46.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:15:46.339+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:46.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:15:46.349+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:15:46.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:15:46.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:16:16.666+0000] {processor.py:157} INFO - Started process (PID=7726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:16.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:16:16.673+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:16.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:16.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:16.707+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:16.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:16:16.718+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:16.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:16:16.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:16:47.054+0000] {processor.py:157} INFO - Started process (PID=7736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:47.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:16:47.057+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:47.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:47.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:16:47.083+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:47.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:16:47.094+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:16:47.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:16:47.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:17:17.351+0000] {processor.py:157} INFO - Started process (PID=7746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:17.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:17:17.353+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:17.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:17.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:17.381+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:17.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:17:17.392+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:17.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:17:17.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:17:47.701+0000] {processor.py:157} INFO - Started process (PID=7756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:47.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:17:47.703+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:47.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:47.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:17:47.728+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:47.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:17:47.739+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:17:47.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:17:47.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:18:18.055+0000] {processor.py:157} INFO - Started process (PID=7766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:18.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:18:18.059+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:18.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:18.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:18.087+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:18.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:18:18.098+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:18.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:18:18.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:18:48.350+0000] {processor.py:157} INFO - Started process (PID=7776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:48.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:18:48.352+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:48.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:48.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:18:48.381+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:48.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:18:48.391+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:18:48.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:18:48.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T16:19:18.733+0000] {processor.py:157} INFO - Started process (PID=7786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:18.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:19:18.737+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:18.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:18.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:18.774+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:18.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:19:18.788+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:18.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:19:18.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T16:19:49.114+0000] {processor.py:157} INFO - Started process (PID=7796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:49.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:19:49.117+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:49.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:49.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:19:49.147+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:49.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:19:49.158+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:19:49.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:19:49.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T16:20:19.467+0000] {processor.py:157} INFO - Started process (PID=7806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:19.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:20:19.470+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:19.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:19.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:19.498+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:19.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:20:19.510+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:19.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:20:19.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:20:49.852+0000] {processor.py:157} INFO - Started process (PID=7816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:49.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:20:49.856+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:49.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:49.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:20:49.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:49.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:20:49.898+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:20:49.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:20:49.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T16:21:20.218+0000] {processor.py:157} INFO - Started process (PID=7826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:20.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:21:20.221+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:20.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:20.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:20.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:20.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:21:20.258+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:20.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:21:20.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T16:21:50.595+0000] {processor.py:157} INFO - Started process (PID=7836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:50.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:21:50.600+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:50.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:50.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:21:50.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:50.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:21:50.641+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:21:50.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:21:50.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T16:22:20.959+0000] {processor.py:157} INFO - Started process (PID=7846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:20.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:22:20.962+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:20.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:20.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:20.995+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:20.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:22:21.008+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:21.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:22:21.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:22:51.284+0000] {processor.py:157} INFO - Started process (PID=7856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:51.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:22:51.288+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:51.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:51.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:22:51.315+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:51.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:22:51.325+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:22:51.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:22:51.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:23:21.616+0000] {processor.py:157} INFO - Started process (PID=7866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:21.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:23:21.619+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:21.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:21.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:21.650+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:21.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:23:21.661+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:21.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:23:21.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:23:51.987+0000] {processor.py:157} INFO - Started process (PID=7876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:51.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:23:51.991+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:51.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:52.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:23:52.017+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:52.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:23:52.026+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:23:52.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:23:52.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T16:24:22.352+0000] {processor.py:157} INFO - Started process (PID=7886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:22.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:24:22.357+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:22.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:22.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:22.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:22.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:24:22.400+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:22.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:24:22.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T16:24:52.739+0000] {processor.py:157} INFO - Started process (PID=7896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:52.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:24:52.746+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:52.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:52.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:24:52.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:52.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:24:52.800+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:24:52.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:24:52.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T16:25:23.192+0000] {processor.py:157} INFO - Started process (PID=7906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:23.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:25:23.195+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:23.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:23.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:23.227+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:23.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:25:23.239+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:23.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:25:23.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:25:53.626+0000] {processor.py:157} INFO - Started process (PID=7916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:53.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:25:53.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:53.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:53.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:25:53.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:53.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:25:53.703+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:25:53.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:25:53.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-09T16:26:23.940+0000] {processor.py:157} INFO - Started process (PID=7926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:23.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:26:23.943+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:23.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:23.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:23.971+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:23.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:26:23.981+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:23.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:26:23.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:26:54.382+0000] {processor.py:157} INFO - Started process (PID=7936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:54.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:26:54.386+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:54.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:54.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:26:54.423+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:54.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:26:54.435+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:26:54.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:26:54.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T16:27:24.749+0000] {processor.py:157} INFO - Started process (PID=7946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:24.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:27:24.752+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:24.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:24.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:24.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:24.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:27:24.795+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:24.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:27:24.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:27:55.113+0000] {processor.py:157} INFO - Started process (PID=7956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:55.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:27:55.117+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:55.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:55.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:27:55.145+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:55.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:27:55.158+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:27:55.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:27:55.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:28:25.472+0000] {processor.py:157} INFO - Started process (PID=7966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:25.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:28:25.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:25.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:25.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:25.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:25.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:28:25.529+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:25.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:28:25.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T16:28:55.740+0000] {processor.py:157} INFO - Started process (PID=7976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:55.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:28:55.743+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:55.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:55.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:28:55.776+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:55.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:28:55.788+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:28:55.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:28:55.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T16:29:26.002+0000] {processor.py:157} INFO - Started process (PID=7986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:26.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:29:26.005+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:26.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:26.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:26.034+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:26.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:29:26.047+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:26.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:29:26.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T16:29:56.428+0000] {processor.py:157} INFO - Started process (PID=7996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:56.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:29:56.430+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:56.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:56.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:29:56.456+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:56.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:29:56.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:29:56.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:29:56.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T16:30:26.781+0000] {processor.py:157} INFO - Started process (PID=8006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:26.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:30:26.788+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:26.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:26.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:26.833+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:26.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:30:26.846+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:26.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:30:26.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T16:30:57.073+0000] {processor.py:157} INFO - Started process (PID=8016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:57.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:30:57.081+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:57.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:57.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:30:57.103+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:57.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:30:57.113+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:30:57.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:30:57.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:31:27.382+0000] {processor.py:157} INFO - Started process (PID=8026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:27.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:31:27.385+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:27.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:27.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:27.413+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:27.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:31:27.425+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:27.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:31:27.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:31:57.738+0000] {processor.py:157} INFO - Started process (PID=8036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:57.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:31:57.742+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:57.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:57.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:31:57.773+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:57.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:31:57.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:31:57.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:31:57.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T16:32:28.127+0000] {processor.py:157} INFO - Started process (PID=8046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:28.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:32:28.131+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:28.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:28.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:28.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:28.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:32:28.178+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:28.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:32:28.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:32:58.480+0000] {processor.py:157} INFO - Started process (PID=8056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:58.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:32:58.483+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:58.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:58.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:32:58.514+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:58.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:32:58.524+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:32:58.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:32:58.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:33:28.853+0000] {processor.py:157} INFO - Started process (PID=8066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:28.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:33:28.857+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:28.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:28.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:28.886+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:28.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:33:28.896+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:28.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:33:28.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T16:33:59.190+0000] {processor.py:157} INFO - Started process (PID=8075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:59.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:33:59.194+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:59.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:59.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:33:59.228+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:59.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:33:59.240+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:33:59.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:33:59.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:34:29.489+0000] {processor.py:157} INFO - Started process (PID=8086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:29.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:34:29.491+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:29.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:29.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:29.518+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:29.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:34:29.529+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:29.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:34:29.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:34:59.919+0000] {processor.py:157} INFO - Started process (PID=8096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:59.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:34:59.930+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:59.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:59.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:34:59.967+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:59.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:34:59.979+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:34:59.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:34:59.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-09T16:35:30.296+0000] {processor.py:157} INFO - Started process (PID=8106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:35:30.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:35:30.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:35:30.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:35:30.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:35:30.332+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:35:30.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:35:30.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:35:30.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:35:30.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T16:36:00.648+0000] {processor.py:157} INFO - Started process (PID=8116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:00.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:36:00.651+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:00.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:00.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:00.678+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:00.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:36:00.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:00.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:36:00.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:36:31.015+0000] {processor.py:157} INFO - Started process (PID=8126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:31.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:36:31.021+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:31.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:31.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:36:31.074+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:31.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:36:31.087+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:36:31.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:36:31.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T16:37:01.343+0000] {processor.py:157} INFO - Started process (PID=8136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:01.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:37:01.345+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:01.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:01.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:01.373+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:01.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:37:01.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:01.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:37:01.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:37:31.732+0000] {processor.py:157} INFO - Started process (PID=8146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:31.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:37:31.736+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:31.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:31.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:37:31.763+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:31.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:37:31.775+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:37:31.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:37:31.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:38:02.117+0000] {processor.py:157} INFO - Started process (PID=8156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:02.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:38:02.121+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:02.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:02.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:02.152+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:02.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:38:02.163+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:02.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:38:02.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T16:38:32.501+0000] {processor.py:157} INFO - Started process (PID=8166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:32.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:38:32.507+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:32.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:32.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:38:32.551+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:32.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:38:32.565+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:38:32.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:38:32.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-09T16:39:02.878+0000] {processor.py:157} INFO - Started process (PID=8176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:02.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:39:02.883+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:02.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:02.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:02.909+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:02.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:39:02.919+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:02.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:39:02.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:39:33.233+0000] {processor.py:157} INFO - Started process (PID=8186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:33.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:39:33.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:33.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:33.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:39:33.262+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:33.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:39:33.271+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:39:33.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:39:33.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-09T16:40:03.614+0000] {processor.py:157} INFO - Started process (PID=8196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:03.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:40:03.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:03.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:03.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:03.655+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:03.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:40:03.667+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:03.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:40:03.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T16:40:33.968+0000] {processor.py:157} INFO - Started process (PID=8206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:33.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:40:33.975+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:33.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:33.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:40:34.010+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:34.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:40:34.020+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:40:34.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:40:34.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:41:04.367+0000] {processor.py:157} INFO - Started process (PID=8216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:04.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:41:04.370+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:04.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:04.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:04.399+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:04.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:41:04.408+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:04.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:41:04.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:41:34.751+0000] {processor.py:157} INFO - Started process (PID=8226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:34.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:41:34.755+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:34.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:34.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:41:34.791+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:34.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:41:34.803+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:41:34.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:41:34.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:42:05.157+0000] {processor.py:157} INFO - Started process (PID=8236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:05.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:42:05.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:05.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:05.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:05.196+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:05.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:42:05.208+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:05.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:42:05.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:42:35.507+0000] {processor.py:157} INFO - Started process (PID=8246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:35.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:42:35.510+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:35.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:35.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:42:35.538+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:35.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:42:35.549+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:42:35.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:42:35.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:43:05.862+0000] {processor.py:157} INFO - Started process (PID=8256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:05.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:43:05.864+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:05.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:05.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:05.891+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:05.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:43:05.901+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:05.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:43:05.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:43:36.196+0000] {processor.py:157} INFO - Started process (PID=8266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:36.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:43:36.199+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:36.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:36.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:43:36.227+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:36.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:43:36.239+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:43:36.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:43:36.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:44:06.556+0000] {processor.py:157} INFO - Started process (PID=8276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:06.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:44:06.560+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:06.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:06.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:06.587+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:06.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:44:06.597+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:06.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:44:06.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:44:36.942+0000] {processor.py:157} INFO - Started process (PID=8286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:36.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:44:36.946+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:36.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:36.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:44:36.985+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:36.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:44:36.997+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:44:36.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:44:37.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T16:45:07.224+0000] {processor.py:157} INFO - Started process (PID=8296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:07.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:45:07.226+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:07.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:07.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:07.255+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:07.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:45:07.266+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:07.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:45:07.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:45:37.618+0000] {processor.py:157} INFO - Started process (PID=8306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:37.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:45:37.621+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:37.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:37.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:45:37.649+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:37.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:45:37.661+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:45:37.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:45:37.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:46:07.991+0000] {processor.py:157} INFO - Started process (PID=8316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:07.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:46:07.993+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:07.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:08.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:08.021+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:08.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:46:08.032+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:08.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:46:08.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T16:46:38.376+0000] {processor.py:157} INFO - Started process (PID=8325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:38.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:46:38.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:38.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:38.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:46:38.416+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:38.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:46:38.429+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:46:38.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:46:38.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:47:08.769+0000] {processor.py:157} INFO - Started process (PID=8336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:08.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:47:08.772+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:08.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:08.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:08.800+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:08.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:47:08.811+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:08.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:47:08.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:47:39.160+0000] {processor.py:157} INFO - Started process (PID=8346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:39.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:47:39.163+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:39.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:39.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:47:39.196+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:39.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:47:39.209+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:47:39.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:47:39.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:48:09.534+0000] {processor.py:157} INFO - Started process (PID=8356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:09.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:48:09.539+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:09.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:09.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:09.576+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:48:09.587+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:09.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:48:09.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T16:48:39.828+0000] {processor.py:157} INFO - Started process (PID=8366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:39.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:48:39.831+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:39.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:39.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:48:39.860+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:39.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:48:39.872+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:48:39.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:48:39.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T16:49:10.228+0000] {processor.py:157} INFO - Started process (PID=8376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:10.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:49:10.231+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:10.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:10.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:10.262+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:10.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:49:10.275+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:10.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:49:10.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T16:49:40.656+0000] {processor.py:157} INFO - Started process (PID=8386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:40.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:49:40.660+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:40.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:40.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:49:40.696+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:40.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:49:40.708+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:49:40.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:49:40.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:50:10.970+0000] {processor.py:157} INFO - Started process (PID=8396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:10.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:50:10.973+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:10.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:10.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:11.001+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:11.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:50:11.012+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:11.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:50:11.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T16:50:41.377+0000] {processor.py:157} INFO - Started process (PID=8406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:41.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:50:41.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:41.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:41.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:50:41.412+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:41.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:50:41.423+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:50:41.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:50:41.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T16:51:11.761+0000] {processor.py:157} INFO - Started process (PID=8416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:11.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:51:11.765+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:11.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:11.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:11.790+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:11.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:51:11.800+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:11.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:51:11.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T16:51:42.219+0000] {processor.py:157} INFO - Started process (PID=8426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:42.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:51:42.224+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:42.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:42.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:51:42.257+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:42.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:51:42.268+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:51:42.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:51:42.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T16:52:12.638+0000] {processor.py:157} INFO - Started process (PID=8436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:12.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:52:12.642+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:12.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:12.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:12.671+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:12.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:52:12.684+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:12.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:52:12.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T16:52:43.029+0000] {processor.py:157} INFO - Started process (PID=8446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:43.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:52:43.032+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:43.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:43.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:52:43.060+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:43.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:52:43.071+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:52:43.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:52:43.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T16:53:13.346+0000] {processor.py:157} INFO - Started process (PID=8456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:13.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:53:13.349+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:13.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:13.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:13.373+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:13.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:53:13.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:13.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:53:13.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T16:53:43.746+0000] {processor.py:157} INFO - Started process (PID=8466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:43.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:53:43.751+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:43.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:43.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:53:43.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:43.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:53:43.798+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:53:43.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:53:43.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T16:54:14.075+0000] {processor.py:157} INFO - Started process (PID=8476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:14.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:54:14.083+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:14.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:14.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:14.133+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:14.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:54:14.146+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:14.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:54:14.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-09T16:54:44.381+0000] {processor.py:157} INFO - Started process (PID=8485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:44.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:54:44.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:44.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:44.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:54:44.431+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:44.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:54:44.440+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:54:44.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:54:44.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T16:55:14.773+0000] {processor.py:157} INFO - Started process (PID=8496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:14.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:55:14.778+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:14.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:14.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:14.813+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:14.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:55:14.828+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:14.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:55:14.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T16:55:45.228+0000] {processor.py:157} INFO - Started process (PID=8506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:45.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:55:45.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:45.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:45.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:55:45.304+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:45.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:55:45.336+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:55:45.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:55:45.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-09T16:56:15.672+0000] {processor.py:157} INFO - Started process (PID=8516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:15.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:56:15.675+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:15.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:15.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:15.709+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:15.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:56:15.718+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:15.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:56:15.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T16:56:46.054+0000] {processor.py:157} INFO - Started process (PID=8526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:46.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:56:46.058+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:46.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:46.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:56:46.126+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:46.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:56:46.139+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:56:46.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:56:46.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-09T16:57:16.373+0000] {processor.py:157} INFO - Started process (PID=8536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:16.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:57:16.376+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:16.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:16.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:16.405+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:16.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:57:16.415+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:16.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:57:16.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T16:57:46.794+0000] {processor.py:157} INFO - Started process (PID=8546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:46.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:57:46.798+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:46.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:46.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:57:46.829+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:46.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:57:46.841+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:57:46.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:57:46.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T16:58:17.186+0000] {processor.py:157} INFO - Started process (PID=8556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:58:17.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T16:58:17.191+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:58:17.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:58:17.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T16:58:17.226+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:58:17.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T16:58:17.239+0000] {logging_mixin.py:151} INFO - [2024-08-09T16:58:17.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T16:58:17.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T17:13:34.068+0000] {processor.py:157} INFO - Started process (PID=8568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:13:34.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:13:34.086+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:13:34.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:13:34.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:13:34.215+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:13:34.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:13:34.258+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:13:34.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:13:34.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-08-09T17:14:04.403+0000] {processor.py:157} INFO - Started process (PID=8578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:04.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:14:04.410+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:04.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:04.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:04.462+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:04.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:14:04.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:04.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:14:04.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-09T17:14:34.754+0000] {processor.py:157} INFO - Started process (PID=8588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:34.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:14:34.764+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:34.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:34.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:14:34.808+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:34.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:14:34.822+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:14:34.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:14:34.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-09T17:15:05.142+0000] {processor.py:157} INFO - Started process (PID=8598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:15:05.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:15:05.146+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:15:05.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:15:05.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:15:05.170+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:15:05.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:15:05.182+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:15:05.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:15:05.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T17:30:40.846+0000] {processor.py:157} INFO - Started process (PID=8608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:30:40.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:30:40.850+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:30:40.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:30:40.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:30:40.902+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:30:40.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:30:40.917+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:30:40.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:30:40.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-09T17:31:11.277+0000] {processor.py:157} INFO - Started process (PID=8618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:11.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:31:11.281+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:11.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:11.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:11.331+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:11.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:31:11.347+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:11.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:31:11.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-09T17:31:41.676+0000] {processor.py:157} INFO - Started process (PID=8628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:41.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:31:41.680+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:41.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:41.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:31:41.708+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:41.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:31:41.720+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:31:41.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:31:41.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T17:32:12.080+0000] {processor.py:157} INFO - Started process (PID=8638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:12.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:32:12.085+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:12.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:12.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:12.114+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:12.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:32:12.124+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:12.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:32:12.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T17:32:42.334+0000] {processor.py:157} INFO - Started process (PID=8648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:42.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:32:42.339+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:42.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:42.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:32:42.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:42.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:32:42.400+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:32:42.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:32:42.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-09T17:38:37.628+0000] {processor.py:157} INFO - Started process (PID=8658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:38:37.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:38:37.631+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:38:37.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:38:37.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:38:37.662+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:38:37.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:38:37.673+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:38:37.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:38:37.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T17:39:08.038+0000] {processor.py:157} INFO - Started process (PID=8669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:08.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:39:08.050+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:08.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:08.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:08.103+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:08.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:39:08.118+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:08.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:39:08.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-09T17:39:38.458+0000] {processor.py:157} INFO - Started process (PID=8679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:38.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:39:38.465+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:38.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:38.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:39:38.509+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:38.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:39:38.526+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:39:38.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:39:38.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T17:40:08.779+0000] {processor.py:157} INFO - Started process (PID=8689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:08.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:40:08.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:08.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:08.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:08.818+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:08.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:40:08.830+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:08.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:40:08.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T17:40:39.173+0000] {processor.py:157} INFO - Started process (PID=8699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:39.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:40:39.176+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:39.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:39.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:40:39.203+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:39.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:40:39.215+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:40:39.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:40:39.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T17:41:09.552+0000] {processor.py:157} INFO - Started process (PID=8709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:09.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:41:09.558+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:09.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:09.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:09.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:09.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:41:09.613+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:09.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:41:09.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T17:41:39.986+0000] {processor.py:157} INFO - Started process (PID=8719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:39.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:41:39.989+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:39.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:40.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:41:40.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:40.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:41:40.030+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:41:40.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:41:40.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T17:42:10.396+0000] {processor.py:157} INFO - Started process (PID=8729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:10.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:42:10.399+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:10.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:10.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:10.425+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:10.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:42:10.434+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:10.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:42:10.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T17:42:40.746+0000] {processor.py:157} INFO - Started process (PID=8739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:40.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:42:40.748+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:40.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:40.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:42:40.777+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:40.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:42:40.790+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:42:40.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:42:40.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T17:43:11.098+0000] {processor.py:157} INFO - Started process (PID=8749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:11.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:43:11.105+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:11.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:11.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:11.142+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:11.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:43:11.153+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:11.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:43:11.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T17:43:41.499+0000] {processor.py:157} INFO - Started process (PID=8759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:41.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:43:41.501+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:41.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:41.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:43:41.532+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:41.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:43:41.545+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:43:41.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:43:41.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T17:44:11.867+0000] {processor.py:157} INFO - Started process (PID=8769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:11.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:44:11.870+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:11.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:11.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:11.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:11.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:44:11.908+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:11.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:44:11.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T17:44:42.314+0000] {processor.py:157} INFO - Started process (PID=8779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:42.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:44:42.320+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:42.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:42.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:44:42.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:42.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:44:42.367+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:44:42.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:44:42.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T17:45:12.697+0000] {processor.py:157} INFO - Started process (PID=8789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:12.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:45:12.702+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:12.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:12.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:12.734+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:12.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:45:12.748+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:12.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:45:12.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T17:45:43.097+0000] {processor.py:157} INFO - Started process (PID=8799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:43.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:45:43.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:43.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:43.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:45:43.141+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:43.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:45:43.156+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:45:43.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:45:43.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T17:46:13.428+0000] {processor.py:157} INFO - Started process (PID=8809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:13.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:46:13.433+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:13.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:13.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:13.463+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:13.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:46:13.474+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:13.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:46:13.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T17:46:43.802+0000] {processor.py:157} INFO - Started process (PID=8819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:43.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:46:43.804+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:43.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:43.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:46:43.836+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:43.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:46:43.848+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:46:43.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:46:43.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T17:47:14.228+0000] {processor.py:157} INFO - Started process (PID=8829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:14.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:47:14.232+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:14.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:14.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:14.268+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:14.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:47:14.281+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:14.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:47:14.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-09T17:47:44.671+0000] {processor.py:157} INFO - Started process (PID=8839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:44.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:47:44.674+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:44.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:44.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:47:44.700+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:44.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:47:44.710+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:47:44.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:47:44.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T17:48:15.123+0000] {processor.py:157} INFO - Started process (PID=8849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:15.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:48:15.126+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:15.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:15.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:15.160+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:15.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:48:15.171+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:15.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:48:15.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T17:48:45.611+0000] {processor.py:157} INFO - Started process (PID=8859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:45.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:48:45.615+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:45.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:45.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:48:45.645+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:45.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:48:45.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:48:45.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:48:45.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T17:49:16.055+0000] {processor.py:157} INFO - Started process (PID=8869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:16.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:49:16.060+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:16.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:16.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:16.099+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:16.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:49:16.111+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:16.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:49:16.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-09T17:49:46.426+0000] {processor.py:157} INFO - Started process (PID=8879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:46.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:49:46.429+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:46.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:46.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:49:46.457+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:46.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:49:46.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:49:46.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:49:46.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T17:50:16.870+0000] {processor.py:157} INFO - Started process (PID=8889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:16.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:50:16.876+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:16.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:16.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:16.913+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:16.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:50:16.925+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:16.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:50:16.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T17:50:47.188+0000] {processor.py:157} INFO - Started process (PID=8899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:47.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:50:47.192+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:47.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:47.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:50:47.226+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:47.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:50:47.238+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:50:47.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:50:47.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T17:51:17.541+0000] {processor.py:157} INFO - Started process (PID=8909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:17.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:51:17.547+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:17.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:17.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:17.584+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:17.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:51:17.596+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:17.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:51:17.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T17:51:47.912+0000] {processor.py:157} INFO - Started process (PID=8919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:47.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:51:47.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:47.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:47.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:51:47.944+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:47.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:51:47.958+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:51:47.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:51:47.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T17:52:18.284+0000] {processor.py:157} INFO - Started process (PID=8929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:18.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:52:18.289+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:18.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:18.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:18.330+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:18.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:52:18.356+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:18.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:52:18.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-09T17:52:48.592+0000] {processor.py:157} INFO - Started process (PID=8939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:48.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:52:48.596+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:48.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:48.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:52:48.627+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:48.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:52:48.636+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:52:48.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:52:48.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T17:53:19.026+0000] {processor.py:157} INFO - Started process (PID=8947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:19.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:53:19.031+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:19.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:19.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:19.087+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:19.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:53:19.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:19.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:53:19.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-09T17:53:49.382+0000] {processor.py:157} INFO - Started process (PID=8959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:49.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T17:53:49.384+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:49.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:49.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T17:53:49.412+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:49.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T17:53:49.423+0000] {logging_mixin.py:151} INFO - [2024-08-09T17:53:49.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T17:53:49.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T18:09:32.122+0000] {processor.py:157} INFO - Started process (PID=8969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:09:32.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:09:32.129+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:09:32.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:09:32.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:09:32.188+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:09:32.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:09:32.202+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:09:32.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:09:32.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-09T18:10:02.412+0000] {processor.py:157} INFO - Started process (PID=8981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:02.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:10:02.432+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:02.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:02.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:02.481+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:02.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:10:02.496+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:02.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:10:02.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-09T18:10:32.702+0000] {processor.py:157} INFO - Started process (PID=8991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:32.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:10:32.707+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:32.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:32.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:10:32.733+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:32.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:10:32.745+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:10:32.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:10:32.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T18:11:03.081+0000] {processor.py:157} INFO - Started process (PID=9001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:11:03.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:11:03.084+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:11:03.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:11:03.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:11:03.111+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:11:03.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:11:03.123+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:11:03.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:11:03.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T18:26:54.118+0000] {processor.py:157} INFO - Started process (PID=9009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:26:54.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:26:54.137+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:26:54.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:26:54.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:26:54.209+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:26:54.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:26:54.246+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:26:54.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:26:54.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-09T18:27:24.446+0000] {processor.py:157} INFO - Started process (PID=9023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:24.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:27:24.453+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:24.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:24.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:24.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:24.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:27:24.531+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:24.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:27:24.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-09T18:27:54.779+0000] {processor.py:157} INFO - Started process (PID=9033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:54.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:27:54.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:54.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:54.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:27:54.810+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:54.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:27:54.820+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:27:54.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:27:54.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T18:39:54.629+0000] {processor.py:157} INFO - Started process (PID=9045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:39:54.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:39:54.638+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:39:54.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:39:54.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:39:54.699+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:39:54.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:39:54.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:39:54.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:39:54.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-09T18:40:25.085+0000] {processor.py:157} INFO - Started process (PID=9055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:40:25.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:40:25.089+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:40:25.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:40:25.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:40:25.117+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:40:25.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:40:25.128+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:40:25.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:40:25.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T18:58:19.425+0000] {processor.py:157} INFO - Started process (PID=9064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:19.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:58:19.433+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:19.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:19.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:19.511+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:19.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:58:19.540+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:19.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:58:19.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-09T18:58:49.908+0000] {processor.py:157} INFO - Started process (PID=9075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:49.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:58:49.912+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:49.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:49.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:58:49.969+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:49.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:58:49.989+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:58:49.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:58:50.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-09T18:59:20.225+0000] {processor.py:157} INFO - Started process (PID=9085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:20.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:59:20.228+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:20.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:20.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:20.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:20.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:59:20.263+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:20.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:59:20.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T18:59:50.634+0000] {processor.py:157} INFO - Started process (PID=9095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:50.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T18:59:50.643+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:50.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:50.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T18:59:50.664+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:50.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T18:59:50.677+0000] {logging_mixin.py:151} INFO - [2024-08-09T18:59:50.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T18:59:50.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T19:16:31.362+0000] {processor.py:157} INFO - Started process (PID=9105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:16:31.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:16:31.367+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:16:31.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:16:31.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:16:31.407+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:16:31.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:16:31.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:16:31.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:16:31.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T19:17:01.717+0000] {processor.py:157} INFO - Started process (PID=9113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:01.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:17:01.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:01.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:01.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:01.786+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:01.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:17:01.800+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:01.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:17:01.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-09T19:17:32.033+0000] {processor.py:157} INFO - Started process (PID=9125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:32.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:17:32.036+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:32.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:32.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:17:32.061+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:32.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:17:32.070+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:17:32.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:17:32.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T19:18:02.413+0000] {processor.py:157} INFO - Started process (PID=9135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:02.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:18:02.417+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:02.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:02.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:02.452+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:02.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:18:02.464+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:02.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:18:02.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T19:18:33.005+0000] {processor.py:157} INFO - Started process (PID=9145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:33.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:18:33.010+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:33.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:33.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:18:33.050+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:33.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:18:33.065+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:18:33.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:18:33.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.379 seconds
[2024-08-09T19:35:34.350+0000] {processor.py:157} INFO - Started process (PID=9155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:35:34.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:35:34.355+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:35:34.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:35:34.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:35:34.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:35:34.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:35:34.392+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:35:34.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:35:34.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T19:36:04.747+0000] {processor.py:157} INFO - Started process (PID=9165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:04.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:36:04.751+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:04.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:04.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:04.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:04.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:36:04.796+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:04.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:36:04.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T19:36:35.133+0000] {processor.py:157} INFO - Started process (PID=9175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:35.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:36:35.136+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:35.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:35.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:36:35.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:35.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:36:35.179+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:36:35.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:36:35.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T19:37:05.528+0000] {processor.py:157} INFO - Started process (PID=9185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:05.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:37:05.533+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:05.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:05.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:05.562+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:05.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:37:05.574+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:05.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:37:05.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T19:37:35.911+0000] {processor.py:157} INFO - Started process (PID=9195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:35.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:37:35.915+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:35.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:35.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:37:35.949+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:35.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:37:35.960+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:37:35.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:37:35.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T19:40:54.672+0000] {processor.py:157} INFO - Started process (PID=9207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:40:54.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:40:54.678+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:40:54.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:40:54.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:40:54.723+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:40:54.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:40:54.744+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:40:54.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:40:54.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-09T19:41:24.931+0000] {processor.py:157} INFO - Started process (PID=9217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:24.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:41:24.935+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:24.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:24.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:24.967+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:24.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:41:24.979+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:24.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:41:24.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T19:41:55.284+0000] {processor.py:157} INFO - Started process (PID=9227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:55.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:41:55.288+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:55.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:55.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:41:55.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:55.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:41:55.328+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:41:55.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:41:55.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T19:42:25.654+0000] {processor.py:157} INFO - Started process (PID=9237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:42:25.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:42:25.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:42:25.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:42:25.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:42:25.942+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:42:25.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:42:25.963+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:42:25.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:42:26.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.377 seconds
[2024-08-09T19:57:54.773+0000] {processor.py:157} INFO - Started process (PID=9249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:57:54.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:57:54.775+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:57:54.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:57:54.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:57:54.802+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:57:54.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:57:54.819+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:57:54.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:57:54.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T19:58:25.164+0000] {processor.py:157} INFO - Started process (PID=9259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:25.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:58:25.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:25.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:25.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:25.205+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:25.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:58:25.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:25.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:58:25.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T19:58:55.465+0000] {processor.py:157} INFO - Started process (PID=9269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:55.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:58:55.467+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:55.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:55.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:58:55.498+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:55.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:58:55.510+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:58:55.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:58:55.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T19:59:25.855+0000] {processor.py:157} INFO - Started process (PID=9279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:25.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:59:25.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:25.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:25.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:25.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:25.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:59:25.900+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:25.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:59:25.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T19:59:56.211+0000] {processor.py:157} INFO - Started process (PID=9289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:56.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T19:59:56.216+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:56.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:56.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T19:59:56.240+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:56.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T19:59:56.249+0000] {logging_mixin.py:151} INFO - [2024-08-09T19:59:56.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T19:59:56.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T20:00:26.605+0000] {processor.py:157} INFO - Started process (PID=9299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:26.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:00:26.607+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:26.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:26.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:26.638+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:26.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:00:26.647+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:26.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:00:26.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:00:57.002+0000] {processor.py:157} INFO - Started process (PID=9309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:57.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:00:57.004+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:57.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:57.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:00:57.034+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:57.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:00:57.045+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:00:57.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:00:57.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:01:27.386+0000] {processor.py:157} INFO - Started process (PID=9319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:27.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:01:27.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:27.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:27.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:27.413+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:27.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:01:27.424+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:27.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:01:27.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T20:01:57.765+0000] {processor.py:157} INFO - Started process (PID=9329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:57.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:01:57.769+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:57.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:57.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:01:57.796+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:57.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:01:57.808+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:01:57.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:01:57.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:02:28.143+0000] {processor.py:157} INFO - Started process (PID=9339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:28.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:02:28.146+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:28.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:28.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:28.175+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:28.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:02:28.186+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:28.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:02:28.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:02:58.580+0000] {processor.py:157} INFO - Started process (PID=9349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:58.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:02:58.583+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:58.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:58.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:02:58.610+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:58.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:02:58.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:02:58.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:02:58.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:03:28.978+0000] {processor.py:157} INFO - Started process (PID=9359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:28.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:03:28.981+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:28.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:28.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:29.009+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:29.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:03:29.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:29.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:03:29.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:03:59.407+0000] {processor.py:157} INFO - Started process (PID=9369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:59.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:03:59.411+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:59.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:59.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:03:59.437+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:59.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:03:59.446+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:03:59.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:03:59.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:04:29.697+0000] {processor.py:157} INFO - Started process (PID=9379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:04:29.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:04:29.701+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:04:29.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:04:29.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:04:29.732+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:04:29.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:04:29.754+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:04:29.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:04:29.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T20:05:00.004+0000] {processor.py:157} INFO - Started process (PID=9389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:00.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:05:00.007+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:00.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:00.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:00.033+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:00.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:05:00.043+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:00.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:05:00.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:05:30.381+0000] {processor.py:157} INFO - Started process (PID=9399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:30.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:05:30.384+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:30.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:30.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:05:30.409+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:30.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:05:30.420+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:05:30.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:05:30.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:06:00.752+0000] {processor.py:157} INFO - Started process (PID=9409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:00.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:06:00.755+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:00.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:00.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:00.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:00.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:06:00.792+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:00.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:06:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:06:31.162+0000] {processor.py:157} INFO - Started process (PID=9419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:31.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:06:31.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:31.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:31.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:06:31.191+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:31.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:06:31.202+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:06:31.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:06:31.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:07:01.570+0000] {processor.py:157} INFO - Started process (PID=9429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:01.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:07:01.572+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:01.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:01.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:01.602+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:01.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:07:01.613+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:01.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:07:01.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:07:32.001+0000] {processor.py:157} INFO - Started process (PID=9439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:32.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:07:32.005+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:32.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:32.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:07:32.041+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:32.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:07:32.053+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:07:32.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:07:32.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T20:08:02.381+0000] {processor.py:157} INFO - Started process (PID=9449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:02.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:08:02.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:02.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:02.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:02.412+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:02.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:08:02.426+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:02.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:08:02.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:08:32.735+0000] {processor.py:157} INFO - Started process (PID=9459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:32.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:08:32.737+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:32.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:32.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:08:32.765+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:32.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:08:32.775+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:08:32.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:08:32.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:09:03.080+0000] {processor.py:157} INFO - Started process (PID=9469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:03.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:09:03.082+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:03.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:03.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:03.115+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:03.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:09:03.123+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:03.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:09:03.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:09:33.463+0000] {processor.py:157} INFO - Started process (PID=9479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:33.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:09:33.469+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:33.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:33.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:09:33.506+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:33.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:09:33.519+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:09:33.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:09:33.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T20:10:03.858+0000] {processor.py:157} INFO - Started process (PID=9489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:03.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:10:03.860+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:03.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:03.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:03.885+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:03.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:10:03.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:03.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:10:03.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:10:34.282+0000] {processor.py:157} INFO - Started process (PID=9499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:34.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:10:34.285+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:34.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:34.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:10:34.312+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:34.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:10:34.324+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:10:34.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:10:34.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:11:04.688+0000] {processor.py:157} INFO - Started process (PID=9509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:04.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:11:04.691+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:04.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:04.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:04.723+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:04.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:11:04.735+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:04.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:11:04.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:11:35.046+0000] {processor.py:157} INFO - Started process (PID=9519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:35.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:11:35.050+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:35.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:35.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:11:35.083+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:35.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:11:35.095+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:11:35.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:11:35.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:12:05.374+0000] {processor.py:157} INFO - Started process (PID=9529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:05.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:12:05.377+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:05.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:05.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:05.403+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:05.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:12:05.414+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:05.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:12:05.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:12:35.718+0000] {processor.py:157} INFO - Started process (PID=9539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:35.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:12:35.721+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:35.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:35.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:12:35.748+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:35.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:12:35.761+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:12:35.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:12:35.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:13:06.071+0000] {processor.py:157} INFO - Started process (PID=9549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:06.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:13:06.074+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:06.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:06.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:06.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:06.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:13:06.113+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:06.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:13:06.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:13:36.472+0000] {processor.py:157} INFO - Started process (PID=9559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:36.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:13:36.475+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:36.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:36.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:13:36.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:36.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:13:36.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:13:36.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:13:36.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:14:06.884+0000] {processor.py:157} INFO - Started process (PID=9569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:06.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:14:06.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:06.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:06.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:06.912+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:06.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:14:06.922+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:14:06.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:14:37.241+0000] {processor.py:157} INFO - Started process (PID=9579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:37.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:14:37.245+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:37.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:37.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:14:37.273+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:37.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:14:37.283+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:14:37.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:14:37.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:15:07.641+0000] {processor.py:157} INFO - Started process (PID=9589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:07.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:15:07.644+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:07.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:07.669+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:07.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:15:07.679+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:07.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:15:07.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:15:38.029+0000] {processor.py:157} INFO - Started process (PID=9599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:38.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:15:38.032+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:38.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:38.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:15:38.062+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:38.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:15:38.071+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:15:38.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:15:38.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:16:08.382+0000] {processor.py:157} INFO - Started process (PID=9609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:08.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:16:08.384+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:08.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:08.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:08.411+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:08.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:16:08.421+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:08.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:16:08.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:16:38.747+0000] {processor.py:157} INFO - Started process (PID=9619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:38.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:16:38.750+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:38.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:38.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:16:38.776+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:38.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:16:38.786+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:16:38.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:16:38.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:17:09.064+0000] {processor.py:157} INFO - Started process (PID=9629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:09.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:17:09.066+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:09.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:09.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:09.096+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:09.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:17:09.109+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:09.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:17:09.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:17:39.463+0000] {processor.py:157} INFO - Started process (PID=9639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:39.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:17:39.465+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:39.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:39.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:17:39.494+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:39.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:17:39.505+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:17:39.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:17:39.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:18:09.827+0000] {processor.py:157} INFO - Started process (PID=9649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:09.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:18:09.830+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:09.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:09.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:09.859+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:09.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:18:09.870+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:09.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:18:09.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:18:40.241+0000] {processor.py:157} INFO - Started process (PID=9659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:40.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:18:40.244+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:40.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:40.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:18:40.268+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:40.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:18:40.278+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:18:40.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:18:40.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T20:19:10.648+0000] {processor.py:157} INFO - Started process (PID=9669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:10.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:19:10.653+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:10.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:10.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:10.686+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:10.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:19:10.699+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:10.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:19:10.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T20:19:41.057+0000] {processor.py:157} INFO - Started process (PID=9679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:41.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:19:41.060+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:41.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:41.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:19:41.093+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:41.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:19:41.104+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:19:41.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:19:41.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:20:11.403+0000] {processor.py:157} INFO - Started process (PID=9689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:11.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:20:11.405+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:11.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:11.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:11.433+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:11.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:20:11.444+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:11.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:20:11.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:20:41.760+0000] {processor.py:157} INFO - Started process (PID=9699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:41.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:20:41.763+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:41.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:41.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:20:41.794+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:41.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:20:41.805+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:20:41.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:20:41.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:21:12.201+0000] {processor.py:157} INFO - Started process (PID=9709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:12.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:21:12.203+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:12.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:12.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:12.233+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:12.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:21:12.245+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:12.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:21:12.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:21:42.602+0000] {processor.py:157} INFO - Started process (PID=9719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:42.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:21:42.607+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:42.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:42.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:21:42.635+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:42.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:21:42.647+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:21:42.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:21:42.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:22:12.917+0000] {processor.py:157} INFO - Started process (PID=9729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:12.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:22:12.922+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:12.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:12.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:12.957+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:12.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:22:12.968+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:12.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:22:12.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T20:22:43.280+0000] {processor.py:157} INFO - Started process (PID=9739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:43.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:22:43.283+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:43.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:43.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:22:43.313+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:43.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:22:43.322+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:22:43.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:22:43.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:23:13.676+0000] {processor.py:157} INFO - Started process (PID=9749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:13.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:23:13.677+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:13.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:13.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:13.709+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:13.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:23:13.720+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:13.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:23:13.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:23:44.101+0000] {processor.py:157} INFO - Started process (PID=9759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:44.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:23:44.105+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:44.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:44.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:23:44.133+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:44.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:23:44.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:23:44.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:23:44.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:24:14.511+0000] {processor.py:157} INFO - Started process (PID=9769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:14.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:24:14.514+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:14.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:14.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:14.541+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:14.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:24:14.552+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:14.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:24:14.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:24:44.808+0000] {processor.py:157} INFO - Started process (PID=9779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:44.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:24:44.811+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:44.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:44.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:24:44.841+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:44.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:24:44.852+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:24:44.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:24:44.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:25:15.191+0000] {processor.py:157} INFO - Started process (PID=9789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:15.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:25:15.199+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:15.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:15.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:15.222+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:15.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:25:15.232+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:15.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:25:15.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:25:45.540+0000] {processor.py:157} INFO - Started process (PID=9799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:45.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:25:45.544+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:45.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:45.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:25:45.568+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:45.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:25:45.579+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:25:45.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:25:45.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:26:15.876+0000] {processor.py:157} INFO - Started process (PID=9809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:15.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:26:15.879+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:15.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:15.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:15.908+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:15.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:26:15.918+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:15.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:26:15.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:26:46.286+0000] {processor.py:157} INFO - Started process (PID=9819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:46.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:26:46.290+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:46.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:46.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:26:46.323+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:46.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:26:46.334+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:26:46.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:26:46.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T20:27:16.662+0000] {processor.py:157} INFO - Started process (PID=9828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:16.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:27:16.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:16.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:16.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:16.690+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:16.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:27:16.703+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:16.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:27:16.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:27:47.072+0000] {processor.py:157} INFO - Started process (PID=9839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:47.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:27:47.075+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:47.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:47.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:27:47.100+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:47.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:27:47.110+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:27:47.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:27:47.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T20:28:17.491+0000] {processor.py:157} INFO - Started process (PID=9849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:17.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:28:17.494+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:17.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:17.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:17.521+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:17.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:28:17.532+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:17.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:28:17.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:28:47.877+0000] {processor.py:157} INFO - Started process (PID=9859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:47.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:28:47.880+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:47.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:47.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:28:47.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:47.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:28:47.919+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:28:47.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:28:47.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:29:18.259+0000] {processor.py:157} INFO - Started process (PID=9869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:18.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:29:18.262+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:18.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:18.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:18.289+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:18.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:29:18.299+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:18.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:29:18.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:29:48.633+0000] {processor.py:157} INFO - Started process (PID=9879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:48.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:29:48.638+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:48.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:48.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:29:48.675+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:48.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:29:48.686+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:29:48.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:29:48.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T20:30:18.941+0000] {processor.py:157} INFO - Started process (PID=9889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:18.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:30:18.943+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:18.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:18.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:18.967+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:18.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:30:18.979+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:18.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:30:18.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:30:49.314+0000] {processor.py:157} INFO - Started process (PID=9899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:49.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:30:49.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:49.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:49.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:30:49.345+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:49.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:30:49.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:30:49.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:30:49.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:31:19.740+0000] {processor.py:157} INFO - Started process (PID=9909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:19.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:31:19.745+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:19.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:19.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:19.771+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:19.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:31:19.784+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:19.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:31:19.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:31:50.098+0000] {processor.py:157} INFO - Started process (PID=9919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:50.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:31:50.101+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:50.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:50.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:31:50.127+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:50.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:31:50.137+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:31:50.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:31:50.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:32:20.412+0000] {processor.py:157} INFO - Started process (PID=9929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:20.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:32:20.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:20.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:20.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:20.443+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:20.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:32:20.452+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:20.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:32:20.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:32:50.794+0000] {processor.py:157} INFO - Started process (PID=9939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:50.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:32:50.796+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:50.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:50.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:32:50.823+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:50.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:32:50.832+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:32:50.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:32:50.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T20:33:21.155+0000] {processor.py:157} INFO - Started process (PID=9949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:21.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:33:21.158+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:21.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:21.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:21.185+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:21.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:33:21.196+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:21.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:33:21.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:33:51.588+0000] {processor.py:157} INFO - Started process (PID=9959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:51.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:33:51.591+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:51.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:51.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:33:51.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:51.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:33:51.630+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:33:51.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:33:51.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:34:21.995+0000] {processor.py:157} INFO - Started process (PID=9969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:21.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:34:21.998+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:21.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:22.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:22.028+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:22.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:34:22.042+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:22.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:34:22.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T20:34:52.353+0000] {processor.py:157} INFO - Started process (PID=9979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:52.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:34:52.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:52.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:52.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:34:52.379+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:52.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:34:52.389+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:34:52.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:34:52.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T20:35:22.728+0000] {processor.py:157} INFO - Started process (PID=9989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:22.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:35:22.731+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:22.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:22.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:22.758+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:22.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:35:22.770+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:22.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:35:22.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:35:53.100+0000] {processor.py:157} INFO - Started process (PID=9999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:53.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:35:53.105+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:53.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:53.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:35:53.133+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:53.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:35:53.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:35:53.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:35:53.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:36:23.493+0000] {processor.py:157} INFO - Started process (PID=10009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:23.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:36:23.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:23.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:23.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:23.523+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:23.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:36:23.534+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:23.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:36:23.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T20:36:53.905+0000] {processor.py:157} INFO - Started process (PID=10019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:53.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:36:53.909+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:53.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:53.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:36:53.939+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:53.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:36:53.950+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:36:53.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:36:53.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:37:24.223+0000] {processor.py:157} INFO - Started process (PID=10029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:24.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:37:24.225+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:24.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:24.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:24.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:24.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:37:24.265+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:24.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:37:24.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:37:54.678+0000] {processor.py:157} INFO - Started process (PID=10039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:54.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:37:54.682+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:54.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:54.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:37:54.712+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:54.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:37:54.722+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:37:54.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:37:54.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:38:25.056+0000] {processor.py:157} INFO - Started process (PID=10049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:25.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:38:25.059+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:25.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:25.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:25.089+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:25.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:38:25.100+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:25.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:38:25.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T20:38:55.454+0000] {processor.py:157} INFO - Started process (PID=10059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:55.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:38:55.457+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:55.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:55.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:38:55.482+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:55.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:38:55.495+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:38:55.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:38:55.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:39:25.817+0000] {processor.py:157} INFO - Started process (PID=10069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:25.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:39:25.822+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:25.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:25.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:25.857+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:25.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:39:25.871+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:25.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:39:25.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T20:39:56.134+0000] {processor.py:157} INFO - Started process (PID=10079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:56.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:39:56.137+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:56.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:56.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:39:56.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:56.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:39:56.175+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:39:56.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:39:56.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:40:26.499+0000] {processor.py:157} INFO - Started process (PID=10089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:26.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:40:26.503+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:26.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:26.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:26.531+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:26.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:40:26.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:26.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:40:26.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:40:56.853+0000] {processor.py:157} INFO - Started process (PID=10099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:56.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:40:56.856+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:56.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:56.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:40:56.885+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:56.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:40:56.897+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:40:56.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:40:56.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T20:41:27.248+0000] {processor.py:157} INFO - Started process (PID=10109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:27.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:41:27.251+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:27.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:27.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:27.281+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:27.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:41:27.293+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:27.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:41:27.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T20:41:57.636+0000] {processor.py:157} INFO - Started process (PID=10119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:57.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:41:57.638+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:57.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:57.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:41:57.666+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:57.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:41:57.676+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:41:57.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:41:57.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T20:42:27.998+0000] {processor.py:157} INFO - Started process (PID=10129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:27.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:42:28.001+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:28.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:28.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:28.027+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:28.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:42:28.037+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:28.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:42:28.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:42:58.377+0000] {processor.py:157} INFO - Started process (PID=10139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:58.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:42:58.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:58.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:58.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:42:58.414+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:58.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:42:58.426+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:42:58.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:42:58.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T20:43:28.702+0000] {processor.py:157} INFO - Started process (PID=10149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:28.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:43:28.706+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:28.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:28.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:28.733+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:28.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:43:28.746+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:28.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:43:28.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:43:59.097+0000] {processor.py:157} INFO - Started process (PID=10159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:59.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:43:59.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:59.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:59.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:43:59.127+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:59.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:43:59.138+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:43:59.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:43:59.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:44:29.518+0000] {processor.py:157} INFO - Started process (PID=10169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:29.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:44:29.523+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:29.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:29.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:29.550+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:29.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:44:29.561+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:29.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:44:29.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T20:44:59.907+0000] {processor.py:157} INFO - Started process (PID=10179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:59.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:44:59.910+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:59.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:59.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:44:59.935+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:59.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:44:59.945+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:44:59.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:44:59.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:45:30.291+0000] {processor.py:157} INFO - Started process (PID=10189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:45:30.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:45:30.293+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:45:30.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:45:30.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:45:30.316+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:45:30.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:45:30.327+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:45:30.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:45:30.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T20:46:00.688+0000] {processor.py:157} INFO - Started process (PID=10199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:00.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:46:00.692+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:00.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:00.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:00.717+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:00.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:46:00.729+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:00.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:46:00.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T20:46:31.147+0000] {processor.py:157} INFO - Started process (PID=10209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:31.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:46:31.150+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:31.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:31.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:46:31.179+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:31.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:46:31.189+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:46:31.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:46:31.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:47:01.563+0000] {processor.py:157} INFO - Started process (PID=10219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:01.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:47:01.566+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:01.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:01.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:01.591+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:01.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:47:01.601+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:01.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:47:01.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T20:47:31.938+0000] {processor.py:157} INFO - Started process (PID=10229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:31.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:47:31.947+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:31.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:31.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:47:31.981+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:31.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:47:31.993+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:47:31.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:47:32.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T20:48:02.350+0000] {processor.py:157} INFO - Started process (PID=10239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:02.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:48:02.352+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:02.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:02.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:02.377+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:02.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:48:02.387+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:02.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:48:02.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-09T20:48:32.724+0000] {processor.py:157} INFO - Started process (PID=10249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:32.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:48:32.727+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:32.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:32.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:48:32.757+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:32.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:48:32.767+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:48:32.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:48:32.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:49:03.070+0000] {processor.py:157} INFO - Started process (PID=10259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:03.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:49:03.072+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:03.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:03.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:03.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:49:03.115+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:03.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:49:03.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:49:33.443+0000] {processor.py:157} INFO - Started process (PID=10269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:33.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:49:33.446+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:33.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:33.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:49:33.480+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:33.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:49:33.492+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:49:33.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:49:33.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T20:50:03.833+0000] {processor.py:157} INFO - Started process (PID=10279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:03.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:50:03.836+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:03.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:03.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:03.870+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:03.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:50:03.881+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:03.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:50:03.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T20:50:34.202+0000] {processor.py:157} INFO - Started process (PID=10289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:34.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:50:34.207+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:34.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:34.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:50:34.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:34.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:50:34.249+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:50:34.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:50:34.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:51:04.582+0000] {processor.py:157} INFO - Started process (PID=10299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:04.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:51:04.585+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:04.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:04.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:04.613+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:04.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:51:04.625+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:04.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:51:04.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:51:34.997+0000] {processor.py:157} INFO - Started process (PID=10309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:34.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:51:35.001+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:35.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:35.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:51:35.037+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:35.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:51:35.048+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:51:35.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:51:35.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T20:52:05.345+0000] {processor.py:157} INFO - Started process (PID=10319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:05.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:52:05.349+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:05.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:05.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:05.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:05.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:52:05.395+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:05.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:52:05.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T20:52:35.727+0000] {processor.py:157} INFO - Started process (PID=10329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:35.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:52:35.730+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:35.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:35.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:52:35.759+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:35.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:52:35.770+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:52:35.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:52:35.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T20:53:06.130+0000] {processor.py:157} INFO - Started process (PID=10339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:06.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:53:06.134+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:06.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:06.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:06.159+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:06.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:53:06.169+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:06.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:53:06.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T20:53:36.543+0000] {processor.py:157} INFO - Started process (PID=10349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:36.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:53:36.546+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:36.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:36.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:53:36.574+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:36.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:53:36.586+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:53:36.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:53:36.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:54:06.879+0000] {processor.py:157} INFO - Started process (PID=10359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:06.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:54:06.883+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:06.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:06.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:06.914+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:06.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:54:06.926+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:06.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:54:06.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:54:37.274+0000] {processor.py:157} INFO - Started process (PID=10369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:37.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:54:37.278+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:37.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:37.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:54:37.311+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:37.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:54:37.322+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:54:37.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:54:37.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T20:55:07.686+0000] {processor.py:157} INFO - Started process (PID=10379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:07.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:55:07.689+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:07.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:07.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:07.715+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:07.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:55:07.725+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:07.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:55:07.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:55:38.025+0000] {processor.py:157} INFO - Started process (PID=10389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:38.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:55:38.028+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:38.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:38.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:55:38.055+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:38.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:55:38.065+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:55:38.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:55:38.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T20:56:08.433+0000] {processor.py:157} INFO - Started process (PID=10399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:08.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:56:08.438+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:08.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:08.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:08.472+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:08.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:56:08.484+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:08.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:56:08.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T20:56:38.852+0000] {processor.py:157} INFO - Started process (PID=10409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:38.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:56:38.854+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:38.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:38.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:56:38.883+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:38.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:56:38.891+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:56:38.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:56:38.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T20:57:09.200+0000] {processor.py:157} INFO - Started process (PID=10419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:09.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:57:09.202+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:09.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:09.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:09.230+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:09.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:57:09.240+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:09.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:57:09.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T20:57:39.520+0000] {processor.py:157} INFO - Started process (PID=10429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:39.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:57:39.523+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:39.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:39.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:57:39.552+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:39.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:57:39.564+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:57:39.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:57:39.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T20:58:09.969+0000] {processor.py:157} INFO - Started process (PID=10439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:58:09.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T20:58:09.973+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:58:09.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:58:09.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T20:58:10.012+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:58:10.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T20:58:10.024+0000] {logging_mixin.py:151} INFO - [2024-08-09T20:58:10.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T20:58:10.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T21:14:06.709+0000] {processor.py:157} INFO - Started process (PID=10450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:06.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:14:06.718+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:06.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:06.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:06.781+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:06.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:14:06.803+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:06.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:14:06.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-09T21:14:37.130+0000] {processor.py:157} INFO - Started process (PID=10461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:37.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:14:37.140+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:37.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:37.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:14:37.179+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:37.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:14:37.200+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:14:37.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:14:37.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-09T21:15:07.441+0000] {processor.py:157} INFO - Started process (PID=10471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:07.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:15:07.446+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:07.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:07.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:07.479+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:07.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:15:07.492+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:07.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:15:07.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T21:15:37.737+0000] {processor.py:157} INFO - Started process (PID=10481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:37.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:15:37.740+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:37.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:37.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:15:37.765+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:37.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:15:37.774+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:15:37.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:15:37.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T21:16:08.092+0000] {processor.py:157} INFO - Started process (PID=10491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:08.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:16:08.095+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:08.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:08.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:08.122+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:08.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:16:08.132+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:08.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:16:08.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:16:38.453+0000] {processor.py:157} INFO - Started process (PID=10501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:38.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:16:38.458+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:38.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:38.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:16:38.495+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:38.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:16:38.506+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:16:38.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:16:38.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T21:17:08.834+0000] {processor.py:157} INFO - Started process (PID=10511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:08.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:17:08.837+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:08.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:08.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:08.868+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:08.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:17:08.880+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:08.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:17:08.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T21:17:39.206+0000] {processor.py:157} INFO - Started process (PID=10521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:39.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:17:39.211+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:39.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:39.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:17:39.245+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:39.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:17:39.256+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:17:39.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:17:39.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T21:18:09.589+0000] {processor.py:157} INFO - Started process (PID=10531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:09.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:18:09.591+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:09.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:09.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:09.619+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:09.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:18:09.629+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:09.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:18:09.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:18:39.955+0000] {processor.py:157} INFO - Started process (PID=10541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:39.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:18:39.957+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:39.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:39.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:18:39.984+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:39.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:18:39.995+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:18:39.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:18:40.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:19:10.300+0000] {processor.py:157} INFO - Started process (PID=10551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:10.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:19:10.302+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:10.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:10.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:10.331+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:10.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:19:10.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:10.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:19:10.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:19:40.652+0000] {processor.py:157} INFO - Started process (PID=10561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:40.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:19:40.654+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:40.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:40.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:19:40.680+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:40.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:19:40.694+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:19:40.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:19:40.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:20:11.000+0000] {processor.py:157} INFO - Started process (PID=10571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:11.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:20:11.004+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:11.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:11.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:11.031+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:11.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:20:11.044+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:11.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:20:11.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:20:41.338+0000] {processor.py:157} INFO - Started process (PID=10581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:41.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:20:41.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:41.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:41.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:20:41.373+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:41.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:20:41.386+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:20:41.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:20:41.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T21:21:11.715+0000] {processor.py:157} INFO - Started process (PID=10591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:11.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:21:11.718+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:11.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:11.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:11.751+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:11.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:21:11.763+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:11.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:21:11.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:21:42.092+0000] {processor.py:157} INFO - Started process (PID=10601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:42.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:21:42.095+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:42.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:42.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:21:42.125+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:42.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:21:42.137+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:21:42.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:21:42.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T21:22:12.439+0000] {processor.py:157} INFO - Started process (PID=10611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:12.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:22:12.442+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:12.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:12.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:12.469+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:12.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:22:12.479+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:12.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:22:12.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T21:22:42.812+0000] {processor.py:157} INFO - Started process (PID=10621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:42.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:22:42.815+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:42.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:42.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:22:42.844+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:42.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:22:42.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:22:42.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:22:42.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T21:23:13.195+0000] {processor.py:157} INFO - Started process (PID=10631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:13.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:23:13.199+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:13.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:13.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:13.232+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:13.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:23:13.243+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:13.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:23:13.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:23:43.588+0000] {processor.py:157} INFO - Started process (PID=10641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:43.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:23:43.590+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:43.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:43.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:23:43.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:43.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:23:43.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:23:43.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:23:43.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T21:24:13.959+0000] {processor.py:157} INFO - Started process (PID=10651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:13.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:24:13.961+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:13.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:13.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:13.990+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:13.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:24:14.001+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:14.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:24:14.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:24:44.290+0000] {processor.py:157} INFO - Started process (PID=10661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:44.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:24:44.300+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:44.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:44.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:24:44.331+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:44.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:24:44.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:24:44.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:24:44.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T21:25:14.613+0000] {processor.py:157} INFO - Started process (PID=10671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:14.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:25:14.616+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:14.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:14.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:14.650+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:14.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:25:14.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:14.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:25:14.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T21:25:44.983+0000] {processor.py:157} INFO - Started process (PID=10681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:44.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:25:44.986+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:44.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:44.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:25:45.013+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:45.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:25:45.024+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:25:45.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:25:45.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:26:15.354+0000] {processor.py:157} INFO - Started process (PID=10691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:15.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:26:15.357+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:15.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:15.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:15.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:15.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:26:15.404+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:15.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:26:15.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T21:26:45.693+0000] {processor.py:157} INFO - Started process (PID=10701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:45.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:26:45.695+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:45.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:45.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:26:45.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:45.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:26:45.735+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:26:45.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:26:45.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:27:16.062+0000] {processor.py:157} INFO - Started process (PID=10711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:16.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:27:16.064+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:16.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:16.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:16.094+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:16.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:27:16.103+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:16.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:27:16.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:27:46.401+0000] {processor.py:157} INFO - Started process (PID=10721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:46.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:27:46.404+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:46.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:46.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:27:46.431+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:46.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:27:46.442+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:27:46.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:27:46.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:28:16.710+0000] {processor.py:157} INFO - Started process (PID=10731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:16.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:28:16.713+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:16.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:16.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:16.744+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:16.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:28:16.755+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:16.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:28:16.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T21:28:47.065+0000] {processor.py:157} INFO - Started process (PID=10741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:47.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:28:47.068+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:47.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:47.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:28:47.096+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:47.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:28:47.106+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:28:47.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:28:47.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:29:17.470+0000] {processor.py:157} INFO - Started process (PID=10751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:17.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:29:17.474+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:17.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:17.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:17.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:17.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:29:17.513+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:17.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:29:17.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:29:47.837+0000] {processor.py:157} INFO - Started process (PID=10761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:47.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:29:47.842+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:47.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:47.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:29:47.869+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:47.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:29:47.879+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:29:47.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:29:47.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T21:30:18.239+0000] {processor.py:157} INFO - Started process (PID=10771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:18.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:30:18.242+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:18.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:18.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:18.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:18.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:30:18.290+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:18.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:30:18.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T21:30:48.536+0000] {processor.py:157} INFO - Started process (PID=10781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:48.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:30:48.540+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:48.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:48.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:30:48.570+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:48.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:30:48.581+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:30:48.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:30:48.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T21:31:18.844+0000] {processor.py:157} INFO - Started process (PID=10791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:18.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:31:18.847+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:18.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:18.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:18.874+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:18.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:31:18.886+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:18.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:31:18.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:31:49.094+0000] {processor.py:157} INFO - Started process (PID=10801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:49.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:31:49.097+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:49.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:49.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:31:49.132+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:31:49.142+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:31:49.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:31:49.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:32:19.453+0000] {processor.py:157} INFO - Started process (PID=10811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:19.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:32:19.457+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:19.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:19.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:19.488+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:19.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:32:19.499+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:19.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:32:19.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T21:32:49.846+0000] {processor.py:157} INFO - Started process (PID=10821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:49.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:32:49.851+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:49.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:49.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:32:49.878+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:49.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:32:49.888+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:32:49.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:32:49.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:33:20.186+0000] {processor.py:157} INFO - Started process (PID=10831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:20.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:33:20.189+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:20.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:20.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:20.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:20.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:33:20.228+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:20.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:33:20.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:33:50.566+0000] {processor.py:157} INFO - Started process (PID=10841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:50.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:33:50.574+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:50.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:50.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:33:50.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:50.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:33:50.609+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:33:50.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:33:50.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:34:20.973+0000] {processor.py:157} INFO - Started process (PID=10851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:20.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:34:20.977+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:20.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:20.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:21.003+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:21.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:34:21.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:21.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:34:21.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:34:51.344+0000] {processor.py:157} INFO - Started process (PID=10861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:51.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:34:51.347+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:51.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:51.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:34:51.375+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:51.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:34:51.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:34:51.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:34:51.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:35:21.693+0000] {processor.py:157} INFO - Started process (PID=10871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:21.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:35:21.696+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:21.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:21.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:21.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:21.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:35:21.735+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:21.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:35:21.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:35:52.016+0000] {processor.py:157} INFO - Started process (PID=10881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:52.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:35:52.019+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:52.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:52.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:35:52.056+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:52.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:35:52.069+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:35:52.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:35:52.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T21:36:22.391+0000] {processor.py:157} INFO - Started process (PID=10891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:22.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:36:22.396+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:22.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:22.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:22.433+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:22.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:36:22.445+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:22.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:36:22.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T21:36:52.706+0000] {processor.py:157} INFO - Started process (PID=10901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:52.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:36:52.712+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:52.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:52.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:36:52.741+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:52.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:36:52.752+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:36:52.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:36:52.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T21:37:23.093+0000] {processor.py:157} INFO - Started process (PID=10911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:23.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:37:23.096+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:23.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:23.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:23.134+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:23.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:37:23.149+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:23.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:37:23.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-09T21:37:53.346+0000] {processor.py:157} INFO - Started process (PID=10921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:53.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:37:53.351+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:53.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:53.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:37:53.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:53.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:37:53.402+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:37:53.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:37:53.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T21:38:23.744+0000] {processor.py:157} INFO - Started process (PID=10931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:23.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:38:23.747+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:23.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:23.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:23.774+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:23.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:38:23.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:23.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:38:23.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:38:54.139+0000] {processor.py:157} INFO - Started process (PID=10941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:54.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:38:54.142+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:54.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:54.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:38:54.176+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:54.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:38:54.188+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:38:54.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:38:54.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T21:39:24.500+0000] {processor.py:157} INFO - Started process (PID=10951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:24.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:39:24.507+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:24.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:24.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:24.538+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:24.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:39:24.550+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:24.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:39:24.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T21:39:54.876+0000] {processor.py:157} INFO - Started process (PID=10961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:54.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:39:54.880+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:54.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:54.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:39:54.912+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:54.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:39:54.923+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:39:54.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:39:54.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T21:40:25.190+0000] {processor.py:157} INFO - Started process (PID=10971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:25.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:40:25.194+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:25.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:25.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:25.230+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:25.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:40:25.241+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:25.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:40:25.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T21:40:55.569+0000] {processor.py:157} INFO - Started process (PID=10981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:55.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:40:55.572+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:55.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:55.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:40:55.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:55.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:40:55.608+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:40:55.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:40:55.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T21:41:25.950+0000] {processor.py:157} INFO - Started process (PID=10991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:25.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:41:25.953+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:25.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:25.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:25.982+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:25.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:41:25.992+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:25.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:41:26.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:41:56.274+0000] {processor.py:157} INFO - Started process (PID=11001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:41:56.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:56.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:56.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:41:56.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:56.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:41:56.311+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:41:56.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:41:56.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T21:42:26.624+0000] {processor.py:157} INFO - Started process (PID=11011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:26.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:42:26.629+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:26.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:26.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:26.664+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:26.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:42:26.677+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:26.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:42:26.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T21:42:56.998+0000] {processor.py:157} INFO - Started process (PID=11021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:56.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:42:57.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:57.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:57.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:42:57.028+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:57.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:42:57.038+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:42:57.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:42:57.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T21:43:27.305+0000] {processor.py:157} INFO - Started process (PID=11031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:27.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:43:27.308+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:27.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:27.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:27.335+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:27.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:43:27.350+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:27.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:43:27.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T21:43:57.597+0000] {processor.py:157} INFO - Started process (PID=11041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:57.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:43:57.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:57.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:57.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:43:57.629+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:57.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:43:57.641+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:43:57.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:43:57.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:44:27.978+0000] {processor.py:157} INFO - Started process (PID=11051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:27.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:44:27.982+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:27.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:27.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:28.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:28.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:44:28.025+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:28.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:44:28.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:44:58.358+0000] {processor.py:157} INFO - Started process (PID=11061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:58.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:44:58.360+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:58.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:58.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:44:58.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:58.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:44:58.400+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:44:58.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:44:58.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:45:28.739+0000] {processor.py:157} INFO - Started process (PID=11071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:28.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:45:28.743+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:28.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:28.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:28.779+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:28.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:45:28.792+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:28.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:45:28.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T21:45:59.110+0000] {processor.py:157} INFO - Started process (PID=11081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:59.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:45:59.113+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:59.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:59.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:45:59.142+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:59.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:45:59.152+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:45:59.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:45:59.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:46:29.473+0000] {processor.py:157} INFO - Started process (PID=11091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:29.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:46:29.476+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:29.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:29.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:29.511+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:29.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:46:29.523+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:29.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:46:29.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T21:46:59.845+0000] {processor.py:157} INFO - Started process (PID=11101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:59.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:46:59.849+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:59.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:59.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:46:59.877+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:59.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:46:59.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:46:59.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:46:59.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:47:30.172+0000] {processor.py:157} INFO - Started process (PID=11111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:47:30.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:47:30.175+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:47:30.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:47:30.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:47:30.201+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:47:30.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:47:30.212+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:47:30.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:47:30.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T21:48:00.480+0000] {processor.py:157} INFO - Started process (PID=11121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:00.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:48:00.484+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:00.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:00.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:00.509+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:00.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:48:00.519+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:00.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:48:00.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:48:30.852+0000] {processor.py:157} INFO - Started process (PID=11131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:30.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:48:30.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:30.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:30.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:48:30.881+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:30.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:48:30.890+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:48:30.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:48:30.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T21:49:01.152+0000] {processor.py:157} INFO - Started process (PID=11141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:01.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:49:01.154+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:01.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:01.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:01.178+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:01.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:49:01.189+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:01.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:49:01.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T21:49:31.455+0000] {processor.py:157} INFO - Started process (PID=11151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:31.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:49:31.458+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:31.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:31.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:49:31.481+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:31.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:49:31.493+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:49:31.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:49:31.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T21:50:01.818+0000] {processor.py:157} INFO - Started process (PID=11161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:01.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:50:01.821+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:01.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:01.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:01.850+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:01.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:50:01.863+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:01.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:50:01.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T21:50:32.127+0000] {processor.py:157} INFO - Started process (PID=11171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:32.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:50:32.131+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:32.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:32.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:50:32.161+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:32.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:50:32.175+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:50:32.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:50:32.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T21:51:02.507+0000] {processor.py:157} INFO - Started process (PID=11181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:02.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:51:02.509+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:02.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:02.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:02.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:02.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:51:02.553+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:02.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:51:02.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:51:32.857+0000] {processor.py:157} INFO - Started process (PID=11191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:32.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:51:32.861+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:32.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:32.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:51:32.893+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:32.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:51:32.907+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:51:32.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:51:32.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T21:52:03.306+0000] {processor.py:157} INFO - Started process (PID=11201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:03.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:52:03.310+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:03.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:03.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:03.343+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:03.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:52:03.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:03.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:52:03.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T21:52:33.692+0000] {processor.py:157} INFO - Started process (PID=11211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:33.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:52:33.695+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:33.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:33.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:52:33.720+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:33.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:52:33.731+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:52:33.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:52:33.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T21:53:04.046+0000] {processor.py:157} INFO - Started process (PID=11221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:04.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:53:04.049+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:04.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:04.076+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:04.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:53:04.086+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:04.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:53:04.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T21:53:34.360+0000] {processor.py:157} INFO - Started process (PID=11231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:34.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:53:34.363+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:34.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:34.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:53:34.391+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:34.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:53:34.402+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:53:34.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:53:34.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:54:04.729+0000] {processor.py:157} INFO - Started process (PID=11241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:04.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:54:04.733+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:04.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:04.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:04.767+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:04.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:54:04.779+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:04.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:54:04.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T21:54:35.109+0000] {processor.py:157} INFO - Started process (PID=11251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:35.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:54:35.111+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:35.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:35.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:54:35.140+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:35.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:54:35.151+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:54:35.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:54:35.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T21:55:05.396+0000] {processor.py:157} INFO - Started process (PID=11261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:05.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:55:05.401+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:05.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:05.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:05.434+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:05.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:55:05.445+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:05.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:55:05.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T21:55:35.720+0000] {processor.py:157} INFO - Started process (PID=11271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:35.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:55:35.724+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:35.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:35.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:55:35.750+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:35.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:55:35.762+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:55:35.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:55:35.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T21:56:06.029+0000] {processor.py:157} INFO - Started process (PID=11281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:06.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:56:06.032+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:06.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:06.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:06.057+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:06.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:56:06.068+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:06.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:56:06.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T21:56:36.375+0000] {processor.py:157} INFO - Started process (PID=11291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:36.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:56:36.378+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:36.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:36.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:56:36.405+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:36.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:56:36.417+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:56:36.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:56:36.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T21:57:06.711+0000] {processor.py:157} INFO - Started process (PID=11301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:06.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:57:06.714+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:06.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:06.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:06.739+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:06.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:57:06.749+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:06.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:57:06.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T21:57:37.000+0000] {processor.py:157} INFO - Started process (PID=11311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:37.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:57:37.004+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:37.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:37.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:57:37.036+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:37.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:57:37.048+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:57:37.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:57:37.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T21:58:07.384+0000] {processor.py:157} INFO - Started process (PID=11321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:07.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:58:07.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:07.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:07.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:07.426+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:07.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:58:07.438+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:07.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:58:07.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T21:58:37.773+0000] {processor.py:157} INFO - Started process (PID=11331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:37.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:58:37.776+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:37.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:37.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:58:37.806+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:37.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:58:37.818+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:58:37.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:58:37.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T21:59:08.098+0000] {processor.py:157} INFO - Started process (PID=11341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:08.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:59:08.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:08.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:08.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:08.132+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:08.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:59:08.145+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:08.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:59:08.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T21:59:38.485+0000] {processor.py:157} INFO - Started process (PID=11351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:38.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T21:59:38.487+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:38.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:38.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T21:59:38.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:38.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T21:59:38.527+0000] {logging_mixin.py:151} INFO - [2024-08-09T21:59:38.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T21:59:38.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:00:08.805+0000] {processor.py:157} INFO - Started process (PID=11361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:08.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:00:08.809+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:08.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:08.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:08.842+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:08.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:00:08.853+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:08.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:00:08.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T22:00:39.160+0000] {processor.py:157} INFO - Started process (PID=11371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:39.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:00:39.162+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:39.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:39.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:00:39.190+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:39.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:00:39.200+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:00:39.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:00:39.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:01:09.475+0000] {processor.py:157} INFO - Started process (PID=11381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:09.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:01:09.477+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:09.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:09.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:09.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:09.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:01:09.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:09.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:01:09.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:01:39.799+0000] {processor.py:157} INFO - Started process (PID=11391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:39.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:01:39.801+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:39.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:39.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:01:39.827+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:39.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:01:39.838+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:01:39.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:01:39.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:02:10.141+0000] {processor.py:157} INFO - Started process (PID=11401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:10.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:02:10.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:10.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:10.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:10.169+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:10.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:02:10.182+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:10.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:02:10.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T22:02:40.514+0000] {processor.py:157} INFO - Started process (PID=11411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:40.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:02:40.517+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:40.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:40.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:02:40.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:40.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:02:40.553+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:02:40.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:02:40.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:03:10.811+0000] {processor.py:157} INFO - Started process (PID=11421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:10.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:03:10.815+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:10.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:10.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:10.846+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:10.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:03:10.859+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:10.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:03:10.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T22:03:41.192+0000] {processor.py:157} INFO - Started process (PID=11431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:41.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:03:41.195+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:41.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:41.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:03:41.230+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:41.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:03:41.244+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:03:41.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:03:41.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T22:04:11.539+0000] {processor.py:157} INFO - Started process (PID=11441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:11.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:04:11.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:11.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:11.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:11.582+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:11.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:04:11.593+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:11.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:04:11.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T22:04:41.845+0000] {processor.py:157} INFO - Started process (PID=11451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:41.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:04:41.848+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:41.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:41.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:04:41.878+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:41.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:04:41.890+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:04:41.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:04:41.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T22:05:12.246+0000] {processor.py:157} INFO - Started process (PID=11461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:12.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:05:12.250+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:12.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:12.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:12.283+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:12.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:05:12.296+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:12.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:05:12.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T22:05:42.559+0000] {processor.py:157} INFO - Started process (PID=11471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:42.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:05:42.564+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:42.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:42.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:05:42.601+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:42.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:05:42.616+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:05:42.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:05:42.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T22:06:12.857+0000] {processor.py:157} INFO - Started process (PID=11481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:12.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:06:12.861+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:12.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:12.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:12.896+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:12.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:06:12.911+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:12.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:06:12.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T22:06:43.245+0000] {processor.py:157} INFO - Started process (PID=11491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:43.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:06:43.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:43.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:43.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:06:43.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:43.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:06:43.288+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:06:43.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:06:43.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T22:07:13.672+0000] {processor.py:157} INFO - Started process (PID=11501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:13.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:07:13.693+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:13.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:13.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:13.781+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:13.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:07:13.802+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:13.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:07:13.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-09T22:07:43.920+0000] {processor.py:157} INFO - Started process (PID=11511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:43.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:07:43.928+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:43.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:43.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:07:43.955+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:43.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:07:43.964+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:07:43.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:07:43.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:08:14.280+0000] {processor.py:157} INFO - Started process (PID=11521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:14.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:08:14.287+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:14.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:14.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:14.332+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:14.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:08:14.345+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:14.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:08:14.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-09T22:08:44.559+0000] {processor.py:157} INFO - Started process (PID=11531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:44.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:08:44.562+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:44.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:44.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:08:44.588+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:44.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:08:44.598+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:08:44.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:08:44.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T22:09:14.892+0000] {processor.py:157} INFO - Started process (PID=11541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:14.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:09:14.894+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:14.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:14.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:14.920+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:14.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:09:14.930+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:14.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:09:14.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T22:09:45.267+0000] {processor.py:157} INFO - Started process (PID=11551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:45.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:09:45.272+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:45.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:45.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:09:45.323+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:45.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:09:45.339+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:09:45.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:09:45.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-09T22:10:15.568+0000] {processor.py:157} INFO - Started process (PID=11561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:15.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:10:15.570+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:15.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:15.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:15.599+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:15.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:10:15.610+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:15.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:10:15.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T22:10:45.869+0000] {processor.py:157} INFO - Started process (PID=11571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:45.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:10:45.872+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:45.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:45.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:10:45.900+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:45.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:10:45.912+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:10:45.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:10:45.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:11:16.248+0000] {processor.py:157} INFO - Started process (PID=11581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:16.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:11:16.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:16.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:16.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:16.295+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:16.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:11:16.309+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:16.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:11:16.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T22:11:46.633+0000] {processor.py:157} INFO - Started process (PID=11591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:46.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:11:46.636+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:46.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:46.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:11:46.664+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:46.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:11:46.677+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:11:46.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:11:46.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T22:12:17.011+0000] {processor.py:157} INFO - Started process (PID=11601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:17.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:12:17.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:17.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:17.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:17.042+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:17.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:12:17.054+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:17.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:12:17.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:12:47.378+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:47.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:12:47.381+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:47.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:47.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:12:47.410+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:47.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:12:47.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:12:47.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:12:47.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:13:17.743+0000] {processor.py:157} INFO - Started process (PID=11621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:17.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:13:17.747+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:17.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:17.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:17.779+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:17.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:13:17.791+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:17.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:13:17.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T22:13:48.093+0000] {processor.py:157} INFO - Started process (PID=11631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:48.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:13:48.095+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:48.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:48.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:13:48.122+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:48.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:13:48.131+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:13:48.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:13:48.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T22:14:18.527+0000] {processor.py:157} INFO - Started process (PID=11641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:18.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:14:18.531+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:18.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:18.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:18.573+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:18.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:14:18.586+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:18.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:14:18.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T22:14:48.807+0000] {processor.py:157} INFO - Started process (PID=11651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:48.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:14:48.810+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:48.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:48.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:14:48.837+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:48.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:14:48.847+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:14:48.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:14:48.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:15:19.116+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:19.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:15:19.118+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:19.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:19.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:19.152+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:19.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:15:19.165+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:19.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:15:19.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T22:15:49.444+0000] {processor.py:157} INFO - Started process (PID=11671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:49.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:15:49.449+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:49.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:49.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:15:49.480+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:49.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:15:49.491+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:15:49.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:15:49.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T22:16:19.822+0000] {processor.py:157} INFO - Started process (PID=11681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:19.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:16:19.827+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:19.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:19.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:19.890+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:19.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:16:19.904+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:19.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:16:19.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-09T22:16:50.231+0000] {processor.py:157} INFO - Started process (PID=11691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:50.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:16:50.235+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:50.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:50.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:16:50.262+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:50.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:16:50.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:16:50.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:16:50.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T22:17:20.620+0000] {processor.py:157} INFO - Started process (PID=11701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:20.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:17:20.625+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:20.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:20.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:20.665+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:20.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:17:20.676+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:20.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:17:20.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T22:17:51.006+0000] {processor.py:157} INFO - Started process (PID=11711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:51.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:17:51.010+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:51.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:51.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:17:51.046+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:51.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:17:51.058+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:17:51.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:17:51.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T22:18:21.385+0000] {processor.py:157} INFO - Started process (PID=11721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:21.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:18:21.388+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:21.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:21.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:21.417+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:21.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:18:21.429+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:21.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:18:21.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T22:18:51.767+0000] {processor.py:157} INFO - Started process (PID=11731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:51.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:18:51.769+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:51.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:51.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:18:51.800+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:51.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:18:51.813+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:18:51.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:18:51.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T22:19:22.164+0000] {processor.py:157} INFO - Started process (PID=11741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:22.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:19:22.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:22.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:22.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:22.193+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:22.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:19:22.205+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:22.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:19:22.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:19:52.511+0000] {processor.py:157} INFO - Started process (PID=11751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:52.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:19:52.516+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:52.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:52.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:19:52.548+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:52.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:19:52.559+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:19:52.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:19:52.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T22:20:22.805+0000] {processor.py:157} INFO - Started process (PID=11761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:22.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:20:22.811+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:22.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:22.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:22.877+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:22.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:20:22.896+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:22.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:20:22.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-09T22:20:53.179+0000] {processor.py:157} INFO - Started process (PID=11771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:53.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:20:53.182+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:53.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:53.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:20:53.208+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:53.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:20:53.218+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:20:53.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:20:53.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:21:23.472+0000] {processor.py:157} INFO - Started process (PID=11781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:23.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:21:23.477+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:23.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:23.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:23.518+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:23.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:21:23.529+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:23.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:21:23.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T22:21:53.868+0000] {processor.py:157} INFO - Started process (PID=11791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:53.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:21:53.872+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:53.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:53.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:21:53.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:53.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:21:53.921+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:21:53.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:21:53.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T22:22:24.178+0000] {processor.py:157} INFO - Started process (PID=11801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:24.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:22:24.180+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:24.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:24.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:24.209+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:24.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:22:24.218+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:24.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:22:24.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:22:54.552+0000] {processor.py:157} INFO - Started process (PID=11811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:54.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:22:54.555+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:54.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:54.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:22:54.579+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:54.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:22:54.588+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:22:54.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:22:54.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T22:23:24.933+0000] {processor.py:157} INFO - Started process (PID=11821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:24.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:23:24.936+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:24.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:24.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:24.962+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:24.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:23:24.975+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:24.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:23:24.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:23:55.294+0000] {processor.py:157} INFO - Started process (PID=11831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:55.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:23:55.298+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:55.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:55.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:23:55.329+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:55.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:23:55.339+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:23:55.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:23:55.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T22:24:25.635+0000] {processor.py:157} INFO - Started process (PID=11841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:25.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:24:25.642+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:25.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:25.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:25.680+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:25.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:24:25.692+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:25.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:24:25.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T22:24:56.002+0000] {processor.py:157} INFO - Started process (PID=11851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:56.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:24:56.005+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:56.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:56.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:24:56.030+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:56.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:24:56.040+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:24:56.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:24:56.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:25:26.380+0000] {processor.py:157} INFO - Started process (PID=11861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:26.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:25:26.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:26.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:26.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:26.410+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:26.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:25:26.422+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:26.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:25:26.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:25:56.742+0000] {processor.py:157} INFO - Started process (PID=11871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:56.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:25:56.745+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:56.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:56.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:25:56.772+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:56.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:25:56.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:25:56.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:25:56.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:26:27.096+0000] {processor.py:157} INFO - Started process (PID=11881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:27.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:26:27.098+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:27.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:27.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:27.122+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:27.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:26:27.132+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:27.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:26:27.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T22:26:57.450+0000] {processor.py:157} INFO - Started process (PID=11891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:57.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:26:57.458+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:57.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:57.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:26:57.510+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:57.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:26:57.522+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:26:57.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:26:57.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-09T22:27:27.762+0000] {processor.py:157} INFO - Started process (PID=11901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:27.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:27:27.766+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:27.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:27.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:27.795+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:27.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:27:27.807+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:27.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:27:27.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T22:27:58.128+0000] {processor.py:157} INFO - Started process (PID=11911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:58.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:27:58.130+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:58.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:58.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:27:58.156+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:58.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:27:58.168+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:27:58.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:27:58.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:28:28.445+0000] {processor.py:157} INFO - Started process (PID=11921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:28.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:28:28.448+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:28.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:28.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:28.474+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:28.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:28:28.484+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:28.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:28:28.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:28:58.821+0000] {processor.py:157} INFO - Started process (PID=11931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:58.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:28:58.827+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:58.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:58.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:28:58.867+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:58.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:28:58.878+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:28:58.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:28:58.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T22:29:29.192+0000] {processor.py:157} INFO - Started process (PID=11941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:29.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:29:29.196+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:29.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:29.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:29.229+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:29.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:29:29.244+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:29.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:29:29.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T22:29:59.572+0000] {processor.py:157} INFO - Started process (PID=11951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:59.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:29:59.575+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:59.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:59.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:29:59.601+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:59.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:29:59.611+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:29:59.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:29:59.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:30:29.935+0000] {processor.py:157} INFO - Started process (PID=11961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:30:29.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:30:29.938+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:30:29.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:30:29.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:30:29.964+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:30:29.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:30:29.975+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:30:29.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:30:29.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:31:00.204+0000] {processor.py:157} INFO - Started process (PID=11971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:00.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:31:00.206+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:00.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:00.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:00.234+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:00.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:31:00.243+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:00.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:31:00.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:31:30.560+0000] {processor.py:157} INFO - Started process (PID=11981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:30.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:31:30.568+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:30.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:30.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:31:30.621+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:30.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:31:30.634+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:31:30.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:31:30.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-09T22:32:00.890+0000] {processor.py:157} INFO - Started process (PID=11991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:00.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:32:00.894+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:00.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:00.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:00.918+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:00.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:32:00.928+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:00.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:32:00.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T22:32:31.230+0000] {processor.py:157} INFO - Started process (PID=12001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:31.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:32:31.235+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:31.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:31.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:32:31.261+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:31.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:32:31.272+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:32:31.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:32:31.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T22:33:01.591+0000] {processor.py:157} INFO - Started process (PID=12011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:01.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:33:01.594+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:01.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:01.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:01.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:01.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:33:01.628+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:01.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:33:01.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T22:33:31.943+0000] {processor.py:157} INFO - Started process (PID=12021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:31.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:33:31.948+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:31.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:31.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:33:31.987+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:31.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:33:32.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:33:32.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:33:32.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T22:34:02.223+0000] {processor.py:157} INFO - Started process (PID=12031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:02.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:34:02.227+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:02.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:02.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:02.260+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:02.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:34:02.274+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:02.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:34:02.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T22:34:32.603+0000] {processor.py:157} INFO - Started process (PID=12041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:32.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:34:32.606+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:32.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:32.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:34:32.635+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:32.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:34:32.645+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:34:32.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:34:32.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:35:02.985+0000] {processor.py:157} INFO - Started process (PID=12051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:02.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:35:02.988+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:02.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:03.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:03.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:03.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:35:03.030+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:03.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:35:03.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T22:35:33.303+0000] {processor.py:157} INFO - Started process (PID=12061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:33.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:35:33.308+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:33.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:33.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:35:33.351+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:33.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:35:33.363+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:35:33.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:35:33.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T22:36:03.609+0000] {processor.py:157} INFO - Started process (PID=12071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:03.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:36:03.611+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:03.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:03.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:03.652+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:03.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:36:03.667+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:03.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:36:03.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-09T22:36:33.916+0000] {processor.py:157} INFO - Started process (PID=12081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:33.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:36:33.919+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:33.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:33.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:36:33.948+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:33.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:36:33.959+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:36:33.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:36:33.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:37:04.290+0000] {processor.py:157} INFO - Started process (PID=12091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:04.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:37:04.292+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:04.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:04.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:04.318+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:04.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:37:04.328+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:04.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:37:04.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T22:37:34.689+0000] {processor.py:157} INFO - Started process (PID=12100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:34.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:37:34.696+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:34.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:34.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:37:34.750+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:34.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:37:34.775+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:37:34.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:37:34.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-09T22:38:05.010+0000] {processor.py:157} INFO - Started process (PID=12111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:05.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:38:05.012+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:05.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:05.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:05.042+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:05.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:38:05.052+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:05.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:38:05.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:38:35.378+0000] {processor.py:157} INFO - Started process (PID=12121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:35.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:38:35.381+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:35.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:35.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:38:35.416+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:35.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:38:35.429+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:38:35.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:38:35.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T22:39:05.752+0000] {processor.py:157} INFO - Started process (PID=12131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:05.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:39:05.758+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:05.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:05.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:05.791+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:05.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:39:05.801+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:05.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:39:05.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T22:39:36.150+0000] {processor.py:157} INFO - Started process (PID=12141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:36.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:39:36.154+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:36.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:36.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:39:36.193+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:36.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:39:36.206+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:39:36.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:39:36.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T22:40:06.495+0000] {processor.py:157} INFO - Started process (PID=12151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:06.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:40:06.500+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:06.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:06.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:06.548+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:06.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:40:06.559+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:06.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:40:06.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-09T22:40:36.891+0000] {processor.py:157} INFO - Started process (PID=12161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:36.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:40:36.894+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:36.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:36.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:40:36.922+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:36.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:40:36.932+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:40:36.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:40:36.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:41:07.261+0000] {processor.py:157} INFO - Started process (PID=12171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:07.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:41:07.265+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:07.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:07.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:07.291+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:07.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:41:07.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:07.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:41:07.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:41:37.592+0000] {processor.py:157} INFO - Started process (PID=12181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:37.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:41:37.594+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:37.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:37.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:41:37.619+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:37.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:41:37.628+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:41:37.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:41:37.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T22:42:07.940+0000] {processor.py:157} INFO - Started process (PID=12191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:07.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:42:07.943+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:07.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:07.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:07.972+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:42:07.982+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:07.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:42:07.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:42:38.259+0000] {processor.py:157} INFO - Started process (PID=12201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:38.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:42:38.267+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:38.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:38.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:42:38.305+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:38.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:42:38.317+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:42:38.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:42:38.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T22:43:08.633+0000] {processor.py:157} INFO - Started process (PID=12211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:08.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:43:08.636+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:08.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:08.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:08.663+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:08.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:43:08.674+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:08.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:43:08.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:43:39.024+0000] {processor.py:157} INFO - Started process (PID=12221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:39.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:43:39.027+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:39.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:39.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:43:39.058+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:39.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:43:39.067+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:43:39.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:43:39.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:44:09.380+0000] {processor.py:157} INFO - Started process (PID=12231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:09.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:44:09.383+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:09.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:09.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:09.409+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:09.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:44:09.419+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:09.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:44:09.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:44:39.739+0000] {processor.py:157} INFO - Started process (PID=12241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:39.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:44:39.742+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:39.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:39.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:44:39.771+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:39.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:44:39.782+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:44:39.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:44:39.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:45:10.111+0000] {processor.py:157} INFO - Started process (PID=12251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:10.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:45:10.114+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:10.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:10.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:10.141+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:10.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:45:10.151+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:10.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:45:10.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:45:40.471+0000] {processor.py:157} INFO - Started process (PID=12261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:40.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:45:40.473+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:40.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:40.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:45:40.498+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:40.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:45:40.509+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:45:40.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:45:40.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T22:46:10.753+0000] {processor.py:157} INFO - Started process (PID=12271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:10.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:46:10.756+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:10.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:10.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:10.785+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:10.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:46:10.794+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:10.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:46:10.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:46:41.097+0000] {processor.py:157} INFO - Started process (PID=12280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:41.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:46:41.103+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:41.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:41.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:46:41.144+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:41.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:46:41.156+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:46:41.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:46:41.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-09T22:47:11.374+0000] {processor.py:157} INFO - Started process (PID=12291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:11.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:47:11.376+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:11.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:11.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:11.403+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:11.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:47:11.413+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:11.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:47:11.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:47:41.705+0000] {processor.py:157} INFO - Started process (PID=12301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:41.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:47:41.709+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:41.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:41.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:47:41.736+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:41.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:47:41.746+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:47:41.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:47:41.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:48:12.042+0000] {processor.py:157} INFO - Started process (PID=12311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:12.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:48:12.046+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:12.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:12.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:12.071+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:12.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:48:12.081+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:12.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:48:12.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:48:42.424+0000] {processor.py:157} INFO - Started process (PID=12321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:42.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:48:42.428+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:42.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:42.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:48:42.462+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:42.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:48:42.473+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:48:42.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:48:42.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T22:49:12.754+0000] {processor.py:157} INFO - Started process (PID=12331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:12.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:49:12.763+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:12.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:12.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:12.814+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:12.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:49:12.825+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:12.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:49:12.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-09T22:49:43.071+0000] {processor.py:157} INFO - Started process (PID=12341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:43.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:49:43.075+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:43.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:43.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:49:43.100+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:43.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:49:43.110+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:49:43.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:49:43.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T22:50:13.447+0000] {processor.py:157} INFO - Started process (PID=12351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:13.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:50:13.450+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:13.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:13.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:13.481+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:13.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:50:13.492+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:13.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:50:13.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T22:50:43.826+0000] {processor.py:157} INFO - Started process (PID=12361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:43.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:50:43.829+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:43.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:43.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:50:43.855+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:43.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:50:43.865+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:50:43.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:50:43.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:51:14.199+0000] {processor.py:157} INFO - Started process (PID=12371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:14.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:51:14.204+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:14.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:14.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:14.236+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:14.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:51:14.247+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:14.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:51:14.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T22:51:44.562+0000] {processor.py:157} INFO - Started process (PID=12381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:44.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:51:44.567+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:44.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:44.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:51:44.605+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:44.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:51:44.615+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:51:44.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:51:44.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T22:52:14.885+0000] {processor.py:157} INFO - Started process (PID=12391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:14.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:52:14.888+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:14.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:14.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:14.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:14.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:52:14.927+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:14.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:52:14.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:52:45.224+0000] {processor.py:157} INFO - Started process (PID=12401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:45.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:52:45.227+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:45.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:45.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:52:45.255+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:45.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:52:45.266+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:52:45.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:52:45.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:53:15.534+0000] {processor.py:157} INFO - Started process (PID=12411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:15.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:53:15.544+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:15.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:15.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:15.564+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:15.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:53:15.573+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:15.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:53:15.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:53:45.906+0000] {processor.py:157} INFO - Started process (PID=12421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:45.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:53:45.909+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:45.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:45.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:53:45.937+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:45.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:53:45.951+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:53:45.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:53:45.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:54:16.282+0000] {processor.py:157} INFO - Started process (PID=12431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:16.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:54:16.284+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:16.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:16.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:16.312+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:16.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:54:16.323+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:16.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:54:16.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:54:46.638+0000] {processor.py:157} INFO - Started process (PID=12441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:46.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:54:46.646+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:46.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:46.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:54:46.667+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:46.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:54:46.677+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:54:46.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:54:46.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T22:55:17.016+0000] {processor.py:157} INFO - Started process (PID=12451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:17.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:55:17.020+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:17.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:17.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:17.057+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:17.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:55:17.070+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:17.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:55:17.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T22:55:47.377+0000] {processor.py:157} INFO - Started process (PID=12461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:47.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:55:47.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:47.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:47.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:55:47.409+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:47.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:55:47.418+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:55:47.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:55:47.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T22:56:17.758+0000] {processor.py:157} INFO - Started process (PID=12471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:17.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:56:17.761+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:17.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:17.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:17.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:56:17.805+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:17.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:56:17.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T22:56:48.122+0000] {processor.py:157} INFO - Started process (PID=12481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:48.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:56:48.126+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:48.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:48.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:56:48.152+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:48.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:56:48.162+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:56:48.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:56:48.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T22:57:18.416+0000] {processor.py:157} INFO - Started process (PID=12491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:18.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:57:18.421+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:18.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:18.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:18.454+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:18.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:57:18.466+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:18.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:57:18.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T22:57:48.807+0000] {processor.py:157} INFO - Started process (PID=12501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:48.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:57:48.810+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:48.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:48.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:57:48.837+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:48.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:57:48.848+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:57:48.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:57:48.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T22:58:19.097+0000] {processor.py:157} INFO - Started process (PID=12511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:19.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:58:19.102+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:19.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:19.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:19.134+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:19.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:58:19.145+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:19.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:58:19.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T22:58:49.449+0000] {processor.py:157} INFO - Started process (PID=12521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:49.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:58:49.453+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:49.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:49.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:58:49.487+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:49.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:58:49.497+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:58:49.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:58:49.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T22:59:19.746+0000] {processor.py:157} INFO - Started process (PID=12531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:19.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:59:19.749+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:19.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:19.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:19.778+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:19.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:59:19.788+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:19.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:59:19.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T22:59:50.105+0000] {processor.py:157} INFO - Started process (PID=12541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:50.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T22:59:50.107+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:50.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:50.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T22:59:50.137+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:50.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T22:59:50.149+0000] {logging_mixin.py:151} INFO - [2024-08-09T22:59:50.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T22:59:50.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:00:20.462+0000] {processor.py:157} INFO - Started process (PID=12551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:20.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:00:20.464+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:20.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:20.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:20.490+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:20.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:00:20.501+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:20.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:00:20.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T23:00:50.763+0000] {processor.py:157} INFO - Started process (PID=12561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:50.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:00:50.766+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:50.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:50.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:00:50.796+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:50.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:00:50.808+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:00:50.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:00:50.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:01:21.132+0000] {processor.py:157} INFO - Started process (PID=12571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:21.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:01:21.136+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:21.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:21.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:21.166+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:21.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:01:21.178+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:21.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:01:21.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:01:51.522+0000] {processor.py:157} INFO - Started process (PID=12581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:51.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:01:51.526+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:51.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:51.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:01:51.552+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:51.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:01:51.562+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:01:51.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:01:51.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:02:21.872+0000] {processor.py:157} INFO - Started process (PID=12591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:21.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:02:21.876+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:21.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:21.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:21.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:21.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:02:21.918+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:21.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:02:21.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T23:02:52.245+0000] {processor.py:157} INFO - Started process (PID=12601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:52.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:02:52.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:52.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:52.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:02:52.286+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:52.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:02:52.297+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:02:52.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:02:52.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-09T23:03:22.630+0000] {processor.py:157} INFO - Started process (PID=12611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:22.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:03:22.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:22.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:22.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:22.658+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:22.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:03:22.671+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:22.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:03:22.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:03:52.927+0000] {processor.py:157} INFO - Started process (PID=12621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:52.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:03:52.932+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:52.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:52.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:03:52.958+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:52.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:03:52.968+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:03:52.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:03:52.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:04:23.298+0000] {processor.py:157} INFO - Started process (PID=12631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:23.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:04:23.303+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:23.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:23.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:23.333+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:23.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:04:23.345+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:23.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:04:23.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T23:04:53.649+0000] {processor.py:157} INFO - Started process (PID=12641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:53.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:04:53.652+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:53.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:53.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:04:53.681+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:53.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:04:53.692+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:04:53.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:04:53.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:05:23.911+0000] {processor.py:157} INFO - Started process (PID=12651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:23.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:05:23.914+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:23.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:23.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:23.942+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:23.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:05:23.954+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:23.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:05:23.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:05:54.274+0000] {processor.py:157} INFO - Started process (PID=12661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:54.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:05:54.280+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:54.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:54.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:05:54.316+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:54.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:05:54.329+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:05:54.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:05:54.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T23:06:24.560+0000] {processor.py:157} INFO - Started process (PID=12671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:24.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:06:24.562+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:24.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:24.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:24.591+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:24.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:06:24.606+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:24.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:06:24.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:06:54.956+0000] {processor.py:157} INFO - Started process (PID=12681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:54.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:06:54.966+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:54.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:54.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:06:55.049+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:55.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:06:55.067+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:06:55.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:06:55.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-09T23:07:25.285+0000] {processor.py:157} INFO - Started process (PID=12691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:25.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:07:25.319+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:25.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:25.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:25.368+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:25.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:07:25.382+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:25.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:07:25.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-09T23:07:55.740+0000] {processor.py:157} INFO - Started process (PID=12701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:55.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:07:55.744+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:55.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:55.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:07:55.770+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:55.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:07:55.781+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:07:55.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:07:55.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T23:08:26.033+0000] {processor.py:157} INFO - Started process (PID=12711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:26.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:08:26.039+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:26.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:26.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:26.077+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:26.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:08:26.090+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:26.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:08:26.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T23:08:56.432+0000] {processor.py:157} INFO - Started process (PID=12721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:56.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:08:56.435+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:56.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:56.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:08:56.462+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:56.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:08:56.472+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:08:56.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:08:56.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:09:26.840+0000] {processor.py:157} INFO - Started process (PID=12731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:26.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:09:26.845+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:26.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:26.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:26.886+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:26.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:09:26.905+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:26.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:09:26.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-09T23:09:57.138+0000] {processor.py:157} INFO - Started process (PID=12741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:57.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:09:57.140+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:57.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:57.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:09:57.177+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:57.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:09:57.190+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:09:57.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:09:57.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T23:10:27.509+0000] {processor.py:157} INFO - Started process (PID=12751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:27.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:10:27.512+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:27.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:27.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:27.541+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:27.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:10:27.554+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:27.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:10:27.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:10:57.857+0000] {processor.py:157} INFO - Started process (PID=12761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:57.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:10:57.861+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:57.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:57.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:10:57.890+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:57.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:10:57.899+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:10:57.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:10:57.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:11:28.210+0000] {processor.py:157} INFO - Started process (PID=12771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:28.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:11:28.215+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:28.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:28.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:28.254+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:28.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:11:28.270+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:28.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:11:28.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-09T23:11:58.600+0000] {processor.py:157} INFO - Started process (PID=12781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:58.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:11:58.603+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:58.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:58.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:11:58.633+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:58.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:11:58.643+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:11:58.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:11:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:12:28.981+0000] {processor.py:157} INFO - Started process (PID=12791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:28.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:12:28.985+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:28.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:28.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:29.015+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:29.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:12:29.026+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:29.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:12:29.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:12:59.324+0000] {processor.py:157} INFO - Started process (PID=12801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:59.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:12:59.327+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:59.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:59.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:12:59.355+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:59.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:12:59.366+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:12:59.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:12:59.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:13:29.705+0000] {processor.py:157} INFO - Started process (PID=12811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:13:29.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:13:29.708+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:13:29.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:13:29.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:13:29.736+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:13:29.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:13:29.748+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:13:29.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:13:29.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:14:00.075+0000] {processor.py:157} INFO - Started process (PID=12821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:00.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:14:00.081+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:00.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:00.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:00.122+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:00.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:14:00.135+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:00.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:14:00.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-09T23:14:30.496+0000] {processor.py:157} INFO - Started process (PID=12831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:30.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:14:30.499+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:30.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:30.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:14:30.530+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:30.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:14:30.543+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:14:30.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:14:30.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T23:15:00.856+0000] {processor.py:157} INFO - Started process (PID=12841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:00.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:15:00.858+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:00.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:00.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:00.885+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:00.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:15:00.896+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:00.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:15:00.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:15:31.224+0000] {processor.py:157} INFO - Started process (PID=12851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:31.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:15:31.226+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:31.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:31.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:15:31.252+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:31.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:15:31.262+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:15:31.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:15:31.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-09T23:16:01.581+0000] {processor.py:157} INFO - Started process (PID=12861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:01.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:16:01.588+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:01.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:01.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:01.625+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:01.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:16:01.639+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:01.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:16:01.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-09T23:16:31.883+0000] {processor.py:157} INFO - Started process (PID=12871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:31.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:16:31.887+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:31.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:31.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:16:31.917+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:31.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:16:31.927+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:16:31.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:16:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:17:02.243+0000] {processor.py:157} INFO - Started process (PID=12881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:02.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:17:02.248+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:02.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:02.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:02.275+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:02.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:17:02.288+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:02.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:17:02.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:17:32.574+0000] {processor.py:157} INFO - Started process (PID=12891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:32.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:17:32.579+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:32.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:32.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:17:32.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:32.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:17:32.633+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:17:32.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:17:32.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-09T23:18:02.961+0000] {processor.py:157} INFO - Started process (PID=12901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:02.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:18:02.964+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:02.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:02.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:02.993+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:02.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:18:03.004+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:03.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:18:03.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:18:33.302+0000] {processor.py:157} INFO - Started process (PID=12911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:33.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:18:33.305+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:33.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:33.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:18:33.336+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:33.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:18:33.346+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:18:33.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:18:33.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:19:03.661+0000] {processor.py:157} INFO - Started process (PID=12921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:03.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:19:03.663+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:03.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:03.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:03.692+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:03.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:19:03.704+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:03.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:19:03.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:19:34.013+0000] {processor.py:157} INFO - Started process (PID=12931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:34.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:19:34.015+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:34.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:34.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:19:34.047+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:34.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:19:34.056+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:19:34.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:19:34.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:20:04.426+0000] {processor.py:157} INFO - Started process (PID=12941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:04.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:20:04.432+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:04.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:04.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:04.478+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:04.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:20:04.493+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:04.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:20:04.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T23:20:34.702+0000] {processor.py:157} INFO - Started process (PID=12951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:34.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:20:34.705+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:34.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:34.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:20:34.735+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:34.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:20:34.747+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:20:34.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:20:34.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:21:05.089+0000] {processor.py:157} INFO - Started process (PID=12961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:05.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:21:05.092+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:05.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:05.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:05.119+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:05.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:21:05.130+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:05.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:21:05.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:21:35.556+0000] {processor.py:157} INFO - Started process (PID=12971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:35.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:21:35.559+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:35.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:35.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:21:35.596+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:35.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:21:35.609+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:21:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:21:35.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T23:22:05.851+0000] {processor.py:157} INFO - Started process (PID=12981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:05.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:22:05.855+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:05.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:05.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:05.883+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:05.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:22:05.893+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:05.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:22:05.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:22:36.215+0000] {processor.py:157} INFO - Started process (PID=12991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:36.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:22:36.217+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:36.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:36.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:22:36.245+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:36.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:22:36.258+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:22:36.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:22:36.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:23:06.527+0000] {processor.py:157} INFO - Started process (PID=13001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:06.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:23:06.529+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:06.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:06.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:06.557+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:06.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:23:06.569+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:06.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:23:06.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:23:36.815+0000] {processor.py:157} INFO - Started process (PID=13011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:36.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:23:36.818+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:36.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:36.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:23:36.842+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:36.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:23:36.852+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:23:36.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:23:36.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T23:24:07.141+0000] {processor.py:157} INFO - Started process (PID=13021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:07.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:24:07.144+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:07.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:07.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:07.170+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:07.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:24:07.181+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:07.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:24:07.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:24:37.472+0000] {processor.py:157} INFO - Started process (PID=13031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:37.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:24:37.475+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:37.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:24:37.502+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:37.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:24:37.513+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:24:37.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:24:37.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:25:07.849+0000] {processor.py:157} INFO - Started process (PID=13041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:07.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:25:07.855+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:07.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:07.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:07.905+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:07.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:25:07.918+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:07.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:25:07.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-09T23:25:38.151+0000] {processor.py:157} INFO - Started process (PID=13051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:38.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:25:38.154+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:38.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:38.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:25:38.185+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:38.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:25:38.194+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:25:38.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:25:38.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:26:08.518+0000] {processor.py:157} INFO - Started process (PID=13061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:08.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:26:08.520+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:08.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:08.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:08.549+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:08.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:26:08.560+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:08.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:26:08.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:26:38.823+0000] {processor.py:157} INFO - Started process (PID=13071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:38.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:26:38.825+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:38.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:38.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:26:38.854+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:38.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:26:38.865+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:26:38.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:26:38.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:27:09.203+0000] {processor.py:157} INFO - Started process (PID=13081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:09.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:27:09.209+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:09.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:09.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:09.246+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:09.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:27:09.260+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:09.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:27:09.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T23:27:39.525+0000] {processor.py:157} INFO - Started process (PID=13091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:39.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:27:39.527+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:39.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:39.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:27:39.555+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:39.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:27:39.565+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:27:39.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:27:39.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:28:09.863+0000] {processor.py:157} INFO - Started process (PID=13101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:09.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:28:09.866+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:09.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:09.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:09.895+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:09.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:28:09.906+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:09.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:28:09.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:28:40.211+0000] {processor.py:157} INFO - Started process (PID=13111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:40.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:28:40.213+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:40.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:40.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:28:40.241+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:40.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:28:40.251+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:28:40.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:28:40.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:29:10.576+0000] {processor.py:157} INFO - Started process (PID=13121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:10.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:29:10.580+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:10.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:10.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:10.608+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:10.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:29:10.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:10.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:29:10.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:29:40.960+0000] {processor.py:157} INFO - Started process (PID=13131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:40.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:29:40.962+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:40.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:40.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:29:40.989+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:40.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:29:41.000+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:29:41.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:29:41.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:30:11.345+0000] {processor.py:157} INFO - Started process (PID=13141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:11.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:30:11.349+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:11.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:11.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:11.385+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:11.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:30:11.397+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:11.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:30:11.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T23:30:41.668+0000] {processor.py:157} INFO - Started process (PID=13151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:41.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:30:41.673+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:41.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:41.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:30:41.700+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:41.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:30:41.710+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:30:41.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:30:41.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:31:11.979+0000] {processor.py:157} INFO - Started process (PID=13161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:11.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:31:11.983+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:11.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:11.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:12.009+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:12.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:31:12.018+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:12.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:31:12.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:31:42.323+0000] {processor.py:157} INFO - Started process (PID=13171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:42.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:31:42.326+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:42.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:42.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:31:42.353+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:42.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:31:42.364+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:31:42.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:31:42.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:32:12.710+0000] {processor.py:157} INFO - Started process (PID=13181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:12.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:32:12.713+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:12.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:12.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:12.740+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:12.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:32:12.751+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:12.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:32:12.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:32:43.032+0000] {processor.py:157} INFO - Started process (PID=13191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:43.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:32:43.036+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:43.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:43.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:32:43.061+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:43.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:32:43.072+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:32:43.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:32:43.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:33:13.337+0000] {processor.py:157} INFO - Started process (PID=13201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:13.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:33:13.342+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:13.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:13.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:13.378+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:13.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:33:13.390+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:13.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:33:13.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T23:33:43.615+0000] {processor.py:157} INFO - Started process (PID=13211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:43.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:33:43.618+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:43.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:43.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:33:43.644+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:43.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:33:43.654+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:33:43.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:33:43.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:34:14.012+0000] {processor.py:157} INFO - Started process (PID=13221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:14.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:34:14.016+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:14.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:14.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:14.046+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:14.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:34:14.056+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:14.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:34:14.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:34:44.396+0000] {processor.py:157} INFO - Started process (PID=13231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:44.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:34:44.399+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:44.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:44.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:34:44.425+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:44.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:34:44.434+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:34:44.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:34:44.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:35:14.724+0000] {processor.py:157} INFO - Started process (PID=13241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:14.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:35:14.726+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:14.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:14.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:14.756+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:14.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:35:14.766+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:14.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:35:14.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:35:45.031+0000] {processor.py:157} INFO - Started process (PID=13251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:45.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:35:45.035+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:45.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:45.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:35:45.062+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:45.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:35:45.075+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:35:45.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:35:45.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-09T23:36:15.402+0000] {processor.py:157} INFO - Started process (PID=13261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:15.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:36:15.408+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:15.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:15.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:15.447+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:15.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:36:15.460+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:15.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:36:15.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-09T23:36:45.801+0000] {processor.py:157} INFO - Started process (PID=13271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:45.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:36:45.804+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:45.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:45.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:36:45.838+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:45.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:36:45.849+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:36:45.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:36:45.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-09T23:37:16.185+0000] {processor.py:157} INFO - Started process (PID=13281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:16.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:37:16.207+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:16.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:16.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:16.253+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:16.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:37:16.265+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:16.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:37:16.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-09T23:37:46.477+0000] {processor.py:157} INFO - Started process (PID=13291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:46.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:37:46.479+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:46.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:46.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:37:46.508+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:46.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:37:46.519+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:37:46.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:37:46.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:38:16.786+0000] {processor.py:157} INFO - Started process (PID=13301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:16.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:38:16.792+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:16.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:16.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:16.828+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:16.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:38:16.840+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:16.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:38:16.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-09T23:38:47.092+0000] {processor.py:157} INFO - Started process (PID=13311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:47.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:38:47.095+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:47.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:47.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:38:47.125+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:47.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:38:47.142+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:38:47.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:38:47.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T23:39:17.482+0000] {processor.py:157} INFO - Started process (PID=13321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:17.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:39:17.486+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:17.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:17.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:17.517+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:17.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:39:17.528+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:17.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:39:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T23:39:47.887+0000] {processor.py:157} INFO - Started process (PID=13331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:47.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:39:47.891+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:47.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:47.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:39:47.920+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:47.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:39:47.930+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:39:47.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:39:47.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:40:18.212+0000] {processor.py:157} INFO - Started process (PID=13341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:18.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:40:18.216+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:18.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:18.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:18.242+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:18.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:40:18.251+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:18.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:40:18.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T23:40:48.581+0000] {processor.py:157} INFO - Started process (PID=13351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:48.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:40:48.584+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:48.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:48.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:40:48.613+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:48.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:40:48.624+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:40:48.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:40:48.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:41:18.934+0000] {processor.py:157} INFO - Started process (PID=13361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:18.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:41:18.938+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:18.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:18.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:18.969+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:18.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:41:18.981+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:18.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:41:18.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-09T23:41:49.312+0000] {processor.py:157} INFO - Started process (PID=13371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:49.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:41:49.318+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:49.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:49.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:41:49.354+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:49.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:41:49.365+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:41:49.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:41:49.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-09T23:42:19.654+0000] {processor.py:157} INFO - Started process (PID=13381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:19.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:42:19.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:19.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:19.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:19.683+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:19.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:42:19.695+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:19.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:42:19.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:42:49.979+0000] {processor.py:157} INFO - Started process (PID=13391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:49.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:42:49.983+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:49.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:49.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:42:50.009+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:50.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:42:50.020+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:42:50.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:42:50.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:43:20.348+0000] {processor.py:157} INFO - Started process (PID=13401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:20.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:43:20.351+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:20.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:20.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:20.380+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:20.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:43:20.391+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:20.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:43:20.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:43:50.727+0000] {processor.py:157} INFO - Started process (PID=13411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:50.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:43:50.730+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:50.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:50.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:43:50.758+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:50.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:43:50.770+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:43:50.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:43:50.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:44:21.086+0000] {processor.py:157} INFO - Started process (PID=13421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:21.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:44:21.088+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:21.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:21.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:21.112+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:21.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:44:21.122+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:21.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:44:21.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-09T23:44:51.455+0000] {processor.py:157} INFO - Started process (PID=13431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:51.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:44:51.458+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:51.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:51.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:44:51.485+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:51.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:44:51.495+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:44:51.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:44:51.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-09T23:45:21.837+0000] {processor.py:157} INFO - Started process (PID=13441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:21.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:45:21.841+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:21.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:21.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:21.880+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:21.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:45:21.892+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:21.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:45:21.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-09T23:45:52.211+0000] {processor.py:157} INFO - Started process (PID=13451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:52.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:45:52.214+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:52.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:52.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:45:52.241+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:52.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:45:52.251+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:45:52.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:45:52.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:46:22.588+0000] {processor.py:157} INFO - Started process (PID=13461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:22.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:46:22.592+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:22.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:22.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:22.620+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:22.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:46:22.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:22.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:46:22.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:46:52.914+0000] {processor.py:157} INFO - Started process (PID=13471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:52.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:46:52.916+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:52.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:52.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:46:52.941+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:52.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:46:52.951+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:46:52.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:46:52.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T23:47:23.218+0000] {processor.py:157} INFO - Started process (PID=13481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:23.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:47:23.222+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:23.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:23.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:23.249+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:23.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:47:23.261+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:23.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:47:23.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:47:53.536+0000] {processor.py:157} INFO - Started process (PID=13491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:53.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:47:53.538+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:53.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:53.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:47:53.566+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:53.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:47:53.576+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:47:53.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:47:53.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-09T23:48:23.863+0000] {processor.py:157} INFO - Started process (PID=13501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:23.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:48:23.867+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:23.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:23.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:23.902+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:23.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:48:23.914+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:23.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:48:23.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-09T23:48:54.106+0000] {processor.py:157} INFO - Started process (PID=13511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:54.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:48:54.109+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:54.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:54.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:48:54.138+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:54.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:48:54.148+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:48:54.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:48:54.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:49:24.384+0000] {processor.py:157} INFO - Started process (PID=13521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:24.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:49:24.389+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:24.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:24.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:24.418+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:24.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:49:24.427+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:24.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:49:24.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:49:54.628+0000] {processor.py:157} INFO - Started process (PID=13531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:54.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:49:54.632+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:54.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:54.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:49:54.657+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:54.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:49:54.671+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:49:54.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:49:54.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-09T23:50:24.971+0000] {processor.py:157} INFO - Started process (PID=13541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:24.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:50:24.976+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:24.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:24.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:25.014+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:25.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:50:25.027+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:25.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:50:25.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-09T23:50:55.262+0000] {processor.py:157} INFO - Started process (PID=13551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:55.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:50:55.265+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:55.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:55.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:50:55.295+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:55.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:50:55.306+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:50:55.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:50:55.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:51:25.581+0000] {processor.py:157} INFO - Started process (PID=13561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:25.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:51:25.587+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:25.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:25.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:25.615+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:25.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:51:25.627+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:25.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:51:25.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T23:51:55.950+0000] {processor.py:157} INFO - Started process (PID=13571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:55.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:51:55.954+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:55.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:55.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:51:55.991+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:55.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:51:56.003+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:51:56.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:51:56.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-09T23:52:26.232+0000] {processor.py:157} INFO - Started process (PID=13581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:26.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:52:26.235+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:26.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:26.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:26.276+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:26.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:52:26.301+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:26.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:52:26.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-09T23:52:56.642+0000] {processor.py:157} INFO - Started process (PID=13591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:56.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:52:56.647+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:56.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:56.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:52:56.674+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:56.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:52:56.685+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:52:56.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:52:56.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:53:27.019+0000] {processor.py:157} INFO - Started process (PID=13601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:27.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:53:27.023+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:27.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:27.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:27.051+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:27.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:53:27.064+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:27.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:53:27.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:53:57.366+0000] {processor.py:157} INFO - Started process (PID=13611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:57.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:53:57.368+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:57.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:57.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:53:57.394+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:57.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:53:57.404+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:53:57.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:53:57.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-09T23:54:27.769+0000] {processor.py:157} INFO - Started process (PID=13621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:27.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:54:27.774+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:27.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:27.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:27.808+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:27.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:54:27.819+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:27.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:54:27.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-09T23:54:58.135+0000] {processor.py:157} INFO - Started process (PID=13631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:58.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:54:58.138+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:58.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:58.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:54:58.164+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:58.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:54:58.174+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:54:58.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:54:58.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-09T23:55:28.473+0000] {processor.py:157} INFO - Started process (PID=13641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:28.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:55:28.477+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:28.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:28.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:28.506+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:28.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:55:28.517+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:28.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:55:28.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:55:58.815+0000] {processor.py:157} INFO - Started process (PID=13651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:58.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:55:58.817+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:58.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:58.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:55:58.843+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:58.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:55:58.856+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:55:58.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:55:58.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:56:29.139+0000] {processor.py:157} INFO - Started process (PID=13661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:29.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:56:29.143+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:29.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:29.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:29.172+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:29.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:56:29.183+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:29.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:56:29.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-09T23:56:59.477+0000] {processor.py:157} INFO - Started process (PID=13671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:59.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:56:59.480+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:59.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:59.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:56:59.508+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:59.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:56:59.520+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:56:59.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:56:59.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-09T23:57:29.847+0000] {processor.py:157} INFO - Started process (PID=13681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:57:29.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:57:29.855+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:57:29.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:57:29.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:57:29.883+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:57:29.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:57:29.892+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:57:29.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:57:29.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:58:00.237+0000] {processor.py:157} INFO - Started process (PID=13691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:00.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:58:00.240+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:00.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:00.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:00.274+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:00.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:58:00.285+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:00.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:58:00.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-09T23:58:30.629+0000] {processor.py:157} INFO - Started process (PID=13701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:30.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:58:30.634+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:30.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:30.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:58:30.663+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:30.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:58:30.673+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:58:30.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:58:30.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-09T23:59:01.007+0000] {processor.py:157} INFO - Started process (PID=13711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:01.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:59:01.011+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:01.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:01.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:01.038+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:01.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:59:01.050+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:01.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:59:01.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-09T23:59:31.291+0000] {processor.py:157} INFO - Started process (PID=13721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:31.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-09T23:59:31.295+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:31.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:31.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-09T23:59:31.320+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:31.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-09T23:59:31.329+0000] {logging_mixin.py:151} INFO - [2024-08-09T23:59:31.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-09T01:00:00+00:00, run_after=2024-08-10T01:00:00+00:00
[2024-08-09T23:59:31.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
