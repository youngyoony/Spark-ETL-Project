[2024-09-08T20:44:02.183+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:02.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:44:02.193+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:02.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:02.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:02.289+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:02.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:44:02.374+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:02.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:44:02.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.263 seconds
[2024-09-08T20:44:33.015+0000] {processor.py:157} INFO - Started process (PID=780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:33.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:44:33.020+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:33.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:33.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:44:33.110+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:33.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:44:33.126+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:44:33.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:44:33.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-08T20:45:03.569+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:03.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:45:03.579+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:03.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:03.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:03.642+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:03.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:45:03.659+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:03.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:45:03.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-08T20:45:33.943+0000] {processor.py:157} INFO - Started process (PID=801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:33.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:45:33.951+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:33.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:33.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:45:34.042+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:34.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:45:34.066+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:45:34.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:45:34.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-08T20:46:04.300+0000] {processor.py:157} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:04.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:46:04.308+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:04.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:04.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:04.395+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:04.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:46:04.415+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:04.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:46:04.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-08T20:46:34.693+0000] {processor.py:157} INFO - Started process (PID=990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:34.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:46:34.701+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:34.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:34.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:46:34.761+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:34.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:46:34.776+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:46:34.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:46:34.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-08T20:47:05.079+0000] {processor.py:157} INFO - Started process (PID=1000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:05.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:47:05.088+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:05.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:05.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:05.147+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:05.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:47:05.173+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:05.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:47:05.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-08T20:47:35.377+0000] {processor.py:157} INFO - Started process (PID=1010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:35.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:47:35.382+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:35.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:35.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:47:35.439+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:35.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:47:35.452+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:47:35.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:47:35.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-08T20:48:05.827+0000] {processor.py:157} INFO - Started process (PID=1020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:05.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:48:05.834+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:05.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:05.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:05.876+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:05.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:48:05.892+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:05.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:48:05.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-08T20:48:36.152+0000] {processor.py:157} INFO - Started process (PID=1030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:36.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:48:36.160+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:36.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:36.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:48:36.181+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:36.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:48:36.200+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:48:36.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:48:36.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-08T20:49:06.597+0000] {processor.py:157} INFO - Started process (PID=1040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:06.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:49:06.600+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:06.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:06.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:06.649+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:06.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:49:06.660+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:06.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:49:06.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T20:49:36.918+0000] {processor.py:157} INFO - Started process (PID=1050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:36.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:49:36.923+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:36.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:36.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:49:36.980+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:36.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:49:36.993+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:49:36.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:49:37.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-08T20:50:07.243+0000] {processor.py:157} INFO - Started process (PID=1060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:07.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:50:07.247+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:07.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:07.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:07.289+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:07.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:50:07.302+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:07.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:50:07.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T20:50:37.583+0000] {processor.py:157} INFO - Started process (PID=1070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:37.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:50:37.585+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:37.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:37.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:50:37.612+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:37.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:50:37.624+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:50:37.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:50:37.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T20:51:07.943+0000] {processor.py:157} INFO - Started process (PID=1080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:07.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:51:07.964+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:07.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:07.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:08.008+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:08.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:51:08.021+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:08.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:51:08.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-08T20:51:38.343+0000] {processor.py:157} INFO - Started process (PID=1090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:38.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:51:38.352+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:38.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:38.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:51:38.376+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:38.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:51:38.385+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:51:38.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:51:38.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-08T20:52:08.625+0000] {processor.py:157} INFO - Started process (PID=1100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:08.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:52:08.632+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:08.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:08.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:08.703+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:08.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:52:08.726+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:08.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:52:08.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-08T20:52:38.890+0000] {processor.py:157} INFO - Started process (PID=1110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:38.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:52:38.895+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:38.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:38.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:52:38.936+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:38.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:52:38.948+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:52:38.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:52:38.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T20:53:09.213+0000] {processor.py:157} INFO - Started process (PID=1120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:09.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:53:09.223+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:09.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:09.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:09.262+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:09.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:53:09.274+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:09.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:53:09.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T20:53:39.520+0000] {processor.py:157} INFO - Started process (PID=1129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:39.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:53:39.525+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:39.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:39.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:53:39.571+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:39.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:53:39.585+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:53:39.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:53:39.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T20:56:45.999+0000] {processor.py:157} INFO - Started process (PID=1141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:56:46.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:56:46.007+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:56:46.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:56:46.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:56:46.079+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:56:46.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:56:46.097+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:56:46.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:56:46.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-08T20:57:16.421+0000] {processor.py:157} INFO - Started process (PID=1151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:57:16.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T20:57:16.426+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:57:16.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:57:16.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T20:57:16.468+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:57:16.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T20:57:16.481+0000] {logging_mixin.py:151} INFO - [2024-09-08T20:57:16.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T20:57:16.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T21:15:07.821+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:07.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:15:07.843+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:07.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:07.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:07.908+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:07.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:15:07.924+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:07.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:15:07.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-08T21:15:38.156+0000] {processor.py:157} INFO - Started process (PID=1174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:38.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:15:38.169+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:38.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:38.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:15:38.212+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:38.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:15:38.225+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:15:38.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:15:38.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-08T21:16:08.434+0000] {processor.py:157} INFO - Started process (PID=1184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:08.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:16:08.438+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:08.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:08.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:08.477+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:08.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:16:08.491+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:08.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:16:08.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T21:16:38.837+0000] {processor.py:157} INFO - Started process (PID=1194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:38.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:16:38.840+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:38.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:38.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:16:38.869+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:38.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:16:38.881+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:16:38.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:16:38.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-08T21:17:09.213+0000] {processor.py:157} INFO - Started process (PID=1204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:09.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:17:09.218+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:09.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:09.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:09.258+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:09.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:17:09.278+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:09.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:17:09.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-08T21:17:39.492+0000] {processor.py:157} INFO - Started process (PID=1214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:39.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:17:39.494+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:39.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:39.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:17:39.524+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:39.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:17:39.535+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:17:39.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:17:39.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:18:09.815+0000] {processor.py:157} INFO - Started process (PID=1223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:09.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:18:09.819+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:09.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:09.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:09.873+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:09.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:18:09.886+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:09.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:18:09.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-08T21:18:40.203+0000] {processor.py:157} INFO - Started process (PID=1234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:40.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:18:40.206+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:40.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:40.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:18:40.232+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:40.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:18:40.242+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:18:40.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:18:40.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-08T21:19:10.577+0000] {processor.py:157} INFO - Started process (PID=1244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:10.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:19:10.581+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:10.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:10.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:10.643+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:10.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:19:10.655+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:10.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:19:10.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-08T21:19:41.031+0000] {processor.py:157} INFO - Started process (PID=1254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:41.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:19:41.037+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:41.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:41.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:19:41.081+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:41.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:19:41.095+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:19:41.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:19:41.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-08T21:20:11.463+0000] {processor.py:157} INFO - Started process (PID=1264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:11.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:20:11.469+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:11.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:11.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:11.528+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:11.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:20:11.541+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:11.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:20:11.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-08T21:20:41.885+0000] {processor.py:157} INFO - Started process (PID=1274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:41.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:20:41.888+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:41.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:41.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:20:41.917+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:41.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:20:41.930+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:20:41.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:20:41.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T21:21:12.282+0000] {processor.py:157} INFO - Started process (PID=1284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:12.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:21:12.301+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:12.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:12.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:12.342+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:12.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:21:12.357+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:12.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:21:12.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-08T21:21:42.539+0000] {processor.py:157} INFO - Started process (PID=1294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:42.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:21:42.544+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:42.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:42.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:21:42.571+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:42.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:21:42.580+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:21:42.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:21:42.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-08T21:22:12.900+0000] {processor.py:157} INFO - Started process (PID=1304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:12.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:22:12.905+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:12.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:12.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:12.940+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:12.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:22:12.952+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:12.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:22:12.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-08T21:22:43.245+0000] {processor.py:157} INFO - Started process (PID=1314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:43.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:22:43.250+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:43.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:43.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:22:43.279+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:43.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:22:43.289+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:22:43.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:22:43.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:23:13.614+0000] {processor.py:157} INFO - Started process (PID=1324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:13.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:23:13.621+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:13.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:13.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:13.656+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:13.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:23:13.668+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:13.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:23:13.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-08T21:23:44.022+0000] {processor.py:157} INFO - Started process (PID=1334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:44.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:23:44.026+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:44.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:44.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:23:44.058+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:44.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:23:44.067+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:23:44.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:23:44.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T21:24:14.397+0000] {processor.py:157} INFO - Started process (PID=1344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:14.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:24:14.401+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:14.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:14.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:14.439+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:14.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:24:14.451+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:14.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:24:14.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-08T21:24:44.780+0000] {processor.py:157} INFO - Started process (PID=1354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:44.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:24:44.783+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:44.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:44.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:24:44.813+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:44.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:24:44.823+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:24:44.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:24:44.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:25:15.186+0000] {processor.py:157} INFO - Started process (PID=1363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:15.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:25:15.191+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:15.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:15.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:15.259+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:15.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:25:15.275+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:15.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:25:15.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-08T21:25:45.605+0000] {processor.py:157} INFO - Started process (PID=1374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:45.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:25:45.608+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:45.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:45.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:25:45.636+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:45.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:25:45.649+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:25:45.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:25:45.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-08T21:26:15.923+0000] {processor.py:157} INFO - Started process (PID=1384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:15.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:26:15.946+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:15.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:15.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:15.990+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:15.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:26:16.004+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:16.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:26:16.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-08T21:26:46.212+0000] {processor.py:157} INFO - Started process (PID=1394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:46.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:26:46.215+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:46.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:46.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:26:46.244+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:46.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:26:46.255+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:26:46.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:26:46.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-08T21:27:16.532+0000] {processor.py:157} INFO - Started process (PID=1403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:16.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:27:16.543+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:16.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:16.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:16.594+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:16.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:27:16.607+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:16.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:27:16.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-08T21:27:46.811+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:46.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:27:46.819+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:46.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:46.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:27:46.849+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:46.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:27:46.859+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:27:46.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:27:46.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T21:28:17.197+0000] {processor.py:157} INFO - Started process (PID=1424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:17.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:28:17.201+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:17.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:17.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:17.254+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:17.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:28:17.272+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:17.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:28:17.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-08T21:28:47.542+0000] {processor.py:157} INFO - Started process (PID=1434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:47.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:28:47.545+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:47.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:47.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:28:47.578+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:47.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:28:47.590+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:28:47.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:28:47.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-08T21:29:17.926+0000] {processor.py:157} INFO - Started process (PID=1443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:17.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:29:17.933+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:17.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:17.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:17.974+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:17.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:29:17.986+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:17.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:29:17.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-08T21:29:48.224+0000] {processor.py:157} INFO - Started process (PID=1454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:48.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:29:48.228+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:48.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:48.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:29:48.262+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:48.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:29:48.272+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:29:48.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:29:48.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-08T21:30:18.636+0000] {processor.py:157} INFO - Started process (PID=1464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:18.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:30:18.642+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:18.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:18.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:18.703+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:18.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:30:18.716+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:18.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:30:18.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-08T21:30:48.963+0000] {processor.py:157} INFO - Started process (PID=1474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:48.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:30:48.969+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:48.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:48.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:30:49.015+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:49.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:30:49.027+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:30:49.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:30:49.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-08T21:31:19.359+0000] {processor.py:157} INFO - Started process (PID=1484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:19.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:31:19.362+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:19.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:19.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:19.393+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:19.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:31:19.407+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:19.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:31:19.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-08T21:31:49.746+0000] {processor.py:157} INFO - Started process (PID=1494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:49.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:31:49.751+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:49.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:49.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:31:49.797+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:49.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:31:49.812+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:31:49.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:31:49.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-08T21:32:20.056+0000] {processor.py:157} INFO - Started process (PID=1504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:20.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:32:20.064+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:20.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:20.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:20.106+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:20.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:32:20.120+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:20.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:32:20.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T21:32:50.392+0000] {processor.py:157} INFO - Started process (PID=1514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:50.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:32:50.402+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:50.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:50.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:32:50.465+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:50.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:32:50.482+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:32:50.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:32:50.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-08T21:33:20.717+0000] {processor.py:157} INFO - Started process (PID=1524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:20.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:33:20.721+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:20.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:20.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:20.749+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:20.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:33:20.761+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:20.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:33:20.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T21:33:51.091+0000] {processor.py:157} INFO - Started process (PID=1534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:51.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:33:51.097+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:51.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:51.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:33:51.149+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:51.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:33:51.176+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:33:51.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:33:51.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-08T21:34:21.393+0000] {processor.py:157} INFO - Started process (PID=1544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:21.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:34:21.397+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:21.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:21.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:21.427+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:21.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:34:21.439+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:21.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:34:21.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:34:51.833+0000] {processor.py:157} INFO - Started process (PID=1554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:51.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:34:51.838+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:51.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:51.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:34:51.905+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:51.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:34:51.923+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:34:51.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:34:51.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-08T21:35:22.181+0000] {processor.py:157} INFO - Started process (PID=1564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:22.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:35:22.185+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:22.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:22.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:22.217+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:22.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:35:22.227+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:22.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:35:22.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:35:52.498+0000] {processor.py:157} INFO - Started process (PID=1574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:52.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:35:52.501+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:52.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:52.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:35:52.543+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:52.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:35:52.555+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:35:52.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:35:52.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-08T21:36:22.964+0000] {processor.py:157} INFO - Started process (PID=1584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:22.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:36:22.967+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:22.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:22.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:22.996+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:22.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:36:23.006+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:23.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:36:23.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T21:36:53.315+0000] {processor.py:157} INFO - Started process (PID=1594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:53.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:36:53.322+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:53.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:53.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:36:53.366+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:53.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:36:53.377+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:36:53.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:36:53.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T21:37:23.684+0000] {processor.py:157} INFO - Started process (PID=1604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:23.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:37:23.686+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:23.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:23.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:23.714+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:23.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:37:23.725+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:23.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:37:23.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-08T21:37:54.092+0000] {processor.py:157} INFO - Started process (PID=1614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:54.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:37:54.097+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:54.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:54.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:37:54.137+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:54.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:37:54.149+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:37:54.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:37:54.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-08T21:38:24.490+0000] {processor.py:157} INFO - Started process (PID=1624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:24.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:38:24.494+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:24.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:24.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:24.524+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:24.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:38:24.535+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:24.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:38:24.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-08T21:38:54.898+0000] {processor.py:157} INFO - Started process (PID=1634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:54.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:38:54.907+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:54.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:54.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:38:54.975+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:54.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:38:54.988+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:38:54.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:38:55.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-08T21:39:25.279+0000] {processor.py:157} INFO - Started process (PID=1644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:25.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:39:25.282+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:25.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:25.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:25.306+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:25.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:39:25.318+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:25.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:39:25.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-08T21:39:55.628+0000] {processor.py:157} INFO - Started process (PID=1654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:55.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:39:55.634+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:55.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:55.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:39:55.682+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:55.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:39:55.708+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:39:55.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:39:55.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-08T21:40:26.053+0000] {processor.py:157} INFO - Started process (PID=1664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:26.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:40:26.058+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:26.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:26.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:26.086+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:26.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:40:26.098+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:26.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:40:26.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T21:40:56.426+0000] {processor.py:157} INFO - Started process (PID=1674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:56.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:40:56.432+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:56.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:56.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:40:56.472+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:56.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:40:56.486+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:40:56.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:40:56.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-08T21:41:26.759+0000] {processor.py:157} INFO - Started process (PID=1684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:26.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:41:26.764+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:26.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:26.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:26.792+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:26.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:41:26.806+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:26.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:41:26.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-08T21:41:57.110+0000] {processor.py:157} INFO - Started process (PID=1694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:57.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:41:57.113+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:57.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:57.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:41:57.142+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:57.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:41:57.155+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:41:57.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:41:57.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-08T21:42:27.422+0000] {processor.py:157} INFO - Started process (PID=1704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:27.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:42:27.428+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:27.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:27.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:27.467+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:27.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:42:27.479+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:27.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:42:27.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-08T21:42:57.824+0000] {processor.py:157} INFO - Started process (PID=1714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:57.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:42:57.827+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:57.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:57.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:42:57.858+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:57.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:42:57.885+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:42:57.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:42:57.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-08T21:43:28.170+0000] {processor.py:157} INFO - Started process (PID=1724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:28.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:43:28.175+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:28.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:28.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:28.214+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:28.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:43:28.228+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:28.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:43:28.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T21:43:58.487+0000] {processor.py:157} INFO - Started process (PID=1734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:58.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:43:58.492+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:58.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:58.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:43:58.531+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:58.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:43:58.543+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:43:58.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:43:58.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-08T21:44:28.983+0000] {processor.py:157} INFO - Started process (PID=1744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:28.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:44:28.994+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:28.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:29.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:29.038+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:29.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:44:29.052+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:29.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:44:29.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-08T21:44:59.319+0000] {processor.py:157} INFO - Started process (PID=1754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:59.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:44:59.322+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:59.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:59.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:44:59.354+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:59.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:44:59.367+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:44:59.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:44:59.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-08T21:45:29.702+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:45:29.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:45:29.707+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:45:29.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:45:29.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:45:29.749+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:45:29.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:45:29.761+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:45:29.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:45:29.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-08T21:46:00.100+0000] {processor.py:157} INFO - Started process (PID=1774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:00.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:46:00.103+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:00.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:00.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:00.155+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:00.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:46:00.170+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:00.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:46:00.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-08T21:46:30.420+0000] {processor.py:157} INFO - Started process (PID=1783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:30.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:46:30.424+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:30.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:30.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:46:30.461+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:30.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:46:30.474+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:46:30.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:46:30.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-08T21:47:00.762+0000] {processor.py:157} INFO - Started process (PID=1794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:00.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:47:00.767+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:00.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:00.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:00.798+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:00.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:47:00.812+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:00.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:47:00.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-08T21:47:31.189+0000] {processor.py:157} INFO - Started process (PID=1804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:31.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:47:31.194+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:31.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:31.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:47:31.247+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:31.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:47:31.261+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:47:31.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:47:31.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-08T21:48:01.533+0000] {processor.py:157} INFO - Started process (PID=1813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:01.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:48:01.544+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:01.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:01.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:01.585+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:01.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:48:01.600+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:01.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:48:01.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T21:48:31.963+0000] {processor.py:157} INFO - Started process (PID=1823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:31.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:48:31.969+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:31.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:32.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:48:32.041+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:32.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:48:32.056+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:48:32.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:48:32.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-08T21:49:02.312+0000] {processor.py:157} INFO - Started process (PID=1834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:02.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:49:02.317+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:02.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:02.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:02.346+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:02.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:49:02.359+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:02.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:49:02.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-08T21:49:32.760+0000] {processor.py:157} INFO - Started process (PID=1844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:32.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:49:32.763+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:32.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:32.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:49:32.792+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:32.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:49:32.805+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:49:32.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:49:32.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T21:50:03.185+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:03.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:50:03.190+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:03.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:03.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:03.259+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:03.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:50:03.275+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:03.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:50:03.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-08T21:50:33.510+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:33.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:50:33.514+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:33.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:33.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:50:33.542+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:33.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:50:33.554+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:50:33.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:50:33.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T21:51:03.847+0000] {processor.py:157} INFO - Started process (PID=1874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:03.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:51:03.852+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:03.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:03.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:03.887+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:03.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:51:03.899+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:03.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:51:03.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-08T21:51:34.204+0000] {processor.py:157} INFO - Started process (PID=1884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:34.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:51:34.208+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:34.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:34.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:51:34.245+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:34.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:51:34.257+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:51:34.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:51:34.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-08T21:52:04.631+0000] {processor.py:157} INFO - Started process (PID=1894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:04.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:52:04.634+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:04.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:04.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:04.662+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:04.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:52:04.674+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:04.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:52:04.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T21:52:34.974+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:34.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:52:34.978+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:34.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:34.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:52:35.016+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:35.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:52:35.040+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:52:35.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:52:35.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T21:53:05.281+0000] {processor.py:157} INFO - Started process (PID=1914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:05.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:53:05.285+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:05.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:05.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:05.317+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:05.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:53:05.331+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:05.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:53:05.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-08T21:53:35.695+0000] {processor.py:157} INFO - Started process (PID=1923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:35.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:53:35.699+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:35.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:35.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:53:35.769+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:35.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:53:35.782+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:53:35.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:53:35.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-08T21:54:06.111+0000] {processor.py:157} INFO - Started process (PID=1934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:06.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:54:06.117+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:06.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:06.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:06.233+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:06.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:54:06.253+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:06.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:54:06.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-08T21:54:36.404+0000] {processor.py:157} INFO - Started process (PID=1944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:36.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:54:36.408+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:36.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:36.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:54:36.433+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:36.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:54:36.443+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:54:36.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:54:36.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-08T21:55:06.797+0000] {processor.py:157} INFO - Started process (PID=1954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:06.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:55:06.800+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:06.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:06.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:06.827+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:06.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:55:06.837+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:06.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:55:06.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-08T21:55:37.178+0000] {processor.py:157} INFO - Started process (PID=1964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:37.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:55:37.181+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:37.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:37.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:55:37.208+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:37.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:55:37.219+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:55:37.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:55:37.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-08T21:56:07.561+0000] {processor.py:157} INFO - Started process (PID=1974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:07.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:56:07.564+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:07.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:07.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:07.593+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:07.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:56:07.604+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:07.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:56:07.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-08T21:56:37.925+0000] {processor.py:157} INFO - Started process (PID=1984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:37.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:56:37.928+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:37.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:37.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:56:37.954+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:37.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:56:37.964+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:56:37.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:56:37.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-08T21:57:08.300+0000] {processor.py:157} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:08.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:57:08.302+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:08.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:08.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:08.332+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:08.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:57:08.344+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:08.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:57:08.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T21:57:38.683+0000] {processor.py:157} INFO - Started process (PID=2004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:38.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:57:38.685+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:38.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:38.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:57:38.712+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:38.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:57:38.722+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:57:38.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:57:38.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-08T21:58:09.082+0000] {processor.py:157} INFO - Started process (PID=2014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:09.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:58:09.088+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:09.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:09.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:09.129+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:09.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:58:09.142+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:09.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:58:09.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-08T21:58:39.458+0000] {processor.py:157} INFO - Started process (PID=2024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:39.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:58:39.461+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:39.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:39.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:58:39.489+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:39.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:58:39.502+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:58:39.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:58:39.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-08T21:59:09.840+0000] {processor.py:157} INFO - Started process (PID=2034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:09.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:59:09.844+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:09.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:09.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:09.869+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:09.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:59:09.878+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:09.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:59:09.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-08T21:59:40.207+0000] {processor.py:157} INFO - Started process (PID=2044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:40.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T21:59:40.211+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:40.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:40.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T21:59:40.237+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:40.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T21:59:40.247+0000] {logging_mixin.py:151} INFO - [2024-09-08T21:59:40.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T21:59:40.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-08T22:00:10.582+0000] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:10.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:00:10.585+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:10.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:10.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:10.613+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:10.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:00:10.626+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:10.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:00:10.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-08T22:00:40.935+0000] {processor.py:157} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:40.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:00:40.939+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:40.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:40.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:00:40.971+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:40.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:00:40.984+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:00:40.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:00:40.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-08T22:01:11.251+0000] {processor.py:157} INFO - Started process (PID=2073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:11.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:01:11.256+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:11.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:11.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:11.298+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:11.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:01:11.315+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:11.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:01:11.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-08T22:01:41.631+0000] {processor.py:157} INFO - Started process (PID=2084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:41.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:01:41.632+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:41.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:41.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:01:41.659+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:41.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:01:41.669+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:01:41.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:01:41.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-08T22:02:12.007+0000] {processor.py:157} INFO - Started process (PID=2094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:12.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:02:12.011+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:12.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:12.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:12.040+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:12.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:02:12.053+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:12.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:02:12.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-08T22:02:42.351+0000] {processor.py:157} INFO - Started process (PID=2104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:42.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:02:42.356+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:42.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:42.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:02:42.418+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:42.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:02:42.435+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:02:42.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:02:42.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-08T22:03:12.667+0000] {processor.py:157} INFO - Started process (PID=2114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:12.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:03:12.677+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:12.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:12.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:12.703+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:12.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:03:12.715+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:12.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:03:12.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-08T22:03:43.080+0000] {processor.py:157} INFO - Started process (PID=2124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:43.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:03:43.082+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:43.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:43.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:03:43.121+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:43.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:03:43.133+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:03:43.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:03:43.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-08T22:04:13.467+0000] {processor.py:157} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:13.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:04:13.469+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:13.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:13.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:13.499+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:13.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:04:13.510+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:13.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:04:13.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-08T22:04:43.863+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:43.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:04:43.866+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:43.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:43.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:04:43.895+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:04:43.905+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:04:43.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:04:43.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-08T22:05:14.259+0000] {processor.py:157} INFO - Started process (PID=2154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:14.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:05:14.262+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:14.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:14.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:14.285+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:14.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:05:14.296+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:14.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:05:14.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-08T22:05:44.601+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:44.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:05:44.606+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:44.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:44.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:05:44.632+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:44.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:05:44.642+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:05:44.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:05:44.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-08T22:06:15.157+0000] {processor.py:157} INFO - Started process (PID=2174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:15.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:06:15.168+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:15.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:15.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:15.232+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:15.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:06:15.252+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:15.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:06:15.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-08T22:06:45.548+0000] {processor.py:157} INFO - Started process (PID=2184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:45.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:06:45.555+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:45.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:45.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:06:45.643+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:45.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:06:45.668+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:06:45.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:06:45.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-08T22:07:15.844+0000] {processor.py:157} INFO - Started process (PID=2194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:15.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:07:15.857+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:15.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:15.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:15.941+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:15.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:07:15.986+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:15.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:07:16.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:07:46.175+0000] {processor.py:157} INFO - Started process (PID=2204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:46.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:07:46.188+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:46.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:46.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:07:46.291+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:46.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:07:46.313+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:07:46.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:07:46.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-08T22:08:16.494+0000] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:16.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:08:16.528+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:16.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:16.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:16.614+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:16.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:08:16.647+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:16.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:08:16.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-08T22:08:46.820+0000] {processor.py:157} INFO - Started process (PID=2224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:46.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:08:46.830+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:46.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:46.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:08:46.933+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:46.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:08:46.957+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:08:46.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:08:46.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-08T22:09:17.143+0000] {processor.py:157} INFO - Started process (PID=2234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:17.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:09:17.155+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:17.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:17.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:17.255+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:17.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:09:17.286+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:17.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:09:17.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-08T22:09:47.596+0000] {processor.py:157} INFO - Started process (PID=2244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:47.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:09:47.616+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:47.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:47.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:09:47.722+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:47.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:09:47.769+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:09:47.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:09:47.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-08T22:10:18.091+0000] {processor.py:157} INFO - Started process (PID=2254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:18.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:10:18.100+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:18.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:18.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:18.236+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:18.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:10:18.263+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:18.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:10:18.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-08T22:10:48.402+0000] {processor.py:157} INFO - Started process (PID=2264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:48.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:10:48.418+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:48.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:10:48.520+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:48.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:10:48.550+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:10:48.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:10:48.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-08T22:11:18.784+0000] {processor.py:157} INFO - Started process (PID=2274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:18.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:11:18.793+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:18.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:18.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:18.895+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:18.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:11:18.919+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:18.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:11:18.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-08T22:11:49.061+0000] {processor.py:157} INFO - Started process (PID=2284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:49.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:11:49.093+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:49.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:49.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:11:49.189+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:49.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:11:49.229+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:11:49.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:11:49.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-09-08T22:12:19.435+0000] {processor.py:157} INFO - Started process (PID=2294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:19.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:12:19.451+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:19.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:19.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:19.542+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:19.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:12:19.563+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:19.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:12:19.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-08T22:12:49.799+0000] {processor.py:157} INFO - Started process (PID=2304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:49.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:12:49.814+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:49.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:49.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:12:49.918+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:49.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:12:49.941+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:12:49.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:12:49.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-08T22:13:20.075+0000] {processor.py:157} INFO - Started process (PID=2314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:20.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:13:20.107+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:20.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:20.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:20.217+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:20.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:13:20.238+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:20.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:13:20.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-08T22:13:50.616+0000] {processor.py:157} INFO - Started process (PID=2323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:50.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:13:50.628+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:50.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:50.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:13:50.724+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:50.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:13:50.747+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:13:50.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:13:50.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-08T22:14:20.953+0000] {processor.py:157} INFO - Started process (PID=2334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:20.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:14:20.965+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:20.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:21.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:21.067+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:21.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:14:21.087+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:21.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:14:21.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-08T22:14:51.274+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:51.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:14:51.291+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:51.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:51.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:14:51.389+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:51.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:14:51.411+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:14:51.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:14:51.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:15:21.668+0000] {processor.py:157} INFO - Started process (PID=2354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:21.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:15:21.677+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:21.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:21.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:21.783+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:21.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:15:21.806+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:21.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:15:21.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-08T22:15:51.966+0000] {processor.py:157} INFO - Started process (PID=2364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:51.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:15:51.976+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:51.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:52.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:15:52.076+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:52.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:15:52.099+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:15:52.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:15:52.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:16:22.304+0000] {processor.py:157} INFO - Started process (PID=2374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:22.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:16:22.312+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:22.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:22.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:22.406+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:22.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:16:22.435+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:22.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:16:22.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-08T22:16:52.688+0000] {processor.py:157} INFO - Started process (PID=2384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:52.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:16:52.696+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:52.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:52.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:16:52.797+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:52.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:16:52.822+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:16:52.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:16:52.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:17:23.002+0000] {processor.py:157} INFO - Started process (PID=2394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:23.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:17:23.011+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:23.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:23.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:23.103+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:23.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:17:23.140+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:23.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:17:23.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-08T22:17:53.320+0000] {processor.py:157} INFO - Started process (PID=2404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:53.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:17:53.350+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:53.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:53.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:17:53.433+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:53.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:17:53.455+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:17:53.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:17:53.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-08T22:18:23.673+0000] {processor.py:157} INFO - Started process (PID=2414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:23.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:18:23.685+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:23.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:23.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:23.769+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:23.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:18:23.798+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:23.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:18:23.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-08T22:18:54.036+0000] {processor.py:157} INFO - Started process (PID=2424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:54.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:18:54.046+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:54.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:54.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:18:54.149+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:54.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:18:54.179+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:18:54.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:18:54.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-08T22:19:24.328+0000] {processor.py:157} INFO - Started process (PID=2434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:24.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:19:24.364+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:24.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:24.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:24.467+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:24.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:19:24.489+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:24.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:19:24.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-08T22:19:54.741+0000] {processor.py:157} INFO - Started process (PID=2443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:54.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:19:54.749+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:54.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:54.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:19:54.852+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:54.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:19:54.875+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:19:54.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:19:54.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-08T22:20:25.113+0000] {processor.py:157} INFO - Started process (PID=2452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:25.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:20:25.125+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:25.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:25.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:25.249+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:25.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:20:25.270+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:25.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:20:25.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.198 seconds
[2024-09-08T22:20:55.662+0000] {processor.py:157} INFO - Started process (PID=2463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:55.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:20:55.672+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:55.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:55.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:20:55.762+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:55.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:20:55.785+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:20:55.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:20:55.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-08T22:21:25.977+0000] {processor.py:157} INFO - Started process (PID=2474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:25.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:21:25.988+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:25.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:26.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:26.085+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:26.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:21:26.106+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:26.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:21:26.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-08T22:21:56.298+0000] {processor.py:157} INFO - Started process (PID=2484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:56.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:21:56.310+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:56.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:56.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:21:56.388+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:56.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:21:56.414+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:21:56.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:21:56.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-08T22:22:26.620+0000] {processor.py:157} INFO - Started process (PID=2494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:26.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:22:26.632+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:26.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:26.753+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:26.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:22:26.774+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:26.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:22:26.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-08T22:22:56.988+0000] {processor.py:157} INFO - Started process (PID=2504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:56.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:22:56.997+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:56.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:57.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:22:57.081+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:57.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:22:57.105+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:22:57.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:22:57.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-08T22:23:27.361+0000] {processor.py:157} INFO - Started process (PID=2514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:27.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:23:27.375+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:27.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:27.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:27.477+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:27.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:23:27.499+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:27.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:23:27.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:23:57.649+0000] {processor.py:157} INFO - Started process (PID=2524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:57.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:23:57.668+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:57.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:57.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:23:57.765+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:57.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:23:57.802+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:23:57.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:23:57.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-08T22:24:27.977+0000] {processor.py:157} INFO - Started process (PID=2534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:27.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:24:28.010+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:28.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:28.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:28.117+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:28.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:24:28.140+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:28.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:24:28.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-08T22:24:58.358+0000] {processor.py:157} INFO - Started process (PID=2543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:58.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:24:58.367+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:58.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:58.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:24:58.475+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:58.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:24:58.500+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:24:58.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:24:58.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-08T22:25:28.888+0000] {processor.py:157} INFO - Started process (PID=2553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:28.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:25:28.912+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:28.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:28.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:28.995+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:28.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:25:29.038+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:29.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:25:29.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-08T22:25:59.194+0000] {processor.py:157} INFO - Started process (PID=2563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:59.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:25:59.202+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:59.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:59.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:25:59.322+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:59.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:25:59.343+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:25:59.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:25:59.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T22:26:29.587+0000] {processor.py:157} INFO - Started process (PID=2573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:26:29.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:26:29.602+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:26:29.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:26:29.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:26:29.702+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:26:29.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:26:29.731+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:26:29.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:26:29.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:26:59.896+0000] {processor.py:157} INFO - Started process (PID=2584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:26:59.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:26:59.924+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:26:59.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:26:59.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:27:00.018+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:27:00.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:27:00.060+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:27:00.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:27:00.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-08T22:27:30.311+0000] {processor.py:157} INFO - Started process (PID=2594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:27:30.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:27:30.321+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:27:30.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:27:30.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:27:30.435+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:27:30.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:27:30.459+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:27:30.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:27:30.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T22:28:00.642+0000] {processor.py:157} INFO - Started process (PID=2604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:00.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:28:00.668+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:00.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:00.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:00.753+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:00.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:28:00.786+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:00.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:28:00.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-08T22:28:31.140+0000] {processor.py:157} INFO - Started process (PID=2614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:31.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:28:31.150+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:31.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:31.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:28:31.224+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:31.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:28:31.250+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:28:31.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:28:31.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-08T22:29:01.427+0000] {processor.py:157} INFO - Started process (PID=2624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:01.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:29:01.437+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:01.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:01.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:01.558+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:01.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:29:01.578+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:01.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:29:01.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T22:29:31.765+0000] {processor.py:157} INFO - Started process (PID=2634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:31.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:29:31.774+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:31.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:31.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:29:31.880+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:31.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:29:31.903+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:29:31.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:29:31.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-08T22:30:02.079+0000] {processor.py:157} INFO - Started process (PID=2644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:02.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:30:02.088+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:02.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:02.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:02.178+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:02.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:30:02.204+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:02.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:30:02.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-08T22:30:32.465+0000] {processor.py:157} INFO - Started process (PID=2654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:32.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:30:32.476+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:32.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:32.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:30:32.574+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:32.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:30:32.598+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:30:32.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:30:32.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-08T22:31:02.737+0000] {processor.py:157} INFO - Started process (PID=2664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:02.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:31:02.755+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:02.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:02.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:02.850+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:02.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:31:02.876+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:02.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:31:02.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-08T22:31:33.095+0000] {processor.py:157} INFO - Started process (PID=2673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:33.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:31:33.107+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:33.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:33.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:31:33.222+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:33.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:31:33.245+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:31:33.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:31:33.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-08T22:32:03.441+0000] {processor.py:157} INFO - Started process (PID=2684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:03.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:32:03.465+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:03.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:03.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:03.559+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:03.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:32:03.579+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:03.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:32:03.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-08T22:32:33.828+0000] {processor.py:157} INFO - Started process (PID=2694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:33.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:32:33.843+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:33.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:33.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:32:33.939+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:33.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:32:33.960+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:32:33.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:32:33.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-08T22:33:04.169+0000] {processor.py:157} INFO - Started process (PID=2704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:04.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:33:04.177+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:04.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:04.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:04.267+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:04.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:33:04.289+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:04.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:33:04.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-08T22:33:34.457+0000] {processor.py:157} INFO - Started process (PID=2714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:34.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:33:34.467+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:34.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:34.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:33:34.578+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:34.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:33:34.602+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:33:34.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:33:34.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-08T22:34:04.787+0000] {processor.py:157} INFO - Started process (PID=2724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:04.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:34:04.803+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:04.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:04.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:04.881+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:04.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:34:04.900+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:04.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:34:04.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-08T22:34:35.161+0000] {processor.py:157} INFO - Started process (PID=2733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:35.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:34:35.192+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:35.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:35.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:34:35.270+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:35.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:34:35.292+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:34:35.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:34:35.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-08T22:35:05.465+0000] {processor.py:157} INFO - Started process (PID=2744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:05.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:35:05.486+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:05.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:05.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:05.574+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:05.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:35:05.598+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:05.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:35:05.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-08T22:35:36.012+0000] {processor.py:157} INFO - Started process (PID=2754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:36.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:35:36.022+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:36.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:36.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:35:36.115+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:36.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:35:36.139+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:35:36.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:35:36.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-08T22:36:06.335+0000] {processor.py:157} INFO - Started process (PID=2764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:06.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:36:06.350+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:06.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:06.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:06.445+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:06.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:36:06.471+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:06.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:36:06.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-08T22:36:36.707+0000] {processor.py:157} INFO - Started process (PID=2774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:36.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:36:36.718+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:36.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:36.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:36:36.809+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:36.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:36:36.831+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:36:36.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:36:36.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-08T22:37:06.995+0000] {processor.py:157} INFO - Started process (PID=2784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:07.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:37:07.015+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:07.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:07.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:07.088+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:07.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:37:07.115+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:07.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:37:07.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-08T22:37:37.497+0000] {processor.py:157} INFO - Started process (PID=2793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:37.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:37:37.510+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:37.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:37.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:37:37.586+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:37.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:37:37.638+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:37:37.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:37:37.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-08T22:38:07.812+0000] {processor.py:157} INFO - Started process (PID=2804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:07.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:38:07.824+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:07.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:07.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:07.955+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:07.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:38:07.977+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:07.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:38:08.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-09-08T22:38:38.315+0000] {processor.py:157} INFO - Started process (PID=2814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:38.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:38:38.329+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:38.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:38.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:38:38.422+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:38.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:38:38.446+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:38:38.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:38:38.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-08T22:39:08.597+0000] {processor.py:157} INFO - Started process (PID=2824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:08.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:39:08.605+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:08.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:08.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:08.701+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:08.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:39:08.725+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:08.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:39:08.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-08T22:39:38.967+0000] {processor.py:157} INFO - Started process (PID=2834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:38.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:39:38.973+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:38.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:39.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:39:39.078+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:39.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:39:39.108+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:39:39.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:39:39.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-08T22:40:09.313+0000] {processor.py:157} INFO - Started process (PID=2843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:09.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:40:09.336+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:09.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:09.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:09.410+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:09.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:40:09.455+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:09.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:40:09.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-08T22:40:39.753+0000] {processor.py:157} INFO - Started process (PID=2854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:39.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:40:39.765+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:39.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:39.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:40:39.853+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:39.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:40:39.872+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:40:39.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:40:39.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-08T22:41:10.072+0000] {processor.py:157} INFO - Started process (PID=2864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:10.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:41:10.088+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:10.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:10.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:10.153+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:10.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:41:10.199+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:10.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:41:10.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-08T22:41:40.392+0000] {processor.py:157} INFO - Started process (PID=2874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:40.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:41:40.416+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:40.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:40.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:41:40.513+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:40.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:41:40.533+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:41:40.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:41:40.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-08T22:42:10.748+0000] {processor.py:157} INFO - Started process (PID=2884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:10.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:42:10.755+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:10.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:10.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:10.809+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:10.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:42:10.828+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:10.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:42:10.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-08T22:42:41.059+0000] {processor.py:157} INFO - Started process (PID=2893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:41.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:42:41.069+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:41.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:41.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:42:41.164+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:41.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:42:41.192+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:42:41.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:42:41.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-08T22:43:11.375+0000] {processor.py:157} INFO - Started process (PID=2904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:11.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:43:11.388+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:11.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:11.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:11.487+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:11.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:43:11.512+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:11.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:43:11.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-08T22:43:41.695+0000] {processor.py:157} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:41.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:43:41.714+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:41.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:41.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:43:41.795+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:41.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:43:41.838+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:43:41.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:43:41.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-08T22:44:12.000+0000] {processor.py:157} INFO - Started process (PID=2924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:12.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:44:12.006+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:12.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:12.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:12.068+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:12.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:44:12.102+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:12.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:44:12.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-08T22:44:42.319+0000] {processor.py:157} INFO - Started process (PID=2934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:42.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:44:42.334+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:42.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:42.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:44:42.429+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:42.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:44:42.478+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:44:42.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:44:42.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-08T22:45:12.672+0000] {processor.py:157} INFO - Started process (PID=2944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:12.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:45:12.684+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:12.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:12.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:12.771+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:12.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:45:12.802+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:12.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:45:12.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T22:45:43.048+0000] {processor.py:157} INFO - Started process (PID=2954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:43.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:45:43.063+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:43.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:43.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:45:43.125+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:43.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:45:43.158+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:45:43.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:45:43.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-08T22:46:13.342+0000] {processor.py:157} INFO - Started process (PID=2964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:13.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:46:13.367+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:13.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:13.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:13.447+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:13.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:46:13.504+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:13.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:46:13.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-08T22:46:43.749+0000] {processor.py:157} INFO - Started process (PID=2972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:43.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:46:43.765+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:43.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:43.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:46:43.918+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:43.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:46:43.988+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:46:43.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:46:44.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.264 seconds
[2024-09-08T22:47:14.139+0000] {processor.py:157} INFO - Started process (PID=2983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:14.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:47:14.147+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:14.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:14.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:14.224+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:14.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:47:14.245+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:14.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:47:14.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-08T22:47:44.528+0000] {processor.py:157} INFO - Started process (PID=2993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:44.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:47:44.559+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:44.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:44.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:47:44.633+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:44.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:47:44.674+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:47:44.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:47:44.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-08T22:48:14.847+0000] {processor.py:157} INFO - Started process (PID=3003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:14.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:48:14.859+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:14.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:14.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:14.940+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:14.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:48:14.969+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:14.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:48:14.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-08T22:48:45.259+0000] {processor.py:157} INFO - Started process (PID=3014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:45.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:48:45.270+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:45.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:45.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:48:45.332+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:45.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:48:45.355+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:48:45.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:48:45.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-08T22:49:15.602+0000] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:15.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:49:15.626+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:15.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:15.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:15.696+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:15.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:49:15.723+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:15.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:49:15.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-08T22:49:45.869+0000] {processor.py:157} INFO - Started process (PID=3034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:45.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:49:45.880+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:45.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:45.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:49:45.950+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:45.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:49:45.989+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:49:45.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:49:46.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-08T22:50:16.232+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:16.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:50:16.250+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:16.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:16.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:16.324+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:16.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:50:16.372+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:16.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:50:16.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-08T22:50:46.572+0000] {processor.py:157} INFO - Started process (PID=3054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:46.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:50:46.584+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:46.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:46.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:50:46.649+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:46.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:50:46.670+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:50:46.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:50:46.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-08T22:51:16.944+0000] {processor.py:157} INFO - Started process (PID=3064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:16.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:51:16.952+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:16.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:16.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:17.046+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:17.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:51:17.070+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:17.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:51:17.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-08T22:51:47.316+0000] {processor.py:157} INFO - Started process (PID=3074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:47.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:51:47.326+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:47.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:47.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:51:47.422+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:47.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:51:47.447+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:51:47.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:51:47.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-08T22:52:17.670+0000] {processor.py:157} INFO - Started process (PID=3084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:17.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:52:17.678+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:17.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:17.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:17.745+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:17.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:52:17.766+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:17.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:52:17.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-08T22:52:48.007+0000] {processor.py:157} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:48.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:52:48.017+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:48.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:48.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:52:48.107+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:48.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:52:48.130+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:52:48.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:52:48.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-08T22:53:18.317+0000] {processor.py:157} INFO - Started process (PID=3104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:18.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:53:18.347+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:18.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:18.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:18.443+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:18.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:53:18.469+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:18.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:53:18.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-08T22:53:48.688+0000] {processor.py:157} INFO - Started process (PID=3113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:48.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:53:48.716+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:48.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:48.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:53:48.794+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:48.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:53:48.820+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:53:48.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:53:48.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-08T22:54:19.011+0000] {processor.py:157} INFO - Started process (PID=3124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:19.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:54:19.023+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:19.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:19.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:19.108+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:19.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:54:19.131+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:19.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:54:19.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-08T22:54:49.491+0000] {processor.py:157} INFO - Started process (PID=3134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:49.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:54:49.503+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:49.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:49.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:54:49.596+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:49.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:54:49.621+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:54:49.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:54:49.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-08T22:55:19.828+0000] {processor.py:157} INFO - Started process (PID=3144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:19.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:55:19.837+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:19.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:19.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:19.926+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:19.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:55:19.946+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:19.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:55:19.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-08T22:55:50.179+0000] {processor.py:157} INFO - Started process (PID=3154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:50.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:55:50.192+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:50.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:50.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:55:50.282+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:50.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:55:50.307+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:55:50.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:55:50.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-08T22:56:20.530+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:20.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:56:20.538+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:20.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:20.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:20.632+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:20.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:56:20.654+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:20.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:56:20.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-08T22:56:50.882+0000] {processor.py:157} INFO - Started process (PID=3174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:50.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:56:50.897+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:50.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:50.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:56:50.988+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:50.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:56:51.013+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:56:51.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:56:51.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-08T22:57:21.211+0000] {processor.py:157} INFO - Started process (PID=3184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:21.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:57:21.224+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:21.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:21.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:21.297+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:21.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:57:21.324+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:21.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:57:21.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-08T22:57:51.626+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:51.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:57:51.648+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:51.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:51.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:57:51.741+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:51.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:57:51.766+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:57:51.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:57:51.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-08T22:58:21.943+0000] {processor.py:157} INFO - Started process (PID=3204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:21.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:58:21.956+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:21.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:21.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:22.024+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:22.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:58:22.048+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:22.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:58:22.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-08T22:58:52.312+0000] {processor.py:157} INFO - Started process (PID=3213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:52.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:58:52.323+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:52.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:52.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:58:52.405+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:52.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:58:52.426+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:58:52.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:58:52.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-08T22:59:22.624+0000] {processor.py:157} INFO - Started process (PID=3224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:22.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:59:22.637+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:22.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:22.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:22.724+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:22.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:59:22.750+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:22.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:59:22.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-08T22:59:53.054+0000] {processor.py:157} INFO - Started process (PID=3234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:53.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T22:59:53.075+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:53.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:53.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T22:59:53.182+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:53.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T22:59:53.210+0000] {logging_mixin.py:151} INFO - [2024-09-08T22:59:53.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T22:59:53.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-08T23:00:23.427+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:23.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:00:23.434+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:23.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:23.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:23.496+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:23.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:00:23.525+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:23.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:00:23.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-08T23:00:53.706+0000] {processor.py:157} INFO - Started process (PID=3254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:53.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:00:53.714+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:53.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:53.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:00:53.823+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:53.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:00:53.846+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:00:53.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:00:53.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-08T23:01:24.027+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:24.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:01:24.049+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:24.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:24.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:24.124+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:24.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:01:24.149+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:24.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:01:24.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-08T23:01:54.356+0000] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:54.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:01:54.382+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:54.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:54.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:01:54.453+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:54.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:01:54.494+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:01:54.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:01:54.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-08T23:02:24.746+0000] {processor.py:157} INFO - Started process (PID=3284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:24.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:02:24.753+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:24.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:24.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:24.850+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:24.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:02:24.876+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:24.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:02:24.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-08T23:02:55.093+0000] {processor.py:157} INFO - Started process (PID=3294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:55.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:02:55.100+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:55.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:55.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:02:55.182+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:55.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:02:55.205+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:02:55.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:02:55.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-08T23:03:25.411+0000] {processor.py:157} INFO - Started process (PID=3304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:25.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:03:25.423+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:25.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:25.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:25.512+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:25.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:03:25.537+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:25.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:03:25.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-08T23:03:55.746+0000] {processor.py:157} INFO - Started process (PID=3314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:55.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:03:55.766+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:55.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:55.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:03:55.830+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:55.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:03:55.865+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:03:55.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:03:55.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-08T23:04:26.016+0000] {processor.py:157} INFO - Started process (PID=3324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:26.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:04:26.023+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:26.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:26.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:26.076+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:26.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:04:26.098+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:26.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:04:26.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-08T23:04:56.366+0000] {processor.py:157} INFO - Started process (PID=3334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:56.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:04:56.394+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:56.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:56.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:04:56.496+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:56.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:04:56.520+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:04:56.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:04:56.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-08T23:05:26.689+0000] {processor.py:157} INFO - Started process (PID=3344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:26.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:05:26.696+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:26.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:26.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:27.461+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:27.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:05:27.503+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:27.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:05:27.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.854 seconds
[2024-09-08T23:05:57.915+0000] {processor.py:157} INFO - Started process (PID=3354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:57.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:05:57.924+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:57.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:57.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:05:57.990+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:57.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:05:58.006+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:05:58.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:05:58.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-08T23:06:28.444+0000] {processor.py:157} INFO - Started process (PID=3364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:28.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:06:28.451+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:28.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:28.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:28.567+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:28.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:06:28.590+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:28.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:06:28.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-08T23:06:58.907+0000] {processor.py:157} INFO - Started process (PID=3374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:58.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:06:58.917+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:58.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:58.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:06:59.016+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:59.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:06:59.036+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:06:59.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:06:59.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-08T23:07:29.191+0000] {processor.py:157} INFO - Started process (PID=3384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:29.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:07:29.200+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:29.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:29.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:29.317+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:29.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:07:29.339+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:29.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:07:29.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T23:07:59.566+0000] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:59.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:07:59.579+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:59.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:59.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:07:59.691+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:59.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:07:59.712+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:07:59.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:07:59.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-08T23:08:29.841+0000] {processor.py:157} INFO - Started process (PID=3404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:08:29.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:08:29.846+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:08:29.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:08:29.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:08:29.905+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:08:29.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:08:29.925+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:08:29.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:08:29.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-08T23:09:00.219+0000] {processor.py:157} INFO - Started process (PID=3414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:00.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:09:00.239+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:00.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:00.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:00.375+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:00.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:09:00.401+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:00.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:09:00.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-08T23:09:30.543+0000] {processor.py:157} INFO - Started process (PID=3424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:30.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:09:30.550+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:30.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:30.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:09:30.667+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:30.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:09:30.688+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:09:30.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:09:30.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-08T23:10:00.891+0000] {processor.py:157} INFO - Started process (PID=3434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:00.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:10:00.902+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:00.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:00.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:01.019+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:01.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:10:01.038+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:01.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:10:01.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-08T23:10:31.253+0000] {processor.py:157} INFO - Started process (PID=3444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:31.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:10:31.262+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:31.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:31.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:10:31.368+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:31.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:10:31.389+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:10:31.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:10:31.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-08T23:11:01.510+0000] {processor.py:157} INFO - Started process (PID=3454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:01.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:11:01.515+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:01.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:01.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:01.571+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:01.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:11:01.582+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:01.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:11:01.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-08T23:11:31.812+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:31.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:11:31.819+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:31.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:31.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:11:31.913+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:31.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:11:31.932+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:11:31.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:11:31.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-08T23:12:02.101+0000] {processor.py:157} INFO - Started process (PID=3474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:02.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:12:02.111+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:02.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:02.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:02.221+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:02.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:12:02.243+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:02.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:12:02.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-08T23:12:32.400+0000] {processor.py:157} INFO - Started process (PID=3484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:32.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:12:32.404+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:32.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:32.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:12:32.450+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:32.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:12:32.467+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:12:32.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:12:32.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-08T23:13:02.698+0000] {processor.py:157} INFO - Started process (PID=3494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:02.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:13:02.703+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:02.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:02.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:02.745+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:02.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:13:02.762+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:02.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:13:02.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-08T23:13:33.024+0000] {processor.py:157} INFO - Started process (PID=3504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:33.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:13:33.029+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:33.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:33.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:13:33.107+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:33.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:13:33.129+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:13:33.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:13:33.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-08T23:14:03.281+0000] {processor.py:157} INFO - Started process (PID=3514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:03.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:14:03.287+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:03.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:03.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:03.325+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:03.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:14:03.345+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:03.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:14:03.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-08T23:14:33.605+0000] {processor.py:157} INFO - Started process (PID=3524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:33.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:14:33.610+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:33.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:33.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:14:33.650+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:33.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:14:33.664+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:14:33.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:14:33.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-08T23:15:03.857+0000] {processor.py:157} INFO - Started process (PID=3534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:03.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:15:03.864+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:03.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:03.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:03.919+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:03.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:15:03.943+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:03.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:15:03.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-08T23:15:34.254+0000] {processor.py:157} INFO - Started process (PID=3544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:34.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:15:34.258+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:34.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:34.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:15:34.298+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:34.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:15:34.316+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:15:34.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:15:34.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-08T23:16:04.517+0000] {processor.py:157} INFO - Started process (PID=3554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:04.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:16:04.523+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:04.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:04.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:04.582+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:04.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:16:04.608+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:04.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:16:04.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-08T23:16:34.877+0000] {processor.py:157} INFO - Started process (PID=3564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:34.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:16:34.880+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:34.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:34.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:16:34.919+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:34.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:16:34.935+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:16:34.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:16:34.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T23:17:05.211+0000] {processor.py:157} INFO - Started process (PID=3574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:05.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:17:05.217+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:05.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:05.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:05.288+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:05.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:17:05.314+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:05.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:17:05.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-08T23:17:35.708+0000] {processor.py:157} INFO - Started process (PID=3584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:35.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:17:35.733+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:35.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:35.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:17:35.843+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:35.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:17:35.891+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:17:35.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:17:35.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-08T23:18:05.983+0000] {processor.py:157} INFO - Started process (PID=3591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:05.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:18:05.989+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:05.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:06.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:06.045+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:06.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:18:06.062+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:06.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:18:06.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-08T23:18:36.360+0000] {processor.py:157} INFO - Started process (PID=3604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:36.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:18:36.364+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:36.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:36.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:18:36.413+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:36.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:18:36.444+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:18:36.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:18:36.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-08T23:19:06.711+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:06.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:19:06.715+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:06.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:06.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:06.754+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:06.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:19:06.786+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:06.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:19:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-08T23:19:36.955+0000] {processor.py:157} INFO - Started process (PID=3624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:36.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:19:36.959+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:36.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:36.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:19:37.009+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:37.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:19:37.030+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:19:37.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:19:37.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-08T23:20:07.242+0000] {processor.py:157} INFO - Started process (PID=3634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:07.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:20:07.246+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:07.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:07.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:07.288+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:07.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:20:07.304+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:07.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:20:07.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-08T23:20:37.552+0000] {processor.py:157} INFO - Started process (PID=3644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:37.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:20:37.560+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:37.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:37.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:20:37.616+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:37.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:20:37.650+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:20:37.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:20:37.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-08T23:21:07.802+0000] {processor.py:157} INFO - Started process (PID=3654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:07.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:21:07.807+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:07.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:07.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:07.862+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:07.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:21:07.882+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:07.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:21:07.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-08T23:21:38.096+0000] {processor.py:157} INFO - Started process (PID=3664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:38.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:21:38.103+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:38.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:38.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:21:38.145+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:38.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:21:38.160+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:21:38.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:21:38.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-08T23:22:08.376+0000] {processor.py:157} INFO - Started process (PID=3674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:08.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:22:08.411+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:08.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:08.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:08.479+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:08.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:22:08.509+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:08.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:22:08.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-08T23:22:38.639+0000] {processor.py:157} INFO - Started process (PID=3684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:38.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:22:38.644+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:38.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:38.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:22:38.695+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:38.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:22:38.715+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:22:38.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:22:38.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-08T23:23:08.946+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:08.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:23:08.949+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:08.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:08.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:08.996+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:08.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:23:09.011+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:09.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:23:09.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-08T23:23:39.229+0000] {processor.py:157} INFO - Started process (PID=3704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:39.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:23:39.237+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:39.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:39.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:23:39.322+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:39.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:23:39.343+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:23:39.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:23:39.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-08T23:24:09.502+0000] {processor.py:157} INFO - Started process (PID=3714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:09.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:24:09.506+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:09.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:09.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:09.545+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:09.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:24:09.562+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:09.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:24:09.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-08T23:24:39.825+0000] {processor.py:157} INFO - Started process (PID=3724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:39.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:24:39.832+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:39.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:39.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:24:39.887+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:39.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:24:39.907+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:24:39.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:24:39.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-08T23:25:10.085+0000] {processor.py:157} INFO - Started process (PID=3734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:10.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:25:10.095+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:10.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:10.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:10.165+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:10.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:25:10.191+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:10.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:25:10.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-08T23:25:40.369+0000] {processor.py:157} INFO - Started process (PID=3744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:40.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:25:40.373+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:40.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:40.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:25:40.410+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:40.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:25:40.421+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:25:40.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:25:40.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-08T23:26:10.675+0000] {processor.py:157} INFO - Started process (PID=3754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:10.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:26:10.685+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:10.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:10.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:10.760+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:10.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:26:10.781+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:10.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:26:10.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-08T23:26:40.951+0000] {processor.py:157} INFO - Started process (PID=3764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:40.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:26:40.955+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:40.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:40.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:26:40.994+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:40.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:26:41.007+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:26:41.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:26:41.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T23:27:11.315+0000] {processor.py:157} INFO - Started process (PID=3774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:11.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:27:11.323+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:11.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:11.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:11.379+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:11.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:27:11.398+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:11.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:27:11.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-08T23:27:41.597+0000] {processor.py:157} INFO - Started process (PID=3784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:41.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:27:41.601+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:41.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:41.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:27:41.634+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:41.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:27:41.648+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:27:41.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:27:41.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-08T23:28:11.959+0000] {processor.py:157} INFO - Started process (PID=3794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:11.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:28:11.990+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:11.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:12.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:12.051+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:12.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:28:12.074+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:12.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:28:12.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-08T23:28:42.405+0000] {processor.py:157} INFO - Started process (PID=3804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:42.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:28:42.410+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:42.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:42.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:28:42.459+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:42.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:28:42.476+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:28:42.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:28:42.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-08T23:29:12.695+0000] {processor.py:157} INFO - Started process (PID=3814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:12.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:29:12.700+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:12.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:12.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:12.745+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:12.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:29:12.775+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:12.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:29:12.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-08T23:29:43.094+0000] {processor.py:157} INFO - Started process (PID=3824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:43.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:29:43.097+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:43.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:43.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:29:43.136+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:43.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:29:43.152+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:29:43.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:29:43.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-08T23:30:13.453+0000] {processor.py:157} INFO - Started process (PID=3833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:13.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:30:13.482+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:13.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:13.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:13.543+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:13.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:30:13.565+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:13.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:30:13.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-08T23:30:43.758+0000] {processor.py:157} INFO - Started process (PID=3844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:43.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:30:43.763+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:43.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:43.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:30:43.812+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:43.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:30:43.829+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:30:43.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:30:43.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-08T23:31:14.080+0000] {processor.py:157} INFO - Started process (PID=3854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:14.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:31:14.084+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:14.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:14.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:14.121+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:14.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:31:14.138+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:14.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:31:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-08T23:31:44.353+0000] {processor.py:157} INFO - Started process (PID=3864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:44.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:31:44.356+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:44.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:44.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:31:44.407+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:44.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:31:44.426+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:31:44.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:31:44.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-08T23:32:14.681+0000] {processor.py:157} INFO - Started process (PID=3874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:14.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:32:14.687+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:14.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:14.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:14.741+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:14.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:32:14.759+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:14.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:32:14.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-08T23:32:45.101+0000] {processor.py:157} INFO - Started process (PID=3884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:45.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:32:45.108+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:45.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:45.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:32:45.180+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:45.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:32:45.200+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:32:45.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:32:45.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-08T23:33:15.351+0000] {processor.py:157} INFO - Started process (PID=3894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:15.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:33:15.355+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:15.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:15.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:15.402+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:15.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:33:15.426+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:15.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:33:15.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-08T23:33:45.749+0000] {processor.py:157} INFO - Started process (PID=3904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:45.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:33:45.755+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:45.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:45.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:33:45.801+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:45.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:33:45.820+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:33:45.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:33:45.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-08T23:34:16.018+0000] {processor.py:157} INFO - Started process (PID=3914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:16.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:34:16.021+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:16.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:16.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:16.061+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:16.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:34:16.074+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:16.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:34:16.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-08T23:34:46.390+0000] {processor.py:157} INFO - Started process (PID=3923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:46.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:34:46.400+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:46.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:46.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:34:46.492+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:46.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:34:46.518+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:34:46.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:34:46.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-08T23:35:16.679+0000] {processor.py:157} INFO - Started process (PID=3934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:16.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:35:16.687+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:16.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:16.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:16.763+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:16.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:35:16.782+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:16.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:35:16.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-08T23:35:47.027+0000] {processor.py:157} INFO - Started process (PID=3944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:47.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:35:47.030+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:47.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:47.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:35:47.066+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:47.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:35:47.082+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:35:47.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:35:47.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T23:36:17.535+0000] {processor.py:157} INFO - Started process (PID=3954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:17.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:36:17.543+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:17.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:17.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:17.604+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:17.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:36:17.624+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:17.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:36:17.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-08T23:36:47.805+0000] {processor.py:157} INFO - Started process (PID=3964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:47.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:36:47.809+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:47.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:47.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:36:47.858+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:47.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:36:47.878+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:36:47.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:36:47.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-08T23:37:18.254+0000] {processor.py:157} INFO - Started process (PID=3974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:18.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:37:18.267+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:18.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:18.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:18.336+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:18.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:37:18.375+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:18.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:37:18.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-08T23:37:48.558+0000] {processor.py:157} INFO - Started process (PID=3984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:48.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:37:48.568+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:48.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:48.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:37:48.631+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:48.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:37:48.653+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:37:48.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:37:48.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-08T23:38:18.843+0000] {processor.py:157} INFO - Started process (PID=3994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:18.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:38:18.863+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:18.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:18.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:18.907+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:18.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:38:18.923+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:18.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:38:18.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-08T23:38:49.271+0000] {processor.py:157} INFO - Started process (PID=4004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:49.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:38:49.281+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:49.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:49.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:38:49.369+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:49.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:38:49.396+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:38:49.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:38:49.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-08T23:39:19.588+0000] {processor.py:157} INFO - Started process (PID=4014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:19.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:39:19.595+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:19.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:19.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:19.673+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:19.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:39:19.695+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:19.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:39:19.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-08T23:39:49.861+0000] {processor.py:157} INFO - Started process (PID=4024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:49.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:39:49.867+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:49.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:49.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:39:49.917+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:49.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:39:49.937+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:39:49.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:39:49.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-08T23:40:20.298+0000] {processor.py:157} INFO - Started process (PID=4034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:20.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:40:20.363+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:20.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:20.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:20.871+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:20.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:40:20.900+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:20.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:40:20.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.626 seconds
[2024-09-08T23:40:51.634+0000] {processor.py:157} INFO - Started process (PID=4044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:51.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:40:51.638+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:51.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:51.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:40:51.737+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:51.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:40:51.761+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:40:51.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:40:51.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-08T23:41:21.962+0000] {processor.py:157} INFO - Started process (PID=4054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:21.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:41:21.967+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:21.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:21.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:22.051+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:22.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:41:22.077+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:22.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:41:22.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-08T23:41:52.261+0000] {processor.py:157} INFO - Started process (PID=4064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:52.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:41:52.270+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:52.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:52.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:41:52.328+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:52.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:41:52.349+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:41:52.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:41:52.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-08T23:42:22.790+0000] {processor.py:157} INFO - Started process (PID=4074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:22.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:42:22.813+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:22.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:22.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:22.879+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:22.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:42:22.904+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:22.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:42:22.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-08T23:42:53.232+0000] {processor.py:157} INFO - Started process (PID=4084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:53.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:42:53.240+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:53.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:53.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:42:53.309+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:53.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:42:53.337+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:42:53.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:42:53.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-08T23:43:23.595+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:23.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:43:23.613+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:23.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:23.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:23.677+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:23.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:43:23.699+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:23.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:43:23.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-08T23:43:53.830+0000] {processor.py:157} INFO - Started process (PID=4104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:53.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:43:53.833+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:53.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:53.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:43:53.874+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:53.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:43:53.891+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:43:53.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:43:53.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-08T23:44:24.145+0000] {processor.py:157} INFO - Started process (PID=4114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:24.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:44:24.152+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:24.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:24.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:24.186+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:24.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:44:24.203+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:24.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:44:24.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-08T23:44:54.783+0000] {processor.py:157} INFO - Started process (PID=4124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:54.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:44:54.796+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:54.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:54.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:44:54.876+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:54.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:44:54.899+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:44:54.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:44:54.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-08T23:45:25.052+0000] {processor.py:157} INFO - Started process (PID=4134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:25.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:45:25.056+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:25.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:25.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:25.090+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:25.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:45:25.109+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:25.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:45:25.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-08T23:45:55.397+0000] {processor.py:157} INFO - Started process (PID=4144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:55.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:45:55.400+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:55.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:55.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:45:55.437+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:55.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:45:55.454+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:45:55.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:45:55.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T23:46:25.654+0000] {processor.py:157} INFO - Started process (PID=4153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:25.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:46:25.662+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:25.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:25.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:25.706+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:25.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:46:25.725+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:25.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:46:25.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-08T23:46:56.057+0000] {processor.py:157} INFO - Started process (PID=4164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:56.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:46:56.066+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:56.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:56.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:46:56.142+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:56.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:46:56.161+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:46:56.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:46:56.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-08T23:47:26.339+0000] {processor.py:157} INFO - Started process (PID=4174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:26.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:47:26.364+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:26.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:26.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:26.439+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:26.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:47:26.461+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:26.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:47:26.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-08T23:47:56.780+0000] {processor.py:157} INFO - Started process (PID=4184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:56.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:47:56.787+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:56.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:56.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:47:56.915+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:56.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:47:56.953+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:47:56.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:47:56.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-08T23:48:27.221+0000] {processor.py:157} INFO - Started process (PID=4194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:27.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:48:27.227+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:27.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:27.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:27.273+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:27.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:48:27.295+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:27.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:48:27.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-08T23:48:57.428+0000] {processor.py:157} INFO - Started process (PID=4204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:57.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:48:57.435+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:57.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:57.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:48:57.470+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:57.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:48:57.484+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:48:57.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:48:57.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-08T23:49:27.759+0000] {processor.py:157} INFO - Started process (PID=4214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:27.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:49:27.762+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:27.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:27.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:27.798+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:27.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:49:27.816+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:27.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:49:27.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T23:49:58.089+0000] {processor.py:157} INFO - Started process (PID=4224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:58.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:49:58.094+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:58.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:58.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:49:58.130+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:58.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:49:58.143+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:49:58.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:49:58.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-08T23:50:28.442+0000] {processor.py:157} INFO - Started process (PID=4234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:28.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:50:28.448+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:28.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:28.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:28.493+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:28.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:50:28.512+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:28.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:50:28.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-08T23:50:58.983+0000] {processor.py:157} INFO - Started process (PID=4244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:58.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:50:58.994+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:58.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:59.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:50:59.059+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:59.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:50:59.081+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:50:59.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:50:59.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-08T23:51:29.297+0000] {processor.py:157} INFO - Started process (PID=4254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:29.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:51:29.305+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:29.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:29.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:29.404+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:29.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:51:29.427+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:29.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:51:29.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-08T23:51:59.547+0000] {processor.py:157} INFO - Started process (PID=4263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:59.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:51:59.555+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:59.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:51:59.637+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:59.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:51:59.658+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:51:59.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:51:59.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-08T23:52:29.834+0000] {processor.py:157} INFO - Started process (PID=4274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:52:29.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:52:29.843+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:52:29.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:52:29.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:52:29.905+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:52:29.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:52:29.923+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:52:29.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:52:29.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-08T23:53:00.021+0000] {processor.py:157} INFO - Started process (PID=4284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:00.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:53:00.024+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:00.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:00.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:00.065+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:00.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:53:00.080+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:00.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:53:00.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-08T23:53:30.427+0000] {processor.py:157} INFO - Started process (PID=4294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:30.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:53:30.437+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:30.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:30.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:53:30.590+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:30.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:53:30.637+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:53:30.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:53:30.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-09-08T23:54:01.190+0000] {processor.py:157} INFO - Started process (PID=4304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:01.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:54:01.197+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:01.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:01.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:01.275+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:01.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:54:01.298+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:01.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:54:01.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-08T23:54:31.744+0000] {processor.py:157} INFO - Started process (PID=4314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:31.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:54:31.748+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:31.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:31.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:54:31.810+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:31.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:54:31.830+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:54:31.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:54:31.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-08T23:55:02.059+0000] {processor.py:157} INFO - Started process (PID=4324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:02.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:55:02.067+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:02.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:02.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:02.142+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:02.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:55:02.162+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:02.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:55:02.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-08T23:55:32.361+0000] {processor.py:157} INFO - Started process (PID=4334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:32.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:55:32.370+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:32.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:32.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:55:32.438+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:32.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:55:32.456+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:55:32.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:55:32.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-08T23:56:02.647+0000] {processor.py:157} INFO - Started process (PID=4344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:02.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:56:02.653+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:02.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:02.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:02.692+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:02.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:56:02.711+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:02.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:56:02.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-08T23:56:32.976+0000] {processor.py:157} INFO - Started process (PID=4354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:32.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:56:32.978+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:32.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:32.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:56:33.014+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:33.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:56:33.027+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:56:33.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:56:33.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-08T23:57:03.286+0000] {processor.py:157} INFO - Started process (PID=4364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:03.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:57:03.293+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:03.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:03.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:03.368+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:03.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:57:03.387+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:03.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:57:03.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-08T23:57:33.615+0000] {processor.py:157} INFO - Started process (PID=4374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:33.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:57:33.625+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:33.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:33.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:57:33.696+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:33.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:57:33.719+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:57:33.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:57:33.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-08T23:58:03.891+0000] {processor.py:157} INFO - Started process (PID=4384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:03.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:58:03.901+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:03.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:03.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:03.943+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:03.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:58:03.959+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:03.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:58:03.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-08T23:58:34.223+0000] {processor.py:157} INFO - Started process (PID=4394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:34.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:58:34.227+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:34.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:34.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:58:34.263+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:34.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:58:34.277+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:58:34.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:58:34.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-08T23:59:04.568+0000] {processor.py:157} INFO - Started process (PID=4404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:04.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:59:04.576+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:04.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:04.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:04.624+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:04.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:59:04.645+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:04.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:59:04.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-08T23:59:34.825+0000] {processor.py:157} INFO - Started process (PID=4414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:34.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-08T23:59:34.838+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:34.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:34.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-08T23:59:34.880+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:34.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-08T23:59:34.898+0000] {logging_mixin.py:151} INFO - [2024-09-08T23:59:34.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-07T01:00:00+00:00, run_after=2024-09-08T01:00:00+00:00
[2024-09-08T23:59:34.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
