[2024-08-19T00:06:40.778+0000] {processor.py:157} INFO - Started process (PID=68596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:06:40.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T00:06:40.787+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:06:40.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:06:40.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:06:40.848+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:06:40.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T00:06:40.869+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:06:40.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-17T01:00:00+00:00, run_after=2024-08-18T01:00:00+00:00
[2024-08-19T00:06:40.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T00:22:38.195+0000] {processor.py:157} INFO - Started process (PID=68607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:22:38.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T00:22:38.198+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:22:38.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:22:38.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T00:22:38.258+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:22:38.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T00:22:38.279+0000] {logging_mixin.py:151} INFO - [2024-08-19T00:22:38.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-17T01:00:00+00:00, run_after=2024-08-18T01:00:00+00:00
[2024-08-19T00:22:38.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T01:05:48.219+0000] {processor.py:157} INFO - Started process (PID=68618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:05:48.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T01:05:48.233+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:05:48.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:05:48.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:05:48.355+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:05:48.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T01:05:48.452+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:05:48.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T01:05:48.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.266 seconds
[2024-08-19T01:06:19.527+0000] {processor.py:157} INFO - Started process (PID=69144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:06:19.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T01:06:19.536+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:06:19.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:06:19.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T01:06:19.653+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:06:19.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T01:06:19.684+0000] {logging_mixin.py:151} INFO - [2024-08-19T01:06:19.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T01:06:19.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-19T03:01:21.937+0000] {processor.py:157} INFO - Started process (PID=69254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:01:21.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T03:01:21.946+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:01:21.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:01:21.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:01:22.021+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:01:22.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T03:01:22.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:01:22.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T03:01:22.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-19T03:07:34.134+0000] {processor.py:157} INFO - Started process (PID=69432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:07:34.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T03:07:34.141+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:07:34.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:07:34.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:07:34.208+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:07:34.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T03:07:34.231+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:07:34.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T03:07:34.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T03:55:22.042+0000] {processor.py:157} INFO - Started process (PID=69442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:55:22.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T03:55:22.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:55:22.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:55:22.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T03:55:22.107+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:55:22.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T03:55:22.124+0000] {logging_mixin.py:151} INFO - [2024-08-19T03:55:22.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T03:55:22.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T04:08:33.219+0000] {processor.py:157} INFO - Started process (PID=69452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:08:33.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T04:08:33.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:08:33.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:08:33.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:08:33.337+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:08:33.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T04:08:33.367+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:08:33.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T04:08:33.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-19T04:42:35.455+0000] {processor.py:157} INFO - Started process (PID=69461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:42:35.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T04:42:35.462+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:42:35.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:42:35.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:42:35.502+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:42:35.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T04:42:35.518+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:42:35.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T04:42:35.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-19T04:48:27.575+0000] {processor.py:157} INFO - Started process (PID=69472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:48:27.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T04:48:27.592+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:48:27.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:48:27.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T04:48:27.659+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:48:27.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T04:48:27.688+0000] {logging_mixin.py:151} INFO - [2024-08-19T04:48:27.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T04:48:27.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T05:09:14.706+0000] {processor.py:157} INFO - Started process (PID=69484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:14.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T05:09:14.711+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:14.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:14.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:14.753+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:14.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T05:09:14.769+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:14.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T05:09:14.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-19T05:09:45.192+0000] {processor.py:157} INFO - Started process (PID=69494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:45.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T05:09:45.197+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:45.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:45.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T05:09:45.252+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:45.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T05:09:45.276+0000] {logging_mixin.py:151} INFO - [2024-08-19T05:09:45.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T05:09:45.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T06:14:03.785+0000] {processor.py:157} INFO - Started process (PID=69503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T06:14:03.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T06:14:03.792+0000] {logging_mixin.py:151} INFO - [2024-08-19T06:14:03.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T06:14:03.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T06:14:03.831+0000] {logging_mixin.py:151} INFO - [2024-08-19T06:14:03.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T06:14:03.843+0000] {logging_mixin.py:151} INFO - [2024-08-19T06:14:03.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T06:14:03.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-19T07:53:55.940+0000] {processor.py:157} INFO - Started process (PID=69514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T07:53:55.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T07:53:55.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T07:53:55.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T07:53:55.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T07:53:56.000+0000] {logging_mixin.py:151} INFO - [2024-08-19T07:53:56.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T07:53:56.022+0000] {logging_mixin.py:151} INFO - [2024-08-19T07:53:56.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T07:53:56.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-19T09:18:05.181+0000] {processor.py:157} INFO - Started process (PID=69524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T09:18:05.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T09:18:05.188+0000] {logging_mixin.py:151} INFO - [2024-08-19T09:18:05.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T09:18:05.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T09:18:05.226+0000] {logging_mixin.py:151} INFO - [2024-08-19T09:18:05.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T09:18:05.240+0000] {logging_mixin.py:151} INFO - [2024-08-19T09:18:05.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T09:18:05.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-19T10:01:19.219+0000] {processor.py:157} INFO - Started process (PID=69535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:01:19.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T10:01:19.226+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:01:19.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:01:19.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:01:19.264+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:01:19.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T10:01:19.278+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:01:19.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T10:01:19.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-19T10:19:29.709+0000] {processor.py:157} INFO - Started process (PID=69545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:19:29.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T10:19:29.714+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:19:29.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:19:29.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T10:19:29.788+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:19:29.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T10:19:29.815+0000] {logging_mixin.py:151} INFO - [2024-08-19T10:19:29.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T10:19:29.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T11:59:01.328+0000] {processor.py:157} INFO - Started process (PID=69555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T11:59:01.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T11:59:01.334+0000] {logging_mixin.py:151} INFO - [2024-08-19T11:59:01.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T11:59:01.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T11:59:01.379+0000] {logging_mixin.py:151} INFO - [2024-08-19T11:59:01.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T11:59:01.394+0000] {logging_mixin.py:151} INFO - [2024-08-19T11:59:01.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T11:59:01.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T12:02:31.348+0000] {processor.py:157} INFO - Started process (PID=69566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:02:31.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T12:02:31.353+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:02:31.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:02:31.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:02:31.396+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:02:31.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T12:02:31.409+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:02:31.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T12:02:31.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T12:35:14.464+0000] {processor.py:157} INFO - Started process (PID=69578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:35:14.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T12:35:14.476+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:35:14.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:35:14.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T12:35:14.530+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:35:14.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T12:35:14.547+0000] {logging_mixin.py:151} INFO - [2024-08-19T12:35:14.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T12:35:14.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T13:01:24.352+0000] {processor.py:157} INFO - Started process (PID=69587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:01:24.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T13:01:24.360+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:01:24.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:01:24.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:01:24.419+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:01:24.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T13:01:24.432+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:01:24.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T13:01:24.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T13:03:14.713+0000] {processor.py:157} INFO - Started process (PID=69598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:14.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T13:03:14.720+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:14.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:14.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:14.758+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:14.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T13:03:14.771+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:14.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T13:03:14.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-19T13:03:45.066+0000] {processor.py:157} INFO - Started process (PID=69608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:45.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T13:03:45.072+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:45.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:45.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T13:03:45.115+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:45.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T13:03:45.131+0000] {logging_mixin.py:151} INFO - [2024-08-19T13:03:45.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T13:03:45.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-19T14:04:14.283+0000] {processor.py:157} INFO - Started process (PID=69618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:14.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:04:14.292+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:14.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:14.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:14.327+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:14.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:04:14.348+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:14.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:04:14.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T14:04:44.745+0000] {processor.py:157} INFO - Started process (PID=69628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:44.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:04:44.751+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:44.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:44.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:04:44.790+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:44.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:04:44.803+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:04:44.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:04:44.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-19T14:13:45.912+0000] {processor.py:157} INFO - Started process (PID=69639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:13:45.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:13:45.931+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:13:45.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:13:45.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:13:45.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:13:45.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:13:45.985+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:13:45.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:13:46.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T14:14:16.307+0000] {processor.py:157} INFO - Started process (PID=69650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:16.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:14:16.312+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:16.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:16.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:16.364+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:16.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:14:16.382+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:16.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:14:16.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T14:14:46.661+0000] {processor.py:157} INFO - Started process (PID=69660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:46.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:14:46.665+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:46.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:46.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:14:46.727+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:46.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:14:46.751+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:14:46.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:14:46.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T14:15:17.019+0000] {processor.py:157} INFO - Started process (PID=69670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:17.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:15:17.024+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:17.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:17.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:17.078+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:17.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:15:17.091+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:17.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:15:17.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T14:15:47.295+0000] {processor.py:157} INFO - Started process (PID=69680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:47.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:15:47.298+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:47.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:47.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:15:47.333+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:47.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:15:47.346+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:15:47.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:15:47.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-19T14:16:17.626+0000] {processor.py:157} INFO - Started process (PID=69690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:17.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:16:17.628+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:17.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:17.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:17.653+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:17.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:16:17.662+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:17.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:16:17.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-19T14:16:48.000+0000] {processor.py:157} INFO - Started process (PID=69700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:48.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:16:48.005+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:48.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:48.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:16:48.041+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:48.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:16:48.054+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:16:48.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:16:48.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-19T14:17:18.411+0000] {processor.py:157} INFO - Started process (PID=69710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:18.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:17:18.414+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:18.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:18.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:18.443+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:18.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:17:18.456+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:18.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:17:18.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-19T14:17:48.787+0000] {processor.py:157} INFO - Started process (PID=69719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:48.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:17:48.792+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:48.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:48.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:17:48.834+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:48.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:17:48.846+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:17:48.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:17:48.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T14:18:19.081+0000] {processor.py:157} INFO - Started process (PID=69730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:19.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:18:19.084+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:19.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:19.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:19.114+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:19.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:18:19.125+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:19.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:18:19.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-19T14:18:49.533+0000] {processor.py:157} INFO - Started process (PID=69740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:49.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:18:49.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:49.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:49.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:18:49.607+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:49.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:18:49.618+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:18:49.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:18:49.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T14:19:19.989+0000] {processor.py:157} INFO - Started process (PID=69750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:19.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:19:19.994+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:19.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:20.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:20.031+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:20.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:19:20.045+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:20.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:19:20.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-19T14:19:50.332+0000] {processor.py:157} INFO - Started process (PID=69760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:50.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:19:50.338+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:50.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:50.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:19:50.400+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:50.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:19:50.415+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:19:50.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:19:50.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T14:20:20.658+0000] {processor.py:157} INFO - Started process (PID=69770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:20.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:20:20.664+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:20.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:20.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:20.698+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:20.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:20:20.709+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:20.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:20:20.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-19T14:20:51.015+0000] {processor.py:157} INFO - Started process (PID=69780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:51.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:20:51.019+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:51.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:51.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:20:51.069+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:51.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:20:51.087+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:20:51.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:20:51.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-19T14:21:21.344+0000] {processor.py:157} INFO - Started process (PID=69789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:21.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:21:21.350+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:21.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:21.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:21.400+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:21.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:21:21.415+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:21.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:21:21.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T14:21:51.727+0000] {processor.py:157} INFO - Started process (PID=69799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:51.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:21:51.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:51.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:51.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:21:51.782+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:51.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:21:51.801+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:21:51.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:21:51.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T14:22:22.090+0000] {processor.py:157} INFO - Started process (PID=69810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:22.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:22:22.094+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:22.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:22.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:22.132+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:22.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:22:22.145+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:22.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:22:22.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-19T14:22:52.522+0000] {processor.py:157} INFO - Started process (PID=69820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:52.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:22:52.531+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:52.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:52.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:22:52.596+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:52.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:22:52.626+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:22:52.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:22:52.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-19T14:23:22.884+0000] {processor.py:157} INFO - Started process (PID=69829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:22.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:23:22.901+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:22.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:22.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:22.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:22.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:23:22.969+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:22.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:23:22.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T14:23:53.249+0000] {processor.py:157} INFO - Started process (PID=69840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:53.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:23:53.251+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:53.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:53.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:23:53.275+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:53.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:23:53.285+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:23:53.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:23:53.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-19T14:24:23.597+0000] {processor.py:157} INFO - Started process (PID=69850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:23.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:24:23.605+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:23.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:23.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:23.652+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:23.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:24:23.669+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:23.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:24:23.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T14:24:53.919+0000] {processor.py:157} INFO - Started process (PID=69860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:53.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:24:53.921+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:53.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:53.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:24:53.949+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:53.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:24:53.958+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:24:53.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:24:53.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T14:25:24.333+0000] {processor.py:157} INFO - Started process (PID=69870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:24.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:25:24.340+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:24.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:24.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:24.404+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:24.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:25:24.418+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:24.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:25:24.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T14:25:54.660+0000] {processor.py:157} INFO - Started process (PID=69880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:54.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:25:54.667+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:54.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:54.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:25:54.711+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:54.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:25:54.739+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:25:54.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:25:54.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T14:26:24.984+0000] {processor.py:157} INFO - Started process (PID=69890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:24.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:26:24.987+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:24.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:24.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:25.013+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:25.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:26:25.022+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:25.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:26:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-19T14:26:55.373+0000] {processor.py:157} INFO - Started process (PID=69900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:55.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:26:55.385+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:55.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:55.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:26:55.434+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:55.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:26:55.458+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:26:55.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:26:55.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T14:27:25.675+0000] {processor.py:157} INFO - Started process (PID=69910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:25.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:27:25.680+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:25.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:25.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:25.719+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:25.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:27:25.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:25.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:27:25.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-19T14:27:56.028+0000] {processor.py:157} INFO - Started process (PID=69920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:56.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:27:56.030+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:56.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:56.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:27:56.062+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:56.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:27:56.074+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:27:56.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:27:56.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-19T14:28:26.362+0000] {processor.py:157} INFO - Started process (PID=69930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:26.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:28:26.368+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:26.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:26.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:26.403+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:26.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:28:26.415+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:26.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:28:26.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-19T14:28:56.783+0000] {processor.py:157} INFO - Started process (PID=69940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:56.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:28:56.788+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:56.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:56.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:28:56.848+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:56.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:28:56.863+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:28:56.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:28:56.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T14:29:27.112+0000] {processor.py:157} INFO - Started process (PID=69950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:27.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:29:27.116+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:27.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:27.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:27.144+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:27.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:29:27.155+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:27.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:29:27.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-19T14:29:57.555+0000] {processor.py:157} INFO - Started process (PID=69959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:57.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:29:57.562+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:57.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:57.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:29:57.614+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:57.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:29:57.628+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:29:57.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:29:57.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T14:30:27.824+0000] {processor.py:157} INFO - Started process (PID=69970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:27.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:30:27.829+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:27.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:27.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:27.861+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:27.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:30:27.872+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:27.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:30:27.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-19T14:30:58.237+0000] {processor.py:157} INFO - Started process (PID=69980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:58.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:30:58.242+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:58.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:58.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:30:58.281+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:58.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:30:58.310+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:30:58.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:30:58.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T14:31:28.617+0000] {processor.py:157} INFO - Started process (PID=69990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:28.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:31:28.626+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:28.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:28.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:28.670+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:28.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:31:28.685+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:28.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:31:28.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T14:31:58.892+0000] {processor.py:157} INFO - Started process (PID=70000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:58.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:31:58.897+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:58.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:58.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:31:58.932+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:58.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:31:58.944+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:31:58.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:31:58.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-19T14:32:29.260+0000] {processor.py:157} INFO - Started process (PID=70010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:29.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:32:29.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:29.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:29.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:29.303+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:29.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:32:29.314+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:29.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:32:29.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-19T14:32:59.660+0000] {processor.py:157} INFO - Started process (PID=70020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:59.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:32:59.668+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:59.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:59.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:32:59.718+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:59.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:32:59.733+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:32:59.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:32:59.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T14:33:30.115+0000] {processor.py:157} INFO - Started process (PID=70030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:33:30.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:33:30.130+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:33:30.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:33:30.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:33:30.195+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:33:30.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:33:30.211+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:33:30.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:33:30.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-19T14:34:00.677+0000] {processor.py:157} INFO - Started process (PID=70040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:00.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:34:00.695+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:00.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:00.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:00.807+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:00.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:34:00.835+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:00.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:34:00.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-19T14:34:31.297+0000] {processor.py:157} INFO - Started process (PID=70050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:31.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:34:31.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:31.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:31.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:34:31.377+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:31.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:34:31.397+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:34:31.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:34:31.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-19T14:35:01.685+0000] {processor.py:157} INFO - Started process (PID=70060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:01.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:35:01.709+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:01.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:01.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:01.757+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:01.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:35:01.773+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:01.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:35:01.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T14:35:32.124+0000] {processor.py:157} INFO - Started process (PID=70070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:32.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:35:32.129+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:32.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:32.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:35:32.192+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:32.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:35:32.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:35:32.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:35:32.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T14:36:02.583+0000] {processor.py:157} INFO - Started process (PID=70080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:02.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:36:02.596+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:02.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:02.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:02.665+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:02.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:36:02.689+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:02.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:36:02.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T14:36:32.907+0000] {processor.py:157} INFO - Started process (PID=70090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:32.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:36:32.913+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:32.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:32.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:36:32.957+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:32.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:36:32.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:36:32.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:36:32.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T14:37:03.355+0000] {processor.py:157} INFO - Started process (PID=70100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:03.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:37:03.363+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:03.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:03.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:03.415+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:03.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:37:03.429+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:03.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:37:03.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T14:37:33.758+0000] {processor.py:157} INFO - Started process (PID=70110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:33.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:37:33.765+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:33.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:33.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:37:33.832+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:33.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:37:33.849+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:37:33.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:37:33.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T14:38:04.080+0000] {processor.py:157} INFO - Started process (PID=70120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:04.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:38:04.086+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:04.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:04.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:04.144+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:04.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:38:04.169+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:04.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:38:04.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T14:38:34.432+0000] {processor.py:157} INFO - Started process (PID=70130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:34.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:38:34.435+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:34.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:34.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:38:34.474+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:34.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:38:34.487+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:38:34.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:38:34.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-19T14:39:04.864+0000] {processor.py:157} INFO - Started process (PID=70140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:04.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:39:04.874+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:04.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:04.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:04.933+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:04.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:39:04.956+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:04.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:39:04.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-19T14:39:35.356+0000] {processor.py:157} INFO - Started process (PID=70150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:35.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:39:35.366+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:35.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:35.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:39:35.448+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:35.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:39:35.466+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:39:35.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:39:35.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T14:40:05.850+0000] {processor.py:157} INFO - Started process (PID=70159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:05.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:40:05.857+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:05.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:05.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:05.909+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:05.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:40:05.925+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:05.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:40:05.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T14:40:36.133+0000] {processor.py:157} INFO - Started process (PID=70170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:36.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:40:36.140+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:36.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:36.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:40:36.164+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:36.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:40:36.176+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:40:36.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:40:36.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T14:41:06.583+0000] {processor.py:157} INFO - Started process (PID=70180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:06.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:41:06.587+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:06.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:06.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:06.654+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:06.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:41:06.671+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:06.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:41:06.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T14:41:37.007+0000] {processor.py:157} INFO - Started process (PID=70190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:37.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:41:37.016+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:37.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:37.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:41:37.078+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:37.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:41:37.092+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:41:37.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:41:37.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T14:42:07.279+0000] {processor.py:157} INFO - Started process (PID=70200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:07.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:42:07.283+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:07.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:07.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:07.310+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:07.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:42:07.322+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:07.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:42:07.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-19T14:42:37.675+0000] {processor.py:157} INFO - Started process (PID=70210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:37.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:42:37.682+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:37.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:37.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:42:37.748+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:37.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:42:37.764+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:42:37.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:42:37.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T14:43:07.988+0000] {processor.py:157} INFO - Started process (PID=70219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:07.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:43:08.030+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:08.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:08.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:08.098+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:08.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:43:08.118+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:08.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:43:08.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-19T14:43:38.318+0000] {processor.py:157} INFO - Started process (PID=70230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:38.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:43:38.327+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:38.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:38.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:43:38.383+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:38.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:43:38.397+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:43:38.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:43:38.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T14:44:08.875+0000] {processor.py:157} INFO - Started process (PID=70240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:08.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:44:08.882+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:08.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:08.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:08.992+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:08.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:44:09.016+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:09.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:44:09.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-19T14:44:39.209+0000] {processor.py:157} INFO - Started process (PID=70250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:39.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:44:39.215+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:39.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:39.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:44:39.271+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:39.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:44:39.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:44:39.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:44:39.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T14:45:09.583+0000] {processor.py:157} INFO - Started process (PID=70260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:09.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:45:09.587+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:09.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:09.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:09.634+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:09.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:45:09.649+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:09.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:45:09.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-19T14:45:40.013+0000] {processor.py:157} INFO - Started process (PID=70270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:40.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:45:40.032+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:40.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:40.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:45:40.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:40.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:45:40.161+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:45:40.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:45:40.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-19T14:46:10.331+0000] {processor.py:157} INFO - Started process (PID=70280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:10.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:46:10.338+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:10.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:10.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:10.402+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:10.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:46:10.417+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:10.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:46:10.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T14:46:40.776+0000] {processor.py:157} INFO - Started process (PID=70290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:40.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:46:40.792+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:40.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:40.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:46:40.849+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:40.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:46:40.870+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:46:40.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:46:40.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T14:47:11.069+0000] {processor.py:157} INFO - Started process (PID=70300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:11.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:47:11.074+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:11.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:11.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:11.112+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:11.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:47:11.126+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:11.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:47:11.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-19T14:47:41.487+0000] {processor.py:157} INFO - Started process (PID=70310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:41.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:47:41.499+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:41.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:41.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:47:41.565+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:41.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:47:41.585+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:47:41.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:47:41.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T14:48:11.886+0000] {processor.py:157} INFO - Started process (PID=70320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:11.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:48:11.896+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:11.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:11.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:11.985+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:11.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:48:12.009+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:12.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:48:12.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-19T14:48:42.435+0000] {processor.py:157} INFO - Started process (PID=70330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:42.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:48:42.451+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:42.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:42.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:48:42.532+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:42.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:48:42.552+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:48:42.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:48:42.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-19T14:49:12.748+0000] {processor.py:157} INFO - Started process (PID=70340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:12.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:49:12.756+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:12.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:12.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:12.830+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:12.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:49:12.850+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:12.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:49:12.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T14:49:43.205+0000] {processor.py:157} INFO - Started process (PID=70350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:43.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:49:43.211+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:43.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:43.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:49:43.271+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:43.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:49:43.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:49:43.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:49:43.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T14:50:13.536+0000] {processor.py:157} INFO - Started process (PID=70360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:13.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:50:13.542+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:13.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:13.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:13.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:13.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:50:13.608+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:13.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:50:13.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-19T14:50:43.909+0000] {processor.py:157} INFO - Started process (PID=70370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:43.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:50:43.920+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:43.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:43.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:50:44.024+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:44.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:50:44.042+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:50:44.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:50:44.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-19T14:51:14.277+0000] {processor.py:157} INFO - Started process (PID=70380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:14.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:51:14.288+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:14.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:14.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:14.358+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:14.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:51:14.376+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:14.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:51:14.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T14:51:44.622+0000] {processor.py:157} INFO - Started process (PID=70389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:44.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:51:44.630+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:44.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:44.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:51:44.683+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:44.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:51:44.700+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:51:44.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:51:44.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T14:52:14.961+0000] {processor.py:157} INFO - Started process (PID=70400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:14.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:52:14.969+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:14.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:14.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:15.035+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:15.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:52:15.066+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:15.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:52:15.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T14:52:45.336+0000] {processor.py:157} INFO - Started process (PID=70410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:45.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:52:45.340+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:45.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:45.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:52:45.383+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:45.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:52:45.404+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:52:45.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:52:45.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T14:53:15.844+0000] {processor.py:157} INFO - Started process (PID=70420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:15.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:53:15.853+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:15.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:15.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:15.929+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:15.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:53:15.955+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:15.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:53:15.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T14:53:46.224+0000] {processor.py:157} INFO - Started process (PID=70430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:46.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:53:46.232+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:46.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:46.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:53:46.283+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:46.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:53:46.299+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:53:46.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:53:46.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T14:54:16.540+0000] {processor.py:157} INFO - Started process (PID=70439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:16.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:54:16.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:16.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:16.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:16.596+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:16.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:54:16.630+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:16.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:54:16.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T14:54:46.916+0000] {processor.py:157} INFO - Started process (PID=70450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:46.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:54:46.935+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:46.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:46.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:54:46.994+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:46.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:54:47.010+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:54:47.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:54:47.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-19T14:55:17.258+0000] {processor.py:157} INFO - Started process (PID=70460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:17.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:55:17.265+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:17.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:17.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:17.316+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:17.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:55:17.334+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:17.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:55:17.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T14:55:47.690+0000] {processor.py:157} INFO - Started process (PID=70470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:47.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:55:47.714+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:47.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:47.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:55:47.801+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:47.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:55:47.836+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:55:47.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:55:47.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-19T14:56:18.107+0000] {processor.py:157} INFO - Started process (PID=70480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:18.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:56:18.117+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:18.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:18.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:18.205+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:18.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:56:18.220+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:18.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:56:18.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-19T14:56:48.505+0000] {processor.py:157} INFO - Started process (PID=70489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:48.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:56:48.514+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:48.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:48.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:56:48.561+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:48.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:56:48.581+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:56:48.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:56:48.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T14:57:18.837+0000] {processor.py:157} INFO - Started process (PID=70500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:18.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:57:18.858+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:18.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:18.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:18.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:18.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:57:18.962+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:18.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:57:18.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-19T14:57:49.146+0000] {processor.py:157} INFO - Started process (PID=70509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:49.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:57:49.151+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:49.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:49.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:57:49.218+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:49.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:57:49.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:57:49.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:57:49.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T14:58:19.676+0000] {processor.py:157} INFO - Started process (PID=70520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:19.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:58:19.683+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:19.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:19.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:19.747+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:19.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:58:19.763+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:19.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:58:19.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-19T14:58:50.111+0000] {processor.py:157} INFO - Started process (PID=70529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:50.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:58:50.141+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:50.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:50.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:58:50.230+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:50.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:58:50.249+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:58:50.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:58:50.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-19T14:59:20.484+0000] {processor.py:157} INFO - Started process (PID=70539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:20.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:59:20.491+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:20.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:20.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:20.552+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:20.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:59:20.569+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:20.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:59:20.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T14:59:50.962+0000] {processor.py:157} INFO - Started process (PID=70550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:50.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T14:59:50.968+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:50.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:51.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T14:59:51.033+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:51.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T14:59:51.049+0000] {logging_mixin.py:151} INFO - [2024-08-19T14:59:51.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T14:59:51.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T15:00:21.305+0000] {processor.py:157} INFO - Started process (PID=70560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:21.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:00:21.309+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:21.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:21.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:21.337+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:21.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:00:21.350+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:21.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:00:21.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-19T15:00:51.666+0000] {processor.py:157} INFO - Started process (PID=70570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:51.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:00:51.672+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:51.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:51.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:00:51.739+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:51.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:00:51.754+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:00:51.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:00:51.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T15:01:22.140+0000] {processor.py:157} INFO - Started process (PID=70580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:22.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:01:22.144+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:22.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:22.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:22.178+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:22.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:01:22.192+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:22.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:01:22.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-19T15:01:52.514+0000] {processor.py:157} INFO - Started process (PID=70590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:52.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:01:52.517+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:52.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:52.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:01:52.555+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:52.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:01:52.568+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:01:52.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:01:52.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-19T15:02:22.793+0000] {processor.py:157} INFO - Started process (PID=70600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:22.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:02:22.796+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:22.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:22.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:22.827+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:22.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:02:22.837+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:22.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:02:22.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-19T15:02:53.231+0000] {processor.py:157} INFO - Started process (PID=70610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:53.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:02:53.249+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:53.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:53.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:02:53.295+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:53.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:02:53.308+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:02:53.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:02:53.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T15:03:23.576+0000] {processor.py:157} INFO - Started process (PID=70620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:23.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:03:23.588+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:23.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:23.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:23.629+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:23.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:03:23.643+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:23.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:03:23.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T15:03:53.971+0000] {processor.py:157} INFO - Started process (PID=70630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:53.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:03:53.976+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:53.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:53.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:03:54.022+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:54.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:03:54.038+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:03:54.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:03:54.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-19T15:04:24.340+0000] {processor.py:157} INFO - Started process (PID=70640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:24.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:04:24.352+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:24.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:24.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:24.404+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:24.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:04:24.420+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:24.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:04:24.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T15:04:54.839+0000] {processor.py:157} INFO - Started process (PID=70649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:54.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:04:54.851+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:54.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:54.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:04:54.947+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:54.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:04:54.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:04:54.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:04:54.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-19T15:05:25.213+0000] {processor.py:157} INFO - Started process (PID=70660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:25.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:05:25.227+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:25.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:25.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:25.292+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:25.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:05:25.320+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:25.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:05:25.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-19T15:05:55.614+0000] {processor.py:157} INFO - Started process (PID=70670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:55.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:05:55.632+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:55.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:55.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:05:55.718+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:55.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:05:55.740+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:05:55.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:05:55.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-19T15:06:26.131+0000] {processor.py:157} INFO - Started process (PID=70680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:26.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:06:26.143+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:26.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:26.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:26.186+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:26.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:06:26.203+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:26.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:06:26.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T15:06:56.468+0000] {processor.py:157} INFO - Started process (PID=70690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:56.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:06:56.479+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:56.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:56.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:06:56.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:56.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:06:56.564+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:06:56.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:06:56.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-19T15:07:26.822+0000] {processor.py:157} INFO - Started process (PID=70700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:26.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:07:26.833+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:26.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:26.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:26.893+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:26.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:07:26.907+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:26.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:07:26.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T15:07:57.098+0000] {processor.py:157} INFO - Started process (PID=70710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:57.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:07:57.107+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:57.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:57.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:07:57.129+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:57.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:07:57.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:07:57.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:07:57.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T15:08:27.442+0000] {processor.py:157} INFO - Started process (PID=70720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:27.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:08:27.447+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:27.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:27.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:27.488+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:27.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:08:27.514+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:27.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:08:27.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T15:08:57.771+0000] {processor.py:157} INFO - Started process (PID=70730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:57.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:08:57.775+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:57.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:57.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:08:57.803+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:57.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:08:57.814+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:08:57.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:08:57.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-19T15:09:28.150+0000] {processor.py:157} INFO - Started process (PID=70740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:28.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:09:28.158+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:28.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:28.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:28.208+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:28.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:09:28.224+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:28.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:09:28.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T15:09:58.510+0000] {processor.py:157} INFO - Started process (PID=70750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:58.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:09:58.516+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:58.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:58.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:09:58.582+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:58.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:09:58.597+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:09:58.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:09:58.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T15:10:28.865+0000] {processor.py:157} INFO - Started process (PID=70760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:28.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:10:28.871+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:28.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:28.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:28.934+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:28.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:10:28.950+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:28.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:10:28.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T15:10:59.213+0000] {processor.py:157} INFO - Started process (PID=70770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:59.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:10:59.218+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:59.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:59.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:10:59.275+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:59.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:10:59.288+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:10:59.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:10:59.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T15:11:29.625+0000] {processor.py:157} INFO - Started process (PID=70780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:11:29.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:11:29.631+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:11:29.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:11:29.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:11:29.751+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:11:29.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:11:29.775+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:11:29.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:11:29.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-19T15:12:00.011+0000] {processor.py:157} INFO - Started process (PID=70790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:00.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:12:00.020+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:00.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:00.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:00.099+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:00.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:12:00.114+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:00.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:12:00.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T15:12:30.382+0000] {processor.py:157} INFO - Started process (PID=70800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:30.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:12:30.394+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:30.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:30.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:12:30.506+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:30.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:12:30.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:12:30.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:12:30.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-19T15:13:00.725+0000] {processor.py:157} INFO - Started process (PID=70810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:00.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:13:00.728+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:00.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:00.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:00.761+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:00.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:13:00.771+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:00.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:13:00.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-19T15:13:31.113+0000] {processor.py:157} INFO - Started process (PID=70820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:31.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:13:31.117+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:31.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:31.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:13:31.157+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:31.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:13:31.171+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:13:31.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:13:31.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-19T15:14:01.451+0000] {processor.py:157} INFO - Started process (PID=70830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:01.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:14:01.453+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:01.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:01.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:01.480+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:01.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:14:01.490+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:01.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:14:01.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T15:14:31.895+0000] {processor.py:157} INFO - Started process (PID=70840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:31.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:14:31.901+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:31.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:31.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:14:31.950+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:31.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:14:31.982+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:14:31.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:14:31.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-19T15:15:02.180+0000] {processor.py:157} INFO - Started process (PID=70850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:02.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:15:02.184+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:02.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:02.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:02.212+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:02.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:15:02.223+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:02.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:15:02.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-19T15:15:32.555+0000] {processor.py:157} INFO - Started process (PID=70860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:32.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:15:32.560+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:32.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:32.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:15:32.610+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:32.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:15:32.627+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:15:32.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:15:32.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T15:16:02.990+0000] {processor.py:157} INFO - Started process (PID=70870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:02.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:16:02.995+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:02.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:03.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:03.030+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:03.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:16:03.047+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:03.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:16:03.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-19T15:16:33.327+0000] {processor.py:157} INFO - Started process (PID=70880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:33.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:16:33.331+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:33.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:33.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:16:33.361+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:33.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:16:33.374+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:16:33.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:16:33.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-19T15:17:03.706+0000] {processor.py:157} INFO - Started process (PID=70890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:03.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:17:03.710+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:03.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:03.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:03.736+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:03.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:17:03.750+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:03.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:17:03.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-19T15:17:34.135+0000] {processor.py:157} INFO - Started process (PID=70899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:34.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:17:34.145+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:34.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:34.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:17:34.189+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:34.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:17:34.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:17:34.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:17:34.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T15:18:04.370+0000] {processor.py:157} INFO - Started process (PID=70910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:04.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:18:04.373+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:04.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:04.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:04.400+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:04.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:18:04.410+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:04.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:18:04.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-19T15:18:34.828+0000] {processor.py:157} INFO - Started process (PID=70920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:34.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:18:34.839+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:34.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:34.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:18:34.899+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:34.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:18:34.922+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:18:34.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:18:34.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-19T15:19:05.168+0000] {processor.py:157} INFO - Started process (PID=70930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:05.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:19:05.171+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:05.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:05.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:05.202+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:05.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:19:05.215+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:05.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:19:05.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T15:19:35.561+0000] {processor.py:157} INFO - Started process (PID=70940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:35.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:19:35.587+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:35.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:35.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:19:35.656+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:35.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:19:35.669+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:19:35.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:19:35.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-19T15:20:06.037+0000] {processor.py:157} INFO - Started process (PID=70950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:06.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:20:06.043+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:06.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:06.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:06.080+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:06.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:20:06.092+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:06.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:20:06.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-19T15:20:36.410+0000] {processor.py:157} INFO - Started process (PID=70960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:36.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:20:36.413+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:36.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:36.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:20:36.443+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:36.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:20:36.456+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:20:36.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:20:36.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T15:21:06.713+0000] {processor.py:157} INFO - Started process (PID=70970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:06.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:21:06.715+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:06.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:06.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:06.741+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:06.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:21:06.751+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:06.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:21:06.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-19T15:21:37.150+0000] {processor.py:157} INFO - Started process (PID=70979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:37.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:21:37.163+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:37.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:37.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:21:37.217+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:37.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:21:37.232+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:21:37.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:21:37.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T15:22:07.525+0000] {processor.py:157} INFO - Started process (PID=70990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:07.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:22:07.531+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:07.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:07.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:07.575+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:07.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:22:07.590+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:07.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:22:07.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-19T15:22:37.914+0000] {processor.py:157} INFO - Started process (PID=71000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:37.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:22:37.917+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:37.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:37.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:22:37.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:37.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:22:37.955+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:22:37.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:22:37.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T15:23:08.347+0000] {processor.py:157} INFO - Started process (PID=71010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:08.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:23:08.368+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:08.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:08.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:08.422+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:08.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:23:08.435+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:08.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:23:08.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T15:23:38.715+0000] {processor.py:157} INFO - Started process (PID=71020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:38.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:23:38.717+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:38.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:38.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:23:38.742+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:38.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:23:38.752+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:23:38.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:23:38.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-19T15:24:09.160+0000] {processor.py:157} INFO - Started process (PID=71030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:09.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:24:09.168+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:09.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:09.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:09.205+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:09.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:24:09.218+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:09.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:24:09.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-19T15:24:39.611+0000] {processor.py:157} INFO - Started process (PID=71040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:39.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:24:39.618+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:39.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:39.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:24:39.669+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:39.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:24:39.683+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:24:39.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:24:39.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T15:25:10.053+0000] {processor.py:157} INFO - Started process (PID=71050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:10.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:25:10.055+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:10.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:10.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:10.079+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:10.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:25:10.093+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:10.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:25:10.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-19T15:25:40.467+0000] {processor.py:157} INFO - Started process (PID=71060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:40.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:25:40.471+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:40.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:40.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:25:40.497+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:40.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:25:40.507+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:25:40.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:25:40.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T15:26:10.834+0000] {processor.py:157} INFO - Started process (PID=71070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:10.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:26:10.842+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:10.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:10.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:10.879+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:10.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:26:10.893+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:10.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:26:10.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-19T15:26:41.168+0000] {processor.py:157} INFO - Started process (PID=71080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:41.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:26:41.172+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:41.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:41.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:26:41.197+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:41.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:26:41.208+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:26:41.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:26:41.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-19T15:27:11.528+0000] {processor.py:157} INFO - Started process (PID=71090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:11.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:27:11.530+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:11.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:11.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:11.557+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:11.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:27:11.567+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:11.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:27:11.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-19T15:27:41.917+0000] {processor.py:157} INFO - Started process (PID=71100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:41.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:27:41.920+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:41.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:41.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:27:41.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:41.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:27:41.955+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:27:41.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:27:41.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T15:28:12.314+0000] {processor.py:157} INFO - Started process (PID=71110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:12.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:28:12.317+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:12.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:12.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:12.344+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:12.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:28:12.355+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:12.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:28:12.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T15:28:42.691+0000] {processor.py:157} INFO - Started process (PID=71120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:42.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:28:42.698+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:42.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:42.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:28:42.731+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:42.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:28:42.746+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:28:42.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:28:42.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-19T15:29:13.077+0000] {processor.py:157} INFO - Started process (PID=71130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:13.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:29:13.079+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:13.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:13.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:13.113+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:13.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:29:13.127+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:13.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:29:13.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-19T15:29:43.498+0000] {processor.py:157} INFO - Started process (PID=71140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:43.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:29:43.501+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:43.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:43.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:29:43.545+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:43.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:29:43.570+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:29:43.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:29:43.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T15:30:13.808+0000] {processor.py:157} INFO - Started process (PID=71150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:13.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:30:13.813+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:13.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:13.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:13.875+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:13.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:30:13.891+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:13.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:30:13.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T15:30:44.224+0000] {processor.py:157} INFO - Started process (PID=71160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:44.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:30:44.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:44.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:44.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:30:44.282+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:44.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:30:44.299+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:30:44.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:30:44.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T15:31:14.590+0000] {processor.py:157} INFO - Started process (PID=71170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:14.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:31:14.600+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:14.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:14.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:14.697+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:14.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:31:14.742+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:14.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:31:14.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-19T15:31:44.946+0000] {processor.py:157} INFO - Started process (PID=71180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:44.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:31:44.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:44.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:44.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:31:45.000+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:45.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:31:45.018+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:31:45.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:31:45.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T15:32:15.369+0000] {processor.py:157} INFO - Started process (PID=71190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:15.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:32:15.381+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:15.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:15.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:15.462+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:15.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:32:15.480+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:15.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:32:15.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-19T15:32:45.740+0000] {processor.py:157} INFO - Started process (PID=71199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:45.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:32:45.747+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:45.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:45.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:32:45.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:45.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:32:45.815+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:32:45.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:32:45.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T15:33:16.012+0000] {processor.py:157} INFO - Started process (PID=71210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:16.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:33:16.014+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:16.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:16.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:16.040+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:16.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:33:16.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:16.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:33:16.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-19T15:33:46.409+0000] {processor.py:157} INFO - Started process (PID=71219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:46.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:33:46.416+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:46.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:46.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:33:46.482+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:46.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:33:46.506+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:33:46.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:33:46.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T15:34:16.730+0000] {processor.py:157} INFO - Started process (PID=71230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:16.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:34:16.756+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:16.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:16.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:16.808+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:16.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:34:16.825+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:16.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:34:16.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T15:34:47.290+0000] {processor.py:157} INFO - Started process (PID=71239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:47.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:34:47.298+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:47.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:47.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:34:47.358+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:47.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:34:47.373+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:34:47.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:34:47.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T15:35:17.814+0000] {processor.py:157} INFO - Started process (PID=71250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:17.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:35:17.830+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:17.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:17.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:17.913+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:17.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:35:17.928+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:17.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:35:17.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-19T15:35:48.187+0000] {processor.py:157} INFO - Started process (PID=71260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:48.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:35:48.195+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:48.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:48.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:35:48.253+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:48.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:35:48.268+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:35:48.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:35:48.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T15:36:18.501+0000] {processor.py:157} INFO - Started process (PID=71270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:18.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:36:18.504+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:18.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:18.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:18.536+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:18.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:36:18.547+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:18.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:36:18.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T15:36:48.899+0000] {processor.py:157} INFO - Started process (PID=71280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:48.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:36:48.904+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:48.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:48.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:36:48.933+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:48.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:36:48.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:36:48.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:36:48.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T15:37:19.243+0000] {processor.py:157} INFO - Started process (PID=71290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:19.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:37:19.247+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:19.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:19.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:19.300+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:19.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:37:19.324+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:19.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:37:19.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T15:37:49.721+0000] {processor.py:157} INFO - Started process (PID=71300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:49.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:37:49.734+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:49.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:49.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:37:49.789+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:49.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:37:49.806+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:37:49.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:37:49.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T15:38:20.047+0000] {processor.py:157} INFO - Started process (PID=71310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:20.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:38:20.077+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:20.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:20.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:20.140+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:20.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:38:20.172+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:20.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:38:20.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-19T15:38:50.586+0000] {processor.py:157} INFO - Started process (PID=71320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:50.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:38:50.593+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:50.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:50.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:38:50.639+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:50.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:38:50.655+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:38:50.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:38:50.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-19T15:39:21.012+0000] {processor.py:157} INFO - Started process (PID=71330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:21.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:39:21.019+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:21.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:21.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:21.072+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:21.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:39:21.087+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:21.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:39:21.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T15:39:51.364+0000] {processor.py:157} INFO - Started process (PID=71339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:51.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:39:51.370+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:51.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:51.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:39:51.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:51.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:39:51.446+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:39:51.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:39:51.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T15:40:21.724+0000] {processor.py:157} INFO - Started process (PID=71350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:21.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:40:21.737+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:21.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:21.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:21.784+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:21.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:40:21.806+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:21.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:40:21.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T15:40:52.036+0000] {processor.py:157} INFO - Started process (PID=71360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:52.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:40:52.039+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:52.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:52.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:40:52.075+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:52.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:40:52.091+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:40:52.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:40:52.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-19T15:41:22.468+0000] {processor.py:157} INFO - Started process (PID=71370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:22.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:41:22.477+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:22.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:22.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:22.553+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:22.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:41:22.584+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:22.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:41:22.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-19T15:41:52.869+0000] {processor.py:157} INFO - Started process (PID=71379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:52.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:41:52.876+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:52.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:52.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:41:52.925+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:52.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:41:52.942+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:41:52.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:41:52.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T15:42:23.235+0000] {processor.py:157} INFO - Started process (PID=71390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:23.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:42:23.242+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:23.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:23.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:23.299+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:23.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:42:23.317+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:23.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:42:23.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T15:42:53.550+0000] {processor.py:157} INFO - Started process (PID=71400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:53.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:42:53.552+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:53.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:53.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:42:53.581+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:53.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:42:53.592+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:42:53.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:42:53.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-19T15:43:24.010+0000] {processor.py:157} INFO - Started process (PID=71410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:24.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:43:24.021+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:24.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:24.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:24.133+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:24.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:43:24.157+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:24.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:43:24.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-19T15:43:54.408+0000] {processor.py:157} INFO - Started process (PID=71420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:54.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:43:54.422+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:54.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:54.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:43:54.513+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:54.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:43:54.532+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:43:54.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:43:54.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-19T15:44:24.790+0000] {processor.py:157} INFO - Started process (PID=71430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:24.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:44:24.797+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:24.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:24.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:24.842+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:24.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:44:24.859+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:24.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:44:24.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T15:44:55.272+0000] {processor.py:157} INFO - Started process (PID=71440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:55.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:44:55.281+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:55.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:55.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:44:55.374+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:55.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:44:55.393+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:44:55.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:44:55.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-19T15:45:25.743+0000] {processor.py:157} INFO - Started process (PID=71450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:25.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:45:25.755+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:25.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:25.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:25.815+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:25.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:45:25.837+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:25.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:45:25.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T15:45:56.098+0000] {processor.py:157} INFO - Started process (PID=71460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:56.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:45:56.105+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:56.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:56.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:45:56.147+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:56.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:45:56.174+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:45:56.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:45:56.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T15:46:26.489+0000] {processor.py:157} INFO - Started process (PID=71470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:26.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:46:26.509+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:26.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:26.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:26.561+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:26.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:46:26.575+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:26.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:46:26.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T15:46:56.936+0000] {processor.py:157} INFO - Started process (PID=71480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:56.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:46:56.943+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:56.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:56.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:46:56.994+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:56.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:46:57.008+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:46:57.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:46:57.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T15:47:27.241+0000] {processor.py:157} INFO - Started process (PID=71490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:47:27.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:27.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:27.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:27.265+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:27.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:47:27.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:27.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:47:27.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-19T15:47:57.632+0000] {processor.py:157} INFO - Started process (PID=71500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:57.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:47:57.642+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:57.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:57.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:47:57.688+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:57.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:47:57.714+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:47:57.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:47:57.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-19T15:48:27.954+0000] {processor.py:157} INFO - Started process (PID=71510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:27.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:48:27.961+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:27.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:27.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:28.012+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:28.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:48:28.025+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:28.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:48:28.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T15:48:58.338+0000] {processor.py:157} INFO - Started process (PID=71520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:58.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:48:58.348+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:58.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:58.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:48:58.392+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:58.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:48:58.417+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:48:58.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:48:58.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T15:49:28.694+0000] {processor.py:157} INFO - Started process (PID=71530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:28.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:49:28.703+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:28.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:28.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:28.748+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:28.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:49:28.768+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:28.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:49:28.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T15:49:59.085+0000] {processor.py:157} INFO - Started process (PID=71540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:59.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:49:59.092+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:59.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:59.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:49:59.148+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:59.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:49:59.170+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:49:59.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:49:59.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T15:50:29.365+0000] {processor.py:157} INFO - Started process (PID=71550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:29.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:50:29.368+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:29.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:29.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:29.397+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:29.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:50:29.406+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:29.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:50:29.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-19T15:50:59.754+0000] {processor.py:157} INFO - Started process (PID=71560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:59.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:50:59.765+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:59.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:59.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:50:59.862+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:59.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:50:59.883+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:50:59.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:50:59.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-19T15:51:30.044+0000] {processor.py:157} INFO - Started process (PID=71570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:51:30.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:51:30.063+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:51:30.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:51:30.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:51:30.110+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:51:30.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:51:30.125+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:51:30.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:51:30.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T15:52:00.510+0000] {processor.py:157} INFO - Started process (PID=71580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:00.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:52:00.524+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:00.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:00.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:00.575+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:00.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:52:00.593+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:00.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:52:00.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T15:52:30.883+0000] {processor.py:157} INFO - Started process (PID=71590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:30.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:52:30.899+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:30.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:30.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:52:30.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:30.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:52:30.985+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:52:30.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:52:30.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T15:53:01.230+0000] {processor.py:157} INFO - Started process (PID=71600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:01.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:53:01.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:01.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:01.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:01.311+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:01.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:53:01.325+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:01.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:53:01.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T15:53:31.548+0000] {processor.py:157} INFO - Started process (PID=71610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:31.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:53:31.553+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:31.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:31.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:53:31.592+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:31.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:53:31.606+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:53:31.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:53:31.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-19T15:54:02.001+0000] {processor.py:157} INFO - Started process (PID=71619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:02.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:54:02.018+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:02.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:02.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:02.102+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:02.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:54:02.147+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:02.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:54:02.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-19T15:54:32.371+0000] {processor.py:157} INFO - Started process (PID=71630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:32.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:54:32.378+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:32.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:32.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:54:32.442+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:32.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:54:32.456+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:54:32.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:54:32.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T15:55:02.756+0000] {processor.py:157} INFO - Started process (PID=71640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:02.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:55:02.768+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:02.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:02.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:02.809+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:02.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:55:02.824+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:02.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:55:02.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T15:55:33.079+0000] {processor.py:157} INFO - Started process (PID=71650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:33.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:55:33.090+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:33.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:33.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:55:33.200+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:33.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:55:33.217+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:55:33.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:55:33.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-19T15:56:03.922+0000] {processor.py:157} INFO - Started process (PID=71660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:03.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:56:03.930+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:03.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:03.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:03.977+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:03.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:56:03.992+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:03.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:56:04.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T15:56:34.228+0000] {processor.py:157} INFO - Started process (PID=71670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:34.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:56:34.231+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:34.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:34.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:56:34.257+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:34.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:56:34.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:56:34.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:56:34.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T15:57:04.684+0000] {processor.py:157} INFO - Started process (PID=71679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:04.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:57:04.717+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:04.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:04.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:04.798+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:04.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:57:04.821+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:04.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:57:04.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-19T15:57:34.980+0000] {processor.py:157} INFO - Started process (PID=71690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:34.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:57:34.985+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:34.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:35.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:57:35.026+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:35.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:57:35.043+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:57:35.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:57:35.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T15:58:05.373+0000] {processor.py:157} INFO - Started process (PID=71700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:05.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:58:05.405+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:05.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:05.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:05.463+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:05.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:58:05.480+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:05.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:58:05.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-19T15:58:36.017+0000] {processor.py:157} INFO - Started process (PID=71710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:36.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:58:36.026+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:36.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:36.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:58:36.113+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:36.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:58:36.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:58:36.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:58:36.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-19T15:59:06.532+0000] {processor.py:157} INFO - Started process (PID=71720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:06.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:59:06.561+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:06.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:06.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:06.619+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:06.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:59:06.646+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:06.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:59:06.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-19T15:59:36.879+0000] {processor.py:157} INFO - Started process (PID=71730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:36.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T15:59:36.891+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:36.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:36.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T15:59:36.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:36.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T15:59:36.989+0000] {logging_mixin.py:151} INFO - [2024-08-19T15:59:36.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T15:59:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-19T16:00:07.393+0000] {processor.py:157} INFO - Started process (PID=71740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:07.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:00:07.399+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:07.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:07.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:07.455+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:07.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:00:07.471+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:07.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:00:07.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T16:00:37.862+0000] {processor.py:157} INFO - Started process (PID=71749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:37.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:00:37.871+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:37.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:37.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:00:37.955+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:37.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:00:37.976+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:00:37.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:00:37.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-19T16:01:08.237+0000] {processor.py:157} INFO - Started process (PID=71760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:08.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:01:08.245+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:08.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:08.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:08.311+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:08.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:01:08.331+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:08.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:01:08.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-19T16:01:38.592+0000] {processor.py:157} INFO - Started process (PID=71770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:38.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:01:38.607+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:38.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:38.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:01:38.733+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:38.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:01:38.753+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:01:38.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:01:38.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-19T16:02:09.162+0000] {processor.py:157} INFO - Started process (PID=71780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:09.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:02:09.172+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:09.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:09.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:09.249+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:09.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:02:09.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:09.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:02:09.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T16:02:39.644+0000] {processor.py:157} INFO - Started process (PID=71790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:39.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:02:39.654+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:39.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:39.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:02:39.733+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:39.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:02:39.753+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:02:39.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:02:39.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-19T16:03:09.964+0000] {processor.py:157} INFO - Started process (PID=71800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:09.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:03:09.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:09.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:09.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:10.030+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:10.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:03:10.047+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:10.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:03:10.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T16:03:40.365+0000] {processor.py:157} INFO - Started process (PID=71809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:40.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:03:40.372+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:40.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:40.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:03:40.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:40.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:03:40.443+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:03:40.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:03:40.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T16:04:10.810+0000] {processor.py:157} INFO - Started process (PID=71820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:10.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:04:10.818+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:10.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:10.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:10.898+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:10.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:04:10.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:10.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:04:10.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-19T16:04:41.199+0000] {processor.py:157} INFO - Started process (PID=71830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:41.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:04:41.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:41.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:41.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:04:41.327+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:41.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:04:41.373+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:04:41.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:04:41.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-08-19T16:05:11.654+0000] {processor.py:157} INFO - Started process (PID=71839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:11.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:05:11.664+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:11.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:11.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:11.707+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:11.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:05:11.734+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:11.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:05:11.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T16:05:42.002+0000] {processor.py:157} INFO - Started process (PID=71850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:42.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:05:42.012+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:42.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:42.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:05:42.075+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:42.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:05:42.096+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:05:42.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:05:42.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T16:06:12.364+0000] {processor.py:157} INFO - Started process (PID=71860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:12.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:06:12.371+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:12.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:12.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:12.461+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:12.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:06:12.499+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:12.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:06:12.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-19T16:06:42.755+0000] {processor.py:157} INFO - Started process (PID=71870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:42.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:06:42.762+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:42.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:42.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:06:42.842+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:42.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:06:42.858+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:06:42.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:06:42.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T16:07:13.100+0000] {processor.py:157} INFO - Started process (PID=71880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:13.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:07:13.108+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:13.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:13.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:13.156+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:13.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:07:13.171+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:13.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:07:13.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T16:07:43.482+0000] {processor.py:157} INFO - Started process (PID=71890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:43.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:07:43.496+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:43.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:43.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:07:43.584+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:43.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:07:43.601+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:07:43.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:07:43.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-19T16:08:13.864+0000] {processor.py:157} INFO - Started process (PID=71900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:13.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:08:13.877+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:13.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:13.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:13.946+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:13.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:08:13.963+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:13.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:08:13.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T16:08:44.196+0000] {processor.py:157} INFO - Started process (PID=71910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:44.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:08:44.206+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:44.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:44.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:08:44.298+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:44.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:08:44.322+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:08:44.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:08:44.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-19T16:09:14.595+0000] {processor.py:157} INFO - Started process (PID=71920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:14.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:09:14.603+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:14.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:14.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:14.650+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:14.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:09:14.664+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:14.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:09:14.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T16:09:44.986+0000] {processor.py:157} INFO - Started process (PID=71930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:44.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:09:44.992+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:44.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:45.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:09:45.041+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:45.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:09:45.056+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:09:45.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:09:45.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T16:10:15.348+0000] {processor.py:157} INFO - Started process (PID=71940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:15.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:10:15.357+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:15.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:15.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:15.408+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:15.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:10:15.423+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:15.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:10:15.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-19T16:10:45.708+0000] {processor.py:157} INFO - Started process (PID=71950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:45.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:10:45.730+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:45.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:45.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:10:45.805+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:45.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:10:45.822+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:10:45.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:10:45.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T16:11:16.073+0000] {processor.py:157} INFO - Started process (PID=71960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:16.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:11:16.082+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:16.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:16.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:16.143+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:16.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:11:16.162+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:16.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:11:16.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-19T16:11:46.368+0000] {processor.py:157} INFO - Started process (PID=71970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:46.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:11:46.375+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:46.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:46.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:11:46.517+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:46.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:11:46.683+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:11:46.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:11:46.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.337 seconds
[2024-08-19T16:12:17.032+0000] {processor.py:157} INFO - Started process (PID=71980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:17.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:12:17.039+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:17.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:17.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:17.092+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:17.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:12:17.108+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:17.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:12:17.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T16:12:47.457+0000] {processor.py:157} INFO - Started process (PID=71990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:47.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:12:47.464+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:47.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:47.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:12:47.512+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:47.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:12:47.527+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:12:47.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:12:47.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T16:13:17.816+0000] {processor.py:157} INFO - Started process (PID=72000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:17.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:13:17.826+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:17.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:17.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:17.890+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:17.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:13:17.907+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:17.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:13:17.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T16:13:48.144+0000] {processor.py:157} INFO - Started process (PID=72010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:48.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:13:48.152+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:48.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:48.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:13:48.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:48.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:13:48.227+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:13:48.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:13:48.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T16:14:18.543+0000] {processor.py:157} INFO - Started process (PID=72020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:18.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:14:18.576+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:18.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:18.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:18.675+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:18.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:14:18.693+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:18.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:14:18.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-19T16:14:48.920+0000] {processor.py:157} INFO - Started process (PID=72029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:48.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:14:48.933+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:48.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:48.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:14:48.988+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:48.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:14:49.004+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:14:49.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:14:49.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T16:15:19.194+0000] {processor.py:157} INFO - Started process (PID=72040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:19.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:15:19.199+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:19.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:19.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:19.256+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:19.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:15:19.275+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:19.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:15:19.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T16:15:49.468+0000] {processor.py:157} INFO - Started process (PID=72050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:49.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:15:49.473+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:49.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:49.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:15:49.511+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:49.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:15:49.524+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:15:49.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:15:49.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-19T16:16:19.880+0000] {processor.py:157} INFO - Started process (PID=72060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:19.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:16:19.887+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:19.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:19.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:19.930+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:19.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:16:19.943+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:19.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:16:19.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-19T16:16:50.255+0000] {processor.py:157} INFO - Started process (PID=72070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:50.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:16:50.281+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:50.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:50.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:16:50.334+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:50.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:16:50.348+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:16:50.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:16:50.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-19T16:17:20.599+0000] {processor.py:157} INFO - Started process (PID=72080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:20.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:17:20.612+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:20.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:20.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:20.663+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:20.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:17:20.682+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:20.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:17:20.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T16:17:50.987+0000] {processor.py:157} INFO - Started process (PID=72090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:50.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:17:50.993+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:50.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:17:51.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:51.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:17:51.069+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:17:51.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:17:51.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T16:18:21.371+0000] {processor.py:157} INFO - Started process (PID=72100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:21.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:18:21.377+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:21.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:21.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:21.423+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:21.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:18:21.437+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:21.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:18:21.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T16:18:51.713+0000] {processor.py:157} INFO - Started process (PID=72110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:51.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:18:51.741+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:51.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:51.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:18:51.818+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:51.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:18:51.856+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:18:51.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:18:51.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-19T16:19:22.124+0000] {processor.py:157} INFO - Started process (PID=72120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:22.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:19:22.132+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:22.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:22.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:22.178+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:22.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:19:22.193+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:22.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:19:22.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T16:19:52.444+0000] {processor.py:157} INFO - Started process (PID=72130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:52.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:19:52.450+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:52.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:52.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:19:52.497+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:52.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:19:52.512+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:19:52.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:19:52.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-19T16:35:25.783+0000] {processor.py:157} INFO - Started process (PID=72141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:25.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:35:25.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:25.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:25.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:25.850+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:25.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:35:25.878+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:25.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:35:25.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T16:35:56.195+0000] {processor.py:157} INFO - Started process (PID=72150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:56.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:35:56.201+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:56.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:56.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:35:56.252+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:56.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:35:56.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:35:56.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:35:56.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T16:36:26.588+0000] {processor.py:157} INFO - Started process (PID=72162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:26.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:36:26.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:26.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:26.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:26.658+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:26.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:36:26.674+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:26.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:36:26.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T16:36:57.059+0000] {processor.py:157} INFO - Started process (PID=72172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:57.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:36:57.065+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:57.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:57.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:36:57.127+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:57.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:36:57.154+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:36:57.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:36:57.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-19T16:37:27.408+0000] {processor.py:157} INFO - Started process (PID=72181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:27.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:37:27.414+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:27.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:27.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:27.457+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:27.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:37:27.471+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:27.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:37:27.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-19T16:37:57.757+0000] {processor.py:157} INFO - Started process (PID=72192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:57.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:37:57.763+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:57.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:57.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:37:57.825+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:57.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:37:57.840+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:37:57.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:37:57.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T16:38:28.161+0000] {processor.py:157} INFO - Started process (PID=72202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:28.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:38:28.168+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:28.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:28.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:28.198+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:28.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:38:28.208+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:28.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:38:28.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-19T16:38:58.495+0000] {processor.py:157} INFO - Started process (PID=72212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:58.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:38:58.499+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:58.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:58.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:38:58.538+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:58.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:38:58.571+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:38:58.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:38:58.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T16:39:28.840+0000] {processor.py:157} INFO - Started process (PID=72222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:28.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:39:28.849+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:28.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:28.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:28.910+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:28.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:39:28.926+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:28.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:39:28.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T16:39:59.299+0000] {processor.py:157} INFO - Started process (PID=72232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:59.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:39:59.303+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:59.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:39:59.344+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:59.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:39:59.357+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:39:59.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:39:59.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-19T16:42:02.511+0000] {processor.py:157} INFO - Started process (PID=72244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:02.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:42:02.520+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:02.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:02.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:02.610+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:02.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:42:02.647+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:02.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:42:02.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-19T16:42:32.989+0000] {processor.py:157} INFO - Started process (PID=72254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:32.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T16:42:33.002+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:33.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:33.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T16:42:33.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:33.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T16:42:33.070+0000] {logging_mixin.py:151} INFO - [2024-08-19T16:42:33.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T16:42:33.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T18:20:01.123+0000] {processor.py:157} INFO - Started process (PID=72264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:20:01.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:20:01.131+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:20:01.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:20:01.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:20:01.179+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:20:01.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:20:01.203+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:20:01.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:20:01.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T18:46:04.314+0000] {processor.py:157} INFO - Started process (PID=72274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:04.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:46:04.323+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:04.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:04.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:04.423+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:04.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:46:04.457+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:04.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:46:04.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-19T18:46:34.637+0000] {processor.py:157} INFO - Started process (PID=72283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:34.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:46:34.645+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:34.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:34.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:46:34.691+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:34.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:46:34.710+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:46:34.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:46:34.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T18:47:05.012+0000] {processor.py:157} INFO - Started process (PID=72294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:05.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:47:05.017+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:05.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:05.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:05.056+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:05.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:47:05.072+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:05.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:47:05.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-19T18:47:35.402+0000] {processor.py:157} INFO - Started process (PID=72304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:35.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:47:35.406+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:35.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:35.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:47:35.431+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:35.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:47:35.441+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:47:35.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:47:35.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T18:48:06.197+0000] {processor.py:157} INFO - Started process (PID=72314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:06.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:48:06.250+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:06.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:06.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:06.409+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:06.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:48:06.437+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:06.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:48:06.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-08-19T18:48:36.854+0000] {processor.py:157} INFO - Started process (PID=72324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:36.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:48:36.904+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:36.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:36.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:48:36.991+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:36.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:48:37.039+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:48:37.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:48:37.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-08-19T18:49:07.273+0000] {processor.py:157} INFO - Started process (PID=72334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:07.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:49:07.285+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:07.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:07.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:07.364+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:07.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:49:07.384+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:07.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:49:07.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-19T18:49:37.733+0000] {processor.py:157} INFO - Started process (PID=72344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:37.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:49:37.738+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:37.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:37.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:49:37.780+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:37.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:49:37.794+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:49:37.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:49:37.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-19T18:50:08.049+0000] {processor.py:157} INFO - Started process (PID=72354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:08.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:50:08.057+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:08.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:08.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:08.076+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:08.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:50:08.086+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:08.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:50:08.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-19T18:50:38.481+0000] {processor.py:157} INFO - Started process (PID=72364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:38.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:50:38.494+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:38.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:38.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:50:38.568+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:38.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:50:38.584+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:50:38.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:50:38.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T18:51:09.005+0000] {processor.py:157} INFO - Started process (PID=72374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:09.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:51:09.018+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:09.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:09.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:09.075+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:09.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:51:09.118+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:09.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:51:09.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-19T18:51:39.392+0000] {processor.py:157} INFO - Started process (PID=72384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:39.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:51:39.399+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:39.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:39.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:51:39.470+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:39.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:51:39.487+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:51:39.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:51:39.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T18:52:09.719+0000] {processor.py:157} INFO - Started process (PID=72394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:09.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:52:09.725+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:09.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:09.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:09.805+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:09.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:52:09.826+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:09.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:52:09.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T18:52:40.046+0000] {processor.py:157} INFO - Started process (PID=72404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:40.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:52:40.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:40.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:40.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:52:40.084+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:40.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:52:40.094+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:52:40.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:52:40.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-19T18:53:10.485+0000] {processor.py:157} INFO - Started process (PID=72414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:10.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:53:10.489+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:10.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:10.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:10.551+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:10.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:53:10.566+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:10.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:53:10.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T18:53:40.988+0000] {processor.py:157} INFO - Started process (PID=72424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:40.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:53:41.016+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:41.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:41.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:53:41.054+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:41.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:53:41.064+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:53:41.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:53:41.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T18:54:11.296+0000] {processor.py:157} INFO - Started process (PID=72434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:11.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:54:11.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:11.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:11.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:11.361+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:11.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:54:11.374+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:11.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:54:11.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T18:54:41.726+0000] {processor.py:157} INFO - Started process (PID=72444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:41.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:54:41.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:41.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:41.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:54:41.765+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:41.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:54:41.775+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:54:41.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:54:41.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-19T18:55:12.078+0000] {processor.py:157} INFO - Started process (PID=72454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:12.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:55:12.084+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:12.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:12.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:12.156+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:12.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:55:12.177+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:12.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:55:12.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-19T18:55:42.423+0000] {processor.py:157} INFO - Started process (PID=72464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:42.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:55:42.429+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:42.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:42.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:55:42.502+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:42.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:55:42.517+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:55:42.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:55:42.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T18:56:12.989+0000] {processor.py:157} INFO - Started process (PID=72474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:12.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:56:12.998+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:12.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:13.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:13.213+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:13.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:56:13.228+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:13.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:56:13.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-08-19T18:56:43.401+0000] {processor.py:157} INFO - Started process (PID=72484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:43.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:56:43.412+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:43.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:43.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:56:43.521+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:43.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:56:43.539+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:56:43.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:56:43.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-19T18:57:13.899+0000] {processor.py:157} INFO - Started process (PID=72494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:13.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:57:13.908+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:13.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:13.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:13.975+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:13.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:57:13.997+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:13.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:57:14.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T18:57:44.304+0000] {processor.py:157} INFO - Started process (PID=72504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:44.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:57:44.313+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:44.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:44.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:57:44.410+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:44.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:57:44.431+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:57:44.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:57:44.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-19T18:58:14.814+0000] {processor.py:157} INFO - Started process (PID=72514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:14.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:58:14.819+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:14.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:14.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:14.877+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:14.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:58:14.901+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:14.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:58:14.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T18:58:45.246+0000] {processor.py:157} INFO - Started process (PID=72524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:45.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:58:45.251+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:45.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:45.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:58:45.325+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:45.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:58:45.340+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:58:45.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:58:45.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T18:59:15.714+0000] {processor.py:157} INFO - Started process (PID=72534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:15.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:59:15.736+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:15.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:15.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:15.797+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:15.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:59:15.813+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:15.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:59:15.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T18:59:46.199+0000] {processor.py:157} INFO - Started process (PID=72542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:46.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T18:59:46.207+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:46.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:46.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T18:59:46.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:46.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T18:59:46.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T18:59:46.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T18:59:46.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T19:00:16.657+0000] {processor.py:157} INFO - Started process (PID=72554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:16.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:00:16.675+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:16.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:16.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:16.754+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:16.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:00:16.781+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:16.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:00:16.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-19T19:00:47.080+0000] {processor.py:157} INFO - Started process (PID=72563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:47.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:00:47.088+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:47.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:47.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:00:47.163+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:47.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:00:47.179+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:00:47.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:00:47.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-19T19:01:17.471+0000] {processor.py:157} INFO - Started process (PID=72574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:17.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:01:17.489+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:17.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:17.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:17.545+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:17.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:01:17.574+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:17.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:01:17.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T19:01:47.854+0000] {processor.py:157} INFO - Started process (PID=72584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:47.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:01:47.861+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:47.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:47.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:01:47.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:47.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:01:47.971+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:01:47.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:01:47.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T19:02:18.405+0000] {processor.py:157} INFO - Started process (PID=72594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:18.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:02:18.415+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:18.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:18.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:18.508+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:18.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:02:18.529+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:18.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:02:18.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-19T19:02:48.918+0000] {processor.py:157} INFO - Started process (PID=72604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:48.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:02:48.927+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:48.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:48.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:02:49.012+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:49.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:02:49.034+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:02:49.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:02:49.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-19T19:03:19.300+0000] {processor.py:157} INFO - Started process (PID=72614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:19.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:03:19.312+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:19.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:19.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:19.371+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:19.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:03:19.387+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:19.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:03:19.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T19:03:49.758+0000] {processor.py:157} INFO - Started process (PID=72624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:49.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:03:49.767+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:49.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:49.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:03:49.817+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:49.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:03:49.831+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:03:49.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:03:49.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T19:04:20.243+0000] {processor.py:157} INFO - Started process (PID=72634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:20.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:04:20.249+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:20.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:20.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:20.328+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:20.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:04:20.344+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:20.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:04:20.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T19:04:50.590+0000] {processor.py:157} INFO - Started process (PID=72644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:50.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:04:50.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:50.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:50.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:04:50.651+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:50.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:04:50.666+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:04:50.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:04:50.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T19:05:20.951+0000] {processor.py:157} INFO - Started process (PID=72653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:20.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:05:20.959+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:20.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:20.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:21.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:21.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:05:21.070+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:21.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:05:21.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-19T19:05:51.339+0000] {processor.py:157} INFO - Started process (PID=72664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:51.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:05:51.345+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:51.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:51.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:05:51.414+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:51.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:05:51.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:05:51.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:05:51.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T19:06:21.857+0000] {processor.py:157} INFO - Started process (PID=72674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:21.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:06:21.889+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:21.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:21.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:21.972+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:21.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:06:21.989+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:21.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:06:22.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-19T19:06:52.414+0000] {processor.py:157} INFO - Started process (PID=72684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:52.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:06:52.420+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:52.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:52.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:06:52.499+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:52.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:06:52.517+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:06:52.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:06:52.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T19:07:22.990+0000] {processor.py:157} INFO - Started process (PID=72694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:22.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:07:22.997+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:22.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:23.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:23.059+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:23.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:07:23.077+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:23.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:07:23.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T19:07:53.327+0000] {processor.py:157} INFO - Started process (PID=72704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:53.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:07:53.333+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:53.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:53.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:07:53.388+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:53.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:07:53.412+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:07:53.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:07:53.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T19:08:23.732+0000] {processor.py:157} INFO - Started process (PID=72714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:23.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:08:23.739+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:23.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:23.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:23.806+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:23.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:08:23.822+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:23.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:08:23.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T19:08:54.199+0000] {processor.py:157} INFO - Started process (PID=72723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:54.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:08:54.213+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:54.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:54.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:08:54.270+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:54.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:08:54.285+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:08:54.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:08:54.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T19:09:24.581+0000] {processor.py:157} INFO - Started process (PID=72734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:24.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:09:24.584+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:24.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:24.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:24.644+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:24.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:09:24.658+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:24.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:09:24.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T19:09:55.026+0000] {processor.py:157} INFO - Started process (PID=72744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:55.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:09:55.040+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:55.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:55.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:09:55.113+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:55.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:09:55.137+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:09:55.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:09:55.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-19T19:10:25.400+0000] {processor.py:157} INFO - Started process (PID=72754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:25.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:10:25.406+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:25.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:25.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:25.463+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:25.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:10:25.477+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:25.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:10:25.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T19:10:55.788+0000] {processor.py:157} INFO - Started process (PID=72763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:55.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:10:55.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:55.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:55.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:10:55.860+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:55.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:10:55.878+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:10:55.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:10:55.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T19:11:26.234+0000] {processor.py:157} INFO - Started process (PID=72774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:26.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:11:26.240+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:26.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:26.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:26.302+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:26.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:11:26.319+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:26.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:11:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T19:11:56.644+0000] {processor.py:157} INFO - Started process (PID=72784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:56.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:11:56.649+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:56.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:56.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:11:56.698+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:56.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:11:56.712+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:11:56.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:11:56.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T19:12:27.054+0000] {processor.py:157} INFO - Started process (PID=72794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:27.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:12:27.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:27.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:27.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:27.237+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:27.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:12:27.257+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:27.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:12:27.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-08-19T19:12:57.466+0000] {processor.py:157} INFO - Started process (PID=72804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:57.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:12:57.473+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:57.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:57.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:12:57.528+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:57.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:12:57.543+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:12:57.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:12:57.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T19:13:27.870+0000] {processor.py:157} INFO - Started process (PID=72814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:27.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:13:27.883+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:27.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:27.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:27.932+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:27.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:13:27.949+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:27.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:13:27.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T19:13:58.339+0000] {processor.py:157} INFO - Started process (PID=72824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:58.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:13:58.347+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:58.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:58.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:13:58.417+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:58.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:13:58.443+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:13:58.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:13:58.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-19T19:14:28.740+0000] {processor.py:157} INFO - Started process (PID=72834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:28.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:14:28.751+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:28.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:28.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:28.824+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:28.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:14:28.843+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:28.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:14:28.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-19T19:14:59.190+0000] {processor.py:157} INFO - Started process (PID=72844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:59.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:14:59.195+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:59.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:59.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:14:59.250+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:59.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:14:59.269+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:14:59.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:14:59.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T19:15:29.674+0000] {processor.py:157} INFO - Started process (PID=72854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:15:29.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:15:29.682+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:15:29.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:15:29.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:15:29.788+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:15:29.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:15:29.808+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:15:29.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:15:29.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-19T19:16:00.089+0000] {processor.py:157} INFO - Started process (PID=72864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:00.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:16:00.098+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:00.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:00.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:00.227+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:00.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:16:00.246+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:00.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:16:00.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-19T19:16:30.590+0000] {processor.py:157} INFO - Started process (PID=72874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:30.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:16:30.604+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:30.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:30.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:16:30.676+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:30.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:16:30.695+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:16:30.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:16:30.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T19:17:00.922+0000] {processor.py:157} INFO - Started process (PID=72884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:00.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:17:00.930+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:00.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:00.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:01.016+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:01.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:17:01.034+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:01.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:17:01.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-19T19:17:31.299+0000] {processor.py:157} INFO - Started process (PID=72894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:31.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:17:31.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:31.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:31.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:17:31.356+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:31.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:17:31.370+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:17:31.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:17:31.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T19:18:01.710+0000] {processor.py:157} INFO - Started process (PID=72904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:01.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:18:01.717+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:01.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:01.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:01.778+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:01.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:18:01.792+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:01.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:18:01.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T19:18:32.471+0000] {processor.py:157} INFO - Started process (PID=72913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:32.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:18:32.485+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:32.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:32.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:18:32.603+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:32.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:18:32.634+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:18:32.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:18:32.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-19T19:19:02.928+0000] {processor.py:157} INFO - Started process (PID=72924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:02.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:19:02.933+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:02.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:02.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:02.989+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:02.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:19:03.005+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:03.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:19:03.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T19:19:33.380+0000] {processor.py:157} INFO - Started process (PID=72934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:33.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:19:33.386+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:33.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:33.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:19:33.447+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:33.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:19:33.461+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:19:33.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:19:33.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T19:20:03.906+0000] {processor.py:157} INFO - Started process (PID=72944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:03.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:20:03.910+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:03.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:03.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:03.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:03.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:20:03.970+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:03.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:20:03.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-19T19:20:34.381+0000] {processor.py:157} INFO - Started process (PID=72954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:34.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:20:34.393+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:34.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:34.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:20:34.457+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:34.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:20:34.477+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:20:34.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:20:34.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T19:21:04.760+0000] {processor.py:157} INFO - Started process (PID=72964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:04.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:21:04.768+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:04.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:04.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:04.790+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:04.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:21:04.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:04.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:21:04.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T19:21:35.064+0000] {processor.py:157} INFO - Started process (PID=72974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:35.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:21:35.073+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:35.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:35.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:21:35.135+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:35.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:21:35.149+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:21:35.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:21:35.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T19:22:05.462+0000] {processor.py:157} INFO - Started process (PID=72984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:05.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:22:05.465+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:05.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:05.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:05.503+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:05.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:22:05.525+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:05.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:22:05.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-19T19:22:35.846+0000] {processor.py:157} INFO - Started process (PID=72994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:35.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:22:35.850+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:35.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:35.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:22:35.881+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:35.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:22:35.896+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:22:35.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:22:35.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-19T19:23:06.197+0000] {processor.py:157} INFO - Started process (PID=73004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:06.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:23:06.206+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:06.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:06.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:06.248+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:06.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:23:06.260+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:06.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:23:06.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T19:23:36.555+0000] {processor.py:157} INFO - Started process (PID=73014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:36.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:23:36.566+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:36.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:36.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:23:36.597+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:36.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:23:36.613+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:23:36.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:23:36.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-19T19:24:06.953+0000] {processor.py:157} INFO - Started process (PID=73023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:06.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:24:06.960+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:06.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:06.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:07.016+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:07.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:24:07.034+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:07.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:24:07.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T19:24:37.352+0000] {processor.py:157} INFO - Started process (PID=73033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:37.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:24:37.365+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:37.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:24:37.424+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:37.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:24:37.438+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:24:37.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:24:37.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T19:25:07.633+0000] {processor.py:157} INFO - Started process (PID=73044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:07.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:25:07.641+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:07.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:07.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:07.663+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:07.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:25:07.676+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:07.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:25:07.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-19T19:25:37.996+0000] {processor.py:157} INFO - Started process (PID=73053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:37.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:25:38.004+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:38.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:38.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:25:38.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:38.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:25:38.065+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:25:38.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:25:38.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-19T19:26:08.381+0000] {processor.py:157} INFO - Started process (PID=73064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:08.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:26:08.383+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:08.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:08.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:08.411+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:08.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:26:08.421+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:08.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:26:08.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T19:26:38.857+0000] {processor.py:157} INFO - Started process (PID=73074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:38.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:26:38.862+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:38.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:38.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:26:38.918+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:38.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:26:38.944+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:26:38.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:26:38.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T19:27:09.164+0000] {processor.py:157} INFO - Started process (PID=73084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:09.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:27:09.172+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:09.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:09.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:09.196+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:09.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:27:09.205+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:09.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:27:09.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T19:27:39.617+0000] {processor.py:157} INFO - Started process (PID=73094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:39.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:27:39.626+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:39.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:39.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:27:39.658+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:39.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:27:39.670+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:27:39.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:27:39.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-19T19:28:10.095+0000] {processor.py:157} INFO - Started process (PID=73104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:10.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:28:10.101+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:10.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:10.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:10.163+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:10.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:28:10.179+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:10.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:28:10.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T19:28:40.467+0000] {processor.py:157} INFO - Started process (PID=73114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:40.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:28:40.473+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:40.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:40.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:28:40.513+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:40.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:28:40.526+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:28:40.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:28:40.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-19T19:29:10.901+0000] {processor.py:157} INFO - Started process (PID=73124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:10.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:29:10.916+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:10.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:10.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:10.966+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:10.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:29:10.979+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:10.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:29:10.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T19:29:41.241+0000] {processor.py:157} INFO - Started process (PID=73134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:41.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:29:41.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:41.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:41.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:29:41.266+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:41.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:29:41.276+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:29:41.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:29:41.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-19T19:30:11.662+0000] {processor.py:157} INFO - Started process (PID=73144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:11.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:30:11.669+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:11.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:11.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:11.727+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:11.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:30:11.744+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:11.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:30:11.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T19:30:42.007+0000] {processor.py:157} INFO - Started process (PID=73154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:42.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:30:42.011+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:42.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:42.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:30:42.059+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:42.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:30:42.073+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:30:42.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:30:42.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-19T19:31:12.437+0000] {processor.py:157} INFO - Started process (PID=73164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:12.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:31:12.442+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:12.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:12.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:12.475+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:12.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:31:12.489+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:12.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:31:12.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-19T19:31:42.874+0000] {processor.py:157} INFO - Started process (PID=73174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:42.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:31:42.882+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:42.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:42.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:31:42.902+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:42.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:31:42.911+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:31:42.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:31:42.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-19T19:32:13.261+0000] {processor.py:157} INFO - Started process (PID=73184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:13.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:32:13.266+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:13.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:13.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:13.320+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:13.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:32:13.334+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:13.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:32:13.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T19:32:43.602+0000] {processor.py:157} INFO - Started process (PID=73194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:43.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:32:43.604+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:43.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:43.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:32:43.634+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:43.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:32:43.646+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:32:43.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:32:43.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-19T19:33:14.035+0000] {processor.py:157} INFO - Started process (PID=73204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:14.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:33:14.061+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:14.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:14.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:14.130+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:14.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:33:14.145+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:14.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:33:14.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T19:33:44.409+0000] {processor.py:157} INFO - Started process (PID=73214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:44.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:33:44.414+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:44.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:44.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:33:44.480+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:44.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:33:44.504+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:33:44.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:33:44.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T19:34:14.786+0000] {processor.py:157} INFO - Started process (PID=73224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:14.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:34:14.793+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:14.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:14.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:14.847+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:14.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:34:14.863+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:14.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:34:14.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T19:34:45.154+0000] {processor.py:157} INFO - Started process (PID=73234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:45.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:34:45.159+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:45.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:45.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:34:45.199+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:45.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:34:45.218+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:34:45.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:34:45.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T19:35:15.508+0000] {processor.py:157} INFO - Started process (PID=73244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:15.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:35:15.510+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:15.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:15.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:15.537+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:15.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:35:15.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:15.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:35:15.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T19:35:45.925+0000] {processor.py:157} INFO - Started process (PID=73254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:45.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:35:45.930+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:45.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:45.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:35:45.985+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:45.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:35:46.001+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:35:46.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:35:46.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T19:36:16.384+0000] {processor.py:157} INFO - Started process (PID=73264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:16.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:36:16.397+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:16.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:16.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:16.448+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:16.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:36:16.466+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:16.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:36:16.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-19T19:36:46.739+0000] {processor.py:157} INFO - Started process (PID=73274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:46.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:36:46.743+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:46.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:46.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:36:46.775+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:46.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:36:46.785+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:36:46.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:36:46.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-19T19:37:17.125+0000] {processor.py:157} INFO - Started process (PID=73284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:17.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:37:17.129+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:17.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:17.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:17.186+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:17.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:37:17.199+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:17.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:37:17.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T19:37:47.639+0000] {processor.py:157} INFO - Started process (PID=73294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:47.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:37:47.643+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:47.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:47.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:37:47.679+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:47.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:37:47.689+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:37:47.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:37:47.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-19T19:38:18.133+0000] {processor.py:157} INFO - Started process (PID=73304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:18.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:38:18.137+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:18.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:18.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:18.184+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:18.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:38:18.204+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:18.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:38:18.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T19:38:48.474+0000] {processor.py:157} INFO - Started process (PID=73314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:48.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:38:48.482+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:48.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:48.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:38:48.505+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:48.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:38:48.515+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:38:48.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:38:48.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T19:39:18.879+0000] {processor.py:157} INFO - Started process (PID=73324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:18.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:39:18.889+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:18.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:18.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:18.931+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:18.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:39:18.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:18.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:39:18.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T19:39:49.235+0000] {processor.py:157} INFO - Started process (PID=73334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:49.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:39:49.242+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:49.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:49.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:39:49.264+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:49.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:39:49.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:39:49.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:39:49.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-19T19:40:19.729+0000] {processor.py:157} INFO - Started process (PID=73344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:19.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:40:19.740+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:19.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:19.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:19.855+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:19.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:40:19.874+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:19.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:40:19.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-19T19:40:50.162+0000] {processor.py:157} INFO - Started process (PID=73354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:50.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:40:50.176+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:50.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:50.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:40:50.242+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:50.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:40:50.259+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:40:50.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:40:50.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T19:41:20.587+0000] {processor.py:157} INFO - Started process (PID=73364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:20.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:41:20.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:20.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:20.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:20.661+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:20.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:41:20.684+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:20.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:41:20.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-19T19:41:51.101+0000] {processor.py:157} INFO - Started process (PID=73374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:51.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:41:51.135+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:51.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:51.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:41:51.198+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:51.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:41:51.216+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:41:51.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:41:51.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T19:42:21.532+0000] {processor.py:157} INFO - Started process (PID=73384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:21.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:42:21.540+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:21.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:21.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:21.609+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:21.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:42:21.622+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:21.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:42:21.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T19:42:51.927+0000] {processor.py:157} INFO - Started process (PID=73394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:51.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:42:51.939+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:51.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:51.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:42:51.996+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:51.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:42:52.011+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:42:52.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:42:52.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T19:43:22.334+0000] {processor.py:157} INFO - Started process (PID=73404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:22.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:43:22.342+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:22.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:22.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:22.404+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:22.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:43:22.420+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:22.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:43:22.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T19:43:52.769+0000] {processor.py:157} INFO - Started process (PID=73414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:52.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:43:52.778+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:52.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:52.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:43:52.864+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:52.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:43:52.882+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:43:52.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:43:52.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T19:44:23.128+0000] {processor.py:157} INFO - Started process (PID=73424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:23.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:44:23.136+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:23.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:23.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:23.234+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:23.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:44:23.247+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:23.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:44:23.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-19T19:44:53.507+0000] {processor.py:157} INFO - Started process (PID=73434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:53.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:44:53.540+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:53.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:53.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:44:53.633+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:53.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:44:53.655+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:44:53.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:44:53.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-19T19:45:23.979+0000] {processor.py:157} INFO - Started process (PID=73444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:23.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:45:23.987+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:23.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:24.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:24.217+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:24.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:45:24.253+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:24.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:45:24.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.309 seconds
[2024-08-19T19:45:54.594+0000] {processor.py:157} INFO - Started process (PID=73454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:54.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:45:54.603+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:54.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:54.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:45:54.671+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:54.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:45:54.687+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:45:54.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:45:54.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T19:46:25.141+0000] {processor.py:157} INFO - Started process (PID=73464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:25.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:46:25.153+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:25.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:25.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:25.252+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:25.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:46:25.275+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:25.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:46:25.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-19T19:46:55.513+0000] {processor.py:157} INFO - Started process (PID=73474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:55.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:46:55.520+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:55.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:55.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:46:55.588+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:55.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:46:55.612+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:46:55.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:46:55.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T19:47:25.915+0000] {processor.py:157} INFO - Started process (PID=73483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:25.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:47:25.929+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:25.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:25.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:25.987+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:25.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:47:26.002+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:26.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:47:26.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T19:47:56.535+0000] {processor.py:157} INFO - Started process (PID=73492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:56.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:47:56.550+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:56.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:56.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:47:56.602+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:56.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:47:56.618+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:47:56.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:47:56.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-19T19:48:27.026+0000] {processor.py:157} INFO - Started process (PID=73504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:27.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:48:27.033+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:27.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:27.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:27.095+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:27.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:48:27.117+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:27.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:48:27.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T19:48:57.398+0000] {processor.py:157} INFO - Started process (PID=73514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:57.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:48:57.408+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:57.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:57.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:48:57.471+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:57.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:48:57.486+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:48:57.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:48:57.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T19:49:27.894+0000] {processor.py:157} INFO - Started process (PID=73524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:27.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:49:27.901+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:27.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:27.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:27.976+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:27.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:49:27.990+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:27.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:49:28.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T19:49:58.356+0000] {processor.py:157} INFO - Started process (PID=73534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:58.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:49:58.362+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:58.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:58.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:49:58.450+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:58.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:49:58.469+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:49:58.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:49:58.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T19:50:28.754+0000] {processor.py:157} INFO - Started process (PID=73544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:28.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:50:28.760+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:28.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:28.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:28.816+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:28.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:50:28.829+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:28.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:50:28.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T19:50:59.245+0000] {processor.py:157} INFO - Started process (PID=73553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:59.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:50:59.251+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:59.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:59.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:50:59.302+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:59.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:50:59.317+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:50:59.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:50:59.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T19:51:29.694+0000] {processor.py:157} INFO - Started process (PID=73564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:51:29.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:51:29.701+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:51:29.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:51:29.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:51:29.771+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:51:29.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:51:29.786+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:51:29.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:51:29.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T19:52:00.265+0000] {processor.py:157} INFO - Started process (PID=73574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:00.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:52:00.271+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:00.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:00.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:00.367+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:00.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:52:00.388+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:00.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:52:00.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-19T19:52:30.624+0000] {processor.py:157} INFO - Started process (PID=73584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:30.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:52:30.632+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:30.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:30.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:52:30.689+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:30.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:52:30.703+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:52:30.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:52:30.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T19:53:01.328+0000] {processor.py:157} INFO - Started process (PID=73594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:01.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:53:01.338+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:01.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:01.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:01.419+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:01.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:53:01.442+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:01.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:53:01.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-19T19:53:31.640+0000] {processor.py:157} INFO - Started process (PID=73604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:31.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:53:31.653+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:31.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:31.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:53:31.731+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:31.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:53:31.749+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:53:31.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:53:31.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-19T19:54:01.994+0000] {processor.py:157} INFO - Started process (PID=73614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:01.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:54:02.002+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:02.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:02.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:02.049+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:02.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:54:02.063+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:02.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:54:02.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T19:54:32.458+0000] {processor.py:157} INFO - Started process (PID=73624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:32.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:54:32.466+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:32.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:32.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:54:32.529+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:32.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:54:32.549+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:54:32.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:54:32.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T19:55:02.844+0000] {processor.py:157} INFO - Started process (PID=73634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:02.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:55:02.851+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:02.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:02.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:02.910+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:02.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:55:02.925+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:02.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:55:02.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T19:55:33.330+0000] {processor.py:157} INFO - Started process (PID=73644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:33.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:55:33.338+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:33.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:55:33.379+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:33.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:55:33.395+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:55:33.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:55:33.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T19:56:03.778+0000] {processor.py:157} INFO - Started process (PID=73654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:03.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:56:03.781+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:03.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:03.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:03.811+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:03.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:56:03.822+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:03.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:56:03.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T19:56:34.210+0000] {processor.py:157} INFO - Started process (PID=73664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:34.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:56:34.216+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:34.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:34.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:56:34.282+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:34.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:56:34.298+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:56:34.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:56:34.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T19:57:04.524+0000] {processor.py:157} INFO - Started process (PID=73674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:04.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:57:04.531+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:04.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:04.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:04.582+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:04.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:57:04.595+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:04.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:57:04.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T19:57:34.973+0000] {processor.py:157} INFO - Started process (PID=73684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:34.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:57:34.979+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:34.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:35.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:57:35.051+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:35.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:57:35.068+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:57:35.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:57:35.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T19:58:05.379+0000] {processor.py:157} INFO - Started process (PID=73694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:05.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:58:05.388+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:05.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:05.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:05.474+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:05.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:58:05.491+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:05.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:58:05.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-19T19:58:35.710+0000] {processor.py:157} INFO - Started process (PID=73704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:35.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:58:35.713+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:35.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:35.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:58:35.774+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:35.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:58:35.787+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:58:35.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:58:35.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T19:59:06.081+0000] {processor.py:157} INFO - Started process (PID=73714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:06.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:59:06.085+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:06.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:06.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:06.159+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:06.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:59:06.176+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:06.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:59:06.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T19:59:36.386+0000] {processor.py:157} INFO - Started process (PID=73724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:36.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T19:59:36.392+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:36.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:36.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T19:59:36.541+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:36.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T19:59:36.577+0000] {logging_mixin.py:151} INFO - [2024-08-19T19:59:36.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T19:59:36.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-08-19T20:00:06.757+0000] {processor.py:157} INFO - Started process (PID=73734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:06.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:00:06.763+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:06.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:06.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:06.813+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:06.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:00:06.838+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:06.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:00:06.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T20:00:37.183+0000] {processor.py:157} INFO - Started process (PID=73744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:37.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:00:37.190+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:37.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:37.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:00:37.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:37.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:00:37.292+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:00:37.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:00:37.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-19T20:01:07.579+0000] {processor.py:157} INFO - Started process (PID=73754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:07.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:01:07.590+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:07.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:07.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:07.639+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:07.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:01:07.653+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:07.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:01:07.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T20:01:37.886+0000] {processor.py:157} INFO - Started process (PID=73764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:37.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:01:37.893+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:37.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:37.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:01:37.931+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:37.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:01:37.944+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:01:37.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:01:37.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-19T20:02:08.199+0000] {processor.py:157} INFO - Started process (PID=73774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:08.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:02:08.204+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:08.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:08.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:08.274+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:08.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:02:08.290+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:08.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:02:08.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T20:02:38.695+0000] {processor.py:157} INFO - Started process (PID=73784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:38.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:02:38.703+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:38.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:38.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:02:38.764+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:38.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:02:38.779+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:02:38.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:02:38.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-19T20:03:09.112+0000] {processor.py:157} INFO - Started process (PID=73794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:09.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:03:09.116+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:09.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:09.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:09.181+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:09.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:03:09.199+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:09.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:03:09.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T20:03:39.456+0000] {processor.py:157} INFO - Started process (PID=73804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:39.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:03:39.471+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:39.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:03:39.544+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:39.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:03:39.566+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:03:39.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:03:39.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-19T20:04:09.822+0000] {processor.py:157} INFO - Started process (PID=73814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:09.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:04:09.833+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:09.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:09.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:09.927+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:09.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:04:09.953+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:09.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:04:09.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-19T20:04:40.215+0000] {processor.py:157} INFO - Started process (PID=73824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:40.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:04:40.222+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:40.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:40.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:04:40.282+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:40.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:04:40.298+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:04:40.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:04:40.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T20:05:10.586+0000] {processor.py:157} INFO - Started process (PID=73834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:10.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:05:10.593+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:10.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:10.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:10.651+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:10.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:05:10.670+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:10.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:05:10.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T20:05:41.036+0000] {processor.py:157} INFO - Started process (PID=73844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:41.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:05:41.042+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:41.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:41.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:05:41.102+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:41.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:05:41.116+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:05:41.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:05:41.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T20:06:11.354+0000] {processor.py:157} INFO - Started process (PID=73854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:11.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:06:11.360+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:11.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:11.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:11.416+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:11.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:06:11.429+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:11.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:06:11.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T20:06:41.756+0000] {processor.py:157} INFO - Started process (PID=73864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:41.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:06:41.763+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:41.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:41.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:06:41.787+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:41.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:06:41.797+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:06:41.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:06:41.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-19T20:07:12.154+0000] {processor.py:157} INFO - Started process (PID=73874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:12.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:07:12.161+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:12.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:12.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:12.212+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:12.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:07:12.229+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:12.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:07:12.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T20:07:42.709+0000] {processor.py:157} INFO - Started process (PID=73884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:42.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:07:42.713+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:42.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:42.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:07:42.766+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:42.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:07:42.780+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:07:42.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:07:42.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T20:08:13.012+0000] {processor.py:157} INFO - Started process (PID=73894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:13.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:08:13.015+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:13.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:13.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:13.043+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:13.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:08:13.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:13.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:08:13.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-19T20:08:43.447+0000] {processor.py:157} INFO - Started process (PID=73904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:43.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:08:43.452+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:43.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:43.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:08:43.516+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:43.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:08:43.536+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:08:43.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:08:43.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T20:09:13.911+0000] {processor.py:157} INFO - Started process (PID=73914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:13.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:09:13.922+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:13.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:13.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:13.965+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:13.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:09:13.983+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:13.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:09:13.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T20:09:44.266+0000] {processor.py:157} INFO - Started process (PID=73924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:44.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:09:44.271+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:44.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:44.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:09:44.336+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:44.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:09:44.353+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:09:44.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:09:44.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T20:10:14.645+0000] {processor.py:157} INFO - Started process (PID=73934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:14.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:10:14.662+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:14.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:14.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:14.720+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:14.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:10:14.736+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:14.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:10:14.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T20:10:44.988+0000] {processor.py:157} INFO - Started process (PID=73944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:44.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:10:44.993+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:44.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:45.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:10:45.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:45.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:10:45.074+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:10:45.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:10:45.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T20:11:15.335+0000] {processor.py:157} INFO - Started process (PID=73954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:15.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:11:15.349+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:15.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:15.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:15.412+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:15.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:11:15.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:15.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:11:15.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-19T20:11:45.682+0000] {processor.py:157} INFO - Started process (PID=73964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:45.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:11:45.691+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:45.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:45.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:11:45.740+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:45.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:11:45.767+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:11:45.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:11:45.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T20:12:16.032+0000] {processor.py:157} INFO - Started process (PID=73973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:16.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:12:16.038+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:16.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:16.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:16.096+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:16.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:12:16.112+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:16.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:12:16.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T20:12:46.377+0000] {processor.py:157} INFO - Started process (PID=73984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:46.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:12:46.384+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:46.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:46.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:12:46.444+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:46.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:12:46.475+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:12:46.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:12:46.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T20:13:16.772+0000] {processor.py:157} INFO - Started process (PID=73993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:16.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:13:16.779+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:16.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:16.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:16.838+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:16.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:13:16.854+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:16.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:13:16.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T20:13:47.147+0000] {processor.py:157} INFO - Started process (PID=74004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:47.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:13:47.163+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:47.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:47.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:13:47.250+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:47.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:13:47.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:13:47.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:13:47.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-19T20:14:17.615+0000] {processor.py:157} INFO - Started process (PID=74014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:17.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:14:17.625+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:17.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:17.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:17.681+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:17.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:14:17.696+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:17.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:14:17.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T20:14:48.023+0000] {processor.py:157} INFO - Started process (PID=74023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:48.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:14:48.029+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:48.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:48.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:14:48.099+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:48.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:14:48.117+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:14:48.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:14:48.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T20:15:18.428+0000] {processor.py:157} INFO - Started process (PID=74034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:18.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:15:18.437+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:18.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:18.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:18.519+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:18.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:15:18.548+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:18.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:15:18.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-19T20:15:48.749+0000] {processor.py:157} INFO - Started process (PID=74044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:48.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:15:48.755+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:48.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:48.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:15:48.811+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:48.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:15:48.825+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:15:48.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:15:48.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T20:16:19.218+0000] {processor.py:157} INFO - Started process (PID=74054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:19.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:16:19.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:19.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:19.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:19.295+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:19.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:16:19.311+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:19.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:16:19.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-19T20:16:49.597+0000] {processor.py:157} INFO - Started process (PID=74064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:49.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:16:49.602+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:49.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:49.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:16:49.653+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:49.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:16:49.665+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:16:49.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:16:49.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T20:17:20.024+0000] {processor.py:157} INFO - Started process (PID=74074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:20.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:17:20.033+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:20.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:20.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:20.122+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:20.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:17:20.137+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:20.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:17:20.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-19T20:17:50.420+0000] {processor.py:157} INFO - Started process (PID=74084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:50.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:17:50.426+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:50.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:50.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:17:50.500+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:50.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:17:50.518+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:17:50.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:17:50.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T20:18:20.796+0000] {processor.py:157} INFO - Started process (PID=74094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:20.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:18:20.802+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:20.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:20.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:20.869+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:20.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:18:20.884+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:20.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:18:20.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T20:18:51.155+0000] {processor.py:157} INFO - Started process (PID=74104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:51.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:18:51.160+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:51.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:51.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:18:51.217+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:51.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:18:51.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:18:51.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:18:51.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T20:19:21.500+0000] {processor.py:157} INFO - Started process (PID=74114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:21.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:19:21.507+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:21.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:21.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:21.564+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:21.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:19:21.579+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:21.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:19:21.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T20:19:51.870+0000] {processor.py:157} INFO - Started process (PID=74124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:51.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:19:51.875+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:51.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:51.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:19:51.942+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:51.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:19:51.957+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:19:51.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:19:51.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T20:20:22.247+0000] {processor.py:157} INFO - Started process (PID=74134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:22.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:20:22.253+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:22.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:22.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:22.326+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:22.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:20:22.343+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:22.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:20:22.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T20:20:52.532+0000] {processor.py:157} INFO - Started process (PID=74144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:52.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:20:52.538+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:52.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:52.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:20:52.588+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:52.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:20:52.602+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:20:52.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:20:52.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-19T20:21:22.929+0000] {processor.py:157} INFO - Started process (PID=74154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:22.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:21:22.935+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:22.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:22.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:23.002+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:23.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:21:23.015+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:23.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:21:23.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T20:21:53.314+0000] {processor.py:157} INFO - Started process (PID=74164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:53.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:21:53.321+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:53.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:53.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:21:53.383+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:53.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:21:53.408+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:21:53.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:21:53.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T20:22:23.825+0000] {processor.py:157} INFO - Started process (PID=74174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:23.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:22:23.837+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:23.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:23.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:23.879+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:23.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:22:23.904+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:23.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:22:23.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T20:22:54.309+0000] {processor.py:157} INFO - Started process (PID=74184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:54.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:22:54.318+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:54.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:54.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:22:54.368+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:54.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:22:54.382+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:22:54.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:22:54.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T20:23:24.694+0000] {processor.py:157} INFO - Started process (PID=74194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:24.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:23:24.702+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:24.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:24.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:24.723+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:24.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:23:24.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:24.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:23:24.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-19T20:23:55.141+0000] {processor.py:157} INFO - Started process (PID=74204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:55.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:23:55.147+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:55.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:55.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:23:55.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:55.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:23:55.227+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:23:55.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:23:55.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T20:24:25.601+0000] {processor.py:157} INFO - Started process (PID=74213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:25.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:24:25.606+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:25.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:25.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:25.667+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:25.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:24:25.684+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:25.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:24:25.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T20:24:55.953+0000] {processor.py:157} INFO - Started process (PID=74224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:55.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:24:55.959+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:55.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:55.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:24:55.989+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:55.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:24:56.000+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:24:56.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:24:56.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-19T20:25:26.360+0000] {processor.py:157} INFO - Started process (PID=74234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:26.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:25:26.365+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:26.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:26.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:26.400+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:26.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:25:26.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:26.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:25:26.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-19T20:25:56.769+0000] {processor.py:157} INFO - Started process (PID=74244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:56.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:25:56.773+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:56.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:56.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:25:56.844+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:56.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:25:56.857+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:25:56.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:25:56.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T20:26:27.168+0000] {processor.py:157} INFO - Started process (PID=74254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:27.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:26:27.174+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:27.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:27.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:27.229+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:27.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:26:27.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:27.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:26:27.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T20:26:57.489+0000] {processor.py:157} INFO - Started process (PID=74264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:57.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:26:57.492+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:57.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:57.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:26:57.521+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:57.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:26:57.532+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:26:57.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:26:57.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T20:27:27.874+0000] {processor.py:157} INFO - Started process (PID=74274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:27.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:27:27.880+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:27.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:27.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:27.949+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:27.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:27:27.963+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:27.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:27:27.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T20:27:58.202+0000] {processor.py:157} INFO - Started process (PID=74284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:58.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:27:58.208+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:58.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:58.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:27:58.278+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:58.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:27:58.291+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:27:58.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:27:58.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-19T20:28:28.713+0000] {processor.py:157} INFO - Started process (PID=74294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:28.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:28:28.722+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:28.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:28.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:28.776+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:28.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:28:28.794+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:28.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:28:28.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T20:28:59.119+0000] {processor.py:157} INFO - Started process (PID=74304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:59.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:28:59.127+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:59.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:59.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:28:59.196+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:59.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:28:59.210+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:28:59.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:28:59.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-19T20:29:29.531+0000] {processor.py:157} INFO - Started process (PID=74314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:29.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:29:29.539+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:29.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:29.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:29.587+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:29.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:29:29.601+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:29.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:29:29.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T20:29:59.863+0000] {processor.py:157} INFO - Started process (PID=74323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:59.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:29:59.870+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:59.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:59.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:29:59.914+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:59.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:29:59.945+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:29:59.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:29:59.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T20:30:30.186+0000] {processor.py:157} INFO - Started process (PID=74334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:30:30.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:30:30.196+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:30:30.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:30:30.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:30:30.257+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:30:30.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:30:30.285+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:30:30.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:30:30.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-19T20:31:00.534+0000] {processor.py:157} INFO - Started process (PID=74344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:00.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:31:00.540+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:00.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:00.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:00.587+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:00.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:31:00.601+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:00.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:31:00.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T20:31:30.816+0000] {processor.py:157} INFO - Started process (PID=74354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:30.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:31:30.823+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:30.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:30.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:31:30.849+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:30.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:31:30.858+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:31:30.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:31:30.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-19T20:32:01.192+0000] {processor.py:157} INFO - Started process (PID=74364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:01.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:32:01.196+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:01.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:01.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:01.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:01.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:32:01.262+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:01.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:32:01.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T20:32:31.768+0000] {processor.py:157} INFO - Started process (PID=74374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:31.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:32:31.774+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:31.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:31.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:32:31.852+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:31.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:32:31.879+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:32:31.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:32:31.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-19T20:33:02.120+0000] {processor.py:157} INFO - Started process (PID=74384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:02.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:33:02.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:02.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:02.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:02.194+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:02.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:33:02.209+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:02.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:33:02.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T20:33:32.509+0000] {processor.py:157} INFO - Started process (PID=74393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:32.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:33:32.529+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:32.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:32.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:33:32.610+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:32.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:33:32.627+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:33:32.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:33:32.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-19T20:34:02.854+0000] {processor.py:157} INFO - Started process (PID=74403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:02.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:34:02.860+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:02.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:02.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:02.940+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:02.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:34:02.969+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:02.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:34:02.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T20:34:33.195+0000] {processor.py:157} INFO - Started process (PID=74414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:33.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:34:33.202+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:33.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:33.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:34:33.269+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:33.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:34:33.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:34:33.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:34:33.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T20:35:04.082+0000] {processor.py:157} INFO - Started process (PID=74424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:04.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:35:04.104+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:04.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:04.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:04.262+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:04.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:35:04.287+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:04.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:35:04.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-08-19T20:35:34.812+0000] {processor.py:157} INFO - Started process (PID=74436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:34.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:35:34.814+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:34.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:34.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:35:34.881+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:34.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:35:34.903+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:35:34.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:35:34.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T20:36:05.294+0000] {processor.py:157} INFO - Started process (PID=74446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:36:05.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T20:36:05.300+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:36:05.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:36:05.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T20:36:05.360+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:36:05.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T20:36:05.375+0000] {logging_mixin.py:151} INFO - [2024-08-19T20:36:05.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T20:36:05.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-19T21:44:27.650+0000] {processor.py:157} INFO - Started process (PID=74456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T21:44:27.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T21:44:27.662+0000] {logging_mixin.py:151} INFO - [2024-08-19T21:44:27.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T21:44:27.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T21:44:27.705+0000] {logging_mixin.py:151} INFO - [2024-08-19T21:44:27.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T21:44:27.720+0000] {logging_mixin.py:151} INFO - [2024-08-19T21:44:27.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T21:44:27.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T22:36:06.080+0000] {processor.py:157} INFO - Started process (PID=74470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:06.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:36:06.100+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:06.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:06.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:06.137+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:06.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:36:06.154+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:06.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:36:06.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T22:36:36.537+0000] {processor.py:157} INFO - Started process (PID=74480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:36.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:36:36.544+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:36.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:36.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:36:36.583+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:36.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:36:36.598+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:36:36.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:36:36.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T22:45:07.735+0000] {processor.py:157} INFO - Started process (PID=74489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:45:07.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:45:07.746+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:45:07.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:45:07.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:45:07.811+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:45:07.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:45:07.837+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:45:07.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:45:07.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-19T22:46:17.364+0000] {processor.py:157} INFO - Started process (PID=74500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:17.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:46:17.375+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:17.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:17.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:17.440+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:17.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:46:17.454+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:17.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:46:17.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T22:46:47.836+0000] {processor.py:157} INFO - Started process (PID=74510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:47.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:46:47.845+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:47.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:47.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:46:47.898+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:47.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:46:47.912+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:46:47.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:46:47.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T22:49:41.545+0000] {processor.py:157} INFO - Started process (PID=74520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:49:41.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:49:41.568+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:49:41.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:49:42.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:49:42.144+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:49:42.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:49:42.214+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:49:42.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:49:42.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.754 seconds
[2024-08-19T22:50:12.930+0000] {processor.py:157} INFO - Started process (PID=74531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:12.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:50:12.938+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:12.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:12.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:13.004+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:13.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:50:13.024+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:13.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:50:13.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T22:50:43.259+0000] {processor.py:157} INFO - Started process (PID=74542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:43.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:50:43.268+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:43.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:43.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:50:43.349+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:43.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:50:43.366+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:50:43.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:50:43.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-19T22:51:13.570+0000] {processor.py:157} INFO - Started process (PID=74552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:13.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:51:13.576+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:13.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:13.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:13.629+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:13.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:51:13.643+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:13.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:51:13.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T22:51:43.894+0000] {processor.py:157} INFO - Started process (PID=74561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:43.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:51:43.901+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:43.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:43.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:51:43.968+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:43.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:51:43.988+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:51:43.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:51:44.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T22:52:14.335+0000] {processor.py:157} INFO - Started process (PID=74572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:14.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:52:14.342+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:14.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:14.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:14.389+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:14.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:52:14.410+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:14.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:52:14.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-19T22:52:44.625+0000] {processor.py:157} INFO - Started process (PID=74582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:44.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:52:44.633+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:44.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:44.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:52:44.684+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:44.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:52:44.709+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:52:44.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:52:44.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T22:53:15.064+0000] {processor.py:157} INFO - Started process (PID=74592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:15.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:53:15.075+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:15.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:15.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:15.153+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:15.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:53:15.173+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:15.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:53:15.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T22:53:45.417+0000] {processor.py:157} INFO - Started process (PID=74602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:45.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:53:45.423+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:45.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:45.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:53:45.478+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:45.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:53:45.492+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:53:45.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:53:45.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T22:54:15.876+0000] {processor.py:157} INFO - Started process (PID=74612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:15.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:54:15.887+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:15.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:15.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:15.968+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:15.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:54:15.988+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:15.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:54:16.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-19T22:54:46.423+0000] {processor.py:157} INFO - Started process (PID=74622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:46.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:54:46.431+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:46.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:46.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:54:46.520+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:46.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:54:46.544+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:54:46.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:54:46.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-19T22:55:16.851+0000] {processor.py:157} INFO - Started process (PID=74632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:16.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:55:16.861+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:16.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:16.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:16.962+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:16.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:55:17.002+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:17.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:55:17.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-19T22:55:47.180+0000] {processor.py:157} INFO - Started process (PID=74642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:47.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:55:47.188+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:47.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:47.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:55:47.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:47.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:55:47.263+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:55:47.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:55:47.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T22:56:17.495+0000] {processor.py:157} INFO - Started process (PID=74652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:17.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:56:17.502+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:17.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:17.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:17.556+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:17.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:56:17.570+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:17.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:56:17.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T22:56:47.868+0000] {processor.py:157} INFO - Started process (PID=74661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:47.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:56:47.875+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:47.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:47.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:56:47.940+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:47.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:56:47.953+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:56:47.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:56:47.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T22:57:18.316+0000] {processor.py:157} INFO - Started process (PID=74672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:18.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:57:18.326+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:18.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:18.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:18.379+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:18.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:57:18.393+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:18.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:57:18.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T22:57:48.690+0000] {processor.py:157} INFO - Started process (PID=74682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:48.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:57:48.697+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:48.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:48.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:57:48.741+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:48.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:57:48.755+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:57:48.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:57:48.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-19T22:58:19.063+0000] {processor.py:157} INFO - Started process (PID=74692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:19.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:58:19.071+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:19.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:19.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:19.158+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:19.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:58:19.176+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:19.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:58:19.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-19T22:58:49.521+0000] {processor.py:157} INFO - Started process (PID=74702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:49.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:58:49.528+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:49.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:49.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:58:49.582+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:49.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:58:49.596+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:58:49.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:58:49.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T22:59:19.846+0000] {processor.py:157} INFO - Started process (PID=74711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:19.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:59:19.858+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:19.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:19.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:19.980+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:19.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:59:20.006+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:20.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:59:20.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-19T22:59:50.156+0000] {processor.py:157} INFO - Started process (PID=74720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:50.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T22:59:50.168+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:50.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:50.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T22:59:50.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:50.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T22:59:50.289+0000] {logging_mixin.py:151} INFO - [2024-08-19T22:59:50.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T22:59:50.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-19T23:00:20.549+0000] {processor.py:157} INFO - Started process (PID=74732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:20.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:00:20.556+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:20.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:20.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:20.610+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:20.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:00:20.627+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:20.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:00:20.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T23:00:50.954+0000] {processor.py:157} INFO - Started process (PID=74742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:50.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:00:50.964+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:50.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:50.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:00:51.025+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:51.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:00:51.043+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:00:51.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:00:51.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T23:01:21.291+0000] {processor.py:157} INFO - Started process (PID=74752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:21.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:01:21.299+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:21.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:21.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:21.362+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:21.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:01:21.379+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:21.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:01:21.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-19T23:01:51.672+0000] {processor.py:157} INFO - Started process (PID=74761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:51.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:01:51.679+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:51.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:51.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:01:51.761+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:51.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:01:51.786+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:01:51.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:01:51.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T23:02:22.011+0000] {processor.py:157} INFO - Started process (PID=74772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:22.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:02:22.022+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:22.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:22.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:22.114+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:22.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:02:22.137+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:22.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:02:22.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-19T23:02:52.356+0000] {processor.py:157} INFO - Started process (PID=74782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:52.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:02:52.370+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:52.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:52.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:02:52.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:52.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:02:52.442+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:02:52.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:02:52.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T23:03:22.699+0000] {processor.py:157} INFO - Started process (PID=74792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:22.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:03:22.707+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:22.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:22.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:22.769+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:22.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:03:22.791+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:22.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:03:22.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-19T23:03:53.065+0000] {processor.py:157} INFO - Started process (PID=74802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:53.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:03:53.075+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:53.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:53.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:03:53.161+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:53.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:03:53.182+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:03:53.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:03:53.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T23:04:23.355+0000] {processor.py:157} INFO - Started process (PID=74812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:23.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:04:23.361+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:23.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:23.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:23.422+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:23.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:04:23.444+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:23.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:04:23.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T23:04:53.725+0000] {processor.py:157} INFO - Started process (PID=74822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:53.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:04:53.734+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:53.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:53.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:04:53.809+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:53.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:04:53.853+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:04:53.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:04:53.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-19T23:05:24.061+0000] {processor.py:157} INFO - Started process (PID=74832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:24.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:05:24.073+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:24.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:24.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:24.115+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:24.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:05:24.132+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:24.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:05:24.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T23:05:54.337+0000] {processor.py:157} INFO - Started process (PID=74842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:54.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:05:54.345+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:54.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:54.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:05:54.397+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:54.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:05:54.411+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:05:54.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:05:54.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T23:06:24.693+0000] {processor.py:157} INFO - Started process (PID=74852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:24.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:06:24.704+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:24.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:24.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:24.749+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:24.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:06:24.766+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:24.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:06:24.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-19T23:06:55.189+0000] {processor.py:157} INFO - Started process (PID=74861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:55.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:06:55.201+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:55.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:55.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:06:55.261+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:55.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:06:55.276+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:06:55.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:06:55.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-19T23:07:25.495+0000] {processor.py:157} INFO - Started process (PID=74872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:25.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:07:25.508+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:25.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:25.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:25.579+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:25.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:07:25.610+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:25.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:07:25.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-19T23:07:55.812+0000] {processor.py:157} INFO - Started process (PID=74881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:55.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:07:55.821+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:55.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:55.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:07:55.894+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:55.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:07:55.914+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:07:55.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:07:55.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T23:08:26.155+0000] {processor.py:157} INFO - Started process (PID=74891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:26.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:08:26.165+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:26.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:26.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:26.240+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:26.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:08:26.263+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:26.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:08:26.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T23:08:56.391+0000] {processor.py:157} INFO - Started process (PID=74902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:56.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:08:56.396+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:56.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:56.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:08:56.424+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:56.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:08:56.434+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:08:56.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:08:56.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-19T23:09:26.782+0000] {processor.py:157} INFO - Started process (PID=74912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:26.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:09:26.789+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:26.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:26.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:26.833+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:26.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:09:26.848+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:26.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:09:26.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-19T23:09:57.183+0000] {processor.py:157} INFO - Started process (PID=74922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:57.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:09:57.214+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:57.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:57.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:09:57.278+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:57.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:09:57.304+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:09:57.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:09:57.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-19T23:10:27.525+0000] {processor.py:157} INFO - Started process (PID=74932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:27.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:10:27.533+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:27.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:27.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:27.580+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:27.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:10:27.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:27.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:10:27.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T23:10:57.841+0000] {processor.py:157} INFO - Started process (PID=74942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:57.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:10:57.862+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:57.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:57.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:10:57.902+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:57.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:10:57.917+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:10:57.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:10:57.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-19T23:11:28.161+0000] {processor.py:157} INFO - Started process (PID=74952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:28.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:11:28.173+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:28.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:28.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:28.236+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:28.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:11:28.255+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:28.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:11:28.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-19T23:11:58.579+0000] {processor.py:157} INFO - Started process (PID=74962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:58.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:11:58.588+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:58.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:58.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:11:58.658+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:58.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:11:58.677+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:11:58.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:11:58.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T23:12:28.903+0000] {processor.py:157} INFO - Started process (PID=74972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:28.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:12:28.920+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:28.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:28.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:28.966+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:28.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:12:28.982+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:28.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:12:28.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T23:12:59.259+0000] {processor.py:157} INFO - Started process (PID=74982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:59.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:12:59.266+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:59.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:59.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:12:59.344+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:59.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:12:59.367+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:12:59.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:12:59.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-19T23:13:29.708+0000] {processor.py:157} INFO - Started process (PID=74992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:13:29.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:13:29.716+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:13:29.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:13:29.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:13:29.788+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:13:29.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:13:29.814+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:13:29.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:13:29.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-19T23:14:00.206+0000] {processor.py:157} INFO - Started process (PID=75002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:00.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:14:00.214+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:00.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:00.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:00.273+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:00.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:14:00.287+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:00.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:14:00.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T23:14:30.598+0000] {processor.py:157} INFO - Started process (PID=75010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:30.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:14:30.603+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:30.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:30.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:14:30.668+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:30.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:14:30.681+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:14:30.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:14:30.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-19T23:15:01.037+0000] {processor.py:157} INFO - Started process (PID=75022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:01.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:15:01.045+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:01.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:01.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:01.119+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:01.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:15:01.136+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:01.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:15:01.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T23:15:31.369+0000] {processor.py:157} INFO - Started process (PID=75032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:31.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:15:31.376+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:31.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:31.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:15:31.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:31.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:15:31.454+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:15:31.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:15:31.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-19T23:16:01.676+0000] {processor.py:157} INFO - Started process (PID=75042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:01.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:16:01.708+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:01.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:01.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:01.828+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:01.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:16:01.849+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:01.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:16:01.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-19T23:16:32.228+0000] {processor.py:157} INFO - Started process (PID=75052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:32.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:16:32.256+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:32.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:32.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:16:32.334+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:32.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:16:32.366+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:16:32.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:16:32.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-19T23:17:02.746+0000] {processor.py:157} INFO - Started process (PID=75062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:02.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:17:02.757+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:02.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:02.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:02.831+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:02.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:17:02.865+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:02.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:17:02.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-19T23:17:33.198+0000] {processor.py:157} INFO - Started process (PID=75072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:33.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:17:33.206+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:33.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:33.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:17:33.250+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:33.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:17:33.266+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:17:33.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:17:33.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T23:18:03.594+0000] {processor.py:157} INFO - Started process (PID=75082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:03.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:18:03.605+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:03.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:03.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:03.682+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:03.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:18:03.698+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:03.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:18:03.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-19T23:18:33.972+0000] {processor.py:157} INFO - Started process (PID=75092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:33.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:18:33.979+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:33.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:34.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:18:34.029+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:34.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:18:34.042+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:18:34.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:18:34.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T23:19:04.470+0000] {processor.py:157} INFO - Started process (PID=75102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:04.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:19:04.480+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:04.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:04.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:04.558+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:04.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:19:04.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:04.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:19:04.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-19T23:19:34.791+0000] {processor.py:157} INFO - Started process (PID=75112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:34.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:19:34.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:34.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:34.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:19:34.855+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:34.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:19:34.872+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:19:34.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:19:34.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T23:20:05.186+0000] {processor.py:157} INFO - Started process (PID=75121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:05.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:20:05.197+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:05.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:05.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:05.258+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:05.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:20:05.278+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:05.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:20:05.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-19T23:20:35.691+0000] {processor.py:157} INFO - Started process (PID=75132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:35.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:20:35.697+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:35.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:35.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:20:35.745+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:35.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:20:35.765+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:20:35.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:20:35.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T23:21:06.138+0000] {processor.py:157} INFO - Started process (PID=75142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:06.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:21:06.166+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:06.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:06.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:06.282+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:06.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:21:06.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:06.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:21:06.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-19T23:21:36.594+0000] {processor.py:157} INFO - Started process (PID=75152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:36.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:21:36.600+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:36.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:36.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:21:36.660+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:36.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:21:36.676+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:21:36.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:21:36.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T23:22:06.925+0000] {processor.py:157} INFO - Started process (PID=75162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:06.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:22:06.934+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:06.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:06.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:07.004+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:07.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:22:07.021+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:07.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:22:07.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T23:22:37.239+0000] {processor.py:157} INFO - Started process (PID=75172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:37.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:22:37.253+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:37.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:37.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:22:37.300+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:37.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:22:37.326+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:22:37.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:22:37.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-19T23:23:07.692+0000] {processor.py:157} INFO - Started process (PID=75182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:07.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:23:07.704+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:07.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:07.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:07.755+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:07.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:23:07.776+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:07.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:23:07.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T23:23:37.970+0000] {processor.py:157} INFO - Started process (PID=75192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:37.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:23:37.976+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:37.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:37.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:23:38.023+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:38.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:23:38.042+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:23:38.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:23:38.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T23:24:08.501+0000] {processor.py:157} INFO - Started process (PID=75202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:08.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:24:08.523+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:08.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:08.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:08.598+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:08.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:24:08.613+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:08.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:24:08.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-19T23:24:38.993+0000] {processor.py:157} INFO - Started process (PID=75211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:38.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:24:39.000+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:39.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:39.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:24:39.068+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:39.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:24:39.084+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:24:39.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:24:39.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-19T23:25:09.439+0000] {processor.py:157} INFO - Started process (PID=75222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:09.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:25:09.450+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:09.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:09.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:09.546+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:09.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:25:09.567+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:09.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:25:09.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-19T23:25:39.901+0000] {processor.py:157} INFO - Started process (PID=75232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:39.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:25:39.914+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:39.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:39.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:25:39.982+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:39.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:25:40.000+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:25:39.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:25:40.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-19T23:26:10.335+0000] {processor.py:157} INFO - Started process (PID=75241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:10.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:26:10.342+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:10.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:10.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:10.386+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:10.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:26:10.409+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:10.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:26:10.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T23:26:40.598+0000] {processor.py:157} INFO - Started process (PID=75252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:40.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:26:40.602+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:40.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:40.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:26:40.632+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:40.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:26:40.643+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:26:40.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:26:40.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-19T23:27:10.943+0000] {processor.py:157} INFO - Started process (PID=75262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:10.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:27:10.948+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:10.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:10.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:10.988+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:10.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:27:11.003+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:11.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:27:11.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-19T23:27:41.238+0000] {processor.py:157} INFO - Started process (PID=75272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:41.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:27:41.245+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:41.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:41.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:27:41.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:41.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:27:41.300+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:27:41.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:27:41.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-19T23:28:11.641+0000] {processor.py:157} INFO - Started process (PID=75281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:11.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:28:11.649+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:11.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:11.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:11.715+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:11.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:28:11.734+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:11.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:28:11.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-19T23:28:42.101+0000] {processor.py:157} INFO - Started process (PID=75292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:42.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:28:42.113+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:42.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:42.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:28:42.154+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:42.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:28:42.168+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:28:42.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:28:42.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-19T23:29:12.568+0000] {processor.py:157} INFO - Started process (PID=75302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:12.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:29:12.577+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:12.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:12.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:12.652+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:12.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:29:12.673+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:12.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:29:12.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-19T23:29:43.006+0000] {processor.py:157} INFO - Started process (PID=75311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:43.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:29:43.020+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:43.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:43.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:29:43.078+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:43.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:29:43.094+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:29:43.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:29:43.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-19T23:30:13.600+0000] {processor.py:157} INFO - Started process (PID=75322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:13.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:30:13.608+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:13.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:13.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:13.710+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:13.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:30:13.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:13.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:30:13.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-19T23:30:43.893+0000] {processor.py:157} INFO - Started process (PID=75332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:43.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:30:43.902+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:43.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:43.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:30:43.950+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:43.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:30:43.964+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:30:43.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:30:43.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-19T23:31:14.432+0000] {processor.py:157} INFO - Started process (PID=75342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:14.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:31:14.443+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:14.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:14.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:14.503+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:14.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:31:14.533+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:14.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:31:14.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T23:31:45.020+0000] {processor.py:157} INFO - Started process (PID=75352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:45.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:31:45.029+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:45.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:45.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:31:45.085+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:45.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:31:45.106+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:31:45.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:31:45.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T23:32:15.460+0000] {processor.py:157} INFO - Started process (PID=75362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:15.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:32:15.467+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:15.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:15.515+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:15.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:32:15.529+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:15.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:32:15.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-19T23:32:45.778+0000] {processor.py:157} INFO - Started process (PID=75372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:45.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:32:45.784+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:45.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:45.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:32:45.845+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:45.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:32:45.859+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:32:45.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:32:45.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-19T23:33:16.182+0000] {processor.py:157} INFO - Started process (PID=75382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:16.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:33:16.189+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:16.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:16.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:16.265+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:16.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:33:16.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:16.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:33:16.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-19T23:33:46.491+0000] {processor.py:157} INFO - Started process (PID=75392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:46.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:33:46.524+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:46.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:46.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:33:46.612+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:46.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:33:46.632+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:33:46.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:33:46.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-19T23:34:16.941+0000] {processor.py:157} INFO - Started process (PID=75401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:16.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:34:16.952+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:16.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:17.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:17.066+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:17.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:34:17.109+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:17.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:34:17.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-19T23:34:47.238+0000] {processor.py:157} INFO - Started process (PID=75411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:47.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:34:47.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:47.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:47.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:34:47.291+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:47.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:34:47.304+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:34:47.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:34:47.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-19T23:35:17.764+0000] {processor.py:157} INFO - Started process (PID=75422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:17.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:35:17.771+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:17.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:17.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:17.818+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:17.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:35:17.835+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:17.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:35:17.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T23:35:48.119+0000] {processor.py:157} INFO - Started process (PID=75432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:48.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:35:48.125+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:48.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:48.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:35:48.185+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:48.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:35:48.199+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:35:48.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:35:48.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T23:36:18.536+0000] {processor.py:157} INFO - Started process (PID=75442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:18.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:36:18.545+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:18.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:18.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:18.615+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:18.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:36:18.631+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:18.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:36:18.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-19T23:36:48.911+0000] {processor.py:157} INFO - Started process (PID=75451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:48.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:36:48.920+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:48.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:48.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:36:48.982+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:48.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:36:48.997+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:36:48.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:36:49.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T23:37:19.188+0000] {processor.py:157} INFO - Started process (PID=75462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:19.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:37:19.207+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:19.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:19.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:19.268+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:19.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:37:19.286+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:19.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:37:19.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-19T23:37:49.654+0000] {processor.py:157} INFO - Started process (PID=75472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:49.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:37:49.661+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:49.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:49.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:37:49.717+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:49.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:37:49.732+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:37:49.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:37:49.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-19T23:38:20.011+0000] {processor.py:157} INFO - Started process (PID=75482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:20.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:38:20.020+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:20.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:20.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:20.099+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:20.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:38:20.116+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:20.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:38:20.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-19T23:38:50.300+0000] {processor.py:157} INFO - Started process (PID=75491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:50.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:38:50.320+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:50.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:50.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:38:50.365+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:50.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:38:50.377+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:38:50.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:38:50.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-19T23:39:20.657+0000] {processor.py:157} INFO - Started process (PID=75502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:20.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:39:20.670+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:20.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:20.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:20.753+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:20.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:39:20.772+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:20.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:39:20.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-19T23:39:51.045+0000] {processor.py:157} INFO - Started process (PID=75512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:51.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:39:51.052+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:51.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:51.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:39:51.120+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:51.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:39:51.135+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:39:51.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:39:51.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T23:40:21.575+0000] {processor.py:157} INFO - Started process (PID=75522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:21.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:40:21.582+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:21.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:21.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:21.627+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:21.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:40:21.645+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:21.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:40:21.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-19T23:40:51.980+0000] {processor.py:157} INFO - Started process (PID=75532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:51.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:40:51.992+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:51.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:52.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:40:52.045+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:52.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:40:52.077+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:40:52.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:40:52.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T23:41:22.377+0000] {processor.py:157} INFO - Started process (PID=75542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:22.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:41:22.384+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:22.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:22.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:22.428+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:22.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:41:22.442+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:22.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:41:22.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-19T23:41:53.256+0000] {processor.py:157} INFO - Started process (PID=75551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:53.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:41:53.267+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:53.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:53.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:41:53.339+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:53.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:41:53.363+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:41:53.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:41:53.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-19T23:42:23.571+0000] {processor.py:157} INFO - Started process (PID=75562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:23.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:42:23.594+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:23.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:23.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:24.238+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:24.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:42:24.367+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:24.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:42:24.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.870 seconds
[2024-08-19T23:42:54.828+0000] {processor.py:157} INFO - Started process (PID=75570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:54.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:42:54.837+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:54.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:54.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:42:54.892+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:54.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:42:54.907+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:42:54.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:42:54.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T23:43:25.176+0000] {processor.py:157} INFO - Started process (PID=75582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:25.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:43:25.183+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:25.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:25.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:25.232+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:25.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:43:25.253+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:25.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:43:25.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-19T23:43:55.518+0000] {processor.py:157} INFO - Started process (PID=75592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:55.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:43:55.524+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:55.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:55.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:43:55.576+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:55.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:43:55.593+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:43:55.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:43:55.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T23:44:25.765+0000] {processor.py:157} INFO - Started process (PID=75602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:25.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:44:25.768+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:25.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:25.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:25.799+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:25.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:44:25.809+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:25.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:44:25.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-19T23:44:56.134+0000] {processor.py:157} INFO - Started process (PID=75612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:56.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:44:56.138+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:56.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:56.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:44:56.180+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:56.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:44:56.193+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:44:56.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:44:56.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-19T23:45:26.594+0000] {processor.py:157} INFO - Started process (PID=75622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:26.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:45:26.602+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:26.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:26.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:26.700+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:26.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:45:26.727+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:26.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:45:26.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-19T23:45:56.885+0000] {processor.py:157} INFO - Started process (PID=75632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:56.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:45:56.893+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:56.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:56.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:45:56.954+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:56.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:45:56.969+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:45:56.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:45:56.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-19T23:46:27.672+0000] {processor.py:157} INFO - Started process (PID=75642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:27.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:46:27.677+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:27.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:27.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:27.739+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:27.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:46:27.763+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:27.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:46:27.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-19T23:46:57.922+0000] {processor.py:157} INFO - Started process (PID=75652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:57.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:46:57.941+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:57.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:57.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:46:58.014+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:58.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:46:58.034+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:46:58.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:46:58.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-19T23:47:28.340+0000] {processor.py:157} INFO - Started process (PID=75662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:28.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:47:28.356+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:28.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:28.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:28.435+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:28.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:47:28.470+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:28.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:47:28.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-19T23:47:58.698+0000] {processor.py:157} INFO - Started process (PID=75672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:58.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:47:58.707+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:58.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:58.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:47:58.770+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:58.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:47:58.786+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:47:58.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:47:58.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-19T23:48:29.109+0000] {processor.py:157} INFO - Started process (PID=75682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:29.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:48:29.115+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:29.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:29.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:29.204+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:29.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:48:29.221+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:29.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:48:29.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-19T23:48:59.475+0000] {processor.py:157} INFO - Started process (PID=75691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:59.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:48:59.483+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:59.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:59.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:48:59.522+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:59.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:48:59.535+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:48:59.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:48:59.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-19T23:49:30.245+0000] {processor.py:157} INFO - Started process (PID=75702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:49:30.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:49:30.255+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:49:30.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:49:30.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:49:30.310+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:49:30.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:49:30.326+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:49:30.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:49:30.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-19T23:50:00.954+0000] {processor.py:157} INFO - Started process (PID=75712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:00.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:50:00.959+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:00.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:00.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:01.019+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:01.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:50:01.036+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:01.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:50:01.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-19T23:50:31.295+0000] {processor.py:157} INFO - Started process (PID=75722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:31.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:50:31.312+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:31.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:31.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:50:31.424+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:31.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:50:31.452+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:50:31.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:50:31.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-08-19T23:51:01.621+0000] {processor.py:157} INFO - Started process (PID=75732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:01.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:51:01.635+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:01.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:01.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:01.703+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:01.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:51:01.725+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:01.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:51:01.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-19T23:51:32.236+0000] {processor.py:157} INFO - Started process (PID=75742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:32.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:51:32.244+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:32.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:32.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:51:32.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:32.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:51:32.324+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:51:32.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:51:32.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-19T23:52:02.524+0000] {processor.py:157} INFO - Started process (PID=75752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:02.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:52:02.544+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:02.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:02.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:02.606+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:02.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:52:02.622+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:02.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:52:02.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-19T23:52:32.970+0000] {processor.py:157} INFO - Started process (PID=75760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:32.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:52:32.977+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:32.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:33.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:52:33.054+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:33.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:52:33.069+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:52:33.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:52:33.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T23:53:03.380+0000] {processor.py:157} INFO - Started process (PID=75772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:03.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:53:03.396+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:03.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:03.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:03.465+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:03.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:53:03.485+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:03.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:53:03.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-19T23:53:33.875+0000] {processor.py:157} INFO - Started process (PID=75782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:33.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:53:33.888+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:33.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:33.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:53:33.943+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:33.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:53:33.956+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:53:33.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:53:33.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-19T23:54:04.206+0000] {processor.py:157} INFO - Started process (PID=75791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:04.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:54:04.215+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:04.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:04.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:04.292+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:04.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:54:04.307+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:04.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:54:04.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T23:54:34.560+0000] {processor.py:157} INFO - Started process (PID=75802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:34.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:54:34.571+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:34.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:34.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:54:34.642+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:34.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:54:34.659+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:54:34.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:54:34.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-19T23:55:04.876+0000] {processor.py:157} INFO - Started process (PID=75812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:04.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:55:04.881+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:04.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:04.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:04.942+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:04.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:55:04.958+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:04.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:55:04.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T23:55:35.201+0000] {processor.py:157} INFO - Started process (PID=75822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:35.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:55:35.207+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:35.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:35.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:55:35.262+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:35.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:55:35.280+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:55:35.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:55:35.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-19T23:56:05.506+0000] {processor.py:157} INFO - Started process (PID=75832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:05.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:56:05.512+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:05.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:05.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:05.553+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:05.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:56:05.568+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:05.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:56:05.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-19T23:56:35.814+0000] {processor.py:157} INFO - Started process (PID=75842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:35.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:56:35.826+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:35.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:35.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:56:35.870+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:35.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:56:35.884+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:56:35.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:56:35.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-19T23:57:06.051+0000] {processor.py:157} INFO - Started process (PID=75852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:06.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:57:06.053+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:06.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:06.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:06.079+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:06.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:57:06.088+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:06.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:57:06.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-19T23:57:36.361+0000] {processor.py:157} INFO - Started process (PID=75862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:36.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:57:36.367+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:36.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:36.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:57:36.404+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:36.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:57:36.416+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:57:36.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:57:36.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-19T23:58:06.626+0000] {processor.py:157} INFO - Started process (PID=75872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:06.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:58:06.629+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:06.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:06.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:06.655+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:06.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:58:06.665+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:06.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:58:06.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-19T23:58:36.975+0000] {processor.py:157} INFO - Started process (PID=75882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:36.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:58:36.978+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:36.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:36.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:58:37.004+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:37.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:58:37.015+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:58:37.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:58:37.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-19T23:59:07.253+0000] {processor.py:157} INFO - Started process (PID=75892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:07.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:59:07.259+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:07.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:07.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:07.290+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:07.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:59:07.299+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:07.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:59:07.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-19T23:59:37.547+0000] {processor.py:157} INFO - Started process (PID=75902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:37.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-19T23:59:37.550+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:37.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:37.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-19T23:59:37.588+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:37.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-19T23:59:37.612+0000] {logging_mixin.py:151} INFO - [2024-08-19T23:59:37.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-18T01:00:00+00:00, run_after=2024-08-19T01:00:00+00:00
[2024-08-19T23:59:37.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
