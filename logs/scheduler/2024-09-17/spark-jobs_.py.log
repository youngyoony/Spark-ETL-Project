[2024-09-17T00:00:24.278+0000] {processor.py:157} INFO - Started process (PID=45813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:24.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:00:24.284+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:24.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:24.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:24.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:24.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:00:24.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:24.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:00:24.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T00:00:54.569+0000] {processor.py:157} INFO - Started process (PID=45823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:54.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:00:54.572+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:54.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:54.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:00:54.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:54.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:00:54.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:00:54.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:00:54.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T00:01:25.086+0000] {processor.py:157} INFO - Started process (PID=45832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:25.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:01:25.094+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:25.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:25.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:25.166+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:25.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:01:25.183+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:25.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:01:25.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T00:01:55.364+0000] {processor.py:157} INFO - Started process (PID=45843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:55.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:01:55.366+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:55.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:55.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:01:55.393+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:55.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:01:55.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:01:55.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:01:55.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-17T00:02:25.717+0000] {processor.py:157} INFO - Started process (PID=45852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:25.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:02:25.738+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:25.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:25.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:25.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:25.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:02:25.859+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:25.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:02:25.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-17T00:02:56.053+0000] {processor.py:157} INFO - Started process (PID=45863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:56.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:02:56.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:56.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:56.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:02:56.101+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:56.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:02:56.116+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:02:56.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:02:56.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T00:03:26.493+0000] {processor.py:157} INFO - Started process (PID=45873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:26.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:03:26.500+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:26.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:26.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:26.572+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:26.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:03:26.590+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:26.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:03:26.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T00:03:56.869+0000] {processor.py:157} INFO - Started process (PID=45883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:56.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:03:56.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:56.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:56.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:03:56.917+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:56.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:03:56.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:03:56.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:03:56.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T00:04:27.331+0000] {processor.py:157} INFO - Started process (PID=45893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:27.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:04:27.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:27.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:27.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:27.394+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:27.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:04:27.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:27.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:04:27.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T00:04:57.679+0000] {processor.py:157} INFO - Started process (PID=45903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:57.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:04:57.687+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:57.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:57.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:04:57.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:57.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:04:57.717+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:04:57.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:04:57.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-17T00:05:28.161+0000] {processor.py:157} INFO - Started process (PID=45911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:28.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:05:28.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:28.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:28.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:28.237+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:28.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:05:28.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:28.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:05:28.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T00:05:58.572+0000] {processor.py:157} INFO - Started process (PID=45923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:58.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:05:58.575+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:58.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:58.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:05:58.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:58.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:05:58.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:05:58.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:05:58.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-17T00:06:29.052+0000] {processor.py:157} INFO - Started process (PID=45932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:29.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:06:29.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:29.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:29.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:29.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:29.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:06:29.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:29.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:06:29.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T00:06:59.352+0000] {processor.py:157} INFO - Started process (PID=45943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:59.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:06:59.357+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:59.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:59.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:06:59.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:59.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:06:59.397+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:06:59.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:06:59.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T00:07:29.782+0000] {processor.py:157} INFO - Started process (PID=45953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:07:29.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:07:29.800+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:07:29.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:07:29.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:07:29.851+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:07:29.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:07:29.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:07:29.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:07:29.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T00:08:00.306+0000] {processor.py:157} INFO - Started process (PID=45963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:00.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:08:00.308+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:00.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:00.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:00.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:00.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:08:00.345+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:00.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:08:00.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-17T00:08:30.764+0000] {processor.py:157} INFO - Started process (PID=45973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:30.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:08:30.783+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:30.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:30.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:08:30.855+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:30.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:08:30.872+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:08:30.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:08:30.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T00:09:01.070+0000] {processor.py:157} INFO - Started process (PID=45983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:01.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:09:01.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:01.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:01.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:01.129+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:01.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:09:01.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:01.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:09:01.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-17T00:09:31.372+0000] {processor.py:157} INFO - Started process (PID=45993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:31.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:09:31.376+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:31.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:31.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:09:31.421+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:31.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:09:31.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:09:31.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:09:31.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T00:25:32.930+0000] {processor.py:157} INFO - Started process (PID=46005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:25:32.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:25:32.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:25:32.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:25:33.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:25:33.107+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:25:33.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:25:33.125+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:25:33.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:25:33.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-09-17T00:26:03.300+0000] {processor.py:157} INFO - Started process (PID=46015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:03.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:26:03.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:03.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:03.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:03.397+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:03.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:26:03.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:03.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:26:03.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T00:26:33.758+0000] {processor.py:157} INFO - Started process (PID=46025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:33.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:26:33.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:33.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:33.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:26:33.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:33.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:26:33.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:26:33.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:26:33.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T00:43:42.782+0000] {processor.py:157} INFO - Started process (PID=46036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:43:42.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:43:42.808+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:43:42.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:43:42.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:43:42.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:43:42.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:43:43.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:43:43.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:43:43.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.291 seconds
[2024-09-17T00:44:13.313+0000] {processor.py:157} INFO - Started process (PID=46721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:13.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:44:13.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:13.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:13.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:13.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:13.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:44:13.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:13.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:44:13.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T00:44:43.673+0000] {processor.py:157} INFO - Started process (PID=46731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:43.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:44:43.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:43.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:43.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:44:43.761+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:43.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:44:43.783+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:44:43.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:44:43.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T00:45:14.023+0000] {processor.py:157} INFO - Started process (PID=46741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:45:14.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T00:45:14.029+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:45:14.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:45:14.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T00:45:14.097+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:45:14.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T00:45:14.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T00:45:14.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-15T01:00:00+00:00, run_after=2024-09-16T01:00:00+00:00
[2024-09-17T00:45:14.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T01:01:10.774+0000] {processor.py:157} INFO - Started process (PID=46751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:10.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:01:10.780+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:10.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:10.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:10.834+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:10.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:01:10.853+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:10.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:01:10.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T01:01:41.146+0000] {processor.py:157} INFO - Started process (PID=46761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:41.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:01:41.152+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:41.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:41.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:01:41.228+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:41.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:01:41.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:01:41.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:01:41.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T01:02:11.672+0000] {processor.py:157} INFO - Started process (PID=46771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:11.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:02:11.682+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:11.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:11.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:11.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:11.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:02:11.774+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:11.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:02:11.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T01:02:42.052+0000] {processor.py:157} INFO - Started process (PID=46781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:42.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:02:42.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:42.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:42.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:02:42.129+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:42.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:02:42.155+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:02:42.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:02:42.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T01:03:12.430+0000] {processor.py:157} INFO - Started process (PID=46791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:03:12.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:03:12.436+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:03:12.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:03:12.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:03:12.502+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:03:12.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:03:12.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:03:12.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:03:12.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T01:20:51.860+0000] {processor.py:157} INFO - Started process (PID=46801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:20:51.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:20:51.883+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:20:51.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:20:51.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:20:52.077+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:20:52.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:20:52.129+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:20:52.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:20:52.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.319 seconds
[2024-09-17T01:21:22.528+0000] {processor.py:157} INFO - Started process (PID=46811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:22.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:21:22.538+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:22.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:22.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:22.618+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:22.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:21:22.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:22.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:21:22.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T01:21:52.896+0000] {processor.py:157} INFO - Started process (PID=46820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:52.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:21:52.902+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:52.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:52.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:21:52.964+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:52.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:21:52.988+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:21:52.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:21:53.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T01:22:23.253+0000] {processor.py:157} INFO - Started process (PID=46831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:23.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:22:23.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:23.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:23.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:23.331+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:23.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:22:23.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:23.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:22:23.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T01:22:53.630+0000] {processor.py:157} INFO - Started process (PID=46841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:53.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:22:53.636+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:53.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:53.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:22:53.686+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:53.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:22:53.703+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:22:53.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:22:53.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-17T01:23:23.987+0000] {processor.py:157} INFO - Started process (PID=46851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:23:23.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:23:23.989+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:23:23.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:23:24.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:23:24.020+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:23:24.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:23:24.031+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:23:24.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:23:24.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T01:30:09.891+0000] {processor.py:157} INFO - Started process (PID=46861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:09.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:30:09.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:09.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:09.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:09.981+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:09.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:30:10.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:10.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:30:10.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T01:30:40.406+0000] {processor.py:157} INFO - Started process (PID=46872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:40.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:30:40.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:40.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:40.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:30:40.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:40.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:30:40.499+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:30:40.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:30:40.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T01:31:10.882+0000] {processor.py:157} INFO - Started process (PID=46883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:10.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:31:10.890+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:10.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:10.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:10.936+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:10.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:31:10.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:10.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:31:10.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T01:31:41.318+0000] {processor.py:157} INFO - Started process (PID=46893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:41.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:31:41.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:41.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:41.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:31:41.350+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:41.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:31:41.379+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:31:41.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:31:41.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-17T01:32:11.771+0000] {processor.py:157} INFO - Started process (PID=46903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:11.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:32:11.789+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:11.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:11.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:11.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:11.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:32:11.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:11.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:32:11.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T01:32:42.055+0000] {processor.py:157} INFO - Started process (PID=46913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:42.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:32:42.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:42.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:42.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:32:42.092+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:42.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:32:42.102+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:32:42.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:32:42.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T01:33:12.481+0000] {processor.py:157} INFO - Started process (PID=46922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:12.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:33:12.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:12.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:12.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:12.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:12.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:33:12.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:12.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:33:12.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T01:33:42.870+0000] {processor.py:157} INFO - Started process (PID=46932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:42.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:33:42.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:42.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:42.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:33:42.952+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:42.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:33:42.974+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:33:42.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:33:42.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T01:34:13.210+0000] {processor.py:157} INFO - Started process (PID=46942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:13.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:34:13.218+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:13.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:13.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:13.276+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:13.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:34:13.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:13.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:34:13.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T01:34:43.717+0000] {processor.py:157} INFO - Started process (PID=46953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:43.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:34:43.723+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:43.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:43.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:34:43.775+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:43.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:34:43.793+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:34:43.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:34:43.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T01:35:14.591+0000] {processor.py:157} INFO - Started process (PID=46963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:14.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:35:14.600+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:14.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:14.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:14.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:14.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:35:14.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:14.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:35:14.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T01:35:44.972+0000] {processor.py:157} INFO - Started process (PID=46973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:44.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:35:44.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:44.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:44.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:35:45.002+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:45.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:35:45.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:35:45.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:35:45.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T01:36:15.270+0000] {processor.py:157} INFO - Started process (PID=46983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:15.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:36:15.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:15.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:15.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:15.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:15.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:36:15.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:15.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:36:15.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T01:36:45.672+0000] {processor.py:157} INFO - Started process (PID=46993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:45.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:36:45.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:45.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:45.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:36:45.728+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:45.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:36:45.747+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:36:45.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:36:45.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T01:37:16.102+0000] {processor.py:157} INFO - Started process (PID=47002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:16.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:37:16.113+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:16.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:16.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:16.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:16.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:37:16.189+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:16.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:37:16.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T01:37:46.563+0000] {processor.py:157} INFO - Started process (PID=47013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:46.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:37:46.569+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:46.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:46.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:37:46.632+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:46.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:37:46.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:37:46.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:37:46.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T01:38:16.943+0000] {processor.py:157} INFO - Started process (PID=47023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:16.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:38:16.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:16.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:16.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:16.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:16.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:38:16.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:16.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:38:16.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T01:38:47.383+0000] {processor.py:157} INFO - Started process (PID=47032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:47.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:38:47.388+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:47.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:47.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:38:47.450+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:47.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:38:47.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:38:47.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:38:47.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T01:39:17.811+0000] {processor.py:157} INFO - Started process (PID=47043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:17.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:39:17.814+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:17.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:17.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:17.847+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:17.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:39:17.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:17.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:39:17.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-17T01:39:48.207+0000] {processor.py:157} INFO - Started process (PID=47053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:48.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:39:48.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:48.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:48.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:39:48.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:48.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:39:48.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:39:48.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:39:48.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T01:40:18.935+0000] {processor.py:157} INFO - Started process (PID=47063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:18.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:40:18.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:18.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:18.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:19.002+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:19.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:40:19.017+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:19.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:40:19.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T01:40:49.219+0000] {processor.py:157} INFO - Started process (PID=47073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:49.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:40:49.222+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:49.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:49.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:40:49.267+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:49.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:40:49.289+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:40:49.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:40:49.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T01:41:19.686+0000] {processor.py:157} INFO - Started process (PID=47083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:19.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:41:19.692+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:19.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:19.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:19.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:19.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:41:19.771+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:19.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:41:19.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T01:41:50.014+0000] {processor.py:157} INFO - Started process (PID=47092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:50.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:41:50.028+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:50.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:50.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:41:50.097+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:50.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:41:50.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:41:50.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:41:50.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T01:42:21.107+0000] {processor.py:157} INFO - Started process (PID=47103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:21.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:42:21.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:21.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:21.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:21.181+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:21.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:42:21.198+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:21.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:42:21.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T01:42:51.450+0000] {processor.py:157} INFO - Started process (PID=47113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:51.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:42:51.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:51.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:51.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:42:51.533+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:51.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:42:51.548+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:42:51.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:42:51.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T01:43:21.952+0000] {processor.py:157} INFO - Started process (PID=47123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:21.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:43:21.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:21.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:22.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:22.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:22.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:43:22.087+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:22.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:43:22.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-17T01:43:52.484+0000] {processor.py:157} INFO - Started process (PID=47133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:52.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:43:52.495+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:52.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:52.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:43:52.557+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:52.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:43:52.585+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:43:52.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:43:52.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T01:44:22.849+0000] {processor.py:157} INFO - Started process (PID=47143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:22.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:44:22.868+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:22.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:22.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:22.938+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:22.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:44:22.954+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:22.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:44:22.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T01:44:53.188+0000] {processor.py:157} INFO - Started process (PID=47153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:53.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:44:53.195+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:53.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:53.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:44:53.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:53.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:44:53.286+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:44:53.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:44:53.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T01:45:23.820+0000] {processor.py:157} INFO - Started process (PID=47163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:23.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:45:23.830+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:23.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:23.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:23.899+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:23.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:45:23.923+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:23.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:45:23.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T01:45:54.214+0000] {processor.py:157} INFO - Started process (PID=47173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:54.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:45:54.221+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:54.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:54.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:45:54.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:54.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:45:54.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:45:54.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:45:54.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T01:46:24.795+0000] {processor.py:157} INFO - Started process (PID=47183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:24.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:46:24.814+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:24.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:24.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:24.918+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:24.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:46:24.947+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:24.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:46:24.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-17T01:46:55.218+0000] {processor.py:157} INFO - Started process (PID=47193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:55.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:46:55.230+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:55.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:55.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:46:55.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:55.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:46:55.359+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:46:55.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:46:55.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-17T01:47:25.794+0000] {processor.py:157} INFO - Started process (PID=47203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:25.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:47:25.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:25.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:25.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:25.908+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:25.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:47:25.931+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:25.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:47:25.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-17T01:47:56.236+0000] {processor.py:157} INFO - Started process (PID=47213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:56.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:47:56.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:56.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:56.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:47:56.304+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:56.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:47:56.328+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:47:56.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:47:56.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T01:48:26.694+0000] {processor.py:157} INFO - Started process (PID=47223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:26.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:48:26.712+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:26.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:26.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:26.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:26.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:48:26.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:26.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:48:26.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-09-17T01:48:57.196+0000] {processor.py:157} INFO - Started process (PID=47233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:57.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:48:57.204+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:57.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:57.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:48:57.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:57.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:48:57.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:48:57.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:48:57.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T01:49:27.580+0000] {processor.py:157} INFO - Started process (PID=47243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:27.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:49:27.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:27.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:27.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:27.652+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:27.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:49:27.673+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:27.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:49:27.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T01:49:57.950+0000] {processor.py:157} INFO - Started process (PID=47253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:57.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:49:57.958+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:57.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:57.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:49:58.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:58.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:49:58.056+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:49:58.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:49:58.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T01:50:28.396+0000] {processor.py:157} INFO - Started process (PID=47263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:28.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:50:28.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:28.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:28.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:28.480+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:28.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:50:28.509+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:28.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:50:28.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T01:50:58.773+0000] {processor.py:157} INFO - Started process (PID=47273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:58.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:50:58.777+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:58.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:58.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:50:58.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:58.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:50:58.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:50:58.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:50:58.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T01:51:29.272+0000] {processor.py:157} INFO - Started process (PID=47283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:29.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:51:29.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:29.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:29.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:29.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:29.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:51:29.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:29.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:51:29.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T01:51:59.623+0000] {processor.py:157} INFO - Started process (PID=47293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:59.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:51:59.629+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:59.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:59.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:51:59.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:59.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:51:59.717+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:51:59.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:51:59.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T01:52:30.056+0000] {processor.py:157} INFO - Started process (PID=47303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:52:30.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:52:30.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:52:30.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:52:30.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:52:30.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:52:30.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:52:30.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:52:30.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:52:30.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T01:53:00.537+0000] {processor.py:157} INFO - Started process (PID=47312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:00.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:53:00.550+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:00.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:00.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:00.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:00.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:53:00.727+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:00.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:53:00.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-09-17T01:53:30.850+0000] {processor.py:157} INFO - Started process (PID=47323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:30.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:53:30.857+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:30.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:30.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:53:30.917+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:30.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:53:30.934+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:53:30.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:53:30.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T01:54:01.169+0000] {processor.py:157} INFO - Started process (PID=47333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:01.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:54:01.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:01.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:01.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:01.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:01.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:54:01.226+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:01.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:54:01.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T01:54:31.568+0000] {processor.py:157} INFO - Started process (PID=47343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:31.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:54:31.575+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:31.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:31.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:54:31.633+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:31.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:54:31.661+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:54:31.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:54:31.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T01:55:01.900+0000] {processor.py:157} INFO - Started process (PID=47353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:01.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:55:01.908+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:01.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:01.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:01.971+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:01.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:55:01.996+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:01.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:55:02.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T01:55:32.303+0000] {processor.py:157} INFO - Started process (PID=47363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:32.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:55:32.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:32.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:32.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:55:32.412+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:32.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:55:32.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:55:32.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:55:32.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-17T01:56:02.646+0000] {processor.py:157} INFO - Started process (PID=47373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:02.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:56:02.676+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:02.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:02.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:02.794+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:02.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:56:02.816+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:02.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:56:02.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-17T01:56:33.137+0000] {processor.py:157} INFO - Started process (PID=47382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:33.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:56:33.145+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:33.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:33.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:56:33.215+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:33.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:56:33.232+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:56:33.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:56:33.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T01:57:03.582+0000] {processor.py:157} INFO - Started process (PID=47393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:03.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:57:03.593+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:03.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:03.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:03.669+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:03.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:57:03.709+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:03.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:57:03.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-17T01:57:33.942+0000] {processor.py:157} INFO - Started process (PID=47403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:33.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:57:33.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:33.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:34.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:57:34.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:34.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:57:34.105+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:57:34.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:57:34.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-17T01:58:04.501+0000] {processor.py:157} INFO - Started process (PID=47413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:04.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:58:04.511+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:04.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:04.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:04.571+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:04.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:58:04.588+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:04.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:58:04.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T01:58:34.895+0000] {processor.py:157} INFO - Started process (PID=47423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:34.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:58:34.900+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:34.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:34.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:58:34.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:34.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:58:34.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:58:34.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:58:34.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T01:59:05.304+0000] {processor.py:157} INFO - Started process (PID=47433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:05.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:59:05.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:05.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:05.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:05.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:05.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:59:05.362+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:05.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:59:05.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-17T01:59:35.604+0000] {processor.py:157} INFO - Started process (PID=47443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:35.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T01:59:35.607+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:35.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:35.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T01:59:35.634+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:35.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T01:59:35.645+0000] {logging_mixin.py:151} INFO - [2024-09-17T01:59:35.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T01:59:35.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T02:00:06.067+0000] {processor.py:157} INFO - Started process (PID=47451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:06.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:00:06.080+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:06.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:06.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:06.237+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:06.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:00:06.255+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:06.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:00:06.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-09-17T02:00:36.608+0000] {processor.py:157} INFO - Started process (PID=47463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:36.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:00:36.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:36.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:36.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:00:36.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:36.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:00:36.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:00:36.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:00:36.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T02:01:06.982+0000] {processor.py:157} INFO - Started process (PID=47473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:06.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:01:06.993+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:06.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:07.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:07.080+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:07.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:01:07.098+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:07.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:01:07.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T02:01:37.535+0000] {processor.py:157} INFO - Started process (PID=47483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:37.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:01:37.540+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:37.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:37.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:01:37.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:37.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:01:37.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:01:37.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:01:37.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T02:02:07.913+0000] {processor.py:157} INFO - Started process (PID=47493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:07.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:02:07.921+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:07.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:07.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:07.983+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:07.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:02:07.999+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:07.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:02:08.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T02:02:38.248+0000] {processor.py:157} INFO - Started process (PID=47503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:38.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:02:38.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:38.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:38.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:02:38.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:38.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:02:38.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:02:38.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:02:38.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T02:03:08.759+0000] {processor.py:157} INFO - Started process (PID=47513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:08.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:03:08.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:08.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:08.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:08.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:08.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:03:08.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:08.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:03:08.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T02:03:39.035+0000] {processor.py:157} INFO - Started process (PID=47523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:39.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:03:39.038+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:39.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:39.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:03:39.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:39.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:03:39.086+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:03:39.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:03:39.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T02:04:09.435+0000] {processor.py:157} INFO - Started process (PID=47533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:09.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:04:09.440+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:09.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:09.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:09.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:09.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:04:09.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:09.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:04:09.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T02:04:39.837+0000] {processor.py:157} INFO - Started process (PID=47543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:39.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:04:39.845+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:39.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:39.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:04:39.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:39.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:04:39.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:04:39.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:04:39.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-17T02:05:10.160+0000] {processor.py:157} INFO - Started process (PID=47552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:10.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:05:10.166+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:10.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:10.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:10.217+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:10.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:05:10.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:10.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:05:10.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T02:05:40.539+0000] {processor.py:157} INFO - Started process (PID=47563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:40.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:05:40.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:40.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:40.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:05:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:40.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:05:40.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:05:40.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:05:40.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T02:06:10.856+0000] {processor.py:157} INFO - Started process (PID=47573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:10.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:06:10.863+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:10.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:10.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:10.925+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:10.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:06:10.949+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:10.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:06:10.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T02:06:41.172+0000] {processor.py:157} INFO - Started process (PID=47583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:41.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:06:41.181+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:41.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:41.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:06:41.247+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:41.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:06:41.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:06:41.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:06:41.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T02:07:11.549+0000] {processor.py:157} INFO - Started process (PID=47593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:11.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:07:11.555+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:11.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:11.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:11.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:11.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:07:11.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:11.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:07:11.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T02:07:41.928+0000] {processor.py:157} INFO - Started process (PID=47603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:41.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:07:41.936+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:41.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:41.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:07:42.016+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:42.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:07:42.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:07:42.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:07:42.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T02:08:12.242+0000] {processor.py:157} INFO - Started process (PID=47613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:12.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:08:12.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:12.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:12.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:12.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:12.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:08:12.358+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:12.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:08:12.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T02:08:42.623+0000] {processor.py:157} INFO - Started process (PID=47621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:42.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:08:42.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:42.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:42.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:08:42.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:42.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:08:42.712+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:08:42.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:08:42.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T02:09:13.074+0000] {processor.py:157} INFO - Started process (PID=47633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:13.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:09:13.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:13.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:13.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:13.118+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:13.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:09:13.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:13.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:09:13.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-17T02:09:43.567+0000] {processor.py:157} INFO - Started process (PID=47643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:43.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:09:43.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:43.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:09:43.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:43.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:09:43.968+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:09:43.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:09:43.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.428 seconds
[2024-09-17T02:10:14.294+0000] {processor.py:157} INFO - Started process (PID=47653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:14.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:10:14.302+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:14.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:14.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:14.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:14.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:10:14.422+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:14.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:10:14.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T02:10:44.700+0000] {processor.py:157} INFO - Started process (PID=47663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:44.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:10:44.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:44.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:44.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:10:44.760+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:44.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:10:44.776+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:10:44.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:10:44.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T02:11:15.004+0000] {processor.py:157} INFO - Started process (PID=47673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:15.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:11:15.007+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:15.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:15.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:15.033+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:15.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:11:15.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:15.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:11:15.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T02:11:45.400+0000] {processor.py:157} INFO - Started process (PID=47682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:45.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:11:45.406+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:45.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:45.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:11:45.472+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:45.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:11:45.488+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:11:45.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:11:45.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T02:12:15.692+0000] {processor.py:157} INFO - Started process (PID=47691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:15.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:12:15.695+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:15.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:15.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:15.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:15.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:12:15.736+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:15.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:12:15.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-17T02:12:46.146+0000] {processor.py:157} INFO - Started process (PID=47701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:46.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:12:46.152+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:46.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:46.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:12:46.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:46.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:12:46.247+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:12:46.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:12:46.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T02:13:16.448+0000] {processor.py:157} INFO - Started process (PID=47712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:16.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:13:16.460+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:16.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:16.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:16.527+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:16.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:13:16.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:16.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:13:16.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T02:13:46.948+0000] {processor.py:157} INFO - Started process (PID=47723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:46.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:13:46.955+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:46.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:46.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:13:47.023+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:47.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:13:47.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:13:47.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:13:47.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T02:14:17.342+0000] {processor.py:157} INFO - Started process (PID=47733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:17.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:14:17.359+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:17.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:17.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:17.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:17.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:14:17.444+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:17.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:14:17.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T02:14:47.693+0000] {processor.py:157} INFO - Started process (PID=47743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:47.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:14:47.698+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:47.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:47.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:14:47.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:47.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:14:47.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:14:47.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:14:47.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T02:15:18.093+0000] {processor.py:157} INFO - Started process (PID=47753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:18.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:15:18.109+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:18.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:18.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:18.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:18.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:15:18.192+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:18.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:15:18.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T02:15:48.405+0000] {processor.py:157} INFO - Started process (PID=47763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:48.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:15:48.409+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:48.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:48.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:15:48.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:48.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:15:48.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:15:48.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:15:48.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T02:16:18.894+0000] {processor.py:157} INFO - Started process (PID=47773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:18.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:16:18.901+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:18.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:18.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:18.958+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:18.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:16:18.983+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:18.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:16:18.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T02:16:49.225+0000] {processor.py:157} INFO - Started process (PID=47781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:49.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:16:49.232+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:49.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:49.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:16:49.303+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:49.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:16:49.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:16:49.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:16:49.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T02:17:19.600+0000] {processor.py:157} INFO - Started process (PID=47793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:19.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:17:19.610+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:19.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:19.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:19.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:19.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:17:19.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:19.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:17:19.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T02:17:50.000+0000] {processor.py:157} INFO - Started process (PID=47803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:50.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:17:50.007+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:50.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:50.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:17:50.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:50.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:17:50.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:17:50.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:17:50.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T02:18:20.363+0000] {processor.py:157} INFO - Started process (PID=47813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:20.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:18:20.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:20.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:20.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:20.432+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:20.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:18:20.448+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:20.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:18:20.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T02:18:50.701+0000] {processor.py:157} INFO - Started process (PID=47823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:50.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:18:50.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:50.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:50.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:18:50.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:50.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:18:50.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:18:50.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:18:50.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T02:19:21.068+0000] {processor.py:157} INFO - Started process (PID=47833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:21.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:19:21.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:21.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:21.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:21.153+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:21.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:19:21.175+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:21.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:19:21.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T02:19:51.457+0000] {processor.py:157} INFO - Started process (PID=47842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:51.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:19:51.464+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:51.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:51.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:19:51.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:51.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:19:51.562+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:19:51.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:19:51.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T02:20:21.946+0000] {processor.py:157} INFO - Started process (PID=47853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:21.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:20:21.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:21.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:21.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:22.045+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:22.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:20:22.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:22.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:20:22.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T02:20:52.347+0000] {processor.py:157} INFO - Started process (PID=47863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:52.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:20:52.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:52.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:52.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:20:52.532+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:52.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:20:52.548+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:20:52.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:20:52.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.245 seconds
[2024-09-17T02:21:22.692+0000] {processor.py:157} INFO - Started process (PID=47873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:22.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:21:22.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:22.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:22.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:22.774+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:22.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:21:22.791+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:22.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:21:22.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T02:21:53.098+0000] {processor.py:157} INFO - Started process (PID=47883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:53.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:21:53.103+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:53.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:53.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:21:53.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:53.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:21:53.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:21:53.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:21:53.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T02:22:23.417+0000] {processor.py:157} INFO - Started process (PID=47893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:23.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:22:23.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:23.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:23.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:23.457+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:23.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:22:23.469+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:23.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:22:23.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-17T02:22:53.797+0000] {processor.py:157} INFO - Started process (PID=47903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:53.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:22:53.810+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:53.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:53.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:22:53.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:53.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:22:53.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:22:53.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:22:53.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T02:23:24.291+0000] {processor.py:157} INFO - Started process (PID=47912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:24.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:23:24.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:24.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:24.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:24.349+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:24.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:23:24.365+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:24.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:23:24.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T02:23:54.751+0000] {processor.py:157} INFO - Started process (PID=47920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:54.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:23:54.760+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:54.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:54.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:23:54.823+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:54.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:23:54.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:23:54.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:23:54.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T02:24:25.082+0000] {processor.py:157} INFO - Started process (PID=47930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:25.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:24:25.087+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:25.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:25.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:25.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:25.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:24:25.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:25.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:24:25.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T02:24:55.417+0000] {processor.py:157} INFO - Started process (PID=47940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:55.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:24:55.422+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:55.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:55.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:24:55.500+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:55.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:24:55.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:24:55.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:24:55.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T02:25:25.783+0000] {processor.py:157} INFO - Started process (PID=47950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:25.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:25:25.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:25.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:25.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:25.843+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:25.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:25:25.857+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:25.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:25:25.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T02:25:56.109+0000] {processor.py:157} INFO - Started process (PID=47960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:56.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:25:56.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:56.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:56.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:25:56.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:56.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:25:56.154+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:25:56.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:25:56.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T02:26:26.546+0000] {processor.py:157} INFO - Started process (PID=47970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:26.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:26:26.551+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:26.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:26.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:26.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:26.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:26:26.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:26.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:26:26.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.415 seconds
[2024-09-17T02:26:57.070+0000] {processor.py:157} INFO - Started process (PID=47980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:57.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:26:57.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:57.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:57.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:26:57.139+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:57.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:26:57.155+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:26:57.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:26:57.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T02:27:27.437+0000] {processor.py:157} INFO - Started process (PID=47990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:27.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:27:27.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:27.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:27.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:27.478+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:27.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:27:27.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:27.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:27:27.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T02:27:57.812+0000] {processor.py:157} INFO - Started process (PID=48000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:57.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:27:57.816+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:57.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:57.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:27:57.853+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:57.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:27:57.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:27:57.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:27:57.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-17T02:28:28.171+0000] {processor.py:157} INFO - Started process (PID=48010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:28.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:28:28.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:28.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:28.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:28.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:28.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:28:28.214+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:28.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:28:28.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T02:28:58.569+0000] {processor.py:157} INFO - Started process (PID=48020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:58.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:28:58.576+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:58.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:58.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:28:58.623+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:58.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:28:58.650+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:28:58.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:28:58.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T02:29:28.843+0000] {processor.py:157} INFO - Started process (PID=48030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:28.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:29:28.847+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:28.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:28.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:28.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:28.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:29:28.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:28.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:29:29.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-09-17T02:29:59.400+0000] {processor.py:157} INFO - Started process (PID=48040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:59.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:29:59.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:59.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:59.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:29:59.469+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:59.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:29:59.484+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:29:59.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:29:59.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T02:30:29.833+0000] {processor.py:157} INFO - Started process (PID=48050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:30:29.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:30:29.840+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:30:29.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:30:29.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:30:29.907+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:30:29.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:30:29.921+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:30:29.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:30:29.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T02:31:00.650+0000] {processor.py:157} INFO - Started process (PID=48060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:00.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:31:00.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:00.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:00.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:00.715+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:00.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:31:00.731+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:00.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:31:00.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T02:31:30.981+0000] {processor.py:157} INFO - Started process (PID=48070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:30.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:31:30.990+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:30.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:31.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:31:31.057+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:31.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:31:31.073+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:31:31.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:31:31.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T02:32:01.226+0000] {processor.py:157} INFO - Started process (PID=48080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:01.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:32:01.229+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:01.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:01.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:01.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:01.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:32:01.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:01.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:32:01.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-17T02:32:31.619+0000] {processor.py:157} INFO - Started process (PID=48090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:31.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:32:31.627+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:31.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:31.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:32:31.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:31.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:32:31.693+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:32:31.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:32:31.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.325 seconds
[2024-09-17T02:33:02.118+0000] {processor.py:157} INFO - Started process (PID=48100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:02.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:33:02.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:02.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:02.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:02.223+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:02.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:33:02.239+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:02.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:33:02.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T02:33:32.438+0000] {processor.py:157} INFO - Started process (PID=48110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:32.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:33:32.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:32.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:32.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:33:32.507+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:32.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:33:32.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:33:32.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:33:32.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T02:34:02.782+0000] {processor.py:157} INFO - Started process (PID=48120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:02.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:34:02.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:02.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:02.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:02.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:02.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:34:02.877+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:02.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:34:02.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T02:34:33.095+0000] {processor.py:157} INFO - Started process (PID=48130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:33.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:34:33.100+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:33.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:33.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:34:33.140+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:33.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:34:33.153+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:34:33.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:34:33.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T02:35:03.432+0000] {processor.py:157} INFO - Started process (PID=48140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:03.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:35:03.438+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:03.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:03.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:03.475+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:03.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:35:03.488+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:03.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:35:03.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T02:35:33.832+0000] {processor.py:157} INFO - Started process (PID=48150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:33.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:35:33.835+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:33.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:33.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:35:33.864+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:33.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:35:33.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:35:33.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:35:34.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.283 seconds
[2024-09-17T02:36:04.226+0000] {processor.py:157} INFO - Started process (PID=48160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:04.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:36:04.230+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:04.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:04.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:04.263+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:04.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:36:04.275+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:04.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:36:04.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T02:36:34.620+0000] {processor.py:157} INFO - Started process (PID=48170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:34.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:36:34.625+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:34.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:36:34.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:34.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:36:34.694+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:36:34.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:36:34.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T02:37:04.976+0000] {processor.py:157} INFO - Started process (PID=48180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:04.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:37:04.983+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:04.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:05.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:05.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:05.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:37:05.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:05.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:37:05.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T02:37:35.317+0000] {processor.py:157} INFO - Started process (PID=48190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:35.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:37:35.322+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:35.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:35.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:37:35.384+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:35.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:37:35.399+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:37:35.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:37:35.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T02:38:05.645+0000] {processor.py:157} INFO - Started process (PID=48200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:05.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:38:05.650+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:05.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:05.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:05.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:05.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:38:05.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:05.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:38:05.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T02:38:36.067+0000] {processor.py:157} INFO - Started process (PID=48210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:36.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:38:36.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:36.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:36.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:38:36.132+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:36.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:38:36.145+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:38:36.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:38:36.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.273 seconds
[2024-09-17T02:39:06.544+0000] {processor.py:157} INFO - Started process (PID=48220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:06.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:39:06.550+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:06.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:06.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:06.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:06.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:39:06.634+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:06.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:39:06.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T02:39:36.842+0000] {processor.py:157} INFO - Started process (PID=48230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:36.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:39:36.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:36.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:36.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:39:36.876+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:36.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:39:36.885+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:39:36.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:39:36.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T02:40:07.190+0000] {processor.py:157} INFO - Started process (PID=48240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:07.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:40:07.194+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:07.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:07.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:07.259+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:07.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:40:07.274+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:07.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:40:07.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T02:40:37.550+0000] {processor.py:157} INFO - Started process (PID=48250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:37.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:40:37.558+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:37.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:37.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:40:37.625+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:37.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:40:37.641+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:40:37.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:40:37.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T02:41:07.868+0000] {processor.py:157} INFO - Started process (PID=48260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:07.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:41:07.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:07.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:07.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:07.936+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:07.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:41:07.960+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:07.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:41:07.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T02:41:38.189+0000] {processor.py:157} INFO - Started process (PID=48270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:38.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:41:38.207+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:38.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:38.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:41:38.266+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:38.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:41:38.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:41:38.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:41:38.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.297 seconds
[2024-09-17T02:42:08.674+0000] {processor.py:157} INFO - Started process (PID=48280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:08.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:42:08.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:08.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:08.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:08.765+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:08.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:42:08.795+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:08.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:42:08.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T02:42:39.001+0000] {processor.py:157} INFO - Started process (PID=48290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:39.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:42:39.007+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:39.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:39.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:42:39.048+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:39.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:42:39.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:42:39.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:42:39.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-17T02:43:09.296+0000] {processor.py:157} INFO - Started process (PID=48300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:09.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:43:09.302+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:09.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:09.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:09.337+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:09.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:43:09.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:09.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:43:09.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-17T02:43:39.602+0000] {processor.py:157} INFO - Started process (PID=48310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:39.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:43:39.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:39.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:39.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:43:39.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:39.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:43:39.692+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:43:39.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:43:39.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T02:44:09.925+0000] {processor.py:157} INFO - Started process (PID=48320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:09.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:44:09.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:09.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:09.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:09.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:09.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:44:09.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:09.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:44:09.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T02:44:40.283+0000] {processor.py:157} INFO - Started process (PID=48330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:44:40.291+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:40.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:40.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:44:40.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:40.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:44:40.568+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:44:40.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:44:40.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.297 seconds
[2024-09-17T02:45:10.737+0000] {processor.py:157} INFO - Started process (PID=48340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:10.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:45:10.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:10.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:10.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:10.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:10.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:45:10.796+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:10.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:45:10.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-17T02:45:41.076+0000] {processor.py:157} INFO - Started process (PID=48350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:41.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:45:41.092+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:41.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:41.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:45:41.130+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:41.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:45:41.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:45:41.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:45:41.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T02:46:11.401+0000] {processor.py:157} INFO - Started process (PID=48360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:11.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:46:11.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:11.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:11.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:11.464+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:11.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:46:11.478+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:11.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:46:11.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T02:46:41.738+0000] {processor.py:157} INFO - Started process (PID=48370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:41.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:46:41.744+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:41.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:41.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:46:41.808+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:41.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:46:41.823+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:46:41.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:46:41.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T02:47:12.101+0000] {processor.py:157} INFO - Started process (PID=48380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:12.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:47:12.106+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:12.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:12.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:12.161+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:12.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:47:12.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:12.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:47:12.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-17T02:47:42.427+0000] {processor.py:157} INFO - Started process (PID=48390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:42.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:47:42.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:42.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:42.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:47:42.470+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:42.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:47:42.705+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:47:42.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:47:42.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.291 seconds
[2024-09-17T02:48:12.914+0000] {processor.py:157} INFO - Started process (PID=48400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:12.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:48:12.918+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:12.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:12.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:12.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:12.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:48:12.996+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:12.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:48:13.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T02:48:43.244+0000] {processor.py:157} INFO - Started process (PID=48410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:43.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:48:43.248+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:43.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:43.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:48:43.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:43.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:48:43.308+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:48:43.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:48:43.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T02:49:13.685+0000] {processor.py:157} INFO - Started process (PID=48420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:13.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:49:13.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:13.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:13.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:13.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:13.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:49:13.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:13.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:49:13.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T02:49:44.046+0000] {processor.py:157} INFO - Started process (PID=48430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:44.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:49:44.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:44.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:44.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:49:44.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:44.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:49:44.127+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:49:44.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:49:44.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T02:50:14.407+0000] {processor.py:157} INFO - Started process (PID=48440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:14.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:50:14.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:14.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:14.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:14.475+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:14.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:50:14.488+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:14.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:50:14.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T02:50:44.836+0000] {processor.py:157} INFO - Started process (PID=48450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:44.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:50:44.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:44.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:44.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:50:44.909+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:44.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:50:45.109+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:50:45.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:50:45.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-09-17T02:51:15.236+0000] {processor.py:157} INFO - Started process (PID=48460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:15.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:51:15.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:15.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:15.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:15.315+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:15.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:51:15.328+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:15.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:51:15.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T02:51:45.669+0000] {processor.py:157} INFO - Started process (PID=48470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:45.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:51:45.676+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:45.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:45.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:51:45.716+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:45.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:51:45.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:51:45.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:51:45.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-17T02:52:15.967+0000] {processor.py:157} INFO - Started process (PID=48480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:15.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:52:15.971+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:15.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:15.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:16.006+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:16.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:52:16.016+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:16.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:52:16.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T02:52:46.380+0000] {processor.py:157} INFO - Started process (PID=48490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:46.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:52:46.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:46.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:46.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:52:46.459+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:46.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:52:46.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:52:46.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:52:46.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T02:53:16.725+0000] {processor.py:157} INFO - Started process (PID=48500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:16.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:53:16.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:16.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:16.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:16.759+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:16.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:53:16.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:16.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:53:17.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-09-17T02:53:47.227+0000] {processor.py:157} INFO - Started process (PID=48510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:47.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:53:47.233+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:47.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:47.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:53:47.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:47.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:53:47.497+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:53:47.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:53:47.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-09-17T02:54:17.667+0000] {processor.py:157} INFO - Started process (PID=48520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:17.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:54:17.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:17.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:17.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:17.745+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:17.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:54:17.759+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:17.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:54:17.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T02:54:47.955+0000] {processor.py:157} INFO - Started process (PID=48530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:47.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:54:47.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:47.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:47.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:54:47.990+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:47.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:54:48.002+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:54:48.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:54:48.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T02:55:18.340+0000] {processor.py:157} INFO - Started process (PID=48540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:18.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:55:18.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:18.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:18.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:18.412+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:18.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:55:18.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:18.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:55:18.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T02:55:48.703+0000] {processor.py:157} INFO - Started process (PID=48550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:48.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:55:48.706+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:48.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:48.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:55:48.736+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:48.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:55:48.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:55:48.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:55:48.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T02:56:19.053+0000] {processor.py:157} INFO - Started process (PID=48560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:19.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:56:19.058+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:19.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:19.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:19.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:19.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:56:19.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:19.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:56:19.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-17T02:56:49.395+0000] {processor.py:157} INFO - Started process (PID=48570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:49.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:56:49.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:49.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:49.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:56:49.484+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:49.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:56:49.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:56:49.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:56:49.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.334 seconds
[2024-09-17T02:57:19.870+0000] {processor.py:157} INFO - Started process (PID=48580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:19.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:57:19.877+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:19.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:19.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:19.931+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:19.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:57:19.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:19.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:57:19.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T02:57:50.266+0000] {processor.py:157} INFO - Started process (PID=48590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:50.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:57:50.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:50.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:50.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:57:50.308+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:50.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:57:50.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:57:50.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:57:50.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T02:58:20.629+0000] {processor.py:157} INFO - Started process (PID=48600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:20.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:58:20.633+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:20.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:20.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:20.660+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:20.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:58:20.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:20.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:58:20.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T02:58:51.004+0000] {processor.py:157} INFO - Started process (PID=48610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:51.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:58:51.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:51.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:51.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:58:51.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:51.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:58:51.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:58:51.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:58:51.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T02:59:21.274+0000] {processor.py:157} INFO - Started process (PID=48620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:21.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:59:21.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:21.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:21.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:21.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:21.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:59:21.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:21.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:59:21.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-09-17T02:59:51.610+0000] {processor.py:157} INFO - Started process (PID=48630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:51.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T02:59:51.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:51.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:51.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T02:59:51.659+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:51.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T02:59:51.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T02:59:51.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T02:59:51.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-17T03:00:22.258+0000] {processor.py:157} INFO - Started process (PID=48640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:22.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:00:22.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:22.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:22.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:22.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:22.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:00:22.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:22.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:00:22.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-17T03:00:52.604+0000] {processor.py:157} INFO - Started process (PID=48650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:52.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:00:52.610+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:52.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:52.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:00:52.665+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:52.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:00:52.679+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:00:52.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:00:52.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T03:01:22.968+0000] {processor.py:157} INFO - Started process (PID=48660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:22.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:01:22.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:22.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:23.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:23.034+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:23.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:01:23.073+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:23.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:01:23.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T03:01:53.277+0000] {processor.py:157} INFO - Started process (PID=48670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:53.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:01:53.281+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:53.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:53.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:01:53.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:53.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:01:53.330+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:01:53.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:01:53.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-17T03:02:23.690+0000] {processor.py:157} INFO - Started process (PID=48680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:23.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:02:23.697+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:23.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:23.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:23.747+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:23.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:02:23.762+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:23.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:02:23.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.315 seconds
[2024-09-17T03:02:54.141+0000] {processor.py:157} INFO - Started process (PID=48690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:54.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:02:54.172+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:54.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:54.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:02:54.233+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:54.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:02:54.436+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:02:54.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:02:54.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.310 seconds
[2024-09-17T03:03:24.639+0000] {processor.py:157} INFO - Started process (PID=48700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:24.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:03:24.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:24.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:24.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:24.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:24.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:03:24.717+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:24.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:03:24.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T03:03:54.959+0000] {processor.py:157} INFO - Started process (PID=48710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:54.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:03:54.968+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:54.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:54.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:03:55.033+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:55.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:03:55.056+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:03:55.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:03:55.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T03:04:25.349+0000] {processor.py:157} INFO - Started process (PID=48720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:25.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:04:25.366+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:25.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:25.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:25.439+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:25.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:04:25.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:25.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:04:25.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T03:04:55.678+0000] {processor.py:157} INFO - Started process (PID=48730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:55.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:04:55.683+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:55.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:55.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:04:55.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:55.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:04:55.753+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:04:55.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:04:55.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T03:05:26.101+0000] {processor.py:157} INFO - Started process (PID=48740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:26.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:05:26.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:26.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:26.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:26.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:26.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:05:26.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:26.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:05:26.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.347 seconds
[2024-09-17T03:05:56.642+0000] {processor.py:157} INFO - Started process (PID=48750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:56.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:05:56.647+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:56.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:56.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:05:56.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:56.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:05:56.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:05:56.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:05:56.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-17T03:06:27.112+0000] {processor.py:157} INFO - Started process (PID=48760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:27.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:06:27.122+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:27.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:27.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:27.243+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:27.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:06:27.262+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:27.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:06:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-17T03:06:57.466+0000] {processor.py:157} INFO - Started process (PID=48770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:57.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:06:57.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:57.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:57.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:06:57.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:57.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:06:57.601+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:06:57.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:06:57.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-17T03:07:27.821+0000] {processor.py:157} INFO - Started process (PID=48780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:27.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:07:27.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:27.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:27.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:27.895+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:27.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:07:27.910+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:27.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:07:27.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T03:07:58.178+0000] {processor.py:157} INFO - Started process (PID=48790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:58.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:07:58.184+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:58.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:58.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:07:58.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:58.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:07:58.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:07:58.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:07:58.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T03:08:28.594+0000] {processor.py:157} INFO - Started process (PID=48800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:28.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:08:28.601+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:28.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:28.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:28.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:28.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:08:28.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:28.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:08:28.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.260 seconds
[2024-09-17T03:08:59.274+0000] {processor.py:157} INFO - Started process (PID=48810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:59.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:08:59.286+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:59.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:08:59.377+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:59.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:08:59.821+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:08:59.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:08:59.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.566 seconds
[2024-09-17T03:09:30.279+0000] {processor.py:157} INFO - Started process (PID=48822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:09:30.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:09:30.286+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:09:30.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:09:30.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:09:30.382+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:09:30.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:09:30.401+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:09:30.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:09:30.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T03:10:00.603+0000] {processor.py:157} INFO - Started process (PID=48833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:00.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:10:00.623+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:00.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:00.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:00.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:00.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:10:00.705+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:00.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:10:00.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T03:10:31.088+0000] {processor.py:157} INFO - Started process (PID=48842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:31.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:10:31.102+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:31.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:31.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:10:31.188+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:31.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:10:31.207+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:10:31.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:10:31.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T03:11:01.490+0000] {processor.py:157} INFO - Started process (PID=48853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:01.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:11:01.500+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:01.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:01.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:01.569+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:01.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:11:01.599+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:01.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:11:02.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.559 seconds
[2024-09-17T03:11:32.415+0000] {processor.py:157} INFO - Started process (PID=48863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:32.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:11:32.424+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:32.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:32.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:11:32.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:32.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:11:32.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:11:32.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:11:32.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-09-17T03:12:03.285+0000] {processor.py:157} INFO - Started process (PID=48873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:03.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:12:03.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:03.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:03.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:03.356+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:03.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:12:03.566+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:03.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:12:03.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-17T03:12:33.908+0000] {processor.py:157} INFO - Started process (PID=48883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:33.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:12:33.922+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:33.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:33.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:12:33.991+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:33.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:12:34.005+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:12:34.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:12:34.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T03:13:04.258+0000] {processor.py:157} INFO - Started process (PID=48893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:04.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:13:04.264+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:04.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:04.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:04.327+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:04.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:13:04.359+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:04.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:13:04.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T03:13:34.560+0000] {processor.py:157} INFO - Started process (PID=48903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:34.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:13:34.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:34.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:34.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:13:34.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:34.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:13:34.640+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:13:34.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:13:34.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T03:14:05.023+0000] {processor.py:157} INFO - Started process (PID=48912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:05.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:14:05.034+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:05.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:05.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:05.100+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:05.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:14:05.118+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:05.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:14:05.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.308 seconds
[2024-09-17T03:14:35.708+0000] {processor.py:157} INFO - Started process (PID=48923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:35.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:14:35.715+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:35.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:35.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:14:35.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:35.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:14:36.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:14:36.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:14:36.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.327 seconds
[2024-09-17T03:15:06.391+0000] {processor.py:157} INFO - Started process (PID=48933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:06.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:15:06.407+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:06.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:06.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:06.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:06.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:15:06.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:06.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:15:06.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.320 seconds
[2024-09-17T03:15:36.974+0000] {processor.py:157} INFO - Started process (PID=48943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:36.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:15:36.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:36.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:15:37.039+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:37.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:15:37.068+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:15:37.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:15:37.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T03:16:07.314+0000] {processor.py:157} INFO - Started process (PID=48953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:07.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:16:07.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:07.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:07.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:07.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:07.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:16:07.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:07.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:16:07.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T03:16:37.683+0000] {processor.py:157} INFO - Started process (PID=48963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:37.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:16:37.698+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:37.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:37.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:16:37.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:37.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:16:37.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:16:37.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:16:37.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T03:17:07.993+0000] {processor.py:157} INFO - Started process (PID=48973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:07.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:17:08.001+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:08.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:08.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:08.088+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:08.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:17:08.109+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:08.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:17:08.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.322 seconds
[2024-09-17T03:17:38.659+0000] {processor.py:157} INFO - Started process (PID=48983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:38.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:17:38.666+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:38.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:38.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:17:38.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:38.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:17:38.957+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:17:38.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:17:38.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.313 seconds
[2024-09-17T03:18:09.352+0000] {processor.py:157} INFO - Started process (PID=48993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:09.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:18:09.358+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:09.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:09.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:09.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:09.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:18:09.645+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:09.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:18:09.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-17T03:18:39.975+0000] {processor.py:157} INFO - Started process (PID=49003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:39.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:18:39.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:39.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:40.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:18:40.058+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:40.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:18:40.079+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:18:40.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:18:40.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T03:19:10.506+0000] {processor.py:157} INFO - Started process (PID=49013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:10.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:19:10.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:10.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:10.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:10.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:10.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:19:10.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:10.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:19:10.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T03:19:40.838+0000] {processor.py:157} INFO - Started process (PID=49023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:40.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:19:40.845+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:40.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:40.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:19:40.913+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:40.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:19:40.943+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:19:40.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:19:40.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T03:20:11.300+0000] {processor.py:157} INFO - Started process (PID=49033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:11.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:20:11.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:11.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:11.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:11.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:11.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:20:11.409+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:11.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:20:11.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.351 seconds
[2024-09-17T03:20:41.975+0000] {processor.py:157} INFO - Started process (PID=49043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:41.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:20:41.983+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:41.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:42.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:20:42.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:42.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:20:42.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:20:42.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:20:42.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.330 seconds
[2024-09-17T03:21:12.640+0000] {processor.py:157} INFO - Started process (PID=49053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:12.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:21:12.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:12.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:12.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:12.728+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:12.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:21:12.922+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:12.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:21:12.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.314 seconds
[2024-09-17T03:21:43.207+0000] {processor.py:157} INFO - Started process (PID=49061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:43.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:21:43.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:43.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:43.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:21:43.288+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:43.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:21:43.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:21:43.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:21:43.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T03:22:13.522+0000] {processor.py:157} INFO - Started process (PID=49073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:13.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:22:13.528+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:13.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:13.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:13.585+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:13.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:22:13.600+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:13.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:22:13.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T03:22:43.955+0000] {processor.py:157} INFO - Started process (PID=49082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:43.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:22:43.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:43.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:43.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:22:44.028+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:44.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:22:44.045+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:22:44.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:22:44.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T03:23:14.202+0000] {processor.py:157} INFO - Started process (PID=49093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:14.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:23:14.205+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:14.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:14.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:14.237+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:14.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:23:14.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:14.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:23:14.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.281 seconds
[2024-09-17T03:23:44.755+0000] {processor.py:157} INFO - Started process (PID=49103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:44.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:23:44.779+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:44.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:44.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:23:44.833+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:44.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:23:45.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:23:45.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:23:45.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.328 seconds
[2024-09-17T03:24:15.438+0000] {processor.py:157} INFO - Started process (PID=49113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:15.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:24:15.445+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:15.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:15.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:15.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:15.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:24:15.742+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:15.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:24:15.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.335 seconds
[2024-09-17T03:24:46.068+0000] {processor.py:157} INFO - Started process (PID=49123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:46.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:24:46.074+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:46.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:46.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:24:46.146+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:46.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:24:46.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:24:46.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:24:46.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T03:25:16.368+0000] {processor.py:157} INFO - Started process (PID=49133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:16.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:25:16.379+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:16.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:16.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:16.468+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:16.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:25:16.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:16.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:25:16.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T03:25:46.875+0000] {processor.py:157} INFO - Started process (PID=49143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:46.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:25:46.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:46.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:46.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:25:46.927+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:46.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:25:46.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:25:46.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:25:46.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T03:26:17.295+0000] {processor.py:157} INFO - Started process (PID=49153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:17.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:26:17.299+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:17.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:17.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:17.328+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:17.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:26:17.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:17.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:26:17.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-09-17T03:26:47.961+0000] {processor.py:157} INFO - Started process (PID=49163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:47.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:26:47.982+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:47.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:48.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:26:48.039+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:48.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:26:48.251+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:26:48.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:26:48.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-09-17T03:27:18.552+0000] {processor.py:157} INFO - Started process (PID=49173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:18.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:27:18.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:18.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:18.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:18.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:18.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:27:18.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:18.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:27:18.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.337 seconds
[2024-09-17T03:27:49.276+0000] {processor.py:157} INFO - Started process (PID=49183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:49.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:27:49.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:49.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:49.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:27:49.359+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:49.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:27:49.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:27:49.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:27:49.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T03:28:19.741+0000] {processor.py:157} INFO - Started process (PID=49193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:19.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:28:19.745+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:19.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:19.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:19.796+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:19.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:28:19.810+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:19.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:28:19.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T03:28:50.157+0000] {processor.py:157} INFO - Started process (PID=49203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:50.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:28:50.159+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:50.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:50.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:28:50.197+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:50.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:28:50.231+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:28:50.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:28:50.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T03:29:20.606+0000] {processor.py:157} INFO - Started process (PID=49213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:20.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:29:20.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:20.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:20.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:20.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:20.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:29:20.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:20.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:29:20.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-17T03:29:51.258+0000] {processor.py:157} INFO - Started process (PID=49223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:51.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:29:51.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:51.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:51.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:29:51.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:51.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:29:51.569+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:29:51.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:29:51.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.324 seconds
[2024-09-17T03:30:21.902+0000] {processor.py:157} INFO - Started process (PID=49232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:21.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:30:21.918+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:21.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:21.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:22.197+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:22.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:30:22.206+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:22.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:30:22.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.327 seconds
[2024-09-17T03:30:52.506+0000] {processor.py:157} INFO - Started process (PID=49242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:52.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:30:52.512+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:52.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:52.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:30:52.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:52.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:30:52.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:30:52.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:30:52.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T03:31:22.790+0000] {processor.py:157} INFO - Started process (PID=49253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:22.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:31:22.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:22.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:22.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:22.870+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:22.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:31:22.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:22.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:31:22.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T03:31:53.207+0000] {processor.py:157} INFO - Started process (PID=49263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:53.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:31:53.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:53.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:53.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:31:53.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:53.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:31:53.257+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:31:53.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:31:53.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T03:32:23.667+0000] {processor.py:157} INFO - Started process (PID=49272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:23.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:32:23.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:23.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:23.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:23.737+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:23.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:32:23.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:23.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:32:23.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-17T03:32:54.329+0000] {processor.py:157} INFO - Started process (PID=49282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:54.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:32:54.337+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:54.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:54.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:32:54.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:54.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:32:54.730+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:32:54.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:32:54.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.425 seconds
[2024-09-17T03:33:25.077+0000] {processor.py:157} INFO - Started process (PID=49293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:25.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:33:25.089+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:25.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:25.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:25.355+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:25.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:33:25.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:25.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:33:25.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-09-17T03:33:55.670+0000] {processor.py:157} INFO - Started process (PID=49303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:55.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:33:55.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:55.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:55.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:33:55.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:55.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:33:55.781+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:33:55.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:33:55.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T03:34:26.193+0000] {processor.py:157} INFO - Started process (PID=49313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:26.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:34:26.215+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:26.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:26.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:26.268+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:26.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:34:26.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:26.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:34:26.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T03:34:56.607+0000] {processor.py:157} INFO - Started process (PID=49323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:56.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:34:56.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:56.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:56.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:34:56.652+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:56.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:34:56.666+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:34:56.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:34:56.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.273 seconds
[2024-09-17T03:35:27.280+0000] {processor.py:157} INFO - Started process (PID=49333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:27.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:35:27.285+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:27.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:27.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:27.326+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:27.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:35:27.565+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:27.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:35:27.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-09-17T03:35:57.823+0000] {processor.py:157} INFO - Started process (PID=49343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:57.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:35:57.829+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:57.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:57.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:35:57.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:57.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:35:58.108+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:35:58.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:35:58.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.299 seconds
[2024-09-17T03:36:28.443+0000] {processor.py:157} INFO - Started process (PID=49351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:28.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:36:28.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:28.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:28.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:28.734+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:28.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:36:28.742+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:28.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:36:28.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.315 seconds
[2024-09-17T03:36:59.101+0000] {processor.py:157} INFO - Started process (PID=49363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:59.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:36:59.108+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:59.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:59.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:36:59.163+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:59.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:36:59.179+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:36:59.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:36:59.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T03:37:29.572+0000] {processor.py:157} INFO - Started process (PID=49373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:37:29.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:37:29.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:37:29.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:37:29.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:37:29.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:37:29.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:37:29.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:37:29.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:37:29.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T03:38:00.040+0000] {processor.py:157} INFO - Started process (PID=49383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:00.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:38:00.049+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:00.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:00.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:00.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:00.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:38:00.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:00.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:38:00.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.300 seconds
[2024-09-17T03:38:30.666+0000] {processor.py:157} INFO - Started process (PID=49392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:30.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:38:30.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:30.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:30.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:38:30.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:30.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:38:30.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:38:30.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:38:30.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.316 seconds
[2024-09-17T03:39:01.300+0000] {processor.py:157} INFO - Started process (PID=49402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:01.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:39:01.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:01.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:01.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:01.383+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:01.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:39:01.598+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:01.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:39:01.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.334 seconds
[2024-09-17T03:39:31.849+0000] {processor.py:157} INFO - Started process (PID=49413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:31.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:39:31.857+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:31.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:31.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:39:31.911+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:31.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:39:31.932+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:39:31.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:39:31.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T03:40:02.301+0000] {processor.py:157} INFO - Started process (PID=49423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:02.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:40:02.305+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:02.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:02.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:02.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:02.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:40:02.382+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:02.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:40:02.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T03:40:32.736+0000] {processor.py:157} INFO - Started process (PID=49433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:32.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:40:32.739+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:32.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:32.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:40:32.773+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:32.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:40:32.813+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:40:32.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:40:32.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T03:41:03.001+0000] {processor.py:157} INFO - Started process (PID=49443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:03.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:41:03.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:03.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:03.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:03.072+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:03.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:41:03.098+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:03.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:41:03.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.296 seconds
[2024-09-17T03:41:33.691+0000] {processor.py:157} INFO - Started process (PID=49453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:33.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:41:33.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:33.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:33.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:41:33.761+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:33.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:41:33.992+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:41:33.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:41:34.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.315 seconds
[2024-09-17T03:42:04.319+0000] {processor.py:157} INFO - Started process (PID=49463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:04.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:42:04.324+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:04.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:04.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:04.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:04.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:42:04.604+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:04.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:42:04.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.299 seconds
[2024-09-17T03:42:34.926+0000] {processor.py:157} INFO - Started process (PID=49473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:34.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:42:34.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:34.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:34.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:42:35.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:35.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:42:35.026+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:42:35.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:42:35.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T03:43:05.274+0000] {processor.py:157} INFO - Started process (PID=49483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:05.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:43:05.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:05.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:05.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:05.339+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:05.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:43:05.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:05.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:43:05.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T03:43:35.656+0000] {processor.py:157} INFO - Started process (PID=49493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:35.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:43:35.662+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:35.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:35.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:43:35.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:35.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:43:35.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:43:35.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:43:35.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T03:44:06.044+0000] {processor.py:157} INFO - Started process (PID=49503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:06.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:44:06.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:06.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:06.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:06.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:06.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:44:06.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:06.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:44:06.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.306 seconds
[2024-09-17T03:44:36.703+0000] {processor.py:157} INFO - Started process (PID=49513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:36.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:44:36.712+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:36.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:36.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:44:36.778+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:36.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:44:36.990+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:44:36.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:44:36.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.300 seconds
[2024-09-17T03:45:07.393+0000] {processor.py:157} INFO - Started process (PID=49523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:07.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:45:07.399+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:07.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:07.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:07.663+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:07.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:45:07.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:07.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:45:07.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.296 seconds
[2024-09-17T03:45:38.030+0000] {processor.py:157} INFO - Started process (PID=49533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:38.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:45:38.037+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:38.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:38.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:45:38.106+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:38.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:45:38.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:45:38.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:45:38.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T03:46:08.322+0000] {processor.py:157} INFO - Started process (PID=49543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:08.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:46:08.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:08.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:08.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:08.393+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:08.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:46:08.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:08.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:46:08.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T03:46:38.740+0000] {processor.py:157} INFO - Started process (PID=49552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:38.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:46:38.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:38.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:38.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:46:38.822+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:38.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:46:38.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:46:38.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:46:38.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T03:47:09.088+0000] {processor.py:157} INFO - Started process (PID=49563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:09.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:47:09.103+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:09.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:09.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:09.171+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:09.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:47:09.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:09.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:47:09.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-09-17T03:47:39.729+0000] {processor.py:157} INFO - Started process (PID=49572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:39.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:47:39.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:39.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:39.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:47:39.813+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:39.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:47:40.023+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:47:40.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:47:40.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.330 seconds
[2024-09-17T03:48:10.327+0000] {processor.py:157} INFO - Started process (PID=49583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:10.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:48:10.334+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:10.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:10.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:10.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:10.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:48:10.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:10.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:48:10.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-17T03:48:40.956+0000] {processor.py:157} INFO - Started process (PID=49593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:40.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:48:40.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:40.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:41.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:48:41.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:41.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:48:41.088+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:48:41.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:48:41.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-17T03:49:11.762+0000] {processor.py:157} INFO - Started process (PID=49603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:11.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:49:11.787+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:11.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:11.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:11.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:11.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:49:11.871+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:11.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:49:11.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T03:49:42.207+0000] {processor.py:157} INFO - Started process (PID=49613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:42.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:49:42.221+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:42.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:42.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:49:42.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:42.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:49:42.327+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:49:42.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:49:42.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T03:50:12.646+0000] {processor.py:157} INFO - Started process (PID=49623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:12.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:50:12.658+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:12.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:12.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:12.731+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:12.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:50:12.971+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:12.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:50:12.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.344 seconds
[2024-09-17T03:50:43.327+0000] {processor.py:157} INFO - Started process (PID=49632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:43.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:50:43.332+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:43.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:43.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:50:43.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:43.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:50:43.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:50:43.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:50:43.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.377 seconds
[2024-09-17T03:51:14.029+0000] {processor.py:157} INFO - Started process (PID=49643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:14.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:51:14.037+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:14.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:14.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:14.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:14.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:51:14.301+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:14.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:51:14.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.286 seconds
[2024-09-17T03:51:44.612+0000] {processor.py:157} INFO - Started process (PID=49653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:44.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:51:44.618+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:44.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:44.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:51:44.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:44.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:51:44.694+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:51:44.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:51:44.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T03:52:14.937+0000] {processor.py:157} INFO - Started process (PID=49663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:14.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:52:14.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:14.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:14.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:15.016+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:15.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:52:15.034+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:15.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:52:15.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T03:52:45.320+0000] {processor.py:157} INFO - Started process (PID=49673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:45.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:52:45.325+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:45.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:45.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:52:45.389+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:45.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:52:45.418+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:52:45.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:52:45.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T03:53:15.644+0000] {processor.py:157} INFO - Started process (PID=49683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:15.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:53:15.649+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:15.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:15.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:15.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:15.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:53:15.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:15.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:53:15.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.259 seconds
[2024-09-17T03:53:45.998+0000] {processor.py:157} INFO - Started process (PID=49693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:46.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:53:46.004+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:46.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:46.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:53:46.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:46.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:53:46.252+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:53:46.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:53:46.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.270 seconds
[2024-09-17T03:54:16.441+0000] {processor.py:157} INFO - Started process (PID=49703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:16.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:54:16.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:16.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:16.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:16.720+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:16.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:54:16.728+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:16.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:54:16.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.300 seconds
[2024-09-17T03:54:47.103+0000] {processor.py:157} INFO - Started process (PID=49713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:47.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:54:47.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:47.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:47.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:54:47.172+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:47.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:54:47.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:54:47.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:54:47.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T03:55:17.402+0000] {processor.py:157} INFO - Started process (PID=49723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:17.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:55:17.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:17.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:17.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:17.449+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:17.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:55:17.463+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:17.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:55:17.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-17T03:55:47.737+0000] {processor.py:157} INFO - Started process (PID=49733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:47.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:55:47.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:47.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:47.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:55:47.815+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:47.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:55:47.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:55:47.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:55:48.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-09-17T03:56:18.073+0000] {processor.py:157} INFO - Started process (PID=49743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:18.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:56:18.080+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:18.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:18.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:18.122+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:18.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:56:18.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:18.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:56:18.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-17T03:56:48.636+0000] {processor.py:157} INFO - Started process (PID=49753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:48.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:56:48.641+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:48.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:48.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:56:48.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:48.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:56:48.892+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:56:48.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:56:48.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.267 seconds
[2024-09-17T03:57:19.263+0000] {processor.py:157} INFO - Started process (PID=49762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:19.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:57:19.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:19.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:19.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:19.447+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:19.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:57:19.459+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:19.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:57:19.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-09-17T03:57:49.867+0000] {processor.py:157} INFO - Started process (PID=49773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:49.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:57:49.896+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:49.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:49.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:57:49.950+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:49.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:57:49.967+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:57:49.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:57:49.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T03:58:20.345+0000] {processor.py:157} INFO - Started process (PID=49783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:20.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:58:20.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:20.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:20.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:20.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:20.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:58:20.421+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:20.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:58:20.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T03:58:50.764+0000] {processor.py:157} INFO - Started process (PID=49791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:50.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:58:50.771+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:50.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:50.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:58:50.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:50.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:58:50.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:58:50.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:58:51.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-17T03:59:21.453+0000] {processor.py:157} INFO - Started process (PID=49803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:21.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:59:21.469+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:21.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:21.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:21.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:21.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:59:21.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:21.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:59:21.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.313 seconds
[2024-09-17T03:59:51.810+0000] {processor.py:157} INFO - Started process (PID=49813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:51.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T03:59:51.815+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:51.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:51.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T03:59:51.857+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:51.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T03:59:51.948+0000] {logging_mixin.py:151} INFO - [2024-09-17T03:59:51.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T03:59:51.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-17T04:00:22.208+0000] {processor.py:157} INFO - Started process (PID=49823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:00:22.220+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:22.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:22.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:22.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:22.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:00:22.531+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:22.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:00:22.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.358 seconds
[2024-09-17T04:00:52.904+0000] {processor.py:157} INFO - Started process (PID=49833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:52.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:00:52.911+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:52.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:52.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:00:52.984+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:52.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:00:53.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:00:53.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:00:53.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T04:01:23.301+0000] {processor.py:157} INFO - Started process (PID=49843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:23.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:01:23.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:23.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:23.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:23.375+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:23.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:01:23.391+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:23.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:01:23.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T04:01:53.634+0000] {processor.py:157} INFO - Started process (PID=49853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:53.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:01:53.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:53.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:53.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:01:53.703+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:53.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:01:53.721+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:01:53.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:01:53.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.279 seconds
[2024-09-17T04:02:24.206+0000] {processor.py:157} INFO - Started process (PID=49863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:24.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:02:24.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:24.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:24.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:24.270+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:24.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:02:24.444+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:24.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:02:24.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.251 seconds
[2024-09-17T04:02:54.530+0000] {processor.py:157} INFO - Started process (PID=49873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:54.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:02:54.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:54.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:54.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:02:54.566+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:54.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:02:54.647+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:02:54.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:02:54.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T04:03:24.854+0000] {processor.py:157} INFO - Started process (PID=49883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:24.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:03:24.858+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:24.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:24.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:25.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:25.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:03:25.125+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:25.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:03:25.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.283 seconds
[2024-09-17T04:03:55.264+0000] {processor.py:157} INFO - Started process (PID=49893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:55.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:03:55.273+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:55.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:55.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:03:55.372+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:55.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:03:55.394+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:03:55.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:03:55.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-17T04:04:25.806+0000] {processor.py:157} INFO - Started process (PID=49903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:25.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:04:25.811+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:25.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:25.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:25.880+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:25.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:04:25.904+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:25.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:04:25.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T04:04:56.127+0000] {processor.py:157} INFO - Started process (PID=49913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:56.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:04:56.131+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:56.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:56.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:04:56.177+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:56.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:04:56.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:04:56.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:04:56.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-09-17T04:05:26.520+0000] {processor.py:157} INFO - Started process (PID=49923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:26.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:05:26.526+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:26.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:26.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:26.583+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:26.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:05:26.782+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:26.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:05:26.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-09-17T04:05:57.003+0000] {processor.py:157} INFO - Started process (PID=49933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:57.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:05:57.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:57.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:57.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:05:57.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:57.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:05:57.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:05:57.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:05:57.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-09-17T04:06:27.635+0000] {processor.py:157} INFO - Started process (PID=49943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:27.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:06:27.650+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:27.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:27.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:27.909+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:27.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:06:27.918+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:27.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:06:27.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-09-17T04:06:58.294+0000] {processor.py:157} INFO - Started process (PID=49952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:58.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:06:58.301+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:58.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:58.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:06:58.373+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:58.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:06:58.394+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:06:58.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:06:58.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T04:07:28.771+0000] {processor.py:157} INFO - Started process (PID=49963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:28.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:07:28.777+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:28.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:28.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:28.848+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:28.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:07:28.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:28.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:07:28.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T04:07:59.045+0000] {processor.py:157} INFO - Started process (PID=49973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:59.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:07:59.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:59.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:59.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:07:59.109+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:59.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:07:59.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:07:59.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:07:59.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.289 seconds
[2024-09-17T04:08:29.660+0000] {processor.py:157} INFO - Started process (PID=49983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:08:29.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:08:29.665+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:08:29.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:08:29.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:08:29.720+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:08:29.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:08:29.910+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:08:29.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:08:29.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.264 seconds
[2024-09-17T04:09:00.036+0000] {processor.py:157} INFO - Started process (PID=49992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:00.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:09:00.042+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:00.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:00.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:00.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:00.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:09:00.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:00.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:09:00.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.309 seconds
[2024-09-17T04:09:30.486+0000] {processor.py:157} INFO - Started process (PID=50003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:30.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:09:30.493+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:30.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:30.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:09:30.752+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:30.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:09:30.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:09:30.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:09:30.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.290 seconds
[2024-09-17T04:10:01.184+0000] {processor.py:157} INFO - Started process (PID=50012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:01.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:10:01.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:01.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:01.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:01.496+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:01.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:10:01.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:01.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:10:01.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.339 seconds
[2024-09-17T04:10:32.023+0000] {processor.py:157} INFO - Started process (PID=50023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:32.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:10:32.036+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:32.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:32.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:10:32.115+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:32.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:10:32.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:10:32.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:10:32.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T04:11:02.311+0000] {processor.py:157} INFO - Started process (PID=50032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:02.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:11:02.323+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:02.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:02.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:02.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:02.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:11:02.433+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:02.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:11:02.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T04:11:32.712+0000] {processor.py:157} INFO - Started process (PID=50043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:32.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:11:32.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:32.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:32.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:11:32.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:32.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:11:32.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:11:32.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:11:32.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T04:12:03.128+0000] {processor.py:157} INFO - Started process (PID=50053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:03.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:12:03.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:03.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:03.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:03.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:03.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:12:03.187+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:03.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:12:03.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-17T04:12:33.450+0000] {processor.py:157} INFO - Started process (PID=50063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:33.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:12:33.457+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:33.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:33.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:12:33.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:33.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:12:33.534+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:12:33.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:12:33.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T04:13:03.763+0000] {processor.py:157} INFO - Started process (PID=50073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:03.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:13:03.768+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:03.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:03.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:03.829+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:03.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:13:03.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:03.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:13:03.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T04:13:34.191+0000] {processor.py:157} INFO - Started process (PID=50083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:34.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:13:34.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:34.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:34.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:13:34.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:34.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:13:34.289+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:13:34.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:13:34.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T04:14:04.514+0000] {processor.py:157} INFO - Started process (PID=50093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:04.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:14:04.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:04.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:04.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:04.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:04.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:14:04.578+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:04.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:14:04.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T04:14:34.938+0000] {processor.py:157} INFO - Started process (PID=50103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:34.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:14:34.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:34.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:34.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:14:35.002+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:35.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:14:35.030+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:14:35.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:14:35.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T04:15:05.283+0000] {processor.py:157} INFO - Started process (PID=50112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:05.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:15:05.289+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:05.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:05.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:05.355+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:05.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:15:05.373+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:05.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:15:05.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T04:15:35.626+0000] {processor.py:157} INFO - Started process (PID=50123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:35.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:15:35.632+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:35.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:35.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:15:35.676+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:35.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:15:35.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:15:35.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:15:35.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T04:16:05.935+0000] {processor.py:157} INFO - Started process (PID=50133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:05.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:16:05.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:05.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:05.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:06.000+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:06.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:16:06.014+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:06.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:16:06.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T04:16:36.319+0000] {processor.py:157} INFO - Started process (PID=50142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:36.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:16:36.331+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:36.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:36.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:16:36.410+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:36.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:16:36.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:16:36.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:16:36.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T04:17:06.640+0000] {processor.py:157} INFO - Started process (PID=50153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:06.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:17:06.645+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:06.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:06.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:06.704+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:06.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:17:06.718+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:06.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:17:06.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T04:17:37.092+0000] {processor.py:157} INFO - Started process (PID=50161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:37.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:17:37.098+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:37.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:37.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:17:37.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:37.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:17:37.205+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:17:37.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:17:37.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T04:18:07.393+0000] {processor.py:157} INFO - Started process (PID=50173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:07.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:18:07.401+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:07.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:07.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:07.449+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:07.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:18:07.463+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:07.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:18:07.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T04:18:37.871+0000] {processor.py:157} INFO - Started process (PID=50183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:37.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:18:37.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:37.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:37.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:18:37.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:37.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:18:37.966+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:18:37.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:18:37.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T04:19:08.259+0000] {processor.py:157} INFO - Started process (PID=50192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:08.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:19:08.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:08.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:08.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:08.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:08.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:19:08.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:08.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:19:08.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T04:19:38.730+0000] {processor.py:157} INFO - Started process (PID=50203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:38.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:19:38.739+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:38.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:38.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:19:38.804+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:38.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:19:38.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:19:38.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:19:38.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T04:20:09.242+0000] {processor.py:157} INFO - Started process (PID=50213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:09.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:20:09.249+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:09.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:09.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:09.322+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:09.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:20:09.347+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:09.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:20:09.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T04:20:39.590+0000] {processor.py:157} INFO - Started process (PID=50223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:39.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:20:39.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:39.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:39.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:20:39.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:39.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:20:39.685+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:20:39.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:20:39.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T04:21:09.933+0000] {processor.py:157} INFO - Started process (PID=50233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:09.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:21:09.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:09.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:09.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:10.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:10.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:21:10.039+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:10.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:21:10.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T04:21:40.284+0000] {processor.py:157} INFO - Started process (PID=50243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:40.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:21:40.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:40.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:40.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:21:40.372+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:40.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:21:40.388+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:21:40.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:21:40.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T04:22:10.684+0000] {processor.py:157} INFO - Started process (PID=50253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:10.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:22:10.704+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:10.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:10.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:10.796+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:10.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:22:10.813+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:10.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:22:10.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-17T04:22:41.054+0000] {processor.py:157} INFO - Started process (PID=50262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:41.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:22:41.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:41.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:41.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:22:41.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:41.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:22:41.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:22:41.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:22:41.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T04:23:11.426+0000] {processor.py:157} INFO - Started process (PID=50273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:11.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:23:11.432+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:11.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:11.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:11.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:11.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:23:11.498+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:11.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:23:11.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T04:23:41.835+0000] {processor.py:157} INFO - Started process (PID=50283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:41.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:23:41.868+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:41.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:41.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:23:41.936+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:41.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:23:41.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:23:41.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:23:41.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T04:24:12.373+0000] {processor.py:157} INFO - Started process (PID=50293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:12.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:24:12.383+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:12.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:12.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:12.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:12.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:24:12.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:12.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:24:12.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T04:24:42.740+0000] {processor.py:157} INFO - Started process (PID=50303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:42.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:24:42.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:42.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:42.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:24:42.800+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:42.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:24:42.815+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:24:42.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:24:42.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T04:25:13.056+0000] {processor.py:157} INFO - Started process (PID=50313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:13.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:25:13.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:13.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:13.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:13.118+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:13.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:25:13.133+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:13.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:25:13.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T04:25:43.527+0000] {processor.py:157} INFO - Started process (PID=50323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:43.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:25:43.542+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:43.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:43.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:25:43.605+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:43.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:25:43.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:25:43.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:25:43.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T04:26:13.870+0000] {processor.py:157} INFO - Started process (PID=50333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:13.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:26:13.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:13.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:13.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:13.907+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:13.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:26:13.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:13.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:26:13.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-17T04:26:44.313+0000] {processor.py:157} INFO - Started process (PID=50343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:44.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:26:44.332+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:44.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:44.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:26:44.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:44.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:26:44.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:26:44.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:26:44.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T04:27:14.644+0000] {processor.py:157} INFO - Started process (PID=50353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:14.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:27:14.661+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:14.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:14.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:14.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:14.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:27:14.697+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:14.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:27:14.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-17T04:27:45.064+0000] {processor.py:157} INFO - Started process (PID=50362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:45.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:27:45.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:45.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:45.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:27:45.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:45.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:27:45.166+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:27:45.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:27:45.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T04:28:15.454+0000] {processor.py:157} INFO - Started process (PID=50373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:15.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:28:15.462+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:15.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:15.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:15.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:15.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:28:15.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:15.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:28:15.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T04:28:45.802+0000] {processor.py:157} INFO - Started process (PID=50383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:45.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:28:45.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:45.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:45.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:28:45.859+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:45.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:28:45.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:28:45.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:28:45.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T04:29:16.191+0000] {processor.py:157} INFO - Started process (PID=50393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:16.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:29:16.209+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:16.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:16.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:16.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:16.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:29:16.298+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:16.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:29:16.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T04:29:46.530+0000] {processor.py:157} INFO - Started process (PID=50403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:46.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:29:46.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:46.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:46.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:29:46.591+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:46.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:29:46.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:29:46.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:29:46.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-17T04:30:16.970+0000] {processor.py:157} INFO - Started process (PID=50413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:16.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:30:16.978+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:16.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:16.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:17.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:17.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:30:17.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:17.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:30:17.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T04:30:47.286+0000] {processor.py:157} INFO - Started process (PID=50423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:47.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:30:47.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:47.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:47.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:30:47.355+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:47.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:30:47.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:30:47.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:30:47.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T04:31:17.644+0000] {processor.py:157} INFO - Started process (PID=50433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:17.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:31:17.648+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:17.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:17.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:17.677+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:17.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:31:17.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:17.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:31:17.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T04:31:48.029+0000] {processor.py:157} INFO - Started process (PID=50443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:48.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:31:48.037+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:48.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:48.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:31:48.095+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:48.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:31:48.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:31:48.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:31:48.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T04:32:18.289+0000] {processor.py:157} INFO - Started process (PID=50453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:18.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:32:18.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:18.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:18.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:18.328+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:18.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:32:18.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:18.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:32:18.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-17T04:32:48.739+0000] {processor.py:157} INFO - Started process (PID=50462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:48.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:32:48.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:48.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:48.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:32:48.812+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:48.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:32:48.840+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:32:48.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:32:48.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T04:33:19.065+0000] {processor.py:157} INFO - Started process (PID=50473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:19.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:33:19.074+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:19.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:19.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:19.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:19.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:33:19.138+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:19.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:33:19.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T04:33:49.393+0000] {processor.py:157} INFO - Started process (PID=50483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:49.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:33:49.406+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:49.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:49.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:33:49.475+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:49.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:33:49.496+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:33:49.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:33:49.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T04:34:19.773+0000] {processor.py:157} INFO - Started process (PID=50493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:19.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:34:19.787+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:19.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:19.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:19.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:19.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:34:19.853+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:19.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:34:19.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T04:34:50.204+0000] {processor.py:157} INFO - Started process (PID=50503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:50.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:34:50.223+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:50.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:50.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:34:50.264+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:50.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:34:50.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:34:50.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:34:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T04:35:20.667+0000] {processor.py:157} INFO - Started process (PID=50512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:20.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:35:20.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:20.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:20.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:20.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:20.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:35:20.809+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:20.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:35:20.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-17T04:35:51.072+0000] {processor.py:157} INFO - Started process (PID=50523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:51.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:35:51.080+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:51.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:51.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:35:51.146+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:51.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:35:51.171+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:35:51.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:35:51.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T04:36:21.397+0000] {processor.py:157} INFO - Started process (PID=50533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:21.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:36:21.401+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:21.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:21.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:21.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:21.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:36:21.439+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:21.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:36:21.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T04:36:51.878+0000] {processor.py:157} INFO - Started process (PID=50543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:51.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:36:51.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:51.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:51.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:36:51.958+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:51.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:36:51.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:36:51.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:36:52.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T04:37:22.201+0000] {processor.py:157} INFO - Started process (PID=50553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:22.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:37:22.206+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:22.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:22.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:22.248+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:22.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:37:22.261+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:22.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:37:22.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T04:37:52.586+0000] {processor.py:157} INFO - Started process (PID=50563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:52.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:37:52.589+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:52.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:52.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:37:52.625+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:52.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:37:52.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:37:52.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:37:52.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T04:38:23.002+0000] {processor.py:157} INFO - Started process (PID=50573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:23.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:38:23.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:23.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:23.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:23.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:23.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:38:23.079+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:23.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:38:23.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T04:38:53.327+0000] {processor.py:157} INFO - Started process (PID=50583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:53.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:38:53.333+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:53.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:53.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:38:53.412+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:53.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:38:53.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:38:53.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:38:53.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T04:39:23.783+0000] {processor.py:157} INFO - Started process (PID=50593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:23.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:39:23.789+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:23.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:23.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:23.858+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:23.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:39:23.888+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:23.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:39:23.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T04:39:54.068+0000] {processor.py:157} INFO - Started process (PID=50603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:54.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:39:54.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:54.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:54.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:39:54.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:54.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:39:54.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:39:54.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:39:54.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-17T04:40:24.504+0000] {processor.py:157} INFO - Started process (PID=50613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:24.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:40:24.510+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:24.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:24.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:24.566+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:24.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:40:24.595+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:24.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:40:24.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T04:40:54.834+0000] {processor.py:157} INFO - Started process (PID=50623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:54.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:40:54.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:54.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:54.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:40:54.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:54.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:40:54.902+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:40:54.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:40:54.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T04:41:25.146+0000] {processor.py:157} INFO - Started process (PID=50633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:25.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:41:25.153+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:25.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:25.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:25.229+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:25.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:41:25.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:25.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:41:25.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T04:41:55.478+0000] {processor.py:157} INFO - Started process (PID=50643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:55.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:41:55.482+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:55.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:41:55.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:55.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:41:55.518+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:41:55.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:41:55.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-17T04:42:25.865+0000] {processor.py:157} INFO - Started process (PID=50653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:25.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:42:25.872+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:25.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:25.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:25.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:25.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:42:25.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:25.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:42:25.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T04:42:56.184+0000] {processor.py:157} INFO - Started process (PID=50663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:56.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:42:56.187+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:56.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:56.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:42:56.215+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:56.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:42:56.228+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:42:56.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:42:56.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T04:43:26.602+0000] {processor.py:157} INFO - Started process (PID=50673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:26.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:43:26.610+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:26.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:26.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:26.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:26.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:43:26.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:26.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:43:26.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T04:43:56.894+0000] {processor.py:157} INFO - Started process (PID=50683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:56.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:43:56.896+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:56.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:56.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:43:56.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:56.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:43:56.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:43:56.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:43:56.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T04:44:27.240+0000] {processor.py:157} INFO - Started process (PID=50693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:27.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:44:27.254+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:27.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:27.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:27.325+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:27.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:44:27.343+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:27.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:44:27.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T04:44:57.561+0000] {processor.py:157} INFO - Started process (PID=50703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:57.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:44:57.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:57.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:57.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:44:57.597+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:57.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:44:57.607+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:44:57.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:44:57.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T04:45:27.956+0000] {processor.py:157} INFO - Started process (PID=50712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:27.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:45:27.984+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:27.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:28.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:28.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:28.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:45:28.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:28.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:45:28.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T04:45:58.499+0000] {processor.py:157} INFO - Started process (PID=50723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:58.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:45:58.506+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:58.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:58.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:45:58.578+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:58.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:45:58.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:45:58.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:45:58.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T04:46:28.806+0000] {processor.py:157} INFO - Started process (PID=50733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:28.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:46:28.808+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:28.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:28.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:28.840+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:28.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:46:28.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:28.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:46:28.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T04:46:59.213+0000] {processor.py:157} INFO - Started process (PID=50743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:59.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:46:59.222+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:59.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:59.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:46:59.285+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:59.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:46:59.303+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:46:59.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:46:59.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T04:47:29.508+0000] {processor.py:157} INFO - Started process (PID=50753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:29.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:47:29.514+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:29.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:29.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:29.567+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:29.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:47:29.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:29.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:47:29.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T04:47:59.872+0000] {processor.py:157} INFO - Started process (PID=50763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:59.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:47:59.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:59.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:59.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:47:59.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:59.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:47:59.913+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:47:59.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:47:59.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T04:48:30.225+0000] {processor.py:157} INFO - Started process (PID=50772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:48:30.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:48:30.240+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:48:30.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:48:30.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:48:30.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:48:30.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:48:30.325+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:48:30.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:48:30.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T04:49:00.475+0000] {processor.py:157} INFO - Started process (PID=50783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:00.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:49:00.481+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:00.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:00.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:00.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:00.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:49:00.558+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:00.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:49:00.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T04:49:30.909+0000] {processor.py:157} INFO - Started process (PID=50792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:30.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:49:30.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:30.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:30.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:49:30.997+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:30.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:49:31.026+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:49:31.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:49:31.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T04:50:01.255+0000] {processor.py:157} INFO - Started process (PID=50803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:01.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:50:01.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:01.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:01.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:01.332+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:01.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:50:01.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:01.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:50:01.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T04:50:31.748+0000] {processor.py:157} INFO - Started process (PID=50813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:31.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:50:31.761+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:31.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:31.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:50:31.842+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:31.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:50:31.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:50:31.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:50:31.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T04:51:02.057+0000] {processor.py:157} INFO - Started process (PID=50823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:02.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:51:02.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:02.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:02.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:02.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:02.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:51:02.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:02.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:51:02.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T04:51:32.476+0000] {processor.py:157} INFO - Started process (PID=50832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:32.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:51:32.492+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:32.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:32.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:51:32.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:32.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:51:32.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:51:32.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:51:32.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T04:52:02.921+0000] {processor.py:157} INFO - Started process (PID=50843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:02.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:52:02.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:02.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:02.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:02.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:02.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:52:02.964+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:02.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:52:02.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-17T04:52:33.292+0000] {processor.py:157} INFO - Started process (PID=50853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:33.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:52:33.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:33.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:33.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:52:33.366+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:33.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:52:33.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:52:33.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:52:33.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T04:53:03.574+0000] {processor.py:157} INFO - Started process (PID=50863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:03.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:53:03.581+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:03.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:03.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:03.616+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:03.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:53:03.627+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:03.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:53:03.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T04:53:33.924+0000] {processor.py:157} INFO - Started process (PID=50873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:33.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:53:33.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:33.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:33.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:53:33.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:33.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:53:34.014+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:53:34.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:53:34.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T04:54:04.206+0000] {processor.py:157} INFO - Started process (PID=50883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:04.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:54:04.215+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:04.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:04.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:04.267+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:04.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:54:04.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:04.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:54:04.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T04:54:34.685+0000] {processor.py:157} INFO - Started process (PID=50893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:34.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:54:34.692+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:34.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:34.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:54:34.760+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:34.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:54:34.791+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:54:34.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:54:34.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T04:55:05.020+0000] {processor.py:157} INFO - Started process (PID=50903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:05.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:55:05.027+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:05.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:05.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:05.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:05.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:55:05.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:05.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:55:05.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-17T04:55:35.509+0000] {processor.py:157} INFO - Started process (PID=50913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:35.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:55:35.516+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:35.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:55:35.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:35.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:55:35.585+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:55:35.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:55:35.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T04:56:05.841+0000] {processor.py:157} INFO - Started process (PID=50923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:05.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:56:05.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:05.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:05.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:05.871+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:05.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:56:05.881+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:05.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:56:05.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-17T04:56:36.198+0000] {processor.py:157} INFO - Started process (PID=50933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:36.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:56:36.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:36.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:36.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:56:36.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:36.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:56:36.283+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:56:36.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:56:36.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T04:57:06.606+0000] {processor.py:157} INFO - Started process (PID=50943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:06.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:57:06.609+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:06.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:06.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:06.636+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:06.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:57:06.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:06.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:57:06.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-17T04:57:36.989+0000] {processor.py:157} INFO - Started process (PID=50953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:36.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:57:36.994+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:36.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:37.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:57:37.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:37.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:57:37.069+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:57:37.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:57:37.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T04:58:07.264+0000] {processor.py:157} INFO - Started process (PID=50963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:07.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:58:07.266+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:07.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:07.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:07.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:07.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:58:07.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:07.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:58:07.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T04:58:37.673+0000] {processor.py:157} INFO - Started process (PID=50973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:37.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:58:37.687+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:37.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:37.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:58:37.753+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:37.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:58:37.768+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:58:37.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:58:37.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T04:59:08.038+0000] {processor.py:157} INFO - Started process (PID=50983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:08.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:59:08.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:08.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:08.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:08.088+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:08.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:59:08.103+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:08.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:59:08.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T04:59:38.375+0000] {processor.py:157} INFO - Started process (PID=50993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:38.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T04:59:38.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:38.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:38.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T04:59:38.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:38.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T04:59:38.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T04:59:38.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T04:59:38.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T05:00:08.706+0000] {processor.py:157} INFO - Started process (PID=51003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:08.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:00:08.711+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:08.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:08.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:08.752+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:08.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:00:08.765+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:08.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:00:08.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-17T05:00:39.074+0000] {processor.py:157} INFO - Started process (PID=51013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:39.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:00:39.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:39.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:39.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:00:39.106+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:39.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:00:39.116+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:00:39.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:00:39.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T05:01:09.379+0000] {processor.py:157} INFO - Started process (PID=51023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:09.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:01:09.384+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:09.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:09.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:09.442+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:09.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:01:09.455+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:09.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:01:09.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T05:01:39.710+0000] {processor.py:157} INFO - Started process (PID=51033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:39.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:01:39.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:39.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:39.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:01:39.753+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:39.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:01:39.786+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:01:39.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:01:39.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T05:02:10.058+0000] {processor.py:157} INFO - Started process (PID=51043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:10.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:02:10.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:10.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:10.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:10.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:10.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:02:10.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:10.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:02:10.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T05:02:40.396+0000] {processor.py:157} INFO - Started process (PID=51053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:40.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:02:40.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:40.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:40.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:02:40.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:40.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:02:40.472+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:02:40.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:02:40.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T05:03:10.672+0000] {processor.py:157} INFO - Started process (PID=51063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:10.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:03:10.675+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:10.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:10.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:10.711+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:10.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:03:10.722+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:10.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:03:10.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-17T05:03:41.069+0000] {processor.py:157} INFO - Started process (PID=51073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:41.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:03:41.078+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:41.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:41.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:03:41.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:41.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:03:41.161+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:03:41.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:03:41.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T05:04:11.522+0000] {processor.py:157} INFO - Started process (PID=51083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:11.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:04:11.525+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:11.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:11.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:11.561+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:11.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:04:11.579+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:11.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:04:11.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-17T05:04:41.981+0000] {processor.py:157} INFO - Started process (PID=51093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:41.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:04:41.989+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:41.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:42.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:04:42.055+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:42.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:04:42.073+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:04:42.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:04:42.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T05:05:12.478+0000] {processor.py:157} INFO - Started process (PID=51103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:12.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:05:12.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:12.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:12.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:12.552+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:12.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:05:12.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:12.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:05:12.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T05:05:42.808+0000] {processor.py:157} INFO - Started process (PID=51113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:42.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:05:42.811+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:42.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:42.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:05:42.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:42.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:05:42.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:05:42.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:05:42.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T05:06:13.195+0000] {processor.py:157} INFO - Started process (PID=51123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:13.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:06:13.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:13.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:13.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:13.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:13.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:06:13.304+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:13.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:06:13.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T05:06:43.556+0000] {processor.py:157} INFO - Started process (PID=51133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:43.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:06:43.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:43.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:43.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:06:43.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:43.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:06:43.637+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:06:43.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:06:43.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T05:07:13.850+0000] {processor.py:157} INFO - Started process (PID=51143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:13.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:07:13.853+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:13.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:13.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:13.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:13.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:07:13.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:13.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:07:13.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T05:07:44.217+0000] {processor.py:157} INFO - Started process (PID=51152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:44.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:07:44.222+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:44.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:44.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:07:44.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:44.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:07:44.308+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:07:44.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:07:44.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T05:08:14.520+0000] {processor.py:157} INFO - Started process (PID=51163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:14.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:08:14.523+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:14.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:14.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:14.551+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:14.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:08:14.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:14.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:08:14.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T05:08:44.877+0000] {processor.py:157} INFO - Started process (PID=51173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:44.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:08:44.891+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:44.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:44.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:08:44.958+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:44.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:08:44.985+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:08:44.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:08:44.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T05:09:15.171+0000] {processor.py:157} INFO - Started process (PID=51183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:15.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:09:15.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:15.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:15.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:15.209+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:15.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:09:15.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:15.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:09:15.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-17T05:09:45.624+0000] {processor.py:157} INFO - Started process (PID=51193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:45.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:09:45.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:45.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:45.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:09:45.698+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:45.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:09:45.717+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:09:45.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:09:45.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T05:10:15.921+0000] {processor.py:157} INFO - Started process (PID=51203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:15.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:10:15.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:15.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:15.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:15.955+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:15.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:10:15.967+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:15.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:10:15.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-17T05:10:46.375+0000] {processor.py:157} INFO - Started process (PID=51213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:46.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:10:46.398+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:46.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:46.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:10:46.472+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:46.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:10:46.506+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:10:46.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:10:46.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-17T05:11:16.680+0000] {processor.py:157} INFO - Started process (PID=51223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:16.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:11:16.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:16.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:16.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:16.722+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:16.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:11:16.733+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:16.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:11:16.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-17T05:11:47.048+0000] {processor.py:157} INFO - Started process (PID=51233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:47.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:11:47.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:47.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:47.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:11:47.116+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:47.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:11:47.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:11:47.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:11:47.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T05:12:17.387+0000] {processor.py:157} INFO - Started process (PID=51243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:17.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:12:17.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:17.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:17.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:17.420+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:17.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:12:17.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:17.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:12:17.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T05:12:47.722+0000] {processor.py:157} INFO - Started process (PID=51252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:47.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:12:47.731+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:47.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:47.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:12:47.792+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:47.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:12:47.809+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:12:47.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:12:47.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T05:13:18.035+0000] {processor.py:157} INFO - Started process (PID=51263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:18.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:13:18.039+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:18.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:18.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:18.097+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:18.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:13:18.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:18.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:13:18.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T05:13:48.281+0000] {processor.py:157} INFO - Started process (PID=51273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:48.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:13:48.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:48.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:48.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:13:48.349+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:48.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:13:48.363+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:13:48.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:13:48.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T05:14:18.690+0000] {processor.py:157} INFO - Started process (PID=51283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:18.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:14:18.699+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:18.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:18.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:18.732+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:18.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:14:18.744+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:18.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:14:18.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-17T05:14:49.003+0000] {processor.py:157} INFO - Started process (PID=51293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:49.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:14:49.007+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:49.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:49.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:14:49.084+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:49.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:14:49.099+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:14:49.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:14:49.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T05:15:19.334+0000] {processor.py:157} INFO - Started process (PID=51303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:19.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:15:19.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:19.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:19.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:19.378+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:19.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:15:19.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:19.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:15:19.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T05:15:49.705+0000] {processor.py:157} INFO - Started process (PID=51313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:49.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:15:49.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:49.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:49.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:15:49.775+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:49.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:15:49.791+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:15:49.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:15:49.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T05:16:20.084+0000] {processor.py:157} INFO - Started process (PID=51322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:20.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:16:20.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:20.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:20.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:20.155+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:20.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:16:20.175+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:20.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:16:20.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T05:16:50.530+0000] {processor.py:157} INFO - Started process (PID=51333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:50.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:16:50.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:50.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:50.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:16:50.574+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:50.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:16:50.587+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:16:50.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:16:50.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T05:17:20.966+0000] {processor.py:157} INFO - Started process (PID=51343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:20.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:17:20.976+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:20.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:20.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:21.047+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:21.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:17:21.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:21.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:17:21.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T05:17:51.268+0000] {processor.py:157} INFO - Started process (PID=51353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:51.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:17:51.273+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:51.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:51.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:17:51.305+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:51.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:17:51.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:17:51.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:17:51.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T05:18:21.679+0000] {processor.py:157} INFO - Started process (PID=51362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:21.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:18:21.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:21.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:21.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:21.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:21.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:18:21.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:21.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:18:21.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T05:18:52.064+0000] {processor.py:157} INFO - Started process (PID=51373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:52.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:18:52.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:52.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:52.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:18:52.153+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:52.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:18:52.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:18:52.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:18:52.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T05:19:22.455+0000] {processor.py:157} INFO - Started process (PID=51383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:22.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:19:22.462+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:22.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:22.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:22.536+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:22.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:19:22.555+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:22.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:19:22.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T05:19:52.809+0000] {processor.py:157} INFO - Started process (PID=51393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:52.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:19:52.814+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:52.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:52.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:19:52.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:52.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:19:52.876+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:19:52.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:19:52.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-17T05:20:23.265+0000] {processor.py:157} INFO - Started process (PID=51402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:23.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:20:23.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:23.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:23.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:23.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:23.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:20:23.374+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:23.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:20:23.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T05:20:53.760+0000] {processor.py:157} INFO - Started process (PID=51413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:53.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:20:53.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:53.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:53.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:20:53.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:53.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:20:53.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:20:53.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:20:53.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T05:21:24.106+0000] {processor.py:157} INFO - Started process (PID=51423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:24.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:21:24.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:24.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:24.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:24.166+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:24.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:21:24.183+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:24.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:21:24.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T05:21:54.481+0000] {processor.py:157} INFO - Started process (PID=51433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:54.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:21:54.496+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:54.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:54.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:21:54.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:54.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:21:54.583+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:21:54.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:21:54.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T05:22:24.823+0000] {processor.py:157} INFO - Started process (PID=51443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:24.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:22:24.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:24.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:24.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:24.858+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:24.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:22:24.871+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:24.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:22:24.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T05:22:55.191+0000] {processor.py:157} INFO - Started process (PID=51453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:55.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:22:55.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:55.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:55.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:22:55.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:55.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:22:55.289+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:22:55.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:22:55.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T05:23:25.469+0000] {processor.py:157} INFO - Started process (PID=51463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:25.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:23:25.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:25.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:25.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:25.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:25.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:23:25.521+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:25.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:23:25.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-17T05:23:55.727+0000] {processor.py:157} INFO - Started process (PID=51473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:55.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:23:55.732+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:55.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:55.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:23:55.811+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:55.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:23:55.827+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:23:55.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:23:55.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T05:24:26.068+0000] {processor.py:157} INFO - Started process (PID=51483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:26.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:24:26.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:26.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:26.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:26.130+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:26.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:24:26.154+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:26.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:24:26.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T05:24:56.481+0000] {processor.py:157} INFO - Started process (PID=51493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:56.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:24:56.490+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:56.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:56.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:24:56.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:56.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:24:56.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:24:56.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:24:56.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-17T05:25:26.891+0000] {processor.py:157} INFO - Started process (PID=51503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:26.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:25:26.893+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:26.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:26.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:26.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:26.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:25:26.970+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:26.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:25:26.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T05:25:57.359+0000] {processor.py:157} INFO - Started process (PID=51513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:57.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:25:57.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:57.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:57.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:25:57.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:57.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:25:57.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:25:57.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:25:57.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T05:26:27.770+0000] {processor.py:157} INFO - Started process (PID=51523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:27.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:26:27.779+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:27.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:27.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:27.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:27.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:26:27.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:27.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:26:27.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T05:26:58.111+0000] {processor.py:157} INFO - Started process (PID=51533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:58.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:26:58.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:58.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:58.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:26:58.146+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:58.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:26:58.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:26:58.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:26:58.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T05:27:28.532+0000] {processor.py:157} INFO - Started process (PID=51542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:28.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:27:28.543+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:28.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:28.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:28.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:28.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:27:28.634+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:28.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:27:28.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T05:27:58.824+0000] {processor.py:157} INFO - Started process (PID=51553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:58.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:27:58.827+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:58.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:58.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:27:58.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:58.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:27:58.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:27:58.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:27:58.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-17T05:28:29.185+0000] {processor.py:157} INFO - Started process (PID=51563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:29.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:28:29.192+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:29.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:29.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:29.261+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:29.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:28:29.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:29.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:28:29.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T05:28:59.492+0000] {processor.py:157} INFO - Started process (PID=51573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:59.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:28:59.500+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:59.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:59.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:28:59.531+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:59.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:28:59.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:28:59.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:28:59.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T05:29:29.826+0000] {processor.py:157} INFO - Started process (PID=51583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:29:29.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:29:29.834+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:29:29.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:29:29.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:29:29.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:29:29.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:29:29.915+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:29:29.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:29:29.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T05:30:00.166+0000] {processor.py:157} INFO - Started process (PID=51593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:00.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:30:00.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:00.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:00.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:00.198+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:00.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:30:00.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:00.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:30:00.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-17T05:30:30.584+0000] {processor.py:157} INFO - Started process (PID=51603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:30.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:30:30.593+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:30.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:30.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:30:30.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:30.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:30:30.658+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:30:30.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:30:30.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T05:31:00.910+0000] {processor.py:157} INFO - Started process (PID=51613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:00.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:31:00.913+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:00.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:00.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:00.945+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:00.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:31:00.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:00.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:31:00.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T05:31:31.337+0000] {processor.py:157} INFO - Started process (PID=51623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:31.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:31:31.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:31.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:31.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:31:31.407+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:31.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:31:31.434+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:31:31.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:31:31.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T05:32:01.657+0000] {processor.py:157} INFO - Started process (PID=51633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:01.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:32:01.660+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:01.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:01.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:01.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:01.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:32:01.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:01.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:32:01.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T05:32:32.021+0000] {processor.py:157} INFO - Started process (PID=51643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:32.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:32:32.027+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:32.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:32.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:32:32.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:32.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:32:32.089+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:32:32.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:32:32.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-17T05:33:02.342+0000] {processor.py:157} INFO - Started process (PID=51653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:02.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:33:02.345+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:02.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:02.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:02.374+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:02.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:33:02.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:02.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:33:02.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-17T05:33:32.702+0000] {processor.py:157} INFO - Started process (PID=51663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:32.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:33:32.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:32.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:32.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:33:32.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:32.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:33:32.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:33:32.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:33:32.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T05:34:03.054+0000] {processor.py:157} INFO - Started process (PID=51673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:03.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:34:03.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:03.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:03.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:03.108+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:03.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:34:03.124+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:03.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:34:03.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T05:34:33.518+0000] {processor.py:157} INFO - Started process (PID=51681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:33.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:34:33.526+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:33.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:33.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:34:33.599+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:33.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:34:33.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:34:33.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:34:33.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T05:35:03.993+0000] {processor.py:157} INFO - Started process (PID=51693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:03.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:35:03.998+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:03.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:04.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:04.032+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:04.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:35:04.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:04.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:35:04.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-17T05:35:34.441+0000] {processor.py:157} INFO - Started process (PID=51703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:34.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:35:34.450+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:34.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:34.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:35:34.514+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:34.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:35:34.531+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:35:34.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:35:34.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T05:36:04.749+0000] {processor.py:157} INFO - Started process (PID=51713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:04.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:36:04.755+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:04.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:04.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:04.779+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:04.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:36:04.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:04.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:36:04.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-17T05:36:35.169+0000] {processor.py:157} INFO - Started process (PID=51722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:35.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:36:35.176+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:35.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:35.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:36:35.243+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:35.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:36:35.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:36:35.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:36:35.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T05:37:05.505+0000] {processor.py:157} INFO - Started process (PID=51733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:05.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:37:05.509+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:05.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:05.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:05.552+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:05.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:37:05.570+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:05.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:37:05.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T05:37:35.834+0000] {processor.py:157} INFO - Started process (PID=51743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:35.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:37:35.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:35.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:35.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:37:35.881+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:35.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:37:35.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:37:35.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:37:35.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-17T05:38:06.197+0000] {processor.py:157} INFO - Started process (PID=51753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:06.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:38:06.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:06.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:06.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:06.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:06.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:38:06.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:06.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:38:06.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-17T05:38:36.613+0000] {processor.py:157} INFO - Started process (PID=51763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:36.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:38:36.623+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:36.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:36.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:38:36.693+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:36.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:38:36.715+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:38:36.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:38:36.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T05:39:06.952+0000] {processor.py:157} INFO - Started process (PID=51773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:06.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:39:06.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:06.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:06.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:07.024+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:07.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:39:07.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:07.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:39:07.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T05:39:37.272+0000] {processor.py:157} INFO - Started process (PID=51783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:37.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:39:37.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:37.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:37.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:39:37.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:37.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:39:37.356+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:39:37.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:39:37.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T05:40:07.558+0000] {processor.py:157} INFO - Started process (PID=51793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:07.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:40:07.565+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:07.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:07.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:07.601+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:07.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:40:07.615+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:07.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:40:07.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-17T05:40:37.976+0000] {processor.py:157} INFO - Started process (PID=51803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:37.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:40:37.985+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:37.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:38.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:40:38.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:38.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:40:38.058+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:40:38.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:40:38.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T05:41:08.347+0000] {processor.py:157} INFO - Started process (PID=51813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:08.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:41:08.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:08.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:08.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:08.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:08.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:41:08.440+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:08.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:41:08.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T05:41:38.664+0000] {processor.py:157} INFO - Started process (PID=51823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:38.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:41:38.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:38.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:38.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:41:38.709+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:38.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:41:38.724+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:41:38.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:41:38.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-17T05:42:09.025+0000] {processor.py:157} INFO - Started process (PID=51833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:09.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:42:09.034+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:09.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:09.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:09.057+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:09.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:42:09.066+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:09.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:42:09.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T05:42:39.421+0000] {processor.py:157} INFO - Started process (PID=51842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:39.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:42:39.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:39.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:39.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:42:39.505+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:39.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:42:39.521+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:42:39.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:42:39.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T05:43:09.894+0000] {processor.py:157} INFO - Started process (PID=51852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:09.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:43:09.900+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:09.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:09.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:09.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:09.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:43:09.982+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:09.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:43:09.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T05:43:40.193+0000] {processor.py:157} INFO - Started process (PID=51862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:40.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:43:40.198+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:40.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:40.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:43:40.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:40.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:43:40.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:43:40.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:43:40.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T05:44:10.504+0000] {processor.py:157} INFO - Started process (PID=51873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:10.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:44:10.509+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:10.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:10.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:10.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:10.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:44:10.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:10.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:44:10.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T05:44:40.974+0000] {processor.py:157} INFO - Started process (PID=51883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:40.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:44:40.980+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:40.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:41.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:44:41.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:41.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:44:41.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:44:41.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:44:41.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T05:45:11.927+0000] {processor.py:157} INFO - Started process (PID=51893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:11.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:45:11.935+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:11.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:11.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:12.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:12.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:45:12.021+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:12.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:45:12.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T05:45:42.643+0000] {processor.py:157} INFO - Started process (PID=51901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:42.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:45:42.670+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:42.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:42.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:45:42.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:42.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:45:42.827+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:45:42.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:45:42.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-09-17T05:46:13.058+0000] {processor.py:157} INFO - Started process (PID=51912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:13.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:46:13.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:13.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:13.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:13.137+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:13.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:46:13.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:13.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:46:13.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T05:46:43.416+0000] {processor.py:157} INFO - Started process (PID=51923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:43.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:46:43.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:43.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:43.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:46:43.486+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:43.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:46:43.505+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:46:43.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:46:43.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T05:47:13.767+0000] {processor.py:157} INFO - Started process (PID=51933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:13.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:47:13.772+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:13.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:13.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:13.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:13.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:47:13.868+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:13.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:47:13.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T05:47:44.213+0000] {processor.py:157} INFO - Started process (PID=51943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:44.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:47:44.221+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:44.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:44.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:47:44.287+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:44.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:47:44.310+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:47:44.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:47:44.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T05:48:14.601+0000] {processor.py:157} INFO - Started process (PID=51953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:14.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:48:14.607+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:14.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:14.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:14.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:14.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:48:14.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:14.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:48:14.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T05:48:44.989+0000] {processor.py:157} INFO - Started process (PID=51963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:44.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:48:44.992+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:44.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:45.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:48:45.018+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:45.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:48:45.030+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:48:45.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:48:45.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T05:49:15.414+0000] {processor.py:157} INFO - Started process (PID=51973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:15.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:49:15.424+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:15.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:15.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:15.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:15.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:49:15.534+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:15.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:49:15.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T05:49:46.178+0000] {processor.py:157} INFO - Started process (PID=51983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:46.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:49:46.185+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:46.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:46.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:49:46.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:46.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:49:46.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:49:46.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:49:46.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T05:50:16.567+0000] {processor.py:157} INFO - Started process (PID=51993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:16.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:50:16.571+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:16.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:16.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:16.598+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:16.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:50:16.608+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:16.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:50:16.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-17T05:50:47.441+0000] {processor.py:157} INFO - Started process (PID=52003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:47.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:50:47.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:47.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:47.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:50:47.501+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:47.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:50:47.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:50:47.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:50:47.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T05:51:17.949+0000] {processor.py:157} INFO - Started process (PID=52013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:17.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:51:17.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:17.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:18.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:18.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:18.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:51:18.106+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:18.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:51:18.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-17T05:51:48.631+0000] {processor.py:157} INFO - Started process (PID=52023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:48.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:51:48.655+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:48.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:48.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:51:48.809+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:48.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:51:48.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:51:48.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:51:48.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-09-17T05:52:19.198+0000] {processor.py:157} INFO - Started process (PID=52033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:19.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:52:19.207+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:19.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:19.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:19.310+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:19.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:52:19.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:19.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:52:19.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-17T05:52:49.505+0000] {processor.py:157} INFO - Started process (PID=52043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:49.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:52:49.515+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:49.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:49.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:52:49.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:49.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:52:49.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:52:49.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:52:49.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T05:53:19.899+0000] {processor.py:157} INFO - Started process (PID=52053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:19.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:53:19.905+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:19.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:19.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:19.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:19.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:53:19.965+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:19.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:53:19.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-17T05:53:50.868+0000] {processor.py:157} INFO - Started process (PID=52063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:50.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:53:50.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:50.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:50.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:53:50.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:50.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:53:50.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:53:50.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:53:51.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T05:54:21.280+0000] {processor.py:157} INFO - Started process (PID=52073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:21.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:54:21.288+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:21.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:21.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:21.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:21.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:54:21.370+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:21.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:54:21.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T05:54:51.685+0000] {processor.py:157} INFO - Started process (PID=52083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:51.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:54:51.694+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:51.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:51.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:54:51.781+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:51.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:54:51.800+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:54:51.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:54:51.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T05:55:22.012+0000] {processor.py:157} INFO - Started process (PID=52093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:22.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:55:22.022+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:22.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:22.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:22.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:22.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:55:22.181+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:22.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:55:22.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-17T05:55:52.568+0000] {processor.py:157} INFO - Started process (PID=52103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:52.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:55:52.577+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:52.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:52.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:55:52.659+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:52.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:55:52.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:55:52.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:55:52.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T05:56:22.920+0000] {processor.py:157} INFO - Started process (PID=52113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:22.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:56:22.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:22.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:22.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:23.009+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:23.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:56:23.028+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:23.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:56:23.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T05:56:53.500+0000] {processor.py:157} INFO - Started process (PID=52123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:53.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:56:53.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:53.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:53.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:56:53.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:53.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:56:53.695+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:56:53.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:56:53.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-17T05:57:23.858+0000] {processor.py:157} INFO - Started process (PID=52133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:23.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:57:23.868+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:23.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:23.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:23.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:23.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:57:24.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:24.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:57:24.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-17T05:57:54.239+0000] {processor.py:157} INFO - Started process (PID=52142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:54.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:57:54.252+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:54.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:54.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:57:54.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:54.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:57:54.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:57:54.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:57:54.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-17T05:58:24.647+0000] {processor.py:157} INFO - Started process (PID=52153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:24.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:58:24.653+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:24.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:24.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:24.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:24.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:58:24.754+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:24.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:58:24.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T05:58:55.053+0000] {processor.py:157} INFO - Started process (PID=52163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:55.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:58:55.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:55.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:55.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:58:55.199+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:55.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:58:55.228+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:58:55.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:58:55.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-09-17T05:59:25.359+0000] {processor.py:157} INFO - Started process (PID=52173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:25.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:59:25.365+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:25.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:25.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:25.449+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:25.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:59:25.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:25.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:59:25.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T05:59:56.086+0000] {processor.py:157} INFO - Started process (PID=52183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:56.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T05:59:56.180+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:56.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:56.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T05:59:56.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:56.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T05:59:56.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T05:59:56.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T05:59:56.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.489 seconds
[2024-09-17T06:00:26.809+0000] {processor.py:157} INFO - Started process (PID=52193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:26.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:00:26.821+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:26.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:26.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:26.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:26.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:00:26.916+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:26.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:00:26.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T06:00:57.177+0000] {processor.py:157} INFO - Started process (PID=52203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:57.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:00:57.198+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:57.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:57.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:00:57.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:57.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:00:57.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:00:57.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:00:57.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-17T06:01:27.541+0000] {processor.py:157} INFO - Started process (PID=52213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:27.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:01:27.552+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:27.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:27.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:27.659+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:27.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:01:27.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:27.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:01:27.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-17T06:01:57.938+0000] {processor.py:157} INFO - Started process (PID=52223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:57.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:01:57.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:57.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:58.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:01:58.111+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:58.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:01:58.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:01:58.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:01:58.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.242 seconds
[2024-09-17T06:02:28.506+0000] {processor.py:157} INFO - Started process (PID=52233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:28.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:02:28.516+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:28.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:28.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:28.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:28.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:02:28.641+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:28.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:02:28.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-17T06:02:58.817+0000] {processor.py:157} INFO - Started process (PID=52243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:58.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:02:58.823+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:58.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:58.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:02:58.890+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:58.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:02:58.906+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:02:58.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:02:58.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T06:03:29.178+0000] {processor.py:157} INFO - Started process (PID=52253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:29.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:03:29.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:29.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:29.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:29.255+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:29.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:03:29.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:29.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:03:29.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T06:03:59.547+0000] {processor.py:157} INFO - Started process (PID=52262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:59.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:03:59.561+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:59.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:59.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:03:59.627+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:59.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:03:59.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:03:59.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:03:59.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T06:04:29.910+0000] {processor.py:157} INFO - Started process (PID=52273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:04:29.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:04:29.920+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:04:29.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:04:29.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:04:30.004+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:04:30.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:04:30.023+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:04:30.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:04:30.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T06:05:00.194+0000] {processor.py:157} INFO - Started process (PID=52283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:00.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:05:00.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:00.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:00.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:00.278+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:00.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:05:00.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:00.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:05:00.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T06:05:30.522+0000] {processor.py:157} INFO - Started process (PID=52293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:30.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:05:30.527+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:30.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:30.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:05:30.599+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:30.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:05:30.616+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:05:30.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:05:30.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T06:06:00.824+0000] {processor.py:157} INFO - Started process (PID=52303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:00.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:06:00.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:00.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:00.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:00.871+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:00.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:06:00.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:00.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:06:00.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-17T06:06:31.178+0000] {processor.py:157} INFO - Started process (PID=52313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:31.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:06:31.185+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:31.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:31.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:06:31.261+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:31.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:06:31.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:06:31.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:06:31.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T06:07:01.483+0000] {processor.py:157} INFO - Started process (PID=52323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:01.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:07:01.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:01.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:01.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:01.574+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:01.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:07:01.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:01.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:07:01.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T06:07:31.832+0000] {processor.py:157} INFO - Started process (PID=52333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:31.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:07:31.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:31.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:31.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:07:31.910+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:31.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:07:31.937+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:07:31.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:07:31.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T06:08:02.236+0000] {processor.py:157} INFO - Started process (PID=52343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:02.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:08:02.243+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:02.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:02.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:02.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:02.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:08:02.356+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:02.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:08:02.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T06:08:32.767+0000] {processor.py:157} INFO - Started process (PID=52353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:32.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:08:32.775+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:32.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:32.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:08:32.965+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:32.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:08:33.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:08:33.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:08:33.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.411 seconds
[2024-09-17T06:09:03.456+0000] {processor.py:157} INFO - Started process (PID=52362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:03.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:09:03.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:03.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:03.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:03.532+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:03.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:09:03.547+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:03.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:09:03.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T06:09:33.794+0000] {processor.py:157} INFO - Started process (PID=52373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:33.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:09:33.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:33.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:33.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:09:33.830+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:33.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:09:33.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:09:33.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:09:33.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T06:10:04.169+0000] {processor.py:157} INFO - Started process (PID=52382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:04.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:10:04.175+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:04.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:04.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:04.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:04.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:10:04.270+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:04.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:10:04.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T06:10:34.463+0000] {processor.py:157} INFO - Started process (PID=52393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:34.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:10:34.469+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:34.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:34.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:10:34.537+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:34.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:10:34.551+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:10:34.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:10:34.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T06:11:04.781+0000] {processor.py:157} INFO - Started process (PID=52403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:04.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:11:04.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:04.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:04.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:04.818+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:04.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:11:04.830+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:04.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:11:04.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T06:11:35.182+0000] {processor.py:157} INFO - Started process (PID=52412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:35.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:11:35.211+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:35.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:35.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:11:35.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:35.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:11:35.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:11:35.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:11:35.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T06:12:05.487+0000] {processor.py:157} INFO - Started process (PID=52423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:05.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:12:05.493+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:05.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:05.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:05.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:05.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:12:05.560+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:05.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:12:05.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T06:12:35.902+0000] {processor.py:157} INFO - Started process (PID=52433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:35.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:12:35.907+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:35.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:35.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:12:35.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:35.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:12:35.965+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:12:35.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:12:35.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T06:13:06.217+0000] {processor.py:157} INFO - Started process (PID=52443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:06.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:13:06.221+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:06.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:06.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:06.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:06.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:13:06.289+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:06.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:13:06.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T06:13:36.574+0000] {processor.py:157} INFO - Started process (PID=52452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:36.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:13:36.579+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:36.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:36.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:13:36.641+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:36.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:13:36.656+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:13:36.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:13:36.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T06:14:06.881+0000] {processor.py:157} INFO - Started process (PID=52463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:06.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:14:06.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:06.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:06.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:06.914+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:06.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:14:06.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:06.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:14:06.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T06:14:37.267+0000] {processor.py:157} INFO - Started process (PID=52473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:37.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:14:37.274+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:37.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:37.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:14:37.339+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:37.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:14:37.354+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:14:37.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:14:37.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T06:15:07.544+0000] {processor.py:157} INFO - Started process (PID=52483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:07.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:15:07.551+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:07.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:07.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:07.591+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:07.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:15:07.608+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:07.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:15:07.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-17T06:15:37.888+0000] {processor.py:157} INFO - Started process (PID=52493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:37.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:15:37.893+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:37.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:37.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:15:37.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:37.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:15:37.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:15:37.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:15:37.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T06:16:08.248+0000] {processor.py:157} INFO - Started process (PID=52503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:08.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:16:08.258+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:08.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:08.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:08.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:08.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:16:08.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:08.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:16:08.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T06:16:38.612+0000] {processor.py:157} INFO - Started process (PID=52513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:38.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:16:38.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:38.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:38.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:16:38.686+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:38.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:16:38.700+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:16:38.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:16:38.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T06:17:08.953+0000] {processor.py:157} INFO - Started process (PID=52523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:08.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:17:08.966+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:08.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:08.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:09.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:09.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:17:09.056+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:09.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:17:09.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T06:17:39.432+0000] {processor.py:157} INFO - Started process (PID=52533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:39.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:17:39.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:39.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:39.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:17:39.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:39.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:17:39.509+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:17:39.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:17:39.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T06:18:09.714+0000] {processor.py:157} INFO - Started process (PID=52543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:09.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:18:09.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:09.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:09.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:09.753+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:09.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:18:09.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:09.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:18:09.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T06:18:40.088+0000] {processor.py:157} INFO - Started process (PID=52553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:40.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:18:40.092+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:40.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:40.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:18:40.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:40.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:18:40.166+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:18:40.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:18:40.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T06:19:10.409+0000] {processor.py:157} INFO - Started process (PID=52563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:10.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:19:10.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:10.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:10.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:10.471+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:10.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:19:10.484+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:10.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:19:10.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T06:19:40.740+0000] {processor.py:157} INFO - Started process (PID=52573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:40.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:19:40.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:40.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:40.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:19:40.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:40.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:19:40.849+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:19:40.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:19:40.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T06:20:11.103+0000] {processor.py:157} INFO - Started process (PID=52583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:11.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:20:11.106+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:11.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:11.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:11.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:11.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:20:11.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:11.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:20:11.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T06:20:41.506+0000] {processor.py:157} INFO - Started process (PID=52593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:41.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:20:41.528+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:41.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:41.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:20:41.578+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:41.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:20:41.593+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:20:41.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:20:41.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T06:21:11.855+0000] {processor.py:157} INFO - Started process (PID=52603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:11.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:21:11.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:11.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:11.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:11.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:11.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:21:11.957+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:11.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:21:11.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T06:21:42.195+0000] {processor.py:157} INFO - Started process (PID=52613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:42.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:21:42.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:42.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:42.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:21:42.242+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:42.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:21:42.258+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:21:42.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:21:42.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-17T06:22:12.554+0000] {processor.py:157} INFO - Started process (PID=52623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:12.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:22:12.557+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:12.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:12.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:12.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:12.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:22:12.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:12.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:22:12.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T06:22:42.978+0000] {processor.py:157} INFO - Started process (PID=52633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:42.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:22:42.984+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:42.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:43.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:22:43.068+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:43.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:22:43.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:22:43.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:22:43.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T06:23:13.313+0000] {processor.py:157} INFO - Started process (PID=52643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:13.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:23:13.316+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:13.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:13.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:13.343+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:13.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:23:13.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:13.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:23:13.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T06:23:43.699+0000] {processor.py:157} INFO - Started process (PID=52653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:43.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:23:43.706+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:43.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:43.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:23:43.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:43.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:23:43.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:23:43.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:23:43.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T06:24:14.014+0000] {processor.py:157} INFO - Started process (PID=52663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:14.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:24:14.020+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:14.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:14.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:14.122+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:14.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:24:14.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:14.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:24:14.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T06:24:44.375+0000] {processor.py:157} INFO - Started process (PID=52673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:44.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:24:44.381+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:44.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:44.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:24:44.458+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:44.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:24:44.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:24:44.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:24:44.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T06:25:14.803+0000] {processor.py:157} INFO - Started process (PID=52683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:14.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:25:14.812+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:14.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:14.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:14.885+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:14.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:25:14.922+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:14.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:25:14.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T06:25:45.343+0000] {processor.py:157} INFO - Started process (PID=52693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:45.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:25:45.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:45.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:45.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:25:45.450+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:45.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:25:45.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:25:45.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:25:45.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T06:26:15.847+0000] {processor.py:157} INFO - Started process (PID=52703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:15.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:26:15.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:15.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:15.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:15.923+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:15.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:26:15.941+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:15.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:26:15.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T06:26:46.173+0000] {processor.py:157} INFO - Started process (PID=52713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:46.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:26:46.180+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:46.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:46.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:26:46.248+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:46.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:26:46.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:26:46.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:26:46.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T06:27:16.565+0000] {processor.py:157} INFO - Started process (PID=52723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:16.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:27:16.572+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:16.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:16.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:16.620+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:16.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:27:16.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:16.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:27:16.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T06:27:46.955+0000] {processor.py:157} INFO - Started process (PID=52733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:46.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:27:46.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:46.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:47.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:27:47.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:47.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:27:47.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:27:47.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:27:47.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T06:28:17.263+0000] {processor.py:157} INFO - Started process (PID=52743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:17.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:28:17.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:17.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:17.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:17.349+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:17.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:28:17.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:17.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:28:17.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T06:28:47.662+0000] {processor.py:157} INFO - Started process (PID=52753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:47.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:28:47.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:47.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:47.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:28:47.752+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:47.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:28:47.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:28:47.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:28:47.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T06:29:18.042+0000] {processor.py:157} INFO - Started process (PID=52763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:18.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:29:18.049+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:18.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:18.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:18.110+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:18.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:29:18.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:18.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:29:18.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T06:29:48.407+0000] {processor.py:157} INFO - Started process (PID=52773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:48.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:29:48.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:48.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:48.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:29:48.496+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:48.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:29:48.517+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:29:48.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:29:48.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T06:30:18.730+0000] {processor.py:157} INFO - Started process (PID=52783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:18.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:30:18.736+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:18.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:18.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:18.783+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:18.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:30:18.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:18.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:30:18.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-17T06:30:49.223+0000] {processor.py:157} INFO - Started process (PID=52793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:49.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:30:49.240+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:49.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:49.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:30:49.316+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:49.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:30:49.333+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:30:49.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:30:49.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T06:31:19.581+0000] {processor.py:157} INFO - Started process (PID=52803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:19.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:31:19.587+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:19.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:19.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:19.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:19.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:31:19.659+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:19.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:31:19.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T06:31:50.034+0000] {processor.py:157} INFO - Started process (PID=52813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:50.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:31:50.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:50.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:50.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:31:50.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:50.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:31:50.148+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:31:50.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:31:50.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T06:32:20.346+0000] {processor.py:157} INFO - Started process (PID=52823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:20.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:32:20.354+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:20.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:20.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:20.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:20.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:32:20.445+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:20.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:32:20.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T06:32:50.668+0000] {processor.py:157} INFO - Started process (PID=52832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:50.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:32:50.675+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:50.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:50.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:32:50.730+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:50.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:32:50.747+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:32:50.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:32:50.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T06:33:20.974+0000] {processor.py:157} INFO - Started process (PID=52842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:20.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:33:20.999+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:20.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:21.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:21.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:21.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:33:21.087+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:21.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:33:21.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T06:33:51.296+0000] {processor.py:157} INFO - Started process (PID=52853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:51.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:33:51.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:51.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:51.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:33:51.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:51.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:33:51.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:33:51.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:33:51.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T06:34:21.664+0000] {processor.py:157} INFO - Started process (PID=52863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:21.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:34:21.670+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:21.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:21.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:21.740+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:21.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:34:21.757+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:21.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:34:21.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T06:34:52.164+0000] {processor.py:157} INFO - Started process (PID=52872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:52.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:34:52.170+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:52.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:52.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:34:52.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:52.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:34:52.263+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:34:52.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:34:52.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T06:35:22.653+0000] {processor.py:157} INFO - Started process (PID=52883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:22.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:35:22.660+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:22.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:22.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:22.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:22.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:35:22.754+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:22.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:35:22.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T06:35:53.125+0000] {processor.py:157} INFO - Started process (PID=52893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:53.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:35:53.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:53.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:53.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:35:53.206+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:53.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:35:53.224+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:35:53.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:35:53.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T06:36:23.378+0000] {processor.py:157} INFO - Started process (PID=52903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:23.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:36:23.384+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:23.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:23.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:23.426+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:23.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:36:23.442+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:23.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:36:23.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T06:36:53.698+0000] {processor.py:157} INFO - Started process (PID=52913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:53.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:36:53.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:53.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:53.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:36:53.759+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:53.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:36:53.780+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:36:53.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:36:53.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T06:37:24.205+0000] {processor.py:157} INFO - Started process (PID=52921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:24.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:37:24.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:24.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:24.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:24.267+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:24.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:37:24.283+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:24.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:37:24.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T06:37:54.569+0000] {processor.py:157} INFO - Started process (PID=52933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:54.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:37:54.576+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:54.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:54.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:37:54.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:54.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:37:54.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:37:54.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:37:54.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T06:38:24.942+0000] {processor.py:157} INFO - Started process (PID=52943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:24.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:38:24.947+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:24.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:24.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:25.000+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:25.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:38:25.015+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:25.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:38:25.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T06:38:55.243+0000] {processor.py:157} INFO - Started process (PID=52953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:55.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:38:55.248+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:55.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:55.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:38:55.278+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:55.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:38:55.291+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:38:55.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:38:55.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T06:39:25.617+0000] {processor.py:157} INFO - Started process (PID=52963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:25.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:39:25.630+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:25.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:25.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:25.699+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:25.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:39:25.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:25.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:39:25.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T06:39:55.921+0000] {processor.py:157} INFO - Started process (PID=52973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:55.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:39:55.935+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:55.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:55.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:39:55.982+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:55.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:39:55.998+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:39:55.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:39:56.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T06:40:26.396+0000] {processor.py:157} INFO - Started process (PID=52982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:26.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:40:26.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:26.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:26.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:26.455+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:26.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:40:26.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:26.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:40:26.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T06:40:56.688+0000] {processor.py:157} INFO - Started process (PID=52993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:56.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:40:56.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:56.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:56.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:40:56.718+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:56.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:40:56.730+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:40:56.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:40:56.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T06:41:27.039+0000] {processor.py:157} INFO - Started process (PID=53003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:27.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:41:27.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:27.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:27.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:27.115+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:27.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:41:27.135+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:27.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:41:27.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T06:41:57.309+0000] {processor.py:157} INFO - Started process (PID=53013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:57.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:41:57.313+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:57.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:57.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:41:57.341+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:57.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:41:57.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:41:57.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:41:57.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T06:42:27.703+0000] {processor.py:157} INFO - Started process (PID=53023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:27.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:42:27.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:27.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:27.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:27.793+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:27.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:42:27.812+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:27.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:42:27.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T06:42:58.015+0000] {processor.py:157} INFO - Started process (PID=53033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:58.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:42:58.021+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:58.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:58.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:42:58.072+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:58.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:42:58.087+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:42:58.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:42:58.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T06:43:28.429+0000] {processor.py:157} INFO - Started process (PID=53043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:28.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:43:28.436+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:28.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:28.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:28.515+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:28.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:43:28.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:28.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:43:28.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T06:43:58.849+0000] {processor.py:157} INFO - Started process (PID=53053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:58.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:43:58.853+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:58.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:58.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:43:58.891+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:58.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:43:58.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:43:58.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:43:58.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T06:44:29.251+0000] {processor.py:157} INFO - Started process (PID=53063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:29.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:44:29.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:29.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:29.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:29.318+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:29.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:44:29.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:29.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:44:29.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T06:44:59.662+0000] {processor.py:157} INFO - Started process (PID=53073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:59.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:44:59.675+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:59.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:59.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:44:59.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:59.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:44:59.768+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:44:59.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:44:59.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T06:45:29.935+0000] {processor.py:157} INFO - Started process (PID=53083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:45:29.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:45:29.960+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:45:29.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:45:29.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:45:30.028+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:45:30.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:45:30.048+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:45:30.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:45:30.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T06:46:00.358+0000] {processor.py:157} INFO - Started process (PID=53093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:00.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:46:00.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:00.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:00.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:00.408+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:00.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:46:00.424+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:00.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:46:00.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-17T06:46:30.671+0000] {processor.py:157} INFO - Started process (PID=53103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:30.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:46:30.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:30.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:30.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:46:30.703+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:30.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:46:30.714+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:46:30.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:46:30.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-17T06:47:01.059+0000] {processor.py:157} INFO - Started process (PID=53113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:01.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:47:01.074+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:01.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:01.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:01.149+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:01.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:47:01.168+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:01.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:47:01.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-17T06:47:31.413+0000] {processor.py:157} INFO - Started process (PID=53123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:31.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:47:31.422+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:31.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:31.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:47:31.506+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:31.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:47:31.527+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:47:31.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:47:31.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T06:48:01.774+0000] {processor.py:157} INFO - Started process (PID=53133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:01.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:48:01.782+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:01.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:01.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:01.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:01.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:48:01.902+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:01.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:48:01.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T06:48:32.112+0000] {processor.py:157} INFO - Started process (PID=53143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:32.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:48:32.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:32.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:32.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:48:32.190+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:32.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:48:32.205+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:48:32.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:48:32.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T06:49:02.742+0000] {processor.py:157} INFO - Started process (PID=53152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:02.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:49:02.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:02.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:02.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:02.805+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:02.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:49:02.830+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:02.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:49:02.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T06:49:33.167+0000] {processor.py:157} INFO - Started process (PID=53163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:33.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:49:33.171+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:33.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:33.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:49:33.220+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:33.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:49:33.238+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:49:33.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:49:33.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T06:50:03.717+0000] {processor.py:157} INFO - Started process (PID=53173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:03.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:50:03.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:03.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:03.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:03.855+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:03.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:50:03.878+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:03.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:50:03.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-17T06:50:34.076+0000] {processor.py:157} INFO - Started process (PID=53183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:34.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:50:34.088+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:34.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:34.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:50:34.183+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:34.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:50:34.205+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:50:34.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:50:34.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T06:51:04.683+0000] {processor.py:157} INFO - Started process (PID=53193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:04.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:51:04.695+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:04.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:04.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:04.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:04.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:51:04.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:04.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:51:04.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.286 seconds
[2024-09-17T06:51:35.255+0000] {processor.py:157} INFO - Started process (PID=53203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:35.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:51:35.263+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:35.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:35.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:51:35.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:35.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:51:35.376+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:51:35.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:51:35.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T06:52:05.665+0000] {processor.py:157} INFO - Started process (PID=53213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:05.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:52:05.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:05.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:05.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:05.757+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:05.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:52:05.773+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:05.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:52:05.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T06:52:36.022+0000] {processor.py:157} INFO - Started process (PID=53223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:36.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:52:36.029+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:36.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:36.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:52:36.113+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:36.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:52:36.130+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:52:36.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:52:36.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T06:53:06.355+0000] {processor.py:157} INFO - Started process (PID=53233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:06.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:53:06.363+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:06.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:06.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:06.432+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:06.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:53:06.459+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:06.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:53:06.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T06:53:36.931+0000] {processor.py:157} INFO - Started process (PID=53243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:36.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:53:36.937+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:36.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:36.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:53:37.015+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:37.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:53:37.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:53:37.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:53:37.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T06:54:07.298+0000] {processor.py:157} INFO - Started process (PID=53253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:07.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:54:07.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:07.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:07.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:07.400+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:07.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:54:07.426+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:07.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:54:07.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T06:54:37.861+0000] {processor.py:157} INFO - Started process (PID=53263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:37.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:54:37.869+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:37.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:37.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:54:37.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:37.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:54:38.006+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:54:38.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:54:38.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-17T06:55:08.171+0000] {processor.py:157} INFO - Started process (PID=53272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:08.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:55:08.179+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:08.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:08.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:08.251+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:08.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:55:08.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:08.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:55:08.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T06:55:38.789+0000] {processor.py:157} INFO - Started process (PID=53282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:38.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:55:38.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:38.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:38.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:55:38.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:38.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:55:38.890+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:55:38.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:55:38.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T06:56:09.191+0000] {processor.py:157} INFO - Started process (PID=53293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:09.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:56:09.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:09.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:09.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:09.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:09.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:56:09.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:09.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:56:09.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T06:56:39.539+0000] {processor.py:157} INFO - Started process (PID=53303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:39.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:56:39.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:39.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:39.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:56:39.672+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:39.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:56:39.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:56:39.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:56:39.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-17T06:57:09.955+0000] {processor.py:157} INFO - Started process (PID=53312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:09.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:57:09.964+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:09.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:09.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:10.038+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:10.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:57:10.066+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:10.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:57:10.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T06:57:40.436+0000] {processor.py:157} INFO - Started process (PID=53323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:40.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:57:40.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:40.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:40.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:57:40.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:40.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:57:40.566+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:57:40.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:57:40.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T06:58:10.949+0000] {processor.py:157} INFO - Started process (PID=53333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:10.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:58:10.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:10.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:10.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:11.013+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:11.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:58:11.035+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:11.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:58:11.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T06:58:41.244+0000] {processor.py:157} INFO - Started process (PID=53343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:41.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:58:41.251+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:41.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:41.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:58:41.300+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:41.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:58:41.316+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:58:41.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:58:41.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T06:59:11.696+0000] {processor.py:157} INFO - Started process (PID=53353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:11.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:59:11.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:11.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:11.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:11.766+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:11.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:59:11.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:11.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:59:11.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T06:59:42.056+0000] {processor.py:157} INFO - Started process (PID=53363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:42.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T06:59:42.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:42.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:42.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T06:59:42.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:42.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T06:59:42.162+0000] {logging_mixin.py:151} INFO - [2024-09-17T06:59:42.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T06:59:42.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T07:00:12.403+0000] {processor.py:157} INFO - Started process (PID=53373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:12.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:00:12.410+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:12.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:12.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:12.484+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:12.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:00:12.500+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:12.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:00:12.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T07:00:42.782+0000] {processor.py:157} INFO - Started process (PID=53383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:42.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:00:42.789+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:42.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:42.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:00:42.856+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:42.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:00:42.875+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:00:42.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:00:42.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T07:01:13.277+0000] {processor.py:157} INFO - Started process (PID=53392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:13.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:01:13.284+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:13.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:13.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:13.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:13.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:01:13.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:13.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:01:13.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T07:01:43.625+0000] {processor.py:157} INFO - Started process (PID=53403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:43.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:01:43.634+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:43.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:43.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:01:43.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:43.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:01:43.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:01:43.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:01:43.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T07:02:13.996+0000] {processor.py:157} INFO - Started process (PID=53412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:13.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:02:14.001+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:14.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:14.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:14.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:14.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:02:14.099+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:14.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:02:14.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T07:02:44.288+0000] {processor.py:157} INFO - Started process (PID=53423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:44.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:02:44.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:44.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:44.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:02:44.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:44.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:02:44.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:02:44.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:02:44.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T07:03:14.722+0000] {processor.py:157} INFO - Started process (PID=53433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:14.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:03:14.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:14.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:14.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:14.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:14.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:03:14.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:14.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:03:14.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T07:03:45.046+0000] {processor.py:157} INFO - Started process (PID=53443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:45.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:03:45.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:45.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:45.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:03:45.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:45.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:03:45.094+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:03:45.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:03:45.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-17T07:04:15.394+0000] {processor.py:157} INFO - Started process (PID=53453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:15.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:04:15.397+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:15.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:15.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:15.469+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:15.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:04:15.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:15.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:04:15.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T07:04:45.876+0000] {processor.py:157} INFO - Started process (PID=53463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:45.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:04:45.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:45.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:45.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:04:45.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:45.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:04:45.971+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:04:45.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:04:45.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T07:05:16.365+0000] {processor.py:157} INFO - Started process (PID=53473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:16.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:05:16.384+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:16.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:16.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:16.451+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:16.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:05:16.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:16.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:05:16.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T07:05:46.742+0000] {processor.py:157} INFO - Started process (PID=53483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:46.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:05:46.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:46.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:46.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:05:46.822+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:46.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:05:46.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:05:46.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:05:46.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T07:06:17.226+0000] {processor.py:157} INFO - Started process (PID=53493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:17.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:06:17.232+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:17.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:17.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:17.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:17.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:06:17.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:17.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:06:17.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T07:06:47.545+0000] {processor.py:157} INFO - Started process (PID=53503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:47.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:06:47.554+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:47.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:47.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:06:47.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:47.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:06:47.644+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:06:47.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:06:47.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T07:07:17.844+0000] {processor.py:157} INFO - Started process (PID=53513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:17.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:07:17.849+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:17.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:17.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:17.893+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:17.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:07:17.908+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:17.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:07:17.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T07:07:48.243+0000] {processor.py:157} INFO - Started process (PID=53523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:48.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:07:48.246+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:48.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:48.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:07:48.283+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:48.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:07:48.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:07:48.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:07:48.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-17T07:08:18.642+0000] {processor.py:157} INFO - Started process (PID=53533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:18.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:08:18.653+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:18.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:18.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:18.692+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:18.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:08:18.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:18.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:08:18.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T07:08:48.935+0000] {processor.py:157} INFO - Started process (PID=53543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:48.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:08:48.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:48.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:48.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:08:48.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:48.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:08:49.009+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:08:49.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:08:49.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T07:09:19.239+0000] {processor.py:157} INFO - Started process (PID=53553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:19.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:09:19.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:19.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:19.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:19.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:19.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:09:19.330+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:19.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:09:19.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T07:09:49.664+0000] {processor.py:157} INFO - Started process (PID=53563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:49.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:09:49.686+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:49.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:49.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:09:49.740+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:49.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:09:49.757+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:09:49.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:09:49.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T07:10:19.942+0000] {processor.py:157} INFO - Started process (PID=53573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:19.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:10:19.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:19.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:19.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:19.974+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:19.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:10:19.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:19.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:10:19.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T07:10:50.391+0000] {processor.py:157} INFO - Started process (PID=53583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:50.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:10:50.398+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:50.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:50.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:10:50.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:50.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:10:50.485+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:10:50.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:10:50.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T07:11:20.705+0000] {processor.py:157} INFO - Started process (PID=53593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:20.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:11:20.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:20.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:20.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:20.809+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:20.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:11:20.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:20.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:11:20.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T07:11:51.053+0000] {processor.py:157} INFO - Started process (PID=53603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:51.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:11:51.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:51.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:51.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:11:51.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:51.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:11:51.160+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:11:51.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:11:51.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T07:12:21.450+0000] {processor.py:157} INFO - Started process (PID=53613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:21.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:12:21.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:21.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:21.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:21.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:21.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:12:21.539+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:21.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:12:21.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T07:12:51.761+0000] {processor.py:157} INFO - Started process (PID=53623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:51.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:12:51.771+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:51.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:51.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:12:51.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:51.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:12:51.858+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:12:51.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:12:51.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:13:22.089+0000] {processor.py:157} INFO - Started process (PID=53633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:22.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:13:22.096+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:22.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:22.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:22.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:22.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:13:22.186+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:22.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:13:22.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T07:13:52.534+0000] {processor.py:157} INFO - Started process (PID=53643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:13:52.539+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:52.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:52.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:13:52.581+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:52.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:13:52.597+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:13:52.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:13:52.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T07:14:22.849+0000] {processor.py:157} INFO - Started process (PID=53653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:22.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:14:22.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:22.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:22.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:22.896+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:22.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:14:22.912+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:22.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:14:22.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-17T07:14:53.196+0000] {processor.py:157} INFO - Started process (PID=53663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:53.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:14:53.201+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:53.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:53.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:14:53.249+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:53.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:14:53.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:14:53.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:14:53.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T07:15:23.508+0000] {processor.py:157} INFO - Started process (PID=53673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:23.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:15:23.520+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:23.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:23.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:23.595+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:23.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:15:23.614+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:23.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:15:23.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:15:53.825+0000] {processor.py:157} INFO - Started process (PID=53683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:53.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:15:53.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:53.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:53.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:15:53.911+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:53.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:15:53.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:15:53.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:15:53.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T07:16:24.195+0000] {processor.py:157} INFO - Started process (PID=53692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:24.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:16:24.202+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:24.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:24.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:24.288+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:24.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:16:24.309+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:24.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:16:24.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T07:16:54.554+0000] {processor.py:157} INFO - Started process (PID=53703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:54.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:16:54.559+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:54.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:54.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:16:54.607+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:54.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:16:54.624+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:16:54.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:16:54.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T07:17:24.990+0000] {processor.py:157} INFO - Started process (PID=53712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:24.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:17:25.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:25.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:25.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:25.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:25.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:17:25.101+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:25.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:17:25.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T07:17:55.438+0000] {processor.py:157} INFO - Started process (PID=53723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:55.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:17:55.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:55.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:55.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:17:55.481+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:55.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:17:55.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:17:55.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:17:55.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T07:18:25.833+0000] {processor.py:157} INFO - Started process (PID=53733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:25.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:18:25.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:25.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:25.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:25.915+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:25.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:18:25.931+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:25.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:18:25.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T07:18:56.180+0000] {processor.py:157} INFO - Started process (PID=53742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:56.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:18:56.187+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:56.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:56.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:18:56.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:56.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:18:56.274+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:18:56.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:18:56.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T07:19:26.535+0000] {processor.py:157} INFO - Started process (PID=53753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:26.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:19:26.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:26.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:26.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:26.609+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:26.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:19:26.629+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:26.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:19:26.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T07:19:57.019+0000] {processor.py:157} INFO - Started process (PID=53763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:57.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:19:57.025+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:57.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:57.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:19:57.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:57.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:19:57.107+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:19:57.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:19:57.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T07:20:27.506+0000] {processor.py:157} INFO - Started process (PID=53771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:27.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:20:27.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:27.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:27.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:27.590+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:27.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:20:27.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:27.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:20:27.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T07:20:57.844+0000] {processor.py:157} INFO - Started process (PID=53783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:57.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:20:57.854+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:57.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:57.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:20:57.925+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:57.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:20:57.947+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:20:57.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:20:57.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T07:21:28.316+0000] {processor.py:157} INFO - Started process (PID=53793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:28.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:21:28.326+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:28.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:28.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:28.396+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:28.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:21:28.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:28.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:21:28.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T07:21:58.770+0000] {processor.py:157} INFO - Started process (PID=53802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:58.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:21:58.774+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:58.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:58.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:21:58.821+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:58.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:21:58.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:21:58.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:21:58.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T07:22:29.178+0000] {processor.py:157} INFO - Started process (PID=53813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:29.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:22:29.197+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:29.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:29.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:29.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:29.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:22:29.273+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:29.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:22:29.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T07:22:59.545+0000] {processor.py:157} INFO - Started process (PID=53823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:59.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:22:59.550+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:59.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:59.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:22:59.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:59.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:22:59.600+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:22:59.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:22:59.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-17T07:23:29.902+0000] {processor.py:157} INFO - Started process (PID=53833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:23:29.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:23:29.908+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:23:29.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:23:29.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:23:29.970+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:23:29.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:23:29.988+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:23:29.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:23:30.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T07:24:00.201+0000] {processor.py:157} INFO - Started process (PID=53843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:00.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:24:00.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:00.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:00.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:00.246+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:00.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:24:00.257+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:00.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:24:00.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-17T07:24:30.574+0000] {processor.py:157} INFO - Started process (PID=53852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:30.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:24:30.579+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:30.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:30.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:24:30.645+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:30.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:24:30.661+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:24:30.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:24:30.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T07:25:01.083+0000] {processor.py:157} INFO - Started process (PID=53861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:01.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:25:01.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:01.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:01.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:01.171+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:01.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:25:01.201+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:01.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:25:01.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T07:25:31.562+0000] {processor.py:157} INFO - Started process (PID=53872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:31.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:25:31.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:31.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:31.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:25:31.660+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:31.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:25:31.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:25:31.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:25:31.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T07:26:02.049+0000] {processor.py:157} INFO - Started process (PID=53881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:02.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:26:02.057+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:02.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:02.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:02.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:02.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:26:02.160+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:02.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:26:02.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T07:26:32.572+0000] {processor.py:157} INFO - Started process (PID=53893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:32.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:26:32.587+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:32.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:32.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:26:32.651+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:32.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:26:32.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:26:32.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:26:32.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T07:27:02.961+0000] {processor.py:157} INFO - Started process (PID=53903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:02.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:27:02.969+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:02.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:03.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:03.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:03.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:27:03.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:03.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:27:03.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T07:27:33.304+0000] {processor.py:157} INFO - Started process (PID=53913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:33.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:27:33.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:33.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:33.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:27:33.399+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:33.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:27:33.430+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:27:33.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:27:33.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-17T07:28:03.650+0000] {processor.py:157} INFO - Started process (PID=53922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:03.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:28:03.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:03.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:03.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:03.745+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:03.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:28:03.768+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:03.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:28:03.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T07:28:34.031+0000] {processor.py:157} INFO - Started process (PID=53932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:34.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:28:34.051+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:34.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:34.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:28:34.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:34.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:28:34.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:28:34.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:28:34.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-17T07:29:04.317+0000] {processor.py:157} INFO - Started process (PID=53943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:04.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:29:04.323+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:04.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:04.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:04.383+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:04.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:29:04.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:04.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:29:04.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T07:29:34.706+0000] {processor.py:157} INFO - Started process (PID=53953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:34.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:29:34.714+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:34.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:34.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:29:34.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:34.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:29:34.812+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:29:34.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:29:34.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T07:30:05.097+0000] {processor.py:157} INFO - Started process (PID=53963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:05.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:30:05.105+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:05.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:05.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:05.176+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:05.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:30:05.194+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:05.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:30:05.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:30:35.392+0000] {processor.py:157} INFO - Started process (PID=53973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:35.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:30:35.400+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:35.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:35.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:30:35.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:35.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:30:35.495+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:30:35.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:30:35.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T07:31:05.713+0000] {processor.py:157} INFO - Started process (PID=53982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:05.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:31:05.718+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:05.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:05.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:05.774+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:05.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:31:05.802+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:05.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:31:05.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T07:31:36.079+0000] {processor.py:157} INFO - Started process (PID=53993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:36.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:31:36.092+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:36.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:36.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:31:36.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:36.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:31:36.183+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:31:36.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:31:36.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T07:32:06.382+0000] {processor.py:157} INFO - Started process (PID=54003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:06.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:32:06.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:06.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:06.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:06.422+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:06.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:32:06.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:06.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:32:06.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-17T07:32:36.696+0000] {processor.py:157} INFO - Started process (PID=54013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:36.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:32:36.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:36.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:36.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:32:36.760+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:36.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:32:36.774+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:32:36.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:32:36.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T07:33:07.077+0000] {processor.py:157} INFO - Started process (PID=54022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:07.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:33:07.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:07.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:07.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:07.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:07.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:33:07.163+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:07.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:33:07.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T07:33:37.449+0000] {processor.py:157} INFO - Started process (PID=54032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:37.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:33:37.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:37.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:37.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:33:37.544+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:37.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:33:37.593+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:33:37.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:33:37.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-17T07:34:07.800+0000] {processor.py:157} INFO - Started process (PID=54043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:07.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:34:07.811+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:07.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:07.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:07.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:07.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:34:07.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:07.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:34:07.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T07:34:38.181+0000] {processor.py:157} INFO - Started process (PID=54052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:38.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:34:38.190+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:38.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:38.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:34:38.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:38.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:34:38.259+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:34:38.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:34:38.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T07:35:08.556+0000] {processor.py:157} INFO - Started process (PID=54061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:08.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:35:08.561+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:08.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:08.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:08.624+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:08.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:35:08.656+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:08.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:35:08.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T07:35:39.376+0000] {processor.py:157} INFO - Started process (PID=54073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:39.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:35:39.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:39.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:39.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:35:39.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:39.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:35:39.523+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:35:39.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:35:39.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-17T07:36:09.669+0000] {processor.py:157} INFO - Started process (PID=54082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:09.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:36:09.685+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:09.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:09.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:09.752+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:09.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:36:09.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:09.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:36:09.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T07:36:40.173+0000] {processor.py:157} INFO - Started process (PID=54092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:40.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:36:40.179+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:40.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:40.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:36:40.262+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:40.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:36:40.280+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:36:40.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:36:40.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T07:37:10.520+0000] {processor.py:157} INFO - Started process (PID=54103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:10.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:37:10.526+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:10.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:10.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:10.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:10.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:37:10.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:10.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:37:10.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T07:37:40.853+0000] {processor.py:157} INFO - Started process (PID=54113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:40.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:37:40.872+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:40.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:40.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:37:40.952+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:40.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:37:40.980+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:37:40.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:37:40.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T07:38:11.194+0000] {processor.py:157} INFO - Started process (PID=54122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:11.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:38:11.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:11.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:11.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:11.277+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:11.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:38:11.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:11.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:38:11.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T07:38:41.611+0000] {processor.py:157} INFO - Started process (PID=54133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:41.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:38:41.620+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:41.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:41.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:38:41.697+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:41.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:38:41.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:38:41.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:38:41.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T07:39:11.934+0000] {processor.py:157} INFO - Started process (PID=54142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:11.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:39:11.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:11.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:11.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:12.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:12.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:39:12.029+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:12.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:39:12.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T07:39:42.328+0000] {processor.py:157} INFO - Started process (PID=54153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:42.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:39:42.337+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:42.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:42.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:39:42.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:42.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:39:42.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:39:42.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:39:42.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:40:12.696+0000] {processor.py:157} INFO - Started process (PID=54163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:12.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:40:12.703+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:12.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:12.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:12.783+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:12.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:40:12.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:12.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:40:12.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T07:40:43.022+0000] {processor.py:157} INFO - Started process (PID=54172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:43.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:40:43.036+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:43.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:43.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:40:43.097+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:43.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:40:43.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:40:43.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:40:43.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T07:41:13.423+0000] {processor.py:157} INFO - Started process (PID=54183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:13.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:41:13.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:13.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:13.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:13.511+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:13.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:41:13.529+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:13.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:41:13.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T07:41:43.890+0000] {processor.py:157} INFO - Started process (PID=54192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:43.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:41:43.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:43.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:43.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:41:43.979+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:43.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:41:43.996+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:41:43.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:41:44.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T07:42:14.214+0000] {processor.py:157} INFO - Started process (PID=54203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:14.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:42:14.244+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:14.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:14.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:14.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:14.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:42:14.337+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:14.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:42:14.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T07:42:44.699+0000] {processor.py:157} INFO - Started process (PID=54213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:44.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:42:44.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:44.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:44.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:42:44.794+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:44.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:42:44.810+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:42:44.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:42:44.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:43:15.193+0000] {processor.py:157} INFO - Started process (PID=54223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:15.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:43:15.207+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:15.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:15.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:15.276+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:15.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:43:15.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:15.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:43:15.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T07:43:45.508+0000] {processor.py:157} INFO - Started process (PID=54233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:45.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:43:45.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:45.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:45.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:43:45.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:45.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:43:45.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:43:45.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:43:45.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T07:44:15.841+0000] {processor.py:157} INFO - Started process (PID=54243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:15.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:44:15.859+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:15.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:15.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:15.925+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:15.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:44:15.942+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:15.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:44:15.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T07:44:46.205+0000] {processor.py:157} INFO - Started process (PID=54253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:46.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:44:46.218+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:46.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:46.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:44:46.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:46.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:44:46.300+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:44:46.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:44:46.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T07:45:16.554+0000] {processor.py:157} INFO - Started process (PID=54263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:16.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:45:16.561+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:16.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:16.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:16.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:16.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:45:16.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:16.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:45:16.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T07:45:46.870+0000] {processor.py:157} INFO - Started process (PID=54272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:46.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:45:46.877+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:46.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:46.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:45:46.968+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:46.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:45:46.985+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:45:46.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:45:47.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T07:46:17.226+0000] {processor.py:157} INFO - Started process (PID=54283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:17.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:46:17.231+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:17.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:17.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:17.301+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:17.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:46:17.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:17.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:46:17.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T07:46:47.679+0000] {processor.py:157} INFO - Started process (PID=54293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:47.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:46:47.685+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:47.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:47.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:46:47.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:47.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:46:47.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:46:47.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:46:47.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T07:47:17.975+0000] {processor.py:157} INFO - Started process (PID=54303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:17.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:47:17.979+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:17.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:17.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:18.033+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:18.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:47:18.045+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:18.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:47:18.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-17T07:47:48.322+0000] {processor.py:157} INFO - Started process (PID=54313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:48.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:47:48.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:48.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:48.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:47:48.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:48.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:47:48.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:47:48.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:47:48.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T07:48:18.688+0000] {processor.py:157} INFO - Started process (PID=54323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:18.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:48:18.694+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:18.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:18.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:18.760+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:18.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:48:18.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:18.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:48:18.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T07:48:48.972+0000] {processor.py:157} INFO - Started process (PID=54333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:48.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:48:48.976+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:48.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:48.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:48:49.021+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:49.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:48:49.036+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:48:49.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:48:49.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T07:49:19.373+0000] {processor.py:157} INFO - Started process (PID=54343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:19.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:49:19.383+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:19.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:19.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:19.459+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:19.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:49:19.476+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:19.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:49:19.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T07:49:49.700+0000] {processor.py:157} INFO - Started process (PID=54353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:49.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:49:49.704+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:49.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:49.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:49:49.747+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:49.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:49:49.762+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:49:49.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:49:49.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-17T07:50:20.008+0000] {processor.py:157} INFO - Started process (PID=54362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:20.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:50:20.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:20.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:20.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:20.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:20.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:50:20.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:20.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:50:20.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-17T07:50:50.468+0000] {processor.py:157} INFO - Started process (PID=54373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:50.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:50:50.475+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:50.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:50.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:50:50.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:50.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:50:50.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:50:50.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:50:50.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T07:51:20.825+0000] {processor.py:157} INFO - Started process (PID=54383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:20.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:51:20.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:20.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:20.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:20.902+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:20.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:51:20.938+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:20.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:51:20.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T07:51:51.133+0000] {processor.py:157} INFO - Started process (PID=54393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:51.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:51:51.140+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:51.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:51.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:51:51.204+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:51.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:51:51.226+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:51:51.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:51:51.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T07:52:21.452+0000] {processor.py:157} INFO - Started process (PID=54403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:21.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:52:21.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:21.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:21.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:21.540+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:21.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:52:21.557+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:21.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:52:21.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T07:52:51.843+0000] {processor.py:157} INFO - Started process (PID=54413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:51.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:52:51.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:51.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:51.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:52:51.916+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:51.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:52:51.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:52:51.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:52:51.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T07:53:22.203+0000] {processor.py:157} INFO - Started process (PID=54423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:22.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:53:22.228+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:22.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:22.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:22.296+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:22.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:53:22.313+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:22.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:53:22.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-17T07:53:52.531+0000] {processor.py:157} INFO - Started process (PID=54433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:53:52.544+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:52.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:52.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:53:52.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:52.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:53:52.637+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:53:52.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:53:52.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T07:54:23.040+0000] {processor.py:157} INFO - Started process (PID=54443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:23.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:54:23.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:23.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:23.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:23.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:23.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:54:23.172+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:23.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:54:23.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-09-17T07:54:53.345+0000] {processor.py:157} INFO - Started process (PID=54453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:53.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:54:53.356+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:53.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:53.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:54:53.438+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:53.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:54:53.476+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:54:53.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:54:53.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T07:55:23.809+0000] {processor.py:157} INFO - Started process (PID=54463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:23.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:55:23.823+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:23.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:23.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:23.893+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:23.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:55:23.911+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:23.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:55:23.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T07:55:54.311+0000] {processor.py:157} INFO - Started process (PID=54473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:54.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:55:54.328+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:54.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:54.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:55:54.395+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:54.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:55:54.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:55:54.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:55:54.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T07:56:24.792+0000] {processor.py:157} INFO - Started process (PID=54483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:24.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:56:24.800+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:24.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:24.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:24.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:24.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:56:24.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:24.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:56:24.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T07:56:55.253+0000] {processor.py:157} INFO - Started process (PID=54493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:55.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:56:55.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:55.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:55.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:56:55.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:55.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:56:55.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:56:55.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:56:55.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T07:57:25.611+0000] {processor.py:157} INFO - Started process (PID=54503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:25.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:57:25.618+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:25.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:25.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:25.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:25.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:57:25.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:25.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:57:25.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T07:57:56.038+0000] {processor.py:157} INFO - Started process (PID=54513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:56.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:57:56.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:56.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:56.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:57:56.116+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:56.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:57:56.142+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:57:56.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:57:56.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T07:58:26.310+0000] {processor.py:157} INFO - Started process (PID=54523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:26.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:58:26.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:26.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:26.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:26.393+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:26.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:58:26.411+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:26.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:58:26.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T07:58:56.650+0000] {processor.py:157} INFO - Started process (PID=54532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:56.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:58:56.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:56.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:56.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:58:56.733+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:56.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:58:56.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:58:56.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:58:56.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T07:59:27.129+0000] {processor.py:157} INFO - Started process (PID=54543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:27.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:59:27.137+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:27.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:27.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:27.204+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:27.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:59:27.238+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:27.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:59:27.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T07:59:57.453+0000] {processor.py:157} INFO - Started process (PID=54553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:57.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T07:59:57.457+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:57.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:57.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T07:59:57.510+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:57.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T07:59:57.530+0000] {logging_mixin.py:151} INFO - [2024-09-17T07:59:57.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T07:59:57.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T08:00:27.802+0000] {processor.py:157} INFO - Started process (PID=54563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:27.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:00:27.820+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:27.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:27.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:27.888+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:27.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:00:27.906+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:27.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:00:27.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T08:00:58.280+0000] {processor.py:157} INFO - Started process (PID=54573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:58.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:00:58.286+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:58.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:58.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:00:58.346+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:58.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:00:58.361+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:00:58.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:00:58.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T08:01:28.610+0000] {processor.py:157} INFO - Started process (PID=54582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:28.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:01:28.615+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:28.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:28.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:28.673+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:28.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:01:28.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:28.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:01:28.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T08:01:58.929+0000] {processor.py:157} INFO - Started process (PID=54593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:58.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:01:58.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:58.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:58.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:01:59.022+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:59.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:01:59.042+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:01:59.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:01:59.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T08:02:29.293+0000] {processor.py:157} INFO - Started process (PID=54602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:29.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:02:29.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:29.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:29.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:29.400+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:29.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:02:29.427+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:29.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:02:29.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-17T08:02:59.600+0000] {processor.py:157} INFO - Started process (PID=54613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:59.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:02:59.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:59.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:59.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:02:59.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:59.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:02:59.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:02:59.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:02:59.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T08:03:29.976+0000] {processor.py:157} INFO - Started process (PID=54623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:03:29.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:03:29.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:03:29.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:03:30.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:03:30.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:03:30.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:03:30.079+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:03:30.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:03:30.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T08:04:00.315+0000] {processor.py:157} INFO - Started process (PID=54633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:00.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:04:00.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:00.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:00.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:00.375+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:00.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:04:00.391+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:00.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:04:00.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T08:04:30.720+0000] {processor.py:157} INFO - Started process (PID=54643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:30.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:04:30.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:30.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:30.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:04:30.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:30.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:04:30.825+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:04:30.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:04:30.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T08:05:01.090+0000] {processor.py:157} INFO - Started process (PID=54652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:01.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:05:01.099+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:01.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:01.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:01.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:01.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:05:01.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:01.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:05:01.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T08:05:31.429+0000] {processor.py:157} INFO - Started process (PID=54662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:31.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:05:31.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:31.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:31.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:05:31.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:31.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:05:31.517+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:05:31.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:05:31.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T08:06:01.793+0000] {processor.py:157} INFO - Started process (PID=54673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:01.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:06:01.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:01.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:01.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:01.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:01.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:06:01.883+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:01.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:06:01.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T08:06:32.248+0000] {processor.py:157} INFO - Started process (PID=54683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:32.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:06:32.255+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:32.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:32.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:06:32.311+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:32.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:06:32.327+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:06:32.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:06:32.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T08:07:02.598+0000] {processor.py:157} INFO - Started process (PID=54693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:02.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:07:02.605+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:02.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:02.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:02.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:02.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:07:02.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:02.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:07:02.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T08:07:32.873+0000] {processor.py:157} INFO - Started process (PID=54703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:32.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:07:32.881+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:32.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:32.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:07:32.933+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:32.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:07:32.949+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:07:32.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:07:32.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T08:08:03.226+0000] {processor.py:157} INFO - Started process (PID=54712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:03.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:08:03.234+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:03.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:03.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:03.302+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:03.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:08:03.318+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:03.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:08:03.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T08:08:33.666+0000] {processor.py:157} INFO - Started process (PID=54722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:33.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:08:33.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:33.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:33.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:08:33.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:33.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:08:33.787+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:08:33.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:08:33.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T08:09:03.991+0000] {processor.py:157} INFO - Started process (PID=54732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:03.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:09:03.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:03.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:04.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:04.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:04.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:09:04.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:04.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:09:04.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T08:09:34.372+0000] {processor.py:157} INFO - Started process (PID=54743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:34.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:09:34.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:34.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:34.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:09:34.464+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:34.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:09:34.480+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:09:34.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:09:34.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T08:10:04.717+0000] {processor.py:157} INFO - Started process (PID=54753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:04.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:10:04.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:04.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:04.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:04.766+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:04.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:10:04.782+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:04.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:10:04.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-17T08:10:35.151+0000] {processor.py:157} INFO - Started process (PID=54763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:35.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:10:35.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:35.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:35.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:10:35.230+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:35.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:10:35.247+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:10:35.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:10:35.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T08:11:05.621+0000] {processor.py:157} INFO - Started process (PID=54773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:05.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:11:05.628+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:05.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:05.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:05.709+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:05.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:11:05.728+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:05.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:11:05.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T08:11:36.051+0000] {processor.py:157} INFO - Started process (PID=54783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:36.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:11:36.069+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:36.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:36.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:11:36.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:36.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:11:36.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:11:36.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:11:36.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T08:12:06.382+0000] {processor.py:157} INFO - Started process (PID=54793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:06.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:12:06.389+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:06.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:06.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:06.440+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:06.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:12:06.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:06.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:12:06.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T08:12:36.741+0000] {processor.py:157} INFO - Started process (PID=54803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:36.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:12:36.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:36.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:36.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:12:36.792+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:36.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:12:36.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:12:36.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:12:36.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-17T08:13:07.056+0000] {processor.py:157} INFO - Started process (PID=54813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:07.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:13:07.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:07.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:07.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:07.195+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:07.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:13:07.226+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:07.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:13:07.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-17T08:13:37.383+0000] {processor.py:157} INFO - Started process (PID=54822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:37.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:13:37.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:37.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:37.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:13:37.480+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:37.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:13:37.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:13:37.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:13:37.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T08:14:07.819+0000] {processor.py:157} INFO - Started process (PID=54833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:07.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:14:07.827+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:07.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:07.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:07.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:07.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:14:07.914+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:07.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:14:07.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T08:14:38.122+0000] {processor.py:157} INFO - Started process (PID=54843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:38.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:14:38.140+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:38.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:38.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:14:38.212+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:38.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:14:38.229+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:14:38.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:14:38.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T08:15:08.596+0000] {processor.py:157} INFO - Started process (PID=54853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:08.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:15:08.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:08.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:08.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:08.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:08.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:15:08.709+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:08.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:15:08.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T08:15:39.029+0000] {processor.py:157} INFO - Started process (PID=54863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:39.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:15:39.037+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:39.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:39.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:15:39.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:39.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:15:39.115+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:15:39.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:15:39.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T08:16:09.419+0000] {processor.py:157} INFO - Started process (PID=54873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:09.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:16:09.427+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:09.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:09.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:09.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:09.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:16:09.524+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:09.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:16:09.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T08:16:39.883+0000] {processor.py:157} INFO - Started process (PID=54883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:39.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:16:39.890+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:39.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:39.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:16:39.955+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:39.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:16:39.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:16:39.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:16:39.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T08:17:10.333+0000] {processor.py:157} INFO - Started process (PID=54893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:10.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:17:10.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:10.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:10.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:10.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:10.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:17:10.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:10.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:17:10.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T08:17:40.685+0000] {processor.py:157} INFO - Started process (PID=54903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:40.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:17:40.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:40.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:40.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:17:40.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:40.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:17:40.779+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:17:40.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:17:40.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T08:18:11.033+0000] {processor.py:157} INFO - Started process (PID=54913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:11.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:18:11.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:11.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:11.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:11.117+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:11.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:18:11.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:11.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:18:11.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T08:18:41.371+0000] {processor.py:157} INFO - Started process (PID=54923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:41.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:18:41.381+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:41.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:41.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:18:41.450+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:41.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:18:41.466+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:18:41.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:18:41.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T08:19:11.693+0000] {processor.py:157} INFO - Started process (PID=54933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:11.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:19:11.709+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:11.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:11.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:11.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:11.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:19:11.804+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:11.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:19:11.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T08:19:42.060+0000] {processor.py:157} INFO - Started process (PID=54943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:42.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:19:42.066+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:42.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:42.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:19:42.145+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:42.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:19:42.163+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:19:42.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:19:42.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T08:20:12.529+0000] {processor.py:157} INFO - Started process (PID=54953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:12.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:20:12.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:12.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:12.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:12.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:12.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:20:12.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:12.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:20:12.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T08:20:43.049+0000] {processor.py:157} INFO - Started process (PID=54963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:43.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:20:43.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:43.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:43.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:20:43.132+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:43.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:20:43.149+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:20:43.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:20:43.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T08:21:13.352+0000] {processor.py:157} INFO - Started process (PID=54973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:13.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:21:13.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:13.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:13.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:13.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:13.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:21:13.460+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:13.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:21:13.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T08:21:43.821+0000] {processor.py:157} INFO - Started process (PID=54983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:43.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:21:43.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:43.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:43.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:21:43.905+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:43.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:21:43.921+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:21:43.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:21:43.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T08:22:14.139+0000] {processor.py:157} INFO - Started process (PID=54993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:22:14.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:22:14.146+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:22:14.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:22:14.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:22:14.191+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:22:14.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:22:14.208+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:22:14.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:22:14.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-17T08:23:03.001+0000] {processor.py:157} INFO - Started process (PID=55003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:03.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:23:03.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:03.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:03.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:03.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:03.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:23:03.096+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:03.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:23:03.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T08:23:33.335+0000] {processor.py:157} INFO - Started process (PID=55015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:33.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T08:23:33.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:33.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:33.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T08:23:33.387+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:33.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T08:23:33.398+0000] {logging_mixin.py:151} INFO - [2024-09-17T08:23:33.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T08:23:33.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T09:28:03.426+0000] {processor.py:157} INFO - Started process (PID=55026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T09:28:03.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T09:28:03.453+0000] {logging_mixin.py:151} INFO - [2024-09-17T09:28:03.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T09:28:03.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T09:28:03.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T09:28:03.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T09:28:03.722+0000] {logging_mixin.py:151} INFO - [2024-09-17T09:28:03.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T09:28:03.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.344 seconds
[2024-09-17T10:23:37.839+0000] {processor.py:157} INFO - Started process (PID=55035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:23:37.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T10:23:37.845+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:23:37.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:23:37.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:23:37.932+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:23:37.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T10:23:37.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:23:37.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T10:23:37.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-17T10:24:08.366+0000] {processor.py:157} INFO - Started process (PID=55047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:24:08.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T10:24:08.374+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:24:08.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:24:08.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:24:08.438+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:24:08.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T10:24:08.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:24:08.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T10:24:08.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T10:39:59.815+0000] {processor.py:157} INFO - Started process (PID=55057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:39:59.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T10:39:59.838+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:39:59.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:39:59.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:39:59.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:39:59.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T10:39:59.971+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:39:59.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T10:39:59.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-17T10:57:37.319+0000] {processor.py:157} INFO - Started process (PID=55067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:57:37.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T10:57:37.326+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:57:37.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:57:37.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T10:57:37.410+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:57:37.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T10:57:37.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T10:57:37.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T10:57:37.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T11:24:52.812+0000] {processor.py:157} INFO - Started process (PID=55077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:24:52.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T11:24:52.818+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:24:52.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:24:52.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:24:52.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:24:52.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T11:24:52.900+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:24:52.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T11:24:52.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T11:40:27.264+0000] {processor.py:157} INFO - Started process (PID=55088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:40:27.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T11:40:27.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:40:27.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:40:27.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T11:40:27.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:40:27.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T11:40:27.410+0000] {logging_mixin.py:151} INFO - [2024-09-17T11:40:27.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T11:40:27.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-17T12:25:49.453+0000] {processor.py:157} INFO - Started process (PID=55098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:25:49.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T12:25:49.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:25:49.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:25:49.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:25:49.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:25:49.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T12:25:49.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:25:49.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T12:25:49.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T12:44:08.774+0000] {processor.py:157} INFO - Started process (PID=55108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:44:08.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T12:44:08.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:44:08.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:44:08.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:44:08.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:44:08.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T12:44:08.921+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:44:08.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T12:44:08.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-17T12:57:33.457+0000] {processor.py:157} INFO - Started process (PID=55120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:57:33.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T12:57:33.468+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:57:33.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:57:33.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T12:57:33.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:57:33.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T12:57:33.629+0000] {logging_mixin.py:151} INFO - [2024-09-17T12:57:33.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T12:57:33.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-17T13:00:10.166+0000] {processor.py:157} INFO - Started process (PID=55129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:10.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T13:00:10.176+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:10.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:10.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:10.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:10.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T13:00:10.301+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:10.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T13:00:10.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T13:00:40.619+0000] {processor.py:157} INFO - Started process (PID=55141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:40.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T13:00:40.625+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:40.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:40.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:00:40.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:40.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T13:00:40.705+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:00:40.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T13:00:40.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T13:26:47.757+0000] {processor.py:157} INFO - Started process (PID=55151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:26:47.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T13:26:47.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:26:47.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:26:47.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:26:47.816+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:26:47.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T13:26:47.844+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:26:47.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T13:26:47.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T13:27:18.193+0000] {processor.py:157} INFO - Started process (PID=55160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:27:18.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T13:27:18.199+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:27:18.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:27:18.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T13:27:18.278+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:27:18.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T13:27:18.311+0000] {logging_mixin.py:151} INFO - [2024-09-17T13:27:18.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T13:27:18.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T14:27:44.190+0000] {processor.py:157} INFO - Started process (PID=55172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:27:44.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T14:27:44.205+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:27:44.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:27:44.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:27:44.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:27:44.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T14:27:44.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:27:44.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T14:27:44.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T14:28:14.511+0000] {processor.py:157} INFO - Started process (PID=55183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:28:14.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T14:28:14.518+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:28:14.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:28:14.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T14:28:14.570+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:28:14.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T14:28:14.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T14:28:14.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T14:28:14.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T15:14:47.608+0000] {processor.py:157} INFO - Started process (PID=55193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:14:47.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:14:47.615+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:14:47.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:14:47.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:14:47.681+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:14:47.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:14:47.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:14:47.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:14:47.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T15:15:18.148+0000] {processor.py:157} INFO - Started process (PID=55203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:15:18.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:15:18.175+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:15:18.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:15:18.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:15:18.242+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:15:18.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:15:18.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:15:18.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:15:18.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T15:21:44.150+0000] {processor.py:157} INFO - Started process (PID=55214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:21:44.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:21:44.161+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:21:44.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:21:44.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:21:44.231+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:21:44.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:21:44.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:21:44.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:21:44.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T15:26:58.989+0000] {processor.py:157} INFO - Started process (PID=55225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:26:58.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:26:59.001+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:26:59.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:26:59.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:26:59.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:26:59.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:26:59.086+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:26:59.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:26:59.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T15:27:29.387+0000] {processor.py:157} INFO - Started process (PID=55234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:27:29.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:27:29.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:27:29.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:27:29.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:27:29.470+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:27:29.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:27:29.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:27:29.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:27:29.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T15:28:02.410+0000] {processor.py:157} INFO - Started process (PID=55244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:28:02.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:28:02.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:28:02.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:28:02.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:28:02.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:28:02.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:28:02.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:28:02.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:28:02.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T15:33:46.962+0000] {processor.py:157} INFO - Started process (PID=55255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:33:46.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:33:46.970+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:33:46.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:33:46.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:33:47.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:33:47.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:33:47.070+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:33:47.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:33:47.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T15:34:17.503+0000] {processor.py:157} INFO - Started process (PID=55265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:34:17.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:34:17.512+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:34:17.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:34:17.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:34:17.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:34:17.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:34:17.600+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:34:17.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:34:17.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T15:56:38.829+0000] {processor.py:157} INFO - Started process (PID=55274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:56:38.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:56:38.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:56:38.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:56:38.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:56:38.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:56:38.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:56:38.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:56:38.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:56:38.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T15:57:09.223+0000] {processor.py:157} INFO - Started process (PID=55285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:57:09.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T15:57:09.238+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:57:09.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:57:09.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T15:57:09.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:57:09.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T15:57:09.373+0000] {logging_mixin.py:151} INFO - [2024-09-17T15:57:09.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T15:57:09.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-17T16:00:17.405+0000] {processor.py:157} INFO - Started process (PID=55297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:17.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:00:17.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:17.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:17.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:17.493+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:17.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:00:17.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:17.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:00:17.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T16:00:47.926+0000] {processor.py:157} INFO - Started process (PID=55307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:47.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:00:47.933+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:47.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:47.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:00:47.985+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:47.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:00:48.006+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:00:48.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:00:48.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T16:01:18.262+0000] {processor.py:157} INFO - Started process (PID=55317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:18.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:01:18.267+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:18.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:18.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:18.327+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:18.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:01:18.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:18.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:01:18.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T16:01:48.624+0000] {processor.py:157} INFO - Started process (PID=55327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:48.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:01:48.628+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:48.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:48.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:01:48.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:48.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:01:48.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:01:48.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:01:48.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T16:02:18.964+0000] {processor.py:157} INFO - Started process (PID=55337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:18.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:02:18.969+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:18.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:18.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:19.029+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:19.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:02:19.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:19.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:02:19.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T16:02:49.310+0000] {processor.py:157} INFO - Started process (PID=55347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:49.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:02:49.322+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:49.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:49.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:02:49.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:49.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:02:49.430+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:02:49.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:02:49.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T16:03:19.607+0000] {processor.py:157} INFO - Started process (PID=55357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:19.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:03:19.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:19.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:19.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:19.673+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:19.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:03:19.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:19.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:03:19.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T16:03:49.977+0000] {processor.py:157} INFO - Started process (PID=55367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:49.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:03:49.984+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:49.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:50.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:03:50.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:50.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:03:50.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:03:50.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:03:50.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T16:04:20.366+0000] {processor.py:157} INFO - Started process (PID=55377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:20.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:04:20.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:20.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:20.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:20.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:20.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:04:20.445+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:20.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:04:20.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T16:04:50.667+0000] {processor.py:157} INFO - Started process (PID=55387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:50.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:04:50.670+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:50.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:50.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:04:50.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:50.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:04:50.714+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:04:50.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:04:50.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T16:05:21.094+0000] {processor.py:157} INFO - Started process (PID=55397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:21.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:05:21.100+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:21.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:21.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:21.160+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:21.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:05:21.179+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:21.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:05:21.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T16:05:51.517+0000] {processor.py:157} INFO - Started process (PID=55407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:51.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:05:51.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:51.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:51.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:05:51.593+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:51.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:05:51.610+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:05:51.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:05:51.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T16:06:21.884+0000] {processor.py:157} INFO - Started process (PID=55417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:21.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:06:21.891+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:21.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:21.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:21.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:21.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:06:21.960+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:21.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:06:21.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T16:06:52.288+0000] {processor.py:157} INFO - Started process (PID=55427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:52.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:06:52.297+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:52.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:52.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:06:52.334+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:52.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:06:52.347+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:06:52.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:06:52.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-17T16:07:22.707+0000] {processor.py:157} INFO - Started process (PID=55437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:22.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:07:22.711+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:22.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:22.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:22.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:22.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:07:22.781+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:22.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:07:22.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-17T16:07:53.038+0000] {processor.py:157} INFO - Started process (PID=55447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:53.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:07:53.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:53.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:53.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:07:53.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:53.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:07:53.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:07:53.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:07:53.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T16:08:23.483+0000] {processor.py:157} INFO - Started process (PID=55457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:23.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:08:23.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:23.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:23.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:23.560+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:23.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:08:23.586+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:23.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:08:23.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T16:08:53.946+0000] {processor.py:157} INFO - Started process (PID=55467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:53.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:08:53.949+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:53.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:53.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:08:53.981+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:53.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:08:53.993+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:08:53.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:08:54.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T16:09:24.398+0000] {processor.py:157} INFO - Started process (PID=55477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:24.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:09:24.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:24.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:24.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:24.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:24.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:09:24.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:24.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:09:24.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T16:09:54.752+0000] {processor.py:157} INFO - Started process (PID=55487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:54.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:09:54.755+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:54.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:54.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:09:54.785+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:54.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:09:54.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:09:54.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:09:54.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T16:10:25.187+0000] {processor.py:157} INFO - Started process (PID=55497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:25.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:10:25.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:25.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:25.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:25.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:25.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:10:25.288+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:25.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:10:25.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T16:10:55.487+0000] {processor.py:157} INFO - Started process (PID=55507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:55.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:10:55.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:55.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:55.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:10:55.521+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:55.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:10:55.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:10:55.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:10:55.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T16:11:25.954+0000] {processor.py:157} INFO - Started process (PID=55517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:25.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:11:25.965+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:25.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:25.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:26.032+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:26.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:11:26.047+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:26.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:11:26.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T16:11:56.254+0000] {processor.py:157} INFO - Started process (PID=55527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:56.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:11:56.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:56.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:56.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:11:56.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:56.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:11:56.322+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:11:56.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:11:56.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-17T16:12:26.691+0000] {processor.py:157} INFO - Started process (PID=55537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:26.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:12:26.694+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:26.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:26.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:26.727+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:26.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:12:26.739+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:26.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:12:26.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-17T16:12:57.082+0000] {processor.py:157} INFO - Started process (PID=55546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:57.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:12:57.095+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:57.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:57.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:12:57.156+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:57.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:12:57.182+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:12:57.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:12:57.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T16:13:27.579+0000] {processor.py:157} INFO - Started process (PID=55557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:27.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:13:27.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:27.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:27.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:27.654+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:27.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:13:27.670+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:27.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:13:27.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T16:13:58.057+0000] {processor.py:157} INFO - Started process (PID=55567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:58.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:13:58.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:58.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:58.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:13:58.097+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:58.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:13:58.125+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:13:58.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:13:58.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-17T16:14:28.359+0000] {processor.py:157} INFO - Started process (PID=55577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:28.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:14:28.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:28.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:28.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:28.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:28.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:14:28.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:28.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:14:28.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-17T16:14:58.692+0000] {processor.py:157} INFO - Started process (PID=55587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:58.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:14:58.698+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:58.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:58.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:14:58.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:58.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:14:58.783+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:14:58.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:14:58.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T16:15:29.059+0000] {processor.py:157} INFO - Started process (PID=55597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:29.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:15:29.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:29.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:29.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:29.096+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:29.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:15:29.105+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:29.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:15:29.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-17T16:15:59.476+0000] {processor.py:157} INFO - Started process (PID=55607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:59.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:15:59.480+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:59.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:59.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:15:59.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:59.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:15:59.528+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:15:59.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:15:59.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-17T16:16:29.914+0000] {processor.py:157} INFO - Started process (PID=55617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:16:29.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:16:29.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:16:29.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:16:29.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:16:29.993+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:16:29.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:16:30.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:16:30.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:16:30.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T16:17:00.206+0000] {processor.py:157} INFO - Started process (PID=55627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:00.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:17:00.211+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:00.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:00.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:00.240+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:00.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:17:00.250+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:00.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:17:00.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-17T16:17:30.707+0000] {processor.py:157} INFO - Started process (PID=55637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:30.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:17:30.716+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:30.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:30.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:17:30.769+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:30.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:17:30.794+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:17:30.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:17:30.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T16:18:01.277+0000] {processor.py:157} INFO - Started process (PID=55647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:01.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:18:01.284+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:01.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:01.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:01.350+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:01.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:18:01.379+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:01.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:18:01.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T16:18:31.573+0000] {processor.py:157} INFO - Started process (PID=55657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:31.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:18:31.576+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:31.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:31.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:18:31.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:31.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:18:31.616+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:18:31.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:18:31.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-17T16:19:02.027+0000] {processor.py:157} INFO - Started process (PID=55667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:02.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:19:02.035+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:02.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:02.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:02.096+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:02.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:19:02.118+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:02.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:19:02.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T16:19:32.420+0000] {processor.py:157} INFO - Started process (PID=55677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:32.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:19:32.424+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:32.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:32.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:19:32.453+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:32.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:19:32.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:19:32.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:19:32.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T16:20:02.880+0000] {processor.py:157} INFO - Started process (PID=55687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:02.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:20:02.885+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:02.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:02.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:02.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:02.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:20:02.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:02.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:20:02.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T16:20:33.369+0000] {processor.py:157} INFO - Started process (PID=55697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:33.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:20:33.373+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:33.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:33.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:20:33.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:33.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:20:33.412+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:20:33.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:20:33.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T16:21:03.825+0000] {processor.py:157} INFO - Started process (PID=55707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:03.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:21:03.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:03.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:03.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:03.883+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:03.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:21:03.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:03.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:21:03.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T16:21:34.110+0000] {processor.py:157} INFO - Started process (PID=55717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:34.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:21:34.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:34.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:34.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:21:34.137+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:34.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:21:34.149+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:21:34.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:21:34.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-17T16:22:04.485+0000] {processor.py:157} INFO - Started process (PID=55727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:04.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:22:04.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:04.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:04.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:04.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:04.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:22:04.562+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:04.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:22:04.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-17T16:22:34.837+0000] {processor.py:157} INFO - Started process (PID=55737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:34.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:22:34.840+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:34.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:34.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:22:34.871+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:34.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:22:34.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:22:34.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:22:34.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-17T16:23:05.331+0000] {processor.py:157} INFO - Started process (PID=55747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:05.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:23:05.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:05.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:05.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:05.402+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:05.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:23:05.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:05.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:23:05.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T16:23:35.613+0000] {processor.py:157} INFO - Started process (PID=55757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:35.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:23:35.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:35.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:35.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:23:35.675+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:35.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:23:35.693+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:23:35.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:23:35.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T16:24:06.039+0000] {processor.py:157} INFO - Started process (PID=55767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:06.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:24:06.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:06.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:06.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:06.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:06.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:24:06.086+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:06.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:24:06.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-17T16:24:36.458+0000] {processor.py:157} INFO - Started process (PID=55777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:36.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:24:36.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:36.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:36.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:24:36.534+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:36.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:24:36.553+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:24:36.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:24:36.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T16:25:07.150+0000] {processor.py:157} INFO - Started process (PID=55787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:07.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:25:07.168+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:07.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:07.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:07.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:07.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:25:07.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:07.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:25:07.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.317 seconds
[2024-09-17T16:25:37.713+0000] {processor.py:157} INFO - Started process (PID=55797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:37.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:25:37.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:37.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:37.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:25:37.878+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:37.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:25:37.910+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:25:37.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:25:37.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-09-17T16:26:08.127+0000] {processor.py:157} INFO - Started process (PID=55807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:08.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:26:08.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:08.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:08.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:08.226+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:08.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:26:08.255+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:08.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:26:08.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T16:26:38.534+0000] {processor.py:157} INFO - Started process (PID=55815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:38.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:26:38.544+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:38.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:38.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:26:38.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:38.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:26:38.639+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:26:38.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:26:38.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T16:27:09.119+0000] {processor.py:157} INFO - Started process (PID=55827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:09.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:27:09.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:09.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:09.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:09.208+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:09.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:27:09.237+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:09.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:27:09.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T16:27:39.656+0000] {processor.py:157} INFO - Started process (PID=55837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:39.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:27:39.664+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:39.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:39.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:27:39.744+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:39.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:27:39.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:27:39.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:27:39.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T16:28:10.027+0000] {processor.py:157} INFO - Started process (PID=55847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:10.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:28:10.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:10.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:10.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:10.124+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:10.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:28:10.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:10.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:28:10.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T16:28:40.508+0000] {processor.py:157} INFO - Started process (PID=55857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:40.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:28:40.514+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:40.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:40.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:28:40.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:40.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:28:40.604+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:28:40.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:28:40.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T16:29:10.930+0000] {processor.py:157} INFO - Started process (PID=55867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:10.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:29:10.937+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:10.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:10.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:11.049+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:11.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:29:11.132+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:11.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:29:11.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-09-17T16:29:41.286+0000] {processor.py:157} INFO - Started process (PID=55877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:41.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:29:41.311+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:41.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:41.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:29:41.388+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:41.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:29:41.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:29:41.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:29:41.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T16:30:11.661+0000] {processor.py:157} INFO - Started process (PID=55887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:11.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:30:11.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:11.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:11.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:11.739+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:11.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:30:11.754+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:11.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:30:11.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T16:30:42.021+0000] {processor.py:157} INFO - Started process (PID=55897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:42.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:30:42.027+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:42.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:42.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:30:42.102+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:42.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:30:42.125+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:30:42.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:30:42.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T16:31:12.528+0000] {processor.py:157} INFO - Started process (PID=55907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:12.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:31:12.538+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:12.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:12.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:12.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:12.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:31:12.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:12.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:31:12.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T16:31:42.978+0000] {processor.py:157} INFO - Started process (PID=55917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:42.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:31:42.988+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:42.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:43.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:31:43.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:43.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:31:43.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:31:43.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:31:43.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T16:32:13.347+0000] {processor.py:157} INFO - Started process (PID=55927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:13.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:32:13.356+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:13.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:13.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:13.444+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:13.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:32:13.462+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:13.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:32:13.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T16:32:43.773+0000] {processor.py:157} INFO - Started process (PID=55937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:43.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:32:43.781+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:43.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:43.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:32:43.887+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:43.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:32:43.909+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:32:43.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:32:43.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-17T16:33:14.172+0000] {processor.py:157} INFO - Started process (PID=55947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:14.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:33:14.186+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:14.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:14.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:14.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:14.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:33:14.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:14.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:33:14.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-17T16:33:44.652+0000] {processor.py:157} INFO - Started process (PID=55957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:44.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:33:44.661+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:44.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:44.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:33:44.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:44.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:33:44.748+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:33:44.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:33:44.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T16:34:15.109+0000] {processor.py:157} INFO - Started process (PID=55967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:15.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:34:15.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:15.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:15.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:15.228+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:15.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:34:15.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:15.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:34:15.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-17T16:34:45.563+0000] {processor.py:157} INFO - Started process (PID=55977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:45.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:34:45.571+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:45.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:45.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:34:45.655+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:45.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:34:45.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:34:45.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:34:45.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T16:35:15.958+0000] {processor.py:157} INFO - Started process (PID=55987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:15.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:35:15.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:15.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:16.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:16.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:16.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:35:16.078+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:16.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:35:16.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T16:35:46.894+0000] {processor.py:157} INFO - Started process (PID=55997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:46.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:35:46.912+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:46.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:47.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:35:47.131+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:47.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:35:47.160+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:35:47.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:35:47.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.319 seconds
[2024-09-17T16:36:17.308+0000] {processor.py:157} INFO - Started process (PID=56006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:17.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:36:17.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:17.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:17.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:17.448+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:17.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:36:17.468+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:17.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:36:17.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-17T16:36:47.968+0000] {processor.py:157} INFO - Started process (PID=56017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:47.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:36:47.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:47.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:48.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:36:48.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:48.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:36:48.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:36:48.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:36:48.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T16:37:18.655+0000] {processor.py:157} INFO - Started process (PID=56027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:18.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:37:18.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:18.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:18.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:18.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:18.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:37:18.802+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:18.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:37:18.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-17T16:37:49.123+0000] {processor.py:157} INFO - Started process (PID=56037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:49.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:37:49.131+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:49.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:49.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:37:49.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:49.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:37:49.246+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:37:49.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:37:49.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T16:38:19.675+0000] {processor.py:157} INFO - Started process (PID=56045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:19.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:38:19.682+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:19.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:19.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:19.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:19.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:38:19.804+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:19.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:38:19.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-17T16:38:50.136+0000] {processor.py:157} INFO - Started process (PID=56057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:50.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:38:50.148+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:50.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:50.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:38:50.304+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:50.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:38:50.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:38:50.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:38:50.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-09-17T16:39:20.514+0000] {processor.py:157} INFO - Started process (PID=56067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:20.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:39:20.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:20.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:20.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:20.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:20.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:39:20.633+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:20.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:39:20.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T16:39:50.884+0000] {processor.py:157} INFO - Started process (PID=56077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:50.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:39:50.890+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:50.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:50.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:39:50.969+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:50.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:39:50.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:39:50.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:39:51.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T16:40:21.325+0000] {processor.py:157} INFO - Started process (PID=56087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:21.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:40:21.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:21.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:21.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:21.480+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:21.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:40:21.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:21.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:40:21.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-17T16:40:51.701+0000] {processor.py:157} INFO - Started process (PID=56097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:51.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:40:51.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:51.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:51.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:40:51.773+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:51.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:40:51.788+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:40:51.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:40:51.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T16:41:22.173+0000] {processor.py:157} INFO - Started process (PID=56107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:22.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:41:22.183+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:22.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:22.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:22.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:22.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:41:22.299+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:22.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:41:22.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T16:41:52.547+0000] {processor.py:157} INFO - Started process (PID=56116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:52.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:41:52.554+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:52.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:52.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:41:52.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:52.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:41:52.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:41:52.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:41:52.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T16:42:22.890+0000] {processor.py:157} INFO - Started process (PID=56127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:22.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:42:22.896+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:22.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:22.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:22.982+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:22.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:42:22.998+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:22.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:42:23.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T16:42:53.299+0000] {processor.py:157} INFO - Started process (PID=56137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:53.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:42:53.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:53.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:53.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:42:53.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:53.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:42:53.434+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:42:53.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:42:53.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T16:43:23.594+0000] {processor.py:157} INFO - Started process (PID=56147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:23.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:43:23.599+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:23.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:23.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:23.675+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:23.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:43:23.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:23.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:43:23.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T16:43:54.083+0000] {processor.py:157} INFO - Started process (PID=56157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:54.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:43:54.089+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:54.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:54.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:43:54.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:54.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:43:54.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:43:54.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:43:54.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T16:44:24.490+0000] {processor.py:157} INFO - Started process (PID=56167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:24.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:44:24.495+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:24.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:24.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:24.590+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:44:24.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:24.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:44:24.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T16:44:55.155+0000] {processor.py:157} INFO - Started process (PID=56177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:55.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:44:55.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:55.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:55.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:44:55.275+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:55.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:44:55.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:44:55.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:44:55.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-17T16:45:25.810+0000] {processor.py:157} INFO - Started process (PID=56187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:25.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:45:25.818+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:25.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:25.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:25.900+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:25.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:45:25.922+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:25.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:45:25.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T16:45:56.395+0000] {processor.py:157} INFO - Started process (PID=56197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:56.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:45:56.406+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:56.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:56.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:45:56.503+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:56.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:45:56.525+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:45:56.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:45:56.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-17T16:46:26.975+0000] {processor.py:157} INFO - Started process (PID=56207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:26.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:46:26.982+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:26.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:27.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:27.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:27.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:46:27.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:27.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:46:27.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T16:46:57.515+0000] {processor.py:157} INFO - Started process (PID=56217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:57.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:46:57.521+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:57.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:57.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:46:57.588+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:57.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:46:57.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:46:57.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:46:57.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T16:47:27.997+0000] {processor.py:157} INFO - Started process (PID=56227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:27.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:47:28.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:28.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:28.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:28.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:28.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:47:28.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:28.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:47:28.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T16:47:58.474+0000] {processor.py:157} INFO - Started process (PID=56237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:58.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:47:58.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:58.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:58.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:47:58.575+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:58.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:47:58.592+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:47:58.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:47:58.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T16:48:29.291+0000] {processor.py:157} INFO - Started process (PID=56247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:29.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:48:29.309+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:29.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:29.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:29.452+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:29.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:48:29.483+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:29.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:48:29.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-09-17T16:48:59.806+0000] {processor.py:157} INFO - Started process (PID=56257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:59.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:48:59.822+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:59.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:59.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:48:59.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:59.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:48:59.906+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:48:59.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:48:59.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T16:49:30.218+0000] {processor.py:157} INFO - Started process (PID=56267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:49:30.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:49:30.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:49:30.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:49:30.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:49:30.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:49:30.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:49:30.319+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:49:30.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:49:30.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T16:50:00.615+0000] {processor.py:157} INFO - Started process (PID=56277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:00.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:50:00.621+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:00.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:00.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:00.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:00.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:50:00.716+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:00.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:50:00.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T16:50:30.971+0000] {processor.py:157} INFO - Started process (PID=56287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:30.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:50:30.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:30.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:31.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:50:31.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:31.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:50:31.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:50:31.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:50:31.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T16:51:01.340+0000] {processor.py:157} INFO - Started process (PID=56297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:01.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:51:01.347+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:01.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:01.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:01.408+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:01.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:51:01.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:01.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:51:01.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T16:51:31.691+0000] {processor.py:157} INFO - Started process (PID=56306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:31.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:51:31.697+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:31.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:31.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:51:31.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:31.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:51:31.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:51:31.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:51:31.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T16:52:02.185+0000] {processor.py:157} INFO - Started process (PID=56317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:02.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:52:02.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:02.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:02.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:02.263+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:02.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:52:02.281+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:02.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:52:02.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T16:52:32.514+0000] {processor.py:157} INFO - Started process (PID=56327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:32.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:52:32.532+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:32.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:32.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:52:32.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:32.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:52:32.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:52:32.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:52:32.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T16:53:02.965+0000] {processor.py:157} INFO - Started process (PID=56337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:02.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:53:02.976+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:02.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:02.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:03.045+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:03.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:53:03.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:03.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:53:03.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T16:53:33.366+0000] {processor.py:157} INFO - Started process (PID=56347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:33.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:53:33.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:33.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:33.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:53:33.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:33.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:53:33.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:53:33.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:53:33.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T16:54:03.918+0000] {processor.py:157} INFO - Started process (PID=56357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:03.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:54:03.926+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:03.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:03.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:04.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:04.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:54:04.087+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:04.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:54:04.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-17T16:54:34.307+0000] {processor.py:157} INFO - Started process (PID=56367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:34.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:54:34.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:34.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:34.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:54:34.392+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:34.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:54:34.409+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:54:34.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:54:34.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T16:55:04.841+0000] {processor.py:157} INFO - Started process (PID=56377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:04.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:55:04.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:04.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:04.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:04.905+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:04.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:55:04.923+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:04.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:55:04.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T16:55:35.182+0000] {processor.py:157} INFO - Started process (PID=56387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:35.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:55:35.188+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:35.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:35.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:55:35.265+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:35.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:55:35.285+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:55:35.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:55:35.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T16:56:05.769+0000] {processor.py:157} INFO - Started process (PID=56397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:05.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:56:05.778+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:05.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:05.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:05.903+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:05.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:56:05.921+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:05.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:56:05.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-17T16:56:36.094+0000] {processor.py:157} INFO - Started process (PID=56406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:36.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:56:36.101+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:36.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:36.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:56:36.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:36.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:56:36.195+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:56:36.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:56:36.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T16:57:06.639+0000] {processor.py:157} INFO - Started process (PID=56417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:06.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:57:06.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:06.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:06.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:06.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:06.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:57:06.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:06.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:57:06.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T16:57:36.987+0000] {processor.py:157} INFO - Started process (PID=56427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:36.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:57:36.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:36.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:37.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:57:37.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:37.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:57:37.088+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:57:37.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:57:37.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T16:58:07.443+0000] {processor.py:157} INFO - Started process (PID=56437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:07.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:58:07.454+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:07.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:07.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:07.530+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:07.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:58:07.546+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:07.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:58:07.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T16:58:37.758+0000] {processor.py:157} INFO - Started process (PID=56447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:37.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:58:37.766+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:37.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:37.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:58:37.838+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:37.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:58:37.867+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:58:37.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:58:37.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T16:59:08.134+0000] {processor.py:157} INFO - Started process (PID=56457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:08.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:59:08.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:08.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:08.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:08.199+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:08.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:59:08.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:08.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:59:08.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T16:59:38.507+0000] {processor.py:157} INFO - Started process (PID=56467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:38.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T16:59:38.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:38.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:38.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T16:59:38.607+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:38.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T16:59:38.632+0000] {logging_mixin.py:151} INFO - [2024-09-17T16:59:38.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T16:59:38.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T17:00:08.896+0000] {processor.py:157} INFO - Started process (PID=56476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:08.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:00:08.904+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:08.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:08.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:08.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:08.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:00:09.004+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:09.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:00:09.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T17:00:39.275+0000] {processor.py:157} INFO - Started process (PID=56487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:39.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:00:39.282+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:39.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:39.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:00:39.378+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:39.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:00:39.396+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:00:39.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:00:39.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T17:01:09.718+0000] {processor.py:157} INFO - Started process (PID=56496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:09.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:01:09.731+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:09.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:09.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:09.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:09.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:01:09.856+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:09.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:01:09.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-17T17:01:40.101+0000] {processor.py:157} INFO - Started process (PID=56507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:40.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:01:40.116+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:40.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:40.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:01:40.192+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:40.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:01:40.213+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:01:40.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:01:40.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T17:02:10.420+0000] {processor.py:157} INFO - Started process (PID=56517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:10.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:02:10.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:10.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:10.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:10.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:10.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:02:10.507+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:10.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:02:10.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T17:02:40.829+0000] {processor.py:157} INFO - Started process (PID=56527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:40.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:02:40.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:40.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:40.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:02:40.907+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:40.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:02:40.923+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:02:40.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:02:40.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T17:03:11.193+0000] {processor.py:157} INFO - Started process (PID=56537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:11.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:03:11.200+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:11.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:11.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:11.276+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:11.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:03:11.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:11.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:03:11.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T17:03:41.588+0000] {processor.py:157} INFO - Started process (PID=56547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:41.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:03:41.595+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:41.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:41.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:03:41.654+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:41.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:03:41.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:03:41.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:03:41.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T17:04:11.991+0000] {processor.py:157} INFO - Started process (PID=56557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:11.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:04:12.006+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:12.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:12.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:12.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:12.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:04:13.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:13.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:04:13.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 1.219 seconds
[2024-09-17T17:04:43.503+0000] {processor.py:157} INFO - Started process (PID=56567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:43.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:04:43.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:43.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:43.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:04:43.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:43.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:04:43.642+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:04:43.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:04:43.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-17T17:05:14.637+0000] {processor.py:157} INFO - Started process (PID=56576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:14.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:05:14.644+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:14.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:14.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:14.700+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:14.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:05:14.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:14.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:05:14.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T17:05:45.014+0000] {processor.py:157} INFO - Started process (PID=56587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:45.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:05:45.023+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:45.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:45.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:05:45.109+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:45.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:05:45.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:05:45.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:05:45.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T17:06:15.400+0000] {processor.py:157} INFO - Started process (PID=56597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:15.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:06:15.409+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:15.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:15.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:15.515+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:15.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:06:15.534+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:15.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:06:15.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-17T17:06:45.767+0000] {processor.py:157} INFO - Started process (PID=56607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:45.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:06:45.775+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:45.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:45.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:06:45.836+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:45.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:06:45.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:06:45.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:06:45.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T17:07:16.144+0000] {processor.py:157} INFO - Started process (PID=56617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:16.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:07:16.159+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:16.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:16.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:16.232+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:16.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:07:16.248+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:16.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:07:16.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T17:07:46.667+0000] {processor.py:157} INFO - Started process (PID=56627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:46.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:07:46.680+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:46.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:46.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:07:46.802+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:46.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:07:46.824+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:07:46.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:07:46.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-17T17:08:17.057+0000] {processor.py:157} INFO - Started process (PID=56637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:17.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:08:17.079+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:17.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:17.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:17.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:17.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:08:17.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:17.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:08:17.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T17:08:47.407+0000] {processor.py:157} INFO - Started process (PID=56647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:47.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:08:47.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:47.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:47.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:08:47.475+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:47.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:08:47.490+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:08:47.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:08:47.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T17:09:17.830+0000] {processor.py:157} INFO - Started process (PID=56657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:17.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:09:17.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:17.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:17.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:17.900+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:17.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:09:17.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:17.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:09:17.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T17:09:48.161+0000] {processor.py:157} INFO - Started process (PID=56667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:48.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:09:48.165+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:48.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:48.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:09:48.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:48.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:09:48.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:09:48.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:09:48.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T17:10:18.714+0000] {processor.py:157} INFO - Started process (PID=56677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:18.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:10:18.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:18.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:18.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:18.862+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:18.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:10:18.888+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:18.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:10:18.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-17T17:10:49.031+0000] {processor.py:157} INFO - Started process (PID=56687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:49.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:10:49.056+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:49.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:49.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:10:49.132+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:10:49.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:10:49.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:10:49.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T17:11:19.499+0000] {processor.py:157} INFO - Started process (PID=56697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:19.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:11:19.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:19.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:19.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:19.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:19.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:11:19.629+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:19.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:11:19.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T17:11:49.988+0000] {processor.py:157} INFO - Started process (PID=56705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:49.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:11:49.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:49.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:50.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:11:50.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:50.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:11:50.089+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:11:50.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:11:50.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T17:12:20.562+0000] {processor.py:157} INFO - Started process (PID=56717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:20.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:12:20.573+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:20.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:20.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:20.644+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:20.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:12:20.663+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:20.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:12:20.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T17:12:50.942+0000] {processor.py:157} INFO - Started process (PID=56726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:50.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:12:50.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:50.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:50.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:12:51.038+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:51.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:12:51.056+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:12:51.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:12:51.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T17:13:21.357+0000] {processor.py:157} INFO - Started process (PID=56736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:21.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:13:21.371+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:21.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:21.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:21.448+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:21.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:13:21.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:21.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:13:21.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T17:13:51.705+0000] {processor.py:157} INFO - Started process (PID=56747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:51.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:13:51.722+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:51.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:51.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:13:51.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:51.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:13:51.817+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:13:51.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:13:51.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T17:14:22.165+0000] {processor.py:157} INFO - Started process (PID=56757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:22.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:14:22.170+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:22.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:22.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:22.245+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:22.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:14:22.278+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:22.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:14:22.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T17:14:52.529+0000] {processor.py:157} INFO - Started process (PID=56767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:52.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:14:52.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:52.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:52.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:14:52.608+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:52.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:14:52.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:14:52.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:14:52.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T17:15:22.932+0000] {processor.py:157} INFO - Started process (PID=56777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:22.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:15:22.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:22.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:22.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:23.032+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:23.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:15:23.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:23.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:15:23.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T17:15:53.282+0000] {processor.py:157} INFO - Started process (PID=56787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:53.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:15:53.290+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:53.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:53.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:15:53.354+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:53.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:15:53.375+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:15:53.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:15:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T17:16:23.685+0000] {processor.py:157} INFO - Started process (PID=56797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:23.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:16:23.713+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:23.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:23.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:23.784+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:23.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:16:23.799+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:23.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:16:23.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T17:16:54.112+0000] {processor.py:157} INFO - Started process (PID=56806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:54.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:16:54.120+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:54.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:54.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:16:54.217+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:54.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:16:54.238+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:16:54.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:16:54.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T17:17:24.540+0000] {processor.py:157} INFO - Started process (PID=56817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:24.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:17:24.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:24.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:24.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:24.682+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:24.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:17:24.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:24.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:17:24.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-17T17:17:54.980+0000] {processor.py:157} INFO - Started process (PID=56827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:54.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:17:55.000+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:54.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:55.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:17:55.098+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:55.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:17:55.115+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:17:55.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:17:55.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-17T17:18:25.537+0000] {processor.py:157} INFO - Started process (PID=56837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:25.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:18:25.548+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:25.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:25.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:25.631+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:25.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:18:25.647+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:25.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:18:25.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T17:18:55.888+0000] {processor.py:157} INFO - Started process (PID=56847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:55.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:18:55.909+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:55.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:55.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:18:55.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:55.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:18:55.989+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:18:55.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:18:56.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T17:19:26.385+0000] {processor.py:157} INFO - Started process (PID=56857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:26.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:19:26.393+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:26.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:26.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:26.458+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:26.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:19:26.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:26.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:19:26.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T17:19:56.714+0000] {processor.py:157} INFO - Started process (PID=56866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:56.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:19:56.720+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:56.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:56.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:19:56.781+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:56.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:19:56.796+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:19:56.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:19:56.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T17:20:27.106+0000] {processor.py:157} INFO - Started process (PID=56877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:27.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:20:27.121+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:27.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:27.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:27.190+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:27.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:20:27.208+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:27.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:20:27.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T17:20:57.455+0000] {processor.py:157} INFO - Started process (PID=56887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:57.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:20:57.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:57.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:57.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:20:57.521+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:57.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:20:57.536+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:20:57.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:20:57.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T17:21:27.800+0000] {processor.py:157} INFO - Started process (PID=56897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:27.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:21:27.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:27.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:27.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:27.867+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:27.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:21:27.892+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:27.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:21:27.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T17:21:58.356+0000] {processor.py:157} INFO - Started process (PID=56907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:58.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:21:58.376+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:58.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:58.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:21:58.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:58.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:21:58.512+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:21:58.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:21:58.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-17T17:22:28.907+0000] {processor.py:157} INFO - Started process (PID=56917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:22:28.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:22:28.915+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:22:28.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:22:28.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:22:29.015+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:22:29.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:22:29.031+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:22:29.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:22:29.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T17:22:59.902+0000] {processor.py:157} INFO - Started process (PID=56927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:22:59.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:22:59.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:22:59.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:22:59.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:23:00.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:23:00.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:23:00.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:23:00.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:23:00.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-09-17T17:23:30.345+0000] {processor.py:157} INFO - Started process (PID=56937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:23:30.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:23:30.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:23:30.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:23:30.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:23:30.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:23:30.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:23:30.427+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:23:30.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:23:30.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T17:24:00.922+0000] {processor.py:157} INFO - Started process (PID=56947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:00.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:24:00.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:00.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:00.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:01.074+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:01.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:24:01.090+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:01.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:24:01.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-17T17:24:31.491+0000] {processor.py:157} INFO - Started process (PID=56957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:31.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:24:31.513+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:31.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:31.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:24:31.696+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:31.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:24:31.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:24:31.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:24:31.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.293 seconds
[2024-09-17T17:25:01.922+0000] {processor.py:157} INFO - Started process (PID=56967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:01.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:25:01.942+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:01.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:01.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:02.042+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:02.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:25:02.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:02.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:25:02.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-17T17:25:32.540+0000] {processor.py:157} INFO - Started process (PID=56977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:32.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:25:32.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:32.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:32.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:25:32.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:32.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:25:32.676+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:25:32.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:25:32.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-17T17:26:02.928+0000] {processor.py:157} INFO - Started process (PID=56987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:02.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:26:02.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:02.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:02.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:03.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:03.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:26:03.077+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:03.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:26:03.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-17T17:26:33.359+0000] {processor.py:157} INFO - Started process (PID=56997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:33.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:26:33.374+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:33.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:33.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:26:33.492+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:33.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:26:33.518+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:26:33.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:26:33.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-17T17:27:03.826+0000] {processor.py:157} INFO - Started process (PID=57007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:03.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:27:03.836+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:03.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:03.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:03.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:03.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:27:03.948+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:03.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:27:03.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-17T17:27:34.117+0000] {processor.py:157} INFO - Started process (PID=57017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:34.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:27:34.133+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:34.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:34.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:27:34.204+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:34.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:27:34.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:27:34.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:27:34.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T17:28:04.667+0000] {processor.py:157} INFO - Started process (PID=57027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:04.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:28:04.679+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:04.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:04.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:04.793+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:04.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:28:04.822+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:04.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:28:04.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-09-17T17:28:35.043+0000] {processor.py:157} INFO - Started process (PID=57037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:35.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:28:35.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:35.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:35.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:28:35.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:35.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:28:35.189+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:28:35.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:28:35.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T17:29:05.428+0000] {processor.py:157} INFO - Started process (PID=57047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:05.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:29:05.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:05.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:05.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:05.567+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:05.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:29:05.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:05.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:29:05.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-17T17:29:36.091+0000] {processor.py:157} INFO - Started process (PID=57057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:36.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:29:36.102+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:36.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:36.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:29:36.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:36.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:29:36.215+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:29:36.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:29:36.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-17T17:30:06.669+0000] {processor.py:157} INFO - Started process (PID=57067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:06.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:30:06.677+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:06.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:06.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:06.754+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:06.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:30:06.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:06.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:30:06.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T17:30:37.108+0000] {processor.py:157} INFO - Started process (PID=57077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:37.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:30:37.113+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:37.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:37.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:30:37.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:37.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:30:37.196+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:30:37.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:30:37.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T17:31:07.618+0000] {processor.py:157} INFO - Started process (PID=57087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:07.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:31:07.627+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:07.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:07.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:07.729+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:07.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:31:07.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:07.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:31:07.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T17:31:37.956+0000] {processor.py:157} INFO - Started process (PID=57097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:37.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:31:37.981+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:37.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:38.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:31:38.073+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:38.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:31:38.115+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:31:38.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:31:38.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-17T17:32:08.410+0000] {processor.py:157} INFO - Started process (PID=57107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:08.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:32:08.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:08.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:08.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:08.502+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:08.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:32:08.517+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:08.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:32:08.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T17:32:38.816+0000] {processor.py:157} INFO - Started process (PID=57117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:38.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:32:38.822+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:38.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:38.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:32:38.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:38.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:32:38.899+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:32:38.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:32:38.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T17:33:09.396+0000] {processor.py:157} INFO - Started process (PID=57127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:09.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:33:09.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:09.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:09.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:09.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:09.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:33:09.525+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:09.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:33:09.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T17:33:39.832+0000] {processor.py:157} INFO - Started process (PID=57137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:39.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:33:39.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:39.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:39.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:33:39.926+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:39.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:33:39.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:33:39.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:33:39.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T17:34:10.369+0000] {processor.py:157} INFO - Started process (PID=57147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:10.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:34:10.395+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:10.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:10.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:10.459+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:10.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:34:10.492+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:10.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:34:10.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T17:34:40.749+0000] {processor.py:157} INFO - Started process (PID=57156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:40.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:34:40.757+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:40.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:40.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:34:40.838+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:40.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:34:40.854+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:34:40.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:34:40.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T17:35:11.251+0000] {processor.py:157} INFO - Started process (PID=57167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:11.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:35:11.263+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:11.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:11.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:11.355+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:11.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:35:11.370+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:11.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:35:11.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T17:35:41.613+0000] {processor.py:157} INFO - Started process (PID=57175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:41.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:35:41.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:41.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:41.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:35:41.687+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:41.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:35:41.703+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:35:41.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:35:41.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-17T17:36:12.129+0000] {processor.py:157} INFO - Started process (PID=57187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:12.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:36:12.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:12.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:12.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:12.190+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:12.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:36:12.211+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:12.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:36:12.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T17:36:42.433+0000] {processor.py:157} INFO - Started process (PID=57197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:42.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:36:42.444+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:42.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:42.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:36:42.520+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:42.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:36:42.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:36:42.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:36:42.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T17:37:12.941+0000] {processor.py:157} INFO - Started process (PID=57207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:12.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:37:12.948+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:12.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:12.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:12.999+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:12.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:37:13.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:13.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:37:13.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-17T17:37:43.252+0000] {processor.py:157} INFO - Started process (PID=57217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:43.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:37:43.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:43.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:43.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:37:43.301+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:43.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:37:43.315+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:37:43.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:37:43.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-17T17:38:13.691+0000] {processor.py:157} INFO - Started process (PID=57227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:13.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:38:13.702+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:13.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:13.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:13.775+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:13.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:38:13.793+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:13.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:38:13.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T17:38:44.058+0000] {processor.py:157} INFO - Started process (PID=57235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:44.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:38:44.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:44.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:44.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:38:44.149+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:44.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:38:44.164+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:38:44.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:38:44.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T17:39:14.426+0000] {processor.py:157} INFO - Started process (PID=57247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:14.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:39:14.436+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:14.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:14.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:14.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:14.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:39:14.510+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:14.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:39:14.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T17:39:44.796+0000] {processor.py:157} INFO - Started process (PID=57257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:44.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:39:44.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:44.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:44.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:39:44.872+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:44.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:39:44.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:39:44.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:39:44.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T17:40:15.132+0000] {processor.py:157} INFO - Started process (PID=57266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:15.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:40:15.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:15.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:15.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:15.227+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:15.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:40:15.246+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:15.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:40:15.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T17:40:45.426+0000] {processor.py:157} INFO - Started process (PID=57277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:45.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:40:45.430+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:45.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:45.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:40:45.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:45.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:40:45.486+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:40:45.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:40:45.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-17T17:41:15.771+0000] {processor.py:157} INFO - Started process (PID=57287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:15.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:41:15.777+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:15.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:15.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:15.833+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:15.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:41:15.846+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:15.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:41:15.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T17:41:46.146+0000] {processor.py:157} INFO - Started process (PID=57297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:46.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:41:46.151+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:46.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:46.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:41:46.221+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:46.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:41:46.246+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:41:46.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:41:46.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T17:42:16.597+0000] {processor.py:157} INFO - Started process (PID=57307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:16.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:42:16.605+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:16.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:16.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:16.684+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:16.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:42:16.698+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:16.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:42:16.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T17:42:46.962+0000] {processor.py:157} INFO - Started process (PID=57317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:46.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:42:46.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:46.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:47.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:42:47.048+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:47.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:42:47.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:42:47.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:42:47.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T17:43:17.343+0000] {processor.py:157} INFO - Started process (PID=57327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:17.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:43:17.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:17.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:17.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:17.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:17.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:43:17.439+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:17.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:43:17.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T17:43:47.670+0000] {processor.py:157} INFO - Started process (PID=57336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:47.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:43:47.682+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:47.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:47.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:43:47.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:47.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:43:47.759+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:43:47.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:43:47.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T17:44:18.120+0000] {processor.py:157} INFO - Started process (PID=57347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:18.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:44:18.127+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:18.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:18.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:18.188+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:18.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:44:18.202+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:18.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:44:18.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T17:44:48.425+0000] {processor.py:157} INFO - Started process (PID=57356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:48.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:44:48.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:48.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:48.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:44:48.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:48.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:44:48.470+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:44:48.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:44:48.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-17T17:45:18.746+0000] {processor.py:157} INFO - Started process (PID=57366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:18.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:45:18.753+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:18.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:18.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:18.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:18.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:45:18.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:18.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:45:18.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T17:45:49.033+0000] {processor.py:157} INFO - Started process (PID=57377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:49.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:45:49.037+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:49.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:49.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:45:49.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:49.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:45:49.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:45:49.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:45:49.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-17T17:46:19.502+0000] {processor.py:157} INFO - Started process (PID=57385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:19.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:46:19.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:19.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:19.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:19.574+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:19.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:46:19.588+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:19.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:46:19.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T17:46:49.882+0000] {processor.py:157} INFO - Started process (PID=57397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:49.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:46:49.895+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:49.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:49.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:46:49.991+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:49.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:46:50.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:46:50.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:46:50.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-17T17:47:20.208+0000] {processor.py:157} INFO - Started process (PID=57406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:20.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:47:20.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:20.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:20.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:20.306+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:20.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:47:20.334+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:20.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:47:20.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T17:47:50.588+0000] {processor.py:157} INFO - Started process (PID=57416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:50.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:47:50.595+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:50.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:50.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:47:50.665+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:50.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:47:50.679+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:47:50.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:47:50.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T17:48:20.912+0000] {processor.py:157} INFO - Started process (PID=57427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:20.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:48:20.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:20.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:20.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:20.998+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:20.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:48:21.027+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:21.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:48:21.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T17:48:51.277+0000] {processor.py:157} INFO - Started process (PID=57437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:51.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:48:51.297+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:51.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:51.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:48:51.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:51.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:48:51.400+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:48:51.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:48:51.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T17:49:21.639+0000] {processor.py:157} INFO - Started process (PID=57446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:21.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:49:21.655+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:21.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:21.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:21.725+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:21.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:49:21.740+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:21.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:49:21.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T17:49:51.883+0000] {processor.py:157} INFO - Started process (PID=57457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:51.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:49:51.889+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:51.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:51.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:49:51.919+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:51.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:49:51.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:49:51.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:49:51.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T17:50:22.283+0000] {processor.py:157} INFO - Started process (PID=57467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:22.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:50:22.291+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:22.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:22.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:22.348+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:22.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:50:22.361+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:22.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:50:22.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-17T17:50:52.619+0000] {processor.py:157} INFO - Started process (PID=57477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:52.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:50:52.634+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:52.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:52.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:50:52.711+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:52.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:50:52.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:50:52.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:50:52.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-17T17:51:22.934+0000] {processor.py:157} INFO - Started process (PID=57487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:22.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:51:22.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:22.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:22.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:23.012+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:23.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:51:23.025+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:23.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:51:23.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T17:51:53.370+0000] {processor.py:157} INFO - Started process (PID=57497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:53.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:51:53.372+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:53.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:53.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:51:53.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:53.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:51:53.417+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:51:53.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:51:53.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-17T17:52:23.736+0000] {processor.py:157} INFO - Started process (PID=57507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:23.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:52:23.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:23.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:23.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:23.820+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:23.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:52:23.834+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:23.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:52:23.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T17:52:54.141+0000] {processor.py:157} INFO - Started process (PID=57517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:54.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:52:54.157+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:54.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:54.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:52:54.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:54.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:52:54.233+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:52:54.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:52:54.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T17:53:24.514+0000] {processor.py:157} INFO - Started process (PID=57527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:24.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:53:24.522+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:24.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:24.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:24.581+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:24.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:53:24.596+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:24.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:53:24.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T17:53:54.991+0000] {processor.py:157} INFO - Started process (PID=57537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:54.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:53:54.999+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:54.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:55.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:53:55.085+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:55.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:53:55.101+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:53:55.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:53:55.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T17:54:25.513+0000] {processor.py:157} INFO - Started process (PID=57547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:25.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:54:25.520+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:25.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:25.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:25.583+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:25.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:54:25.602+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:25.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:54:25.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T17:54:55.955+0000] {processor.py:157} INFO - Started process (PID=57556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:55.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:54:55.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:55.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:55.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:54:56.035+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:56.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:54:56.061+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:54:56.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:54:56.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T17:55:26.343+0000] {processor.py:157} INFO - Started process (PID=57567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:26.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:55:26.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:26.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:26.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:26.411+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:26.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:55:26.427+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:26.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:55:26.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T17:55:56.778+0000] {processor.py:157} INFO - Started process (PID=57577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:56.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:55:56.786+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:56.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:56.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:55:56.863+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:56.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:55:56.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:55:56.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:55:56.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T17:56:27.242+0000] {processor.py:157} INFO - Started process (PID=57585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:27.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:56:27.249+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:27.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:27.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:27.304+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:27.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:56:27.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:27.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:56:27.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T17:56:57.797+0000] {processor.py:157} INFO - Started process (PID=57595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:57.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:56:57.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:57.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:57.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:56:57.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:57.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:56:57.902+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:56:57.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:56:57.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-17T17:57:28.139+0000] {processor.py:157} INFO - Started process (PID=57607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:28.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:57:28.147+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:28.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:28.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:28.217+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:28.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:57:28.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:28.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:57:28.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T17:57:58.717+0000] {processor.py:157} INFO - Started process (PID=57617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:58.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:57:58.730+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:58.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:58.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:57:58.825+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:58.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:57:58.863+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:57:58.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:57:58.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T17:58:29.061+0000] {processor.py:157} INFO - Started process (PID=57626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:29.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:58:29.072+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:29.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:29.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:29.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:29.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:58:29.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:29.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:58:29.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T17:58:59.495+0000] {processor.py:157} INFO - Started process (PID=57637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:59.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:58:59.503+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:59.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:59.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:58:59.587+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:59.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:58:59.605+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:58:59.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:58:59.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T17:59:29.755+0000] {processor.py:157} INFO - Started process (PID=57647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:59:29.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T17:59:29.761+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:59:29.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:59:29.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T17:59:29.814+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:59:29.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T17:59:29.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T17:59:29.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T17:59:29.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-17T18:00:00.213+0000] {processor.py:157} INFO - Started process (PID=57657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:00.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:00:00.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:00.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:00.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:00.346+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:00.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:00:00.378+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:00.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:00:00.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-17T18:00:30.778+0000] {processor.py:157} INFO - Started process (PID=57667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:30.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:00:30.792+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:30.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:30.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:00:30.943+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:30.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:00:30.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:00:30.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:00:30.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-09-17T18:01:01.196+0000] {processor.py:157} INFO - Started process (PID=57677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:01.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:01:01.216+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:01.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:01.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:01.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:01.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:01:01.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:01.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:01:01.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-09-17T18:01:31.738+0000] {processor.py:157} INFO - Started process (PID=57687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:31.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:01:31.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:31.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:31.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:01:31.825+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:31.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:01:31.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:01:31.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:01:31.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T18:02:02.256+0000] {processor.py:157} INFO - Started process (PID=57697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:02.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:02:02.262+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:02.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:02.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:02.315+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:02.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:02:02.332+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:02.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:02:02.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-17T18:02:32.710+0000] {processor.py:157} INFO - Started process (PID=57707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:32.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:02:32.721+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:32.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:32.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:02:32.791+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:32.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:02:32.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:02:32.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:02:32.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T18:03:03.076+0000] {processor.py:157} INFO - Started process (PID=57717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:03.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:03:03.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:03.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:03.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:03.139+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:03.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:03:03.153+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:03.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:03:03.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T18:03:33.411+0000] {processor.py:157} INFO - Started process (PID=57727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:33.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:03:33.426+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:33.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:33.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:03:33.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:33.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:03:33.505+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:03:33.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:03:33.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T18:04:03.811+0000] {processor.py:157} INFO - Started process (PID=57737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:03.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:04:03.817+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:03.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:03.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:03.869+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:03.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:04:03.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:03.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:04:03.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T18:04:34.165+0000] {processor.py:157} INFO - Started process (PID=57747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:34.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:04:34.180+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:34.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:34.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:04:34.242+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:34.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:04:34.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:04:34.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:04:34.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T18:05:04.477+0000] {processor.py:157} INFO - Started process (PID=57756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:04.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:05:04.483+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:04.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:04.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:04.559+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:04.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:05:04.573+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:04.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:05:04.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T18:05:34.914+0000] {processor.py:157} INFO - Started process (PID=57767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:34.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:05:34.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:34.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:34.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:05:35.004+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:35.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:05:35.019+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:05:35.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:05:35.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T18:06:05.361+0000] {processor.py:157} INFO - Started process (PID=57776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:05.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:06:05.367+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:05.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:05.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:05.443+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:05.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:06:05.460+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:05.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:06:05.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T18:06:35.848+0000] {processor.py:157} INFO - Started process (PID=57787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:35.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:06:35.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:35.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:35.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:06:35.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:35.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:06:35.942+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:06:35.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:06:35.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-17T18:07:06.411+0000] {processor.py:157} INFO - Started process (PID=57797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:06.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:07:06.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:06.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:06.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:06.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:06.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:07:06.516+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:06.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:07:06.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T18:07:36.780+0000] {processor.py:157} INFO - Started process (PID=57807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:36.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:07:36.798+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:36.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:36.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:07:36.861+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:36.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:07:36.882+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:07:36.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:07:36.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T18:08:07.341+0000] {processor.py:157} INFO - Started process (PID=57816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:07.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:08:07.354+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:07.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:07.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:07.431+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:07.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:08:07.445+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:07.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:08:07.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T18:08:37.804+0000] {processor.py:157} INFO - Started process (PID=57827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:37.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:08:37.811+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:37.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:08:37.879+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:37.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:08:37.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:08:37.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:08:37.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T18:09:08.294+0000] {processor.py:157} INFO - Started process (PID=57837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:08.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:09:08.313+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:08.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:08.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:08.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:08.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:09:08.460+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:08.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:09:08.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-17T18:09:38.829+0000] {processor.py:157} INFO - Started process (PID=57846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:38.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:09:38.835+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:38.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:38.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:09:38.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:38.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:09:38.916+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:09:38.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:09:38.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T18:10:09.339+0000] {processor.py:157} INFO - Started process (PID=57857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:09.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:10:09.351+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:09.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:09.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:09.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:09.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:10:09.451+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:09.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:10:09.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T18:10:39.791+0000] {processor.py:157} INFO - Started process (PID=57867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:39.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:10:39.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:39.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:39.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:10:39.864+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:39.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:10:39.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:10:39.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:10:39.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T18:11:10.307+0000] {processor.py:157} INFO - Started process (PID=57877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:10.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:11:10.315+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:10.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:10.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:10.436+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:10.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:11:10.451+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:10.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:11:10.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-09-17T18:11:40.861+0000] {processor.py:157} INFO - Started process (PID=57887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:40.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:11:40.867+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:40.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:40.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:11:40.931+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:40.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:11:40.949+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:11:40.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:11:40.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T18:12:11.334+0000] {processor.py:157} INFO - Started process (PID=57897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:11.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:12:11.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:11.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:11.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:11.401+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:11.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:12:11.416+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:11.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:12:11.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-17T18:12:41.740+0000] {processor.py:157} INFO - Started process (PID=57907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:41.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:12:41.749+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:41.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:41.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:12:41.808+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:41.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:12:41.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:12:41.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:12:41.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T18:13:12.151+0000] {processor.py:157} INFO - Started process (PID=57917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:12.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:13:12.193+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:12.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:12.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:12.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:12.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:13:12.285+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:12.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:13:12.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-17T18:13:42.577+0000] {processor.py:157} INFO - Started process (PID=57927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:42.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:13:42.595+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:42.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:42.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:13:42.718+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:42.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:13:42.746+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:13:42.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:13:42.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-17T18:14:12.937+0000] {processor.py:157} INFO - Started process (PID=57937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:12.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:14:12.944+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:12.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:12.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:13.024+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:13.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:14:13.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:13.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:14:13.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T18:14:43.373+0000] {processor.py:157} INFO - Started process (PID=57947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:43.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:14:43.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:43.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:43.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:14:43.457+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:43.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:14:43.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:14:43.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:14:43.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T18:15:13.809+0000] {processor.py:157} INFO - Started process (PID=57957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:13.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:15:13.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:13.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:13.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:13.909+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:13.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:15:13.923+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:13.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:15:13.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T18:15:44.168+0000] {processor.py:157} INFO - Started process (PID=57967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:44.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:15:44.181+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:44.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:44.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:15:44.250+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:44.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:15:44.270+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:15:44.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:15:44.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T18:16:14.578+0000] {processor.py:157} INFO - Started process (PID=57977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:14.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:16:14.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:14.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:14.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:14.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:14.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:16:14.691+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:14.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:16:14.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T18:16:45.027+0000] {processor.py:157} INFO - Started process (PID=57987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:45.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:16:45.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:45.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:45.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:16:45.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:45.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:16:45.176+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:16:45.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:16:45.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-17T18:17:15.400+0000] {processor.py:157} INFO - Started process (PID=57997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:15.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:17:15.406+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:15.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:15.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:15.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:15.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:17:15.492+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:15.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:17:15.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T18:17:45.835+0000] {processor.py:157} INFO - Started process (PID=58007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:45.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:17:45.843+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:45.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:45.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:17:45.916+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:45.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:17:45.933+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:17:45.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:17:45.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T18:18:16.187+0000] {processor.py:157} INFO - Started process (PID=58017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:16.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:18:16.195+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:16.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:16.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:16.287+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:16.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:18:16.310+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:16.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:18:16.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T18:18:46.656+0000] {processor.py:157} INFO - Started process (PID=58027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:46.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:18:46.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:46.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:46.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:18:46.773+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:46.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:18:46.790+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:18:46.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:18:46.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-17T18:19:17.020+0000] {processor.py:157} INFO - Started process (PID=58037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:17.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:19:17.053+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:17.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:17.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:17.165+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:17.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:19:17.187+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:17.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:19:17.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-17T18:19:47.373+0000] {processor.py:157} INFO - Started process (PID=58046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:47.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:19:47.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:47.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:47.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:19:47.441+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:47.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:19:47.466+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:19:47.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:19:47.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T18:20:17.805+0000] {processor.py:157} INFO - Started process (PID=58057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:17.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:20:17.813+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:17.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:17.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:17.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:17.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:20:17.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:17.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:20:17.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T18:20:48.087+0000] {processor.py:157} INFO - Started process (PID=58067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:48.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:20:48.104+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:48.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:48.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:20:48.176+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:48.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:20:48.191+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:20:48.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:20:48.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T18:21:18.552+0000] {processor.py:157} INFO - Started process (PID=58077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:18.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:21:18.561+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:18.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:18.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:18.645+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:18.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:21:18.660+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:18.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:21:18.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T18:21:49.040+0000] {processor.py:157} INFO - Started process (PID=58087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:49.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:21:49.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:49.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:49.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:21:49.164+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:49.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:21:49.184+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:21:49.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:21:49.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-17T18:22:19.331+0000] {processor.py:157} INFO - Started process (PID=58097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:19.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:22:19.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:19.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:19.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:19.407+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:19.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:22:19.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:19.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:22:19.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T18:22:49.809+0000] {processor.py:157} INFO - Started process (PID=58107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:49.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:22:49.817+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:49.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:49.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:22:49.880+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:49.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:22:49.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:22:49.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:22:49.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T18:23:20.107+0000] {processor.py:157} INFO - Started process (PID=58117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:20.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:23:20.137+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:20.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:20.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:20.242+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:20.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:23:20.260+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:20.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:23:20.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-17T18:23:50.464+0000] {processor.py:157} INFO - Started process (PID=58127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:50.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:23:50.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:50.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:50.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:23:50.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:50.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:23:50.571+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:23:50.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:23:50.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T18:24:20.938+0000] {processor.py:157} INFO - Started process (PID=58137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:20.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:24:20.947+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:20.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:20.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:21.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:21.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:24:21.092+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:21.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:24:21.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-17T18:24:51.301+0000] {processor.py:157} INFO - Started process (PID=58146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:51.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:24:51.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:51.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:51.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:24:51.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:51.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:24:51.435+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:24:51.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:24:51.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-17T18:25:21.675+0000] {processor.py:157} INFO - Started process (PID=58157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:21.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:25:21.683+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:21.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:21.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:21.763+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:21.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:25:21.782+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:21.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:25:21.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T18:25:52.068+0000] {processor.py:157} INFO - Started process (PID=58167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:52.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:25:52.080+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:52.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:52.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:25:52.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:52.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:25:52.167+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:25:52.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:25:52.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T18:26:22.528+0000] {processor.py:157} INFO - Started process (PID=58177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:22.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:26:22.544+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:22.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:22.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:22.647+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:22.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:26:22.670+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:22.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:26:22.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T18:26:52.961+0000] {processor.py:157} INFO - Started process (PID=58187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:52.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:26:52.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:52.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:52.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:26:53.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:53.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:26:53.069+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:26:53.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:26:53.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-17T18:27:23.284+0000] {processor.py:157} INFO - Started process (PID=58197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:23.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:27:23.291+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:23.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:23.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:23.370+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:23.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:27:23.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:23.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:27:23.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T18:27:53.804+0000] {processor.py:157} INFO - Started process (PID=58207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:53.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:27:53.813+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:53.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:53.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:27:53.872+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:53.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:27:53.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:27:53.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:27:53.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T18:28:24.306+0000] {processor.py:157} INFO - Started process (PID=58217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:24.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:28:24.326+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:24.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:24.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:24.421+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:24.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:28:24.461+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:24.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:28:24.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-17T18:28:54.793+0000] {processor.py:157} INFO - Started process (PID=58227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:54.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:28:54.801+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:54.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:54.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:28:54.870+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:54.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:28:54.888+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:28:54.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:28:54.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T18:29:25.167+0000] {processor.py:157} INFO - Started process (PID=58237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:25.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:29:25.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:25.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:25.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:25.243+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:25.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:29:25.257+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:25.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:29:25.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-17T18:29:55.455+0000] {processor.py:157} INFO - Started process (PID=58247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:55.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:29:55.472+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:55.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:29:55.540+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:55.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:29:55.554+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:29:55.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:29:55.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T18:30:25.818+0000] {processor.py:157} INFO - Started process (PID=58257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:25.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:30:25.825+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:25.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:25.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:25.920+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:25.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:30:25.938+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:25.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:30:25.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-17T18:30:56.273+0000] {processor.py:157} INFO - Started process (PID=58267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:56.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:30:56.279+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:56.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:56.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:30:56.365+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:56.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:30:56.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:30:56.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:30:56.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T18:31:26.638+0000] {processor.py:157} INFO - Started process (PID=58277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:26.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:31:26.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:26.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:26.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:26.728+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:26.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:31:26.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:26.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:31:26.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T18:31:57.035+0000] {processor.py:157} INFO - Started process (PID=58287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:57.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:31:57.050+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:57.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:57.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:31:57.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:57.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:31:57.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:31:57.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:31:57.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T18:32:27.420+0000] {processor.py:157} INFO - Started process (PID=58297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:27.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:32:27.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:27.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:27.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:27.491+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:27.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:32:27.510+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:27.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:32:27.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-17T18:32:57.944+0000] {processor.py:157} INFO - Started process (PID=58307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:57.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:32:57.953+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:57.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:57.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:32:58.041+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:58.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:32:58.058+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:32:58.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:32:58.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T18:33:28.443+0000] {processor.py:157} INFO - Started process (PID=58317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:28.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:33:28.467+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:28.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:28.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:28.567+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:28.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:33:28.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:28.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:33:28.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T18:33:58.736+0000] {processor.py:157} INFO - Started process (PID=58327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:58.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:33:58.744+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:58.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:58.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:33:58.818+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:58.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:33:58.835+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:33:58.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:33:58.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T18:34:29.256+0000] {processor.py:157} INFO - Started process (PID=58337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:29.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:34:29.273+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:29.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:29.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:29.414+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:29.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:34:29.438+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:29.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:34:29.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-17T18:34:59.618+0000] {processor.py:157} INFO - Started process (PID=58347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:59.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:34:59.624+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:59.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:59.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:34:59.700+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:59.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:34:59.715+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:34:59.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:34:59.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T18:35:30.061+0000] {processor.py:157} INFO - Started process (PID=58356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:35:30.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:35:30.069+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:35:30.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:35:30.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:35:30.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:35:30.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:35:30.152+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:35:30.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:35:30.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T18:36:00.561+0000] {processor.py:157} INFO - Started process (PID=58367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:00.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:36:00.570+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:00.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:00.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:00.681+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:00.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:36:00.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:00.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:36:00.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T18:36:31.210+0000] {processor.py:157} INFO - Started process (PID=58377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:31.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:36:31.224+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:31.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:31.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:36:31.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:31.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:36:31.326+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:36:31.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:36:31.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T18:37:01.660+0000] {processor.py:157} INFO - Started process (PID=58387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:01.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:37:01.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:01.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:01.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:01.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:01.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:37:01.749+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:01.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:37:01.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-17T18:37:31.960+0000] {processor.py:157} INFO - Started process (PID=58397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:31.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:37:31.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:31.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:31.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:37:32.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:32.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:37:32.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:37:32.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:37:32.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T18:38:02.520+0000] {processor.py:157} INFO - Started process (PID=58407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:02.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:38:02.534+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:02.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:02.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:02.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:02.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:38:02.658+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:02.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:38:02.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T18:38:32.971+0000] {processor.py:157} INFO - Started process (PID=58416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:32.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:38:32.979+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:32.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:33.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:38:33.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:33.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:38:33.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:38:33.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:38:33.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T18:39:03.483+0000] {processor.py:157} INFO - Started process (PID=58427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:03.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:39:03.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:03.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:03.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:03.550+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:03.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:39:03.565+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:03.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:39:03.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-17T18:39:33.920+0000] {processor.py:157} INFO - Started process (PID=58437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:33.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:39:33.930+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:33.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:33.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:39:34.002+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:34.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:39:34.020+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:39:34.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:39:34.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T18:40:04.417+0000] {processor.py:157} INFO - Started process (PID=58447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:04.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:40:04.446+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:04.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:04.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:04.539+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:04.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:40:04.556+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:04.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:40:04.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-17T18:40:34.762+0000] {processor.py:157} INFO - Started process (PID=58457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:34.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:40:34.780+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:34.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:34.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:40:34.881+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:34.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:40:34.897+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:40:34.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:40:34.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-17T18:41:05.223+0000] {processor.py:157} INFO - Started process (PID=58467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:05.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:41:05.231+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:05.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:05.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:05.333+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:05.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:41:05.349+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:05.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:41:05.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T18:41:35.523+0000] {processor.py:157} INFO - Started process (PID=58477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:35.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:41:35.532+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:35.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:35.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:41:35.604+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:35.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:41:35.619+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:41:35.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:41:35.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T18:42:05.966+0000] {processor.py:157} INFO - Started process (PID=58487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:05.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:42:05.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:05.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:06.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:06.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:06.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:42:06.078+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:06.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:42:06.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-17T18:42:36.375+0000] {processor.py:157} INFO - Started process (PID=58497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:36.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:42:36.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:36.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:36.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:42:36.483+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:36.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:42:36.503+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:42:36.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:42:36.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T18:43:06.834+0000] {processor.py:157} INFO - Started process (PID=58507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:06.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:43:06.852+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:06.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:06.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:06.940+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:06.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:43:06.962+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:06.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:43:06.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T18:43:37.192+0000] {processor.py:157} INFO - Started process (PID=58517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:37.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:43:37.206+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:37.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:37.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:43:37.303+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:37.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:43:37.322+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:43:37.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:43:37.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-17T18:44:07.590+0000] {processor.py:157} INFO - Started process (PID=58527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:07.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:44:07.599+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:07.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:07.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:07.657+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:07.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:44:07.682+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:07.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:44:07.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-17T18:44:37.973+0000] {processor.py:157} INFO - Started process (PID=58537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:37.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:44:37.983+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:37.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:38.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:44:38.060+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:38.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:44:38.076+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:44:38.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:44:38.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T18:45:08.417+0000] {processor.py:157} INFO - Started process (PID=58547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:08.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:45:08.434+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:08.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:08.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:08.496+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:08.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:45:08.514+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:08.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:45:08.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T18:45:38.736+0000] {processor.py:157} INFO - Started process (PID=58557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:38.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:45:38.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:38.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:38.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:45:38.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:38.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:45:38.841+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:45:38.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:45:38.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T18:46:09.084+0000] {processor.py:157} INFO - Started process (PID=58567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:09.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:46:09.103+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:09.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:09.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:09.313+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:09.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:46:09.336+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:09.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:46:09.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.306 seconds
[2024-09-17T18:46:39.640+0000] {processor.py:157} INFO - Started process (PID=58577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:39.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:46:39.648+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:39.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:39.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:46:39.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:39.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:46:39.717+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:46:39.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:46:39.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T18:47:10.015+0000] {processor.py:157} INFO - Started process (PID=58587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:10.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:47:10.022+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:10.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:10.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:10.108+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:10.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:47:10.123+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:10.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:47:10.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T18:47:40.485+0000] {processor.py:157} INFO - Started process (PID=58597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:40.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:47:40.493+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:40.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:40.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:47:40.568+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:40.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:47:40.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:47:40.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:47:40.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T18:48:10.885+0000] {processor.py:157} INFO - Started process (PID=58607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:10.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:48:10.893+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:10.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:10.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:10.942+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:10.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:48:10.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:10.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:48:10.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T18:48:41.196+0000] {processor.py:157} INFO - Started process (PID=58617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:41.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:48:41.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:41.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:41.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:48:41.298+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:41.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:48:41.329+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:48:41.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:48:41.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-17T18:49:11.527+0000] {processor.py:157} INFO - Started process (PID=58625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:11.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:49:11.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:11.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:11.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:11.609+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:11.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:49:11.624+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:11.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:49:11.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-17T18:49:41.965+0000] {processor.py:157} INFO - Started process (PID=58637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:41.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:49:41.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:41.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:42.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:49:42.038+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:42.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:49:42.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:49:42.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:49:42.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T18:50:12.313+0000] {processor.py:157} INFO - Started process (PID=58647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:12.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:50:12.337+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:12.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:12.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:12.386+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:12.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:50:12.411+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:12.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:50:12.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T18:50:42.640+0000] {processor.py:157} INFO - Started process (PID=58657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:42.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:50:42.648+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:42.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:42.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:50:42.727+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:42.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:50:42.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:50:42.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:50:42.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T18:51:13.054+0000] {processor.py:157} INFO - Started process (PID=58667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:13.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:51:13.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:13.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:13.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:13.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:13.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:51:13.164+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:13.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:51:13.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T18:51:43.449+0000] {processor.py:157} INFO - Started process (PID=58677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:43.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:51:43.457+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:43.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:43.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:51:43.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:43.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:51:43.558+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:51:43.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:51:43.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T18:52:13.897+0000] {processor.py:157} INFO - Started process (PID=58687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:13.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:52:13.904+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:13.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:13.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:13.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:13.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:52:13.994+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:13.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:52:14.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T18:52:44.289+0000] {processor.py:157} INFO - Started process (PID=58697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:44.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:52:44.293+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:44.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:44.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:52:44.394+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:44.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:52:44.412+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:52:44.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:52:44.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T18:53:14.824+0000] {processor.py:157} INFO - Started process (PID=58706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:14.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:53:14.834+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:14.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:14.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:14.916+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:14.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:53:14.932+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:14.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:53:14.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-17T18:53:45.205+0000] {processor.py:157} INFO - Started process (PID=58717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:45.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:53:45.212+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:45.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:45.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:53:45.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:45.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:53:45.302+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:53:45.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:53:45.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T18:54:15.655+0000] {processor.py:157} INFO - Started process (PID=58727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:15.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:54:15.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:15.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:15.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:15.831+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:15.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:54:15.857+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:15.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:54:15.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-17T18:54:46.174+0000] {processor.py:157} INFO - Started process (PID=58737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:46.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:54:46.182+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:46.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:46.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:54:46.269+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:46.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:54:46.283+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:54:46.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:54:46.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-17T18:55:16.557+0000] {processor.py:157} INFO - Started process (PID=58747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:16.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:55:16.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:16.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:16.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:16.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:16.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:55:16.687+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:16.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:55:16.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T18:55:46.859+0000] {processor.py:157} INFO - Started process (PID=58757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:46.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:55:46.876+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:46.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:46.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:55:46.946+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:46.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:55:46.960+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:55:46.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:55:46.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T18:56:17.338+0000] {processor.py:157} INFO - Started process (PID=58767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:17.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:56:17.350+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:17.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:17.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:17.413+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:17.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:56:17.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:17.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:56:17.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T18:56:47.734+0000] {processor.py:157} INFO - Started process (PID=58777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:47.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:56:47.742+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:47.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:47.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:56:47.795+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:47.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:56:47.816+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:56:47.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:56:47.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T18:57:18.208+0000] {processor.py:157} INFO - Started process (PID=58787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:18.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:57:18.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:18.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:18.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:18.316+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:18.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:57:18.336+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:18.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:57:18.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T18:57:48.576+0000] {processor.py:157} INFO - Started process (PID=58797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:48.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:57:48.588+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:48.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:48.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:57:48.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:48.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:57:48.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:57:48.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:57:48.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-17T18:58:19.111+0000] {processor.py:157} INFO - Started process (PID=58807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:19.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:58:19.119+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:19.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:19.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:19.199+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:19.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:58:19.218+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:19.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:58:19.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T18:58:49.449+0000] {processor.py:157} INFO - Started process (PID=58817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:49.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:58:49.464+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:49.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:49.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:58:49.535+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:49.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:58:49.558+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:58:49.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:58:49.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T18:59:19.881+0000] {processor.py:157} INFO - Started process (PID=58827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:19.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:59:19.901+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:19.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:19.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:19.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:19.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:59:20.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:20.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:59:20.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-17T18:59:50.376+0000] {processor.py:157} INFO - Started process (PID=58837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:50.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T18:59:50.387+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:50.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:50.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T18:59:50.458+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:50.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T18:59:50.476+0000] {logging_mixin.py:151} INFO - [2024-09-17T18:59:50.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T18:59:50.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T19:00:20.918+0000] {processor.py:157} INFO - Started process (PID=58847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:20.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:00:20.924+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:20.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:20.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:20.987+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:20.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:00:21.001+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:21.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:00:21.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T19:00:51.396+0000] {processor.py:157} INFO - Started process (PID=58856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:51.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:00:51.405+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:51.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:51.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:00:51.485+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:51.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:00:51.501+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:00:51.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:00:51.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T19:01:21.699+0000] {processor.py:157} INFO - Started process (PID=58867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:21.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:01:21.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:21.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:21.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:21.766+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:21.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:01:21.780+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:21.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:01:21.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-17T19:01:52.043+0000] {processor.py:157} INFO - Started process (PID=58877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:52.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:01:52.049+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:52.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:52.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:01:52.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:52.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:01:52.142+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:01:52.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:01:52.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T19:02:22.431+0000] {processor.py:157} INFO - Started process (PID=58887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:22.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:02:22.448+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:22.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:22.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:22.510+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:22.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:02:22.528+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:22.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:02:22.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T19:02:52.872+0000] {processor.py:157} INFO - Started process (PID=58897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:52.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:02:52.891+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:52.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:52.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:02:52.991+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:52.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:02:53.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:02:53.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:02:53.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T19:03:23.250+0000] {processor.py:157} INFO - Started process (PID=58907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:23.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:03:23.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:23.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:23.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:23.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:23.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:03:23.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:23.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:03:23.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T19:03:53.604+0000] {processor.py:157} INFO - Started process (PID=58917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:53.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:03:53.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:53.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:53.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:03:53.727+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:53.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:03:53.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:03:53.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:03:53.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-17T19:04:24.335+0000] {processor.py:157} INFO - Started process (PID=58927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:24.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:04:24.344+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:24.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:24.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:24.439+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:24.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:04:24.456+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:24.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:04:24.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T19:04:54.755+0000] {processor.py:157} INFO - Started process (PID=58937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:54.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:04:54.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:54.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:54.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:04:54.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:54.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:04:54.899+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:04:54.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:04:54.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T19:05:25.114+0000] {processor.py:157} INFO - Started process (PID=58947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:25.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:05:25.133+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:25.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:25.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:25.202+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:25.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:05:25.216+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:25.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:05:25.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T19:05:55.551+0000] {processor.py:157} INFO - Started process (PID=58957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:55.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:05:55.560+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:55.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:55.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:05:55.651+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:55.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:05:55.669+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:05:55.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:05:55.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T19:06:25.879+0000] {processor.py:157} INFO - Started process (PID=58967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:25.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:06:25.887+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:25.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:25.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:25.974+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:25.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:06:25.990+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:25.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:06:26.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T19:06:56.304+0000] {processor.py:157} INFO - Started process (PID=58977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:56.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:06:56.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:56.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:56.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:06:56.370+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:56.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:06:56.383+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:06:56.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:06:56.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-17T19:07:26.868+0000] {processor.py:157} INFO - Started process (PID=58987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:26.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:07:26.894+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:26.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:26.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:26.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:26.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:07:26.990+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:26.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:07:27.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-17T19:07:57.282+0000] {processor.py:157} INFO - Started process (PID=58997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:57.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:07:57.292+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:57.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:57.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:07:57.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:57.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:07:57.385+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:07:57.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:07:57.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T19:08:27.661+0000] {processor.py:157} INFO - Started process (PID=59007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:27.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:08:27.666+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:27.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:27.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:27.738+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:27.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:08:27.751+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:27.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:08:27.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-17T19:08:57.940+0000] {processor.py:157} INFO - Started process (PID=59017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:57.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:08:57.943+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:57.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:57.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:08:57.973+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:57.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:08:57.984+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:08:57.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:08:57.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-17T19:09:28.294+0000] {processor.py:157} INFO - Started process (PID=59027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:28.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:09:28.300+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:28.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:28.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:28.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:28.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:09:28.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:28.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:09:28.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-17T19:09:58.763+0000] {processor.py:157} INFO - Started process (PID=59037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:58.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:09:58.776+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:58.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:58.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:09:58.839+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:58.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:09:58.856+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:09:58.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:09:58.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T19:10:29.182+0000] {processor.py:157} INFO - Started process (PID=59047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:29.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:10:29.192+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:29.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:29.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:29.256+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:29.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:10:29.271+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:29.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:10:29.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T19:10:59.748+0000] {processor.py:157} INFO - Started process (PID=59057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:59.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:10:59.758+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:59.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:59.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:10:59.828+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:59.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:10:59.842+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:10:59.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:10:59.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T19:11:30.215+0000] {processor.py:157} INFO - Started process (PID=59067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:11:30.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:11:30.229+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:11:30.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:11:30.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:11:30.291+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:11:30.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:11:30.305+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:11:30.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:11:30.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T19:12:00.624+0000] {processor.py:157} INFO - Started process (PID=59077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:00.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:12:00.631+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:00.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:00.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:00.711+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:00.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:12:00.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:00.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:12:00.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T19:12:31.069+0000] {processor.py:157} INFO - Started process (PID=59086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:31.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:12:31.082+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:31.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:31.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:12:31.169+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:31.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:12:31.195+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:12:31.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:12:31.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-17T19:13:01.396+0000] {processor.py:157} INFO - Started process (PID=59097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:01.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:13:01.406+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:01.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:01.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:01.477+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:01.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:13:01.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:01.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:13:01.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-17T19:13:31.799+0000] {processor.py:157} INFO - Started process (PID=59107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:31.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:13:31.806+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:31.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:31.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:13:31.868+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:31.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:13:31.884+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:13:31.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:13:31.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T19:14:02.132+0000] {processor.py:157} INFO - Started process (PID=59117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:02.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:14:02.141+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:02.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:02.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:02.210+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:02.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:14:02.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:02.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:14:02.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T19:14:32.522+0000] {processor.py:157} INFO - Started process (PID=59127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:32.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:14:32.533+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:32.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:32.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:14:32.603+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:32.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:14:32.622+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:14:32.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:14:32.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T19:15:02.913+0000] {processor.py:157} INFO - Started process (PID=59137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:02.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:15:02.920+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:02.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:02.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:02.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:02.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:15:03.016+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:03.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:15:03.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T19:15:33.235+0000] {processor.py:157} INFO - Started process (PID=59147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:33.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:15:33.244+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:33.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:33.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:15:33.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:33.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:15:33.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:15:33.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:15:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T19:16:03.662+0000] {processor.py:157} INFO - Started process (PID=59157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:03.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:16:03.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:03.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:03.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:03.757+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:03.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:16:03.771+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:03.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:16:03.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T19:16:34.060+0000] {processor.py:157} INFO - Started process (PID=59167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:34.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:16:34.066+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:34.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:34.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:16:34.129+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:34.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:16:34.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:16:34.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:16:34.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T19:17:04.730+0000] {processor.py:157} INFO - Started process (PID=59177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:04.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:17:04.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:04.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:04.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:04.855+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:04.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:17:04.873+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:04.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:17:04.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-17T19:17:35.116+0000] {processor.py:157} INFO - Started process (PID=59186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:35.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:17:35.128+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:35.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:35.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:17:35.211+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:35.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:17:35.229+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:17:35.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:17:35.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T19:18:05.510+0000] {processor.py:157} INFO - Started process (PID=59197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:05.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:18:05.520+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:05.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:05.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:05.611+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:05.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:18:05.627+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:05.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:18:05.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T19:18:35.996+0000] {processor.py:157} INFO - Started process (PID=59207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:35.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:18:36.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:36.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:36.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:18:36.051+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:36.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:18:36.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:18:36.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:18:36.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-17T19:19:06.332+0000] {processor.py:157} INFO - Started process (PID=59217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:06.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:19:06.338+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:06.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:06.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:06.401+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:06.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:19:06.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:06.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:19:06.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T19:19:36.658+0000] {processor.py:157} INFO - Started process (PID=59227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:36.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:19:36.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:36.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:36.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:19:36.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:36.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:19:36.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:19:36.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:19:36.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T19:20:07.074+0000] {processor.py:157} INFO - Started process (PID=59236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:07.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:20:07.081+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:07.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:07.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:07.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:07.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:20:07.148+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:07.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:20:07.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-17T19:20:37.350+0000] {processor.py:157} INFO - Started process (PID=59247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:37.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:20:37.353+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:37.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:37.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:20:37.380+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:37.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:20:37.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:20:37.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:20:37.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-17T19:21:07.761+0000] {processor.py:157} INFO - Started process (PID=59257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:07.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:21:07.773+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:07.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:07.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:07.850+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:07.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:21:07.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:07.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:21:07.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T19:21:38.131+0000] {processor.py:157} INFO - Started process (PID=59266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:38.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:21:38.139+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:38.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:38.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:21:38.214+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:38.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:21:38.232+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:21:38.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:21:38.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T19:22:08.479+0000] {processor.py:157} INFO - Started process (PID=59276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:08.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:22:08.502+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:08.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:08.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:08.584+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:08.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:22:08.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:08.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:22:08.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T19:22:38.914+0000] {processor.py:157} INFO - Started process (PID=59287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:38.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:22:38.934+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:38.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:38.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:22:39.026+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:39.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:22:39.043+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:22:39.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:22:39.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T19:23:09.254+0000] {processor.py:157} INFO - Started process (PID=59297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:09.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:23:09.273+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:09.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:09.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:09.340+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:09.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:23:09.355+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:09.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:23:09.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T19:23:39.649+0000] {processor.py:157} INFO - Started process (PID=59307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:39.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:23:39.677+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:39.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:39.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:23:39.724+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:39.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:23:39.738+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:23:39.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:23:39.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T19:24:10.162+0000] {processor.py:157} INFO - Started process (PID=59317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:24:10.173+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:10.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:10.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:10.258+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:10.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:24:10.274+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:10.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:24:10.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T19:24:40.571+0000] {processor.py:157} INFO - Started process (PID=59327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:40.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:24:40.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:40.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:40.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:24:40.668+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:40.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:24:40.688+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:24:40.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:24:40.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T19:25:10.994+0000] {processor.py:157} INFO - Started process (PID=59337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:10.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:25:11.008+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:11.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:11.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:11.150+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:11.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:25:11.174+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:11.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:25:11.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-17T19:25:41.417+0000] {processor.py:157} INFO - Started process (PID=59347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:41.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:25:41.423+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:41.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:41.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:25:41.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:41.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:25:41.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:25:41.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:25:41.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T19:26:11.858+0000] {processor.py:157} INFO - Started process (PID=59357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:11.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:26:11.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:11.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:11.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:11.939+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:11.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:26:11.955+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:11.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:26:11.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T19:26:42.247+0000] {processor.py:157} INFO - Started process (PID=59367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:42.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:26:42.255+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:42.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:42.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:26:42.360+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:42.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:26:42.382+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:26:42.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:26:42.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T19:27:12.724+0000] {processor.py:157} INFO - Started process (PID=59377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:12.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:27:12.735+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:12.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:12.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:12.826+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:12.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:27:12.859+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:12.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:27:12.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T19:27:43.215+0000] {processor.py:157} INFO - Started process (PID=59387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:43.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:27:43.225+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:43.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:43.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:27:43.314+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:43.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:27:43.332+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:27:43.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:27:43.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-17T19:28:13.571+0000] {processor.py:157} INFO - Started process (PID=59397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:13.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:28:13.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:13.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:13.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:13.655+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:13.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:28:13.676+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:13.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:28:13.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T19:28:43.953+0000] {processor.py:157} INFO - Started process (PID=59407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:43.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:28:43.961+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:43.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:43.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:28:44.030+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:44.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:28:44.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:28:44.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:28:44.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-17T19:29:14.395+0000] {processor.py:157} INFO - Started process (PID=59417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:14.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:29:14.432+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:14.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:14.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:14.591+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:14.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:29:14.614+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:14.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:29:14.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.280 seconds
[2024-09-17T19:29:44.735+0000] {processor.py:157} INFO - Started process (PID=59427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:44.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:29:44.743+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:44.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:44.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:29:44.842+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:44.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:29:44.891+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:29:44.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:29:44.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-17T19:30:15.278+0000] {processor.py:157} INFO - Started process (PID=59437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:15.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:30:15.284+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:15.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:15.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:15.370+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:15.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:30:15.391+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:15.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:30:15.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T19:30:45.788+0000] {processor.py:157} INFO - Started process (PID=59447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:45.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:30:45.794+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:45.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:45.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:30:45.878+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:45.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:30:45.912+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:30:45.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:30:45.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T19:31:16.127+0000] {processor.py:157} INFO - Started process (PID=59457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:16.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:31:16.143+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:16.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:16.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:16.224+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:16.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:31:16.244+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:16.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:31:16.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T19:31:46.603+0000] {processor.py:157} INFO - Started process (PID=59467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:46.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:31:46.618+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:46.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:46.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:31:46.697+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:46.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:31:46.721+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:31:46.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:31:46.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T19:32:16.950+0000] {processor.py:157} INFO - Started process (PID=59477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:16.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:32:16.957+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:16.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:16.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:17.045+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:17.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:32:17.063+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:17.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:32:17.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T19:32:47.529+0000] {processor.py:157} INFO - Started process (PID=59487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:47.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:32:47.537+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:47.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:47.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:32:47.600+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:47.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:32:47.632+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:32:47.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:32:47.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T19:33:17.977+0000] {processor.py:157} INFO - Started process (PID=59497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:17.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:33:17.986+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:17.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:18.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:18.093+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:18.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:33:18.112+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:18.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:33:18.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T19:33:48.400+0000] {processor.py:157} INFO - Started process (PID=59507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:48.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:33:48.415+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:48.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:48.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:33:48.565+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:48.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:33:48.587+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:33:48.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:33:48.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-09-17T19:34:18.677+0000] {processor.py:157} INFO - Started process (PID=59517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:18.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:34:18.685+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:18.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:18.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:18.749+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:18.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:34:18.778+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:18.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:34:18.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-17T19:34:49.165+0000] {processor.py:157} INFO - Started process (PID=59527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:49.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:34:49.177+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:49.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:49.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:34:49.239+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:49.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:34:49.259+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:34:49.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:34:49.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-17T19:35:19.518+0000] {processor.py:157} INFO - Started process (PID=59537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:19.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:35:19.530+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:19.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:19.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:19.661+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:19.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:35:19.726+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:19.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:35:19.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-17T19:35:49.855+0000] {processor.py:157} INFO - Started process (PID=59547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:49.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:35:49.864+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:49.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:49.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:35:49.945+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:49.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:35:49.964+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:35:49.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:35:49.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T19:36:20.423+0000] {processor.py:157} INFO - Started process (PID=59557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:20.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:36:20.429+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:20.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:20.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:20.503+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:20.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:36:20.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:20.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:36:20.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-17T19:36:50.813+0000] {processor.py:157} INFO - Started process (PID=59567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:50.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:36:50.833+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:50.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:50.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:36:50.906+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:50.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:36:50.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:36:50.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:36:50.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T19:37:21.230+0000] {processor.py:157} INFO - Started process (PID=59577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:21.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:37:21.241+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:21.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:21.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:21.350+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:21.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:37:21.377+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:21.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:37:21.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-17T19:37:51.666+0000] {processor.py:157} INFO - Started process (PID=59587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:51.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:37:51.685+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:51.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:51.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:37:51.764+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:51.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:37:51.786+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:37:51.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:37:51.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-17T19:38:22.055+0000] {processor.py:157} INFO - Started process (PID=59597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:22.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:38:22.066+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:22.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:22.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:22.158+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:22.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:38:22.186+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:22.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:38:22.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-17T19:38:52.396+0000] {processor.py:157} INFO - Started process (PID=59607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:52.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:38:52.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:52.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:52.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:38:52.489+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:52.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:38:52.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:38:52.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:38:52.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T19:39:22.865+0000] {processor.py:157} INFO - Started process (PID=59617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:22.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:39:22.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:22.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:22.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:22.981+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:22.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:39:23.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:23.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:39:23.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-17T19:39:53.193+0000] {processor.py:157} INFO - Started process (PID=59627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:53.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:39:53.214+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:53.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:53.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:39:53.300+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:53.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:39:53.317+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:39:53.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:39:53.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T19:40:23.620+0000] {processor.py:157} INFO - Started process (PID=59637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:23.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:40:23.638+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:23.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:23.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:23.721+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:23.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:40:23.747+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:23.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:40:23.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T19:40:53.952+0000] {processor.py:157} INFO - Started process (PID=59647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:53.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:40:53.959+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:53.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:53.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:40:54.032+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:54.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:40:54.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:40:54.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:40:54.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T19:41:24.463+0000] {processor.py:157} INFO - Started process (PID=59657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:24.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:41:24.472+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:24.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:24.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:24.540+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:24.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:41:24.563+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:24.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:41:24.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T19:41:54.794+0000] {processor.py:157} INFO - Started process (PID=59667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:54.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:41:54.803+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:54.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:54.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:41:54.967+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:54.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:41:54.994+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:41:54.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:41:55.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-09-17T19:42:25.132+0000] {processor.py:157} INFO - Started process (PID=59677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:25.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:42:25.140+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:25.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:25.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:25.253+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:25.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:42:25.276+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:25.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:42:25.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T19:42:55.574+0000] {processor.py:157} INFO - Started process (PID=59687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:55.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:42:55.580+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:55.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:55.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:42:55.640+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:55.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:42:55.656+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:42:55.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:42:55.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-17T19:43:25.971+0000] {processor.py:157} INFO - Started process (PID=59697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:25.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:43:25.975+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:25.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:25.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:26.018+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:26.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:43:26.033+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:26.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:43:26.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-17T19:43:56.264+0000] {processor.py:157} INFO - Started process (PID=59707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:56.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:43:56.280+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:56.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:56.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:43:56.331+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:56.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:43:56.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:43:56.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:43:56.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-17T19:44:26.569+0000] {processor.py:157} INFO - Started process (PID=59717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:26.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:44:26.573+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:26.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:26.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:26.610+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:26.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:44:26.637+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:26.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:44:26.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-17T19:44:56.893+0000] {processor.py:157} INFO - Started process (PID=59727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:56.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:44:56.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:56.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:56.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:44:56.948+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:56.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:44:56.960+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:44:56.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:44:56.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-17T19:45:27.316+0000] {processor.py:157} INFO - Started process (PID=59737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:27.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:45:27.323+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:27.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:27.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:27.403+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:27.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:45:27.419+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:27.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:45:27.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T19:45:57.667+0000] {processor.py:157} INFO - Started process (PID=59747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:57.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:45:57.674+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:57.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:57.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:45:57.750+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:57.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:45:57.767+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:45:57.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:45:57.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-17T19:46:27.949+0000] {processor.py:157} INFO - Started process (PID=59757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:27.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:46:27.954+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:27.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:27.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:28.003+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:28.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:46:28.024+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:28.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:46:28.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-17T19:46:58.360+0000] {processor.py:157} INFO - Started process (PID=59767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:58.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:46:58.368+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:58.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:58.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:46:58.448+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:58.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:46:58.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:46:58.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:46:58.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-17T19:47:28.931+0000] {processor.py:157} INFO - Started process (PID=59777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:28.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:47:28.943+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:28.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:28.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:29.040+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:29.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:47:29.065+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:29.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:47:29.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-17T19:47:59.493+0000] {processor.py:157} INFO - Started process (PID=59786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:59.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:47:59.504+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:59.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:59.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:47:59.598+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:59.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:47:59.629+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:47:59.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:47:59.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T19:48:30.043+0000] {processor.py:157} INFO - Started process (PID=59797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:48:30.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:48:30.051+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:48:30.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:48:30.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:48:30.126+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:48:30.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:48:30.145+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:48:30.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:48:30.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-17T19:49:00.331+0000] {processor.py:157} INFO - Started process (PID=59807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:00.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:49:00.339+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:00.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:00.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:00.411+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:00.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:49:00.437+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:00.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:49:00.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T19:49:30.784+0000] {processor.py:157} INFO - Started process (PID=59816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:30.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:49:30.790+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:30.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:30.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:49:30.859+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:30.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:49:30.877+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:49:30.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:49:30.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-17T19:50:01.201+0000] {processor.py:157} INFO - Started process (PID=59827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:01.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:50:01.208+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:01.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:01.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:01.288+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:01.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:50:01.307+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:01.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:50:01.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T19:50:31.639+0000] {processor.py:157} INFO - Started process (PID=59837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:31.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:50:31.654+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:31.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:31.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:50:31.718+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:31.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:50:31.755+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:50:31.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:50:31.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T19:51:02.029+0000] {processor.py:157} INFO - Started process (PID=59847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:02.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:51:02.048+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:02.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:02.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:02.114+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:02.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:51:02.134+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:02.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:51:02.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-17T19:51:32.463+0000] {processor.py:157} INFO - Started process (PID=59857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:32.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:51:32.474+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:32.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:32.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:51:32.557+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:32.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:51:32.582+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:51:32.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:51:32.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T19:52:02.850+0000] {processor.py:157} INFO - Started process (PID=59866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:02.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:52:02.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:02.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:02.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:02.936+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:02.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:52:02.958+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:02.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:52:02.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T19:52:33.374+0000] {processor.py:157} INFO - Started process (PID=59877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:33.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:52:33.382+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:33.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:33.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:52:33.494+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:33.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:52:33.515+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:52:33.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:52:33.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-17T19:53:03.733+0000] {processor.py:157} INFO - Started process (PID=59887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:03.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:53:03.740+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:03.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:03.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:03.837+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:03.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:53:03.866+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:03.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:53:03.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T19:53:34.168+0000] {processor.py:157} INFO - Started process (PID=59897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:34.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:53:34.184+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:34.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:34.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:53:34.249+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:34.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:53:34.283+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:53:34.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:53:34.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-17T19:54:04.467+0000] {processor.py:157} INFO - Started process (PID=59907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:04.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:54:04.478+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:04.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:04.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:04.558+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:04.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:54:04.592+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:04.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:54:04.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T19:54:34.852+0000] {processor.py:157} INFO - Started process (PID=59917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:34.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:54:34.860+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:34.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:34.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:54:34.948+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:34.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:54:34.972+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:54:34.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:54:34.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T19:55:05.213+0000] {processor.py:157} INFO - Started process (PID=59927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:05.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:55:05.219+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:05.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:05.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:05.275+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:05.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:55:05.294+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:05.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:55:05.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T19:55:35.538+0000] {processor.py:157} INFO - Started process (PID=59936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:35.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:55:35.564+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:35.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:35.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:55:35.656+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:35.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:55:35.695+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:55:35.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:55:35.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-17T19:56:06.104+0000] {processor.py:157} INFO - Started process (PID=59947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:06.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:56:06.113+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:06.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:06.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:06.202+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:06.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:56:06.223+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:06.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:56:06.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-17T19:56:36.566+0000] {processor.py:157} INFO - Started process (PID=59957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:36.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:56:36.576+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:36.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:36.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:56:36.647+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:36.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:56:36.671+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:56:36.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:56:36.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-17T19:57:06.948+0000] {processor.py:157} INFO - Started process (PID=59966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:06.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:57:06.955+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:06.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:06.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:07.052+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:07.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:57:07.093+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:07.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:57:07.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-17T19:57:37.314+0000] {processor.py:157} INFO - Started process (PID=59977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:37.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:57:37.325+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:37.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:37.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:57:37.408+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:37.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:57:37.452+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:57:37.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:57:37.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-17T19:58:07.703+0000] {processor.py:157} INFO - Started process (PID=59987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:07.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:58:07.710+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:07.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:07.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:07.802+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:07.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:58:07.824+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:07.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:58:07.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-17T19:58:38.031+0000] {processor.py:157} INFO - Started process (PID=59996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:38.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:58:38.039+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:38.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:38.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:58:38.120+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:38.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:58:38.139+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:58:38.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:58:38.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T19:59:08.694+0000] {processor.py:157} INFO - Started process (PID=60007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:08.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:59:08.706+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:08.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:08.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:08.797+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:08.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:59:08.819+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:08.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:59:08.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-17T19:59:39.113+0000] {processor.py:157} INFO - Started process (PID=60017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:39.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T19:59:39.127+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:39.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:39.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T19:59:39.223+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:39.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T19:59:39.257+0000] {logging_mixin.py:151} INFO - [2024-09-17T19:59:39.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T19:59:39.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-17T20:00:09.526+0000] {processor.py:157} INFO - Started process (PID=60027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:09.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:00:09.545+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:09.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:09.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:09.617+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:09.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:00:09.646+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:09.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:00:09.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-17T20:00:39.785+0000] {processor.py:157} INFO - Started process (PID=60037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:39.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:00:39.790+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:39.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:39.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:00:39.865+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:39.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:00:39.888+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:00:39.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:00:39.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-17T20:01:10.297+0000] {processor.py:157} INFO - Started process (PID=60047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:10.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:01:10.308+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:10.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:10.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:10.397+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:10.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:01:10.425+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:10.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:01:10.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-17T20:01:40.603+0000] {processor.py:157} INFO - Started process (PID=60057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:40.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:01:40.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:40.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:40.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:01:40.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:40.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:01:40.708+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:01:40.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:01:40.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T20:02:11.006+0000] {processor.py:157} INFO - Started process (PID=60067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:11.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:02:11.013+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:11.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:11.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:11.067+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:11.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:02:11.084+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:11.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:02:11.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-17T20:02:41.357+0000] {processor.py:157} INFO - Started process (PID=60077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:41.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:02:41.365+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:41.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:41.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:02:41.447+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:41.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:02:41.473+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:02:41.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:02:41.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-17T20:03:11.762+0000] {processor.py:157} INFO - Started process (PID=60087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:11.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:03:11.772+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:11.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:11.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:11.874+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:11.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:03:11.898+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:11.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:03:11.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-17T20:03:42.192+0000] {processor.py:157} INFO - Started process (PID=60097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:42.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:03:42.201+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:42.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:42.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:03:42.297+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:42.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:03:42.321+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:03:42.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:03:42.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-17T20:04:12.721+0000] {processor.py:157} INFO - Started process (PID=60107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:12.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:04:12.741+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:12.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:12.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:12.820+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:12.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:04:12.843+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:12.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:04:12.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-17T20:04:43.295+0000] {processor.py:157} INFO - Started process (PID=60117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:43.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:04:43.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:43.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:43.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:04:43.487+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:43.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:04:43.519+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:04:43.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:04:43.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.322 seconds
[2024-09-17T20:05:13.669+0000] {processor.py:157} INFO - Started process (PID=60127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:13.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:05:13.678+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:13.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:13.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:13.770+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:13.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:05:13.810+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:13.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:05:13.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-17T20:05:44.128+0000] {processor.py:157} INFO - Started process (PID=60137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:44.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:05:44.138+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:44.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:44.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:05:44.230+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:44.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:05:44.268+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:05:44.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:05:44.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-17T20:06:14.594+0000] {processor.py:157} INFO - Started process (PID=60147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:14.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:06:14.615+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:14.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:14.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:14.714+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:14.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:06:14.737+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:14.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:06:14.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-17T20:06:44.962+0000] {processor.py:157} INFO - Started process (PID=60157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:44.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:06:44.979+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:44.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:45.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:06:45.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:45.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:06:45.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:06:45.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:06:45.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T20:07:15.303+0000] {processor.py:157} INFO - Started process (PID=60167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:15.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:07:15.312+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:15.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:15.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:15.404+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:15.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:07:15.424+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:15.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:07:15.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T20:07:45.825+0000] {processor.py:157} INFO - Started process (PID=60177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:45.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:07:45.834+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:45.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:45.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:07:45.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:45.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:07:45.951+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:07:45.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:07:45.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-17T20:08:16.186+0000] {processor.py:157} INFO - Started process (PID=60187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:16.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:08:16.192+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:16.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:16.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:16.252+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:16.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:08:16.268+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:16.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:08:16.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-17T20:08:46.588+0000] {processor.py:157} INFO - Started process (PID=60197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:46.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:08:46.594+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:46.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:46.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:08:46.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:46.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:08:46.689+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:08:46.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:08:46.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T20:09:17.039+0000] {processor.py:157} INFO - Started process (PID=60207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:17.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:09:17.049+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:17.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:17.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:17.127+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:17.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:09:17.144+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:17.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:09:17.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-17T20:09:47.377+0000] {processor.py:157} INFO - Started process (PID=60217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:47.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:09:47.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:47.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:47.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:09:47.465+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:47.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:09:47.490+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:09:47.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:09:47.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-17T20:10:17.740+0000] {processor.py:157} INFO - Started process (PID=60227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:17.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:10:17.749+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:17.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:17.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:17.814+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:17.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:10:17.832+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:17.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:10:17.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T20:10:48.095+0000] {processor.py:157} INFO - Started process (PID=60237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:48.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:10:48.104+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:48.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:48.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:10:48.180+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:48.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:10:48.199+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:10:48.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:10:48.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T20:11:18.523+0000] {processor.py:157} INFO - Started process (PID=60247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:18.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:11:18.530+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:18.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:18.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:18.606+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:18.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:11:18.628+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:18.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:11:18.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T20:11:49.051+0000] {processor.py:157} INFO - Started process (PID=60257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:49.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:11:49.059+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:49.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:49.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:11:49.146+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:49.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:11:49.165+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:11:49.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:11:49.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-17T20:12:19.415+0000] {processor.py:157} INFO - Started process (PID=60267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:19.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:12:19.430+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:19.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:19.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:19.508+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:19.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:12:19.531+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:19.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:12:19.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T20:12:49.743+0000] {processor.py:157} INFO - Started process (PID=60277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:49.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:12:49.752+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:49.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:49.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:12:49.840+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:49.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:12:49.863+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:12:49.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:12:49.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-17T20:13:20.264+0000] {processor.py:157} INFO - Started process (PID=60287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:20.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:13:20.272+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:20.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:20.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:20.335+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:20.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:13:20.352+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:20.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:13:20.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T20:13:50.651+0000] {processor.py:157} INFO - Started process (PID=60297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:50.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:13:50.658+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:50.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:50.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:13:50.719+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:50.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:13:50.736+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:13:50.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:13:50.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-17T20:14:20.974+0000] {processor.py:157} INFO - Started process (PID=60307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:20.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:14:20.981+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:20.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:21.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:21.044+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:21.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:14:21.062+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:21.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:14:21.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-17T20:14:51.308+0000] {processor.py:157} INFO - Started process (PID=60317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:51.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:14:51.320+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:51.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:51.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:14:51.438+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:51.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:14:51.462+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:14:51.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:14:51.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-17T20:15:21.737+0000] {processor.py:157} INFO - Started process (PID=60327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:21.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:15:21.745+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:21.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:21.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:21.867+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:21.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:15:21.886+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:21.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:15:21.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-17T20:15:52.130+0000] {processor.py:157} INFO - Started process (PID=60337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:52.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:15:52.136+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:52.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:52.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:15:52.203+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:52.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:15:52.220+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:15:52.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:15:52.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-17T20:16:22.502+0000] {processor.py:157} INFO - Started process (PID=60347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:22.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:16:22.509+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:22.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:22.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:22.591+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:22.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:16:22.613+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:22.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:16:22.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-17T20:16:52.945+0000] {processor.py:157} INFO - Started process (PID=60357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:52.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:16:52.956+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:52.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:52.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:16:53.046+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:53.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:16:53.071+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:16:53.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:16:53.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T20:17:23.540+0000] {processor.py:157} INFO - Started process (PID=60367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:23.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:17:23.553+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:23.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:23.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:23.635+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:23.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:17:23.658+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:23.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:17:23.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-17T20:17:53.923+0000] {processor.py:157} INFO - Started process (PID=60377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:53.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:17:53.929+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:53.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:53.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:17:53.995+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:53.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:17:54.021+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:17:54.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:17:54.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T20:18:24.372+0000] {processor.py:157} INFO - Started process (PID=60387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:24.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:18:24.379+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:24.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:24.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:24.454+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:24.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:18:24.479+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:24.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:18:24.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-17T20:18:54.957+0000] {processor.py:157} INFO - Started process (PID=60397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:54.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:18:54.966+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:54.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:55.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:18:55.054+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:55.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:18:55.073+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:18:55.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:18:55.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-17T20:19:25.287+0000] {processor.py:157} INFO - Started process (PID=60407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:25.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:19:25.295+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:25.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:25.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:25.364+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:25.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:19:25.390+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:25.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:19:25.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T20:19:55.608+0000] {processor.py:157} INFO - Started process (PID=60417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:55.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:19:55.616+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:55.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:55.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:19:55.690+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:55.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:19:55.715+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:19:55.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:19:55.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-17T20:20:26.068+0000] {processor.py:157} INFO - Started process (PID=60427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:26.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:20:26.078+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:26.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:26.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:26.160+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:26.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:20:26.179+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:26.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:20:26.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-17T20:20:56.530+0000] {processor.py:157} INFO - Started process (PID=60437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:56.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:20:56.541+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:56.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:56.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:20:56.640+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:56.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:20:56.667+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:20:56.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:20:56.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-17T20:21:26.937+0000] {processor.py:157} INFO - Started process (PID=60447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:26.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:21:26.945+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:26.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:26.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:27.010+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:27.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:21:27.029+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:27.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:21:27.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-17T20:21:57.266+0000] {processor.py:157} INFO - Started process (PID=60457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:57.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:21:57.270+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:57.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:57.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:21:57.330+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:57.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:21:57.347+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:21:57.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:21:57.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-17T20:22:27.604+0000] {processor.py:157} INFO - Started process (PID=60467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:27.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:22:27.612+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:27.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:27.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:27.681+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:27.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:22:27.701+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:27.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:22:27.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-17T20:22:57.997+0000] {processor.py:157} INFO - Started process (PID=60477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:58.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:22:58.006+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:58.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:58.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:22:58.075+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:58.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:22:58.093+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:22:58.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:22:58.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-17T20:23:28.333+0000] {processor.py:157} INFO - Started process (PID=60487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:23:28.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-17T20:23:28.342+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:23:28.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:23:28.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-17T20:23:28.428+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:23:28.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-17T20:23:28.453+0000] {logging_mixin.py:151} INFO - [2024-09-17T20:23:28.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-16T01:00:00+00:00, run_after=2024-09-17T01:00:00+00:00
[2024-09-17T20:23:28.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
