[2024-09-14T00:21:57.316+0000] {processor.py:157} INFO - Started process (PID=80747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:21:57.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:21:57.323+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:21:57.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:21:57.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:21:57.833+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:21:57.833+0000] {security.py:708} INFO - Not syncing DAG-level permissions for DAG 'DAG:spark_data_processing_pipeline' as access control is unset.
[2024-09-14T00:21:57.834+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:21:57.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:21:57.862+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:21:57.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:21:57.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.587 seconds
[2024-09-14T00:22:28.356+0000] {processor.py:157} INFO - Started process (PID=80758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:22:28.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:22:28.359+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:22:28.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:22:28.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:22:28.416+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:22:28.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:22:28.433+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:22:28.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:22:28.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-14T00:29:55.194+0000] {processor.py:157} INFO - Started process (PID=80768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:29:55.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:29:55.196+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:29:55.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:29:55.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:29:55.248+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:29:55.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:29:55.276+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:29:55.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:29:55.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-14T00:30:25.822+0000] {processor.py:157} INFO - Started process (PID=81366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:25.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:30:25.834+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:25.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:25.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:25.894+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:25.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:30:25.911+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:25.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:30:25.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-14T00:30:56.175+0000] {processor.py:157} INFO - Started process (PID=81376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:56.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:30:56.176+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:56.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:56.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:30:56.215+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:56.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:30:56.230+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:30:56.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:30:56.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-14T00:31:26.463+0000] {processor.py:157} INFO - Started process (PID=81385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:31:26.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:31:26.466+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:31:26.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:31:26.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:31:26.514+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:31:26.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:31:26.541+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:31:26.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:31:26.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-14T00:41:14.305+0000] {processor.py:157} INFO - Started process (PID=81396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:14.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:41:14.307+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:14.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:14.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:14.376+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:14.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:41:14.390+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:14.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:41:14.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-14T00:41:44.860+0000] {processor.py:157} INFO - Started process (PID=81574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:44.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:41:44.863+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:44.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:44.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:41:44.932+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:44.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:41:44.954+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:41:44.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:41:44.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-14T00:42:17.133+0000] {processor.py:157} INFO - Started process (PID=81584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:17.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:42:17.135+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:17.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:17.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:17.177+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:17.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:42:17.201+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:17.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:42:17.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-14T00:42:47.647+0000] {processor.py:157} INFO - Started process (PID=81594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:47.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:42:47.649+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:47.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:47.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:42:47.703+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:47.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:42:47.721+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:42:47.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:42:47.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-14T00:53:20.677+0000] {processor.py:157} INFO - Started process (PID=81604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:53:20.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T00:53:20.680+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:53:20.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:53:20.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T00:53:20.734+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:53:20.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T00:53:20.752+0000] {logging_mixin.py:151} INFO - [2024-09-14T00:53:20.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-14T00:53:20.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-14T01:08:09.990+0000] {processor.py:157} INFO - Started process (PID=81615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:09.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:08:09.992+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:09.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:10.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:10.047+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:10.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:08:10.070+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:10.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:08:10.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-14T01:08:40.339+0000] {processor.py:157} INFO - Started process (PID=81623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:40.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:08:40.343+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:40.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:40.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:08:40.409+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:40.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:08:40.424+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:08:40.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:08:40.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-14T01:30:20.474+0000] {processor.py:157} INFO - Started process (PID=81637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:30:20.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:30:20.477+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:30:20.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:30:20.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:30:20.546+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:30:20.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:30:20.566+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:30:20.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:30:20.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-14T01:34:30.328+0000] {processor.py:157} INFO - Started process (PID=81647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:34:30.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:34:30.332+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:34:30.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:34:30.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:34:30.419+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:34:30.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:34:30.456+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:34:30.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:34:30.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-14T01:35:01.441+0000] {processor.py:157} INFO - Started process (PID=81657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:01.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:35:01.443+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:01.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:01.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:01.491+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:01.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:35:01.509+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:01.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:35:01.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-14T01:35:31.769+0000] {processor.py:157} INFO - Started process (PID=81667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:31.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:35:31.771+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:31.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:31.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:35:31.804+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:31.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:35:31.816+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:35:31.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:35:31.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-14T01:36:02.154+0000] {processor.py:157} INFO - Started process (PID=81677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:02.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:36:02.158+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:02.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:02.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:02.237+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:02.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:36:02.260+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:02.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:36:02.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-14T01:36:32.469+0000] {processor.py:157} INFO - Started process (PID=81687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:32.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:36:32.470+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:32.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:32.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:36:32.504+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:32.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:36:32.514+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:36:32.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:36:32.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-14T01:37:02.787+0000] {processor.py:157} INFO - Started process (PID=81697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:02.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:37:02.790+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:02.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:02.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:02.835+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:02.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:37:02.852+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:02.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:37:02.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-14T01:37:33.134+0000] {processor.py:157} INFO - Started process (PID=81707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:33.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:37:33.139+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:33.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:33.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:37:33.303+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:33.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:37:33.334+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:37:33.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:37:33.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-09-14T01:38:03.430+0000] {processor.py:157} INFO - Started process (PID=81717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:03.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:38:03.432+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:03.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:03.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:03.475+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:03.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:38:03.491+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:03.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:38:03.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-14T01:38:33.757+0000] {processor.py:157} INFO - Started process (PID=81727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:33.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:38:33.758+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:33.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:33.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:38:33.787+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:33.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:38:33.803+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:38:33.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:38:33.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-14T01:39:04.068+0000] {processor.py:157} INFO - Started process (PID=81737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:04.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:39:04.073+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:04.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:04.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:04.141+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:04.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:39:04.161+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:04.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:39:04.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-14T01:39:34.370+0000] {processor.py:157} INFO - Started process (PID=81747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:34.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:39:34.374+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:34.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:34.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:39:34.414+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:34.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:39:34.429+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:39:34.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:39:34.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-14T01:40:04.752+0000] {processor.py:157} INFO - Started process (PID=81757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:04.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:40:04.755+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:04.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:04.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:04.843+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:04.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:40:04.861+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:04.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:40:04.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-14T01:40:35.065+0000] {processor.py:157} INFO - Started process (PID=81767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:35.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:40:35.068+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:35.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:35.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:40:35.151+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:35.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:40:35.191+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:40:35.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:40:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-14T01:41:05.540+0000] {processor.py:157} INFO - Started process (PID=81777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:05.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:41:05.557+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:05.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:05.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:05.605+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:05.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:41:05.620+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:05.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:41:05.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-14T01:41:35.781+0000] {processor.py:157} INFO - Started process (PID=81787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:35.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:41:35.783+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:35.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:35.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:41:35.815+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:35.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:41:35.826+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:41:35.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:41:35.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-14T01:42:06.133+0000] {processor.py:157} INFO - Started process (PID=81796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:06.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:42:06.137+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:06.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:06.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:06.185+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:06.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:42:06.199+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:06.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:42:06.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-14T01:42:36.539+0000] {processor.py:157} INFO - Started process (PID=81807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:36.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:42:36.540+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:36.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:36.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:42:36.568+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:36.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:42:36.578+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:42:36.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:42:36.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-14T01:43:06.863+0000] {processor.py:157} INFO - Started process (PID=81817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:06.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:43:06.865+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:06.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:06.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:06.911+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:06.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:43:06.927+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:06.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:43:06.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-14T01:43:37.295+0000] {processor.py:157} INFO - Started process (PID=81827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:37.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:43:37.298+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:37.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:37.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:43:37.360+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:37.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:43:37.375+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:43:37.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:43:37.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-14T01:44:07.620+0000] {processor.py:157} INFO - Started process (PID=81837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:07.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:44:07.623+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:07.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:07.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:07.677+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:07.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:44:07.689+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:07.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:44:07.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-14T01:44:37.938+0000] {processor.py:157} INFO - Started process (PID=81847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:37.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:44:37.942+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:37.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:37.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:44:37.989+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:37.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:44:38.001+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:44:38.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:44:38.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-14T01:45:08.251+0000] {processor.py:157} INFO - Started process (PID=81857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:08.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:45:08.266+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:08.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:08.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:08.313+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:08.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:45:08.328+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:08.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:45:08.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-14T01:45:38.718+0000] {processor.py:157} INFO - Started process (PID=81867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:38.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:45:38.732+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:38.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:38.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:45:38.810+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:38.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:45:38.839+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:45:38.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:45:38.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-14T01:46:09.047+0000] {processor.py:157} INFO - Started process (PID=81877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:09.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:46:09.051+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:09.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:09.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:09.101+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:09.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:46:09.120+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:09.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:46:09.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-14T01:46:39.352+0000] {processor.py:157} INFO - Started process (PID=81887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:39.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:46:39.356+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:39.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:39.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:46:39.431+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:39.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:46:39.459+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:46:39.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:46:39.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-14T01:47:09.736+0000] {processor.py:157} INFO - Started process (PID=81897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:47:09.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:47:09.740+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:47:09.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:47:09.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:47:09.837+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:47:09.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:47:09.857+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:47:09.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:47:09.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-14T01:56:37.462+0000] {processor.py:157} INFO - Started process (PID=81907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:56:37.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:56:37.464+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:56:37.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:56:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:56:37.515+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:56:37.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:56:37.528+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:56:37.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:56:37.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-14T01:57:07.771+0000] {processor.py:157} INFO - Started process (PID=81919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:57:07.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T01:57:07.775+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:57:07.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:57:07.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T01:57:07.834+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:57:07.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T01:57:07.848+0000] {logging_mixin.py:151} INFO - [2024-09-14T01:57:07.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T01:57:07.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-14T02:00:12.784+0000] {processor.py:157} INFO - Started process (PID=81927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:12.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:00:12.946+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:12.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:13.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:13.246+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:13.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:00:13.294+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:13.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:00:13.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.544 seconds
[2024-09-14T02:00:43.665+0000] {processor.py:157} INFO - Started process (PID=81939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:43.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:00:43.669+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:43.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:43.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:00:43.725+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:43.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:00:43.738+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:00:43.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:00:43.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-14T02:01:14.257+0000] {processor.py:157} INFO - Started process (PID=81949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:14.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:01:14.270+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:14.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:14.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:14.527+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:14.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:01:14.681+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:14.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:01:14.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.501 seconds
[2024-09-14T02:01:45.065+0000] {processor.py:157} INFO - Started process (PID=81959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:45.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:01:45.068+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:45.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:45.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:01:45.144+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:45.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:01:45.157+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:01:45.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:01:45.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-14T02:02:15.457+0000] {processor.py:157} INFO - Started process (PID=81969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:15.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:02:15.460+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:15.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:15.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:15.546+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:15.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:02:15.565+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:15.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:02:15.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-14T02:02:45.788+0000] {processor.py:157} INFO - Started process (PID=81979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:45.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:02:45.790+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:45.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:02:45.863+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:45.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:02:45.892+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:02:45.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:02:45.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-14T02:03:16.078+0000] {processor.py:157} INFO - Started process (PID=81989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:16.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:03:16.089+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:16.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:16.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:16.177+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:16.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:03:16.211+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:16.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:03:16.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-14T02:03:47.105+0000] {processor.py:157} INFO - Started process (PID=81999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:47.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:03:47.108+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:47.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:47.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:03:47.191+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:47.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:03:47.213+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:03:47.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:03:47.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-14T02:04:17.369+0000] {processor.py:157} INFO - Started process (PID=82009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:17.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:04:17.372+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:17.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:17.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:17.425+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:17.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:04:17.444+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:17.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:04:17.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-14T02:04:47.692+0000] {processor.py:157} INFO - Started process (PID=82019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:47.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:04:47.695+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:47.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:47.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:04:47.743+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:47.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:04:47.759+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:04:47.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:04:47.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-14T02:05:18.048+0000] {processor.py:157} INFO - Started process (PID=82029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:18.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:05:18.050+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:18.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:18.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:18.083+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:18.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:05:18.097+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:18.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:05:18.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-14T02:05:48.646+0000] {processor.py:157} INFO - Started process (PID=82039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:48.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:05:48.647+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:48.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:48.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:05:48.719+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:48.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:05:48.736+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:05:48.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:05:48.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-14T02:06:19.273+0000] {processor.py:157} INFO - Started process (PID=82049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:19.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:06:19.275+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:19.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:19.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:19.319+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:19.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:06:19.332+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:19.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:06:19.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-14T02:06:49.639+0000] {processor.py:157} INFO - Started process (PID=82059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:49.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:06:49.642+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:49.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:49.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:06:49.713+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:49.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:06:49.739+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:06:49.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:06:49.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-14T02:07:20.002+0000] {processor.py:157} INFO - Started process (PID=82069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:20.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:07:20.006+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:20.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:20.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:20.090+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:20.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:07:20.111+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:20.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:07:20.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-14T02:07:50.531+0000] {processor.py:157} INFO - Started process (PID=82079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:50.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:07:50.535+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:50.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:50.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:07:50.583+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:50.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:07:50.599+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:07:50.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:07:50.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-14T02:08:20.898+0000] {processor.py:157} INFO - Started process (PID=82089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:20.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:08:20.907+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:20.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:20.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:20.982+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:20.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:08:21.005+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:21.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:08:21.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-14T02:08:51.249+0000] {processor.py:157} INFO - Started process (PID=82099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:51.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:08:51.255+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:51.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:51.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:08:51.315+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:51.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:08:51.331+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:08:51.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:08:51.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-14T02:09:21.703+0000] {processor.py:157} INFO - Started process (PID=82108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:21.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:09:21.710+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:21.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:21.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:21.785+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:21.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:09:21.806+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:21.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:09:21.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-14T02:09:52.196+0000] {processor.py:157} INFO - Started process (PID=82119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:52.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:09:52.202+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:52.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:52.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:09:52.289+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:52.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:09:52.308+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:09:52.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:09:52.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-14T02:10:22.476+0000] {processor.py:157} INFO - Started process (PID=82129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:22.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:10:22.484+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:22.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:22.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:22.543+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:22.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:10:22.575+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:22.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:10:22.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-14T02:10:52.803+0000] {processor.py:157} INFO - Started process (PID=82139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:52.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:10:52.807+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:52.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:52.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:10:52.882+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:52.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:10:52.905+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:10:52.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:10:52.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-14T02:11:23.117+0000] {processor.py:157} INFO - Started process (PID=82149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:23.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:11:23.122+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:23.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:23.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:23.184+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:23.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:11:23.204+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:23.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:11:23.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-14T02:11:53.425+0000] {processor.py:157} INFO - Started process (PID=82159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:53.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:11:53.434+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:53.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:53.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:11:53.500+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:53.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:11:53.524+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:11:53.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:11:53.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-14T02:12:23.750+0000] {processor.py:157} INFO - Started process (PID=82169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:23.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:12:23.755+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:23.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:23.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:23.823+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:23.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:12:23.844+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:23.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:12:23.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-14T02:12:54.127+0000] {processor.py:157} INFO - Started process (PID=82179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:54.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:12:54.131+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:54.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:54.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:12:54.225+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:54.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:12:54.243+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:12:54.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:12:54.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-14T02:13:24.448+0000] {processor.py:157} INFO - Started process (PID=82189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:24.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:13:24.454+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:24.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:24.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:24.535+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:24.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:13:24.559+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:24.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:13:24.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-14T02:13:54.741+0000] {processor.py:157} INFO - Started process (PID=82199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:54.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:13:54.745+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:54.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:54.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:13:54.827+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:54.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:13:54.847+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:13:54.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:13:54.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-14T02:14:25.119+0000] {processor.py:157} INFO - Started process (PID=82209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:25.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:14:25.123+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:25.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:25.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:25.202+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:25.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:14:25.227+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:25.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:14:25.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-14T02:14:55.424+0000] {processor.py:157} INFO - Started process (PID=82219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:55.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:14:55.429+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:55.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:55.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:14:55.523+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:55.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:14:55.542+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:14:55.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:14:55.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-14T02:15:25.750+0000] {processor.py:157} INFO - Started process (PID=82229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:25.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:15:25.754+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:25.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:25.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:25.834+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:25.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:15:25.858+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:25.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:15:25.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-14T02:15:56.059+0000] {processor.py:157} INFO - Started process (PID=82239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:56.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:15:56.064+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:56.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:56.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:15:56.138+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:56.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:15:56.171+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:15:56.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:15:56.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-14T02:16:26.399+0000] {processor.py:157} INFO - Started process (PID=82249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:26.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:16:26.406+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:26.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:26.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:26.463+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:26.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:16:26.482+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:26.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:16:26.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-14T02:16:56.754+0000] {processor.py:157} INFO - Started process (PID=82259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:56.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:16:56.759+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:56.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:56.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:16:56.829+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:56.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:16:56.848+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:16:56.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:16:56.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-14T02:17:27.120+0000] {processor.py:157} INFO - Started process (PID=82269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:27.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:17:27.124+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:27.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:27.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:27.206+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:27.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:17:27.225+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:27.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:17:27.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-14T02:17:57.444+0000] {processor.py:157} INFO - Started process (PID=82278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:57.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:17:57.449+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:57.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:57.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:17:57.519+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:57.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:17:57.539+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:17:57.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:17:57.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-14T02:18:27.750+0000] {processor.py:157} INFO - Started process (PID=82289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:27.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:18:27.758+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:27.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:27.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:27.812+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:27.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:18:27.831+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:27.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:18:27.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-14T02:18:58.041+0000] {processor.py:157} INFO - Started process (PID=82299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:58.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:18:58.064+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:58.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:58.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:18:58.124+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:58.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:18:58.144+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:18:58.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:18:58.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-14T02:19:28.327+0000] {processor.py:157} INFO - Started process (PID=82309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:28.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:19:28.331+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:28.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:28.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:28.407+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:28.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:19:28.428+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:28.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:19:28.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-14T02:19:58.746+0000] {processor.py:157} INFO - Started process (PID=82319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:58.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:19:58.749+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:58.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:58.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:19:58.841+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:58.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:19:58.865+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:19:58.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:19:58.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-14T02:20:29.075+0000] {processor.py:157} INFO - Started process (PID=82329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:29.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:20:29.080+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:29.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:29.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:29.158+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:29.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:20:29.180+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:29.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:20:29.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-14T02:20:59.432+0000] {processor.py:157} INFO - Started process (PID=82338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:59.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:20:59.439+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:59.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:59.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:20:59.527+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:59.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:20:59.548+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:20:59.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:20:59.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-14T02:21:30.131+0000] {processor.py:157} INFO - Started process (PID=82349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:21:30.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:21:30.150+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:21:30.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:21:30.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:21:30.211+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:21:30.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:21:30.231+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:21:30.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:21:30.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-14T02:22:00.548+0000] {processor.py:157} INFO - Started process (PID=82359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:00.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:22:00.553+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:00.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:00.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:00.623+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:00.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:22:00.642+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:00.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:22:00.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-14T02:22:30.773+0000] {processor.py:157} INFO - Started process (PID=82369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:30.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:22:30.775+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:30.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:30.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:22:30.825+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:30.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:22:30.842+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:22:30.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:22:30.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-14T02:23:01.136+0000] {processor.py:157} INFO - Started process (PID=82379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:01.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:23:01.138+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:01.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:01.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:01.185+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:01.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:23:01.201+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:01.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:23:01.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-14T02:23:31.524+0000] {processor.py:157} INFO - Started process (PID=82389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:31.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:23:31.528+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:31.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:31.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:23:31.592+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:31.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:23:31.612+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:23:31.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:23:31.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-14T02:24:01.791+0000] {processor.py:157} INFO - Started process (PID=82399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:01.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:24:01.794+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:01.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:01.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:01.870+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:01.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:24:01.886+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:01.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:24:01.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-14T02:24:32.064+0000] {processor.py:157} INFO - Started process (PID=82409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:32.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:24:32.067+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:32.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:32.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:24:32.144+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:32.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:24:32.158+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:24:32.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:24:32.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-14T02:25:02.388+0000] {processor.py:157} INFO - Started process (PID=82419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:02.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:25:02.391+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:02.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:02.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:02.464+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:02.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:25:02.480+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:02.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:25:02.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-14T02:25:32.705+0000] {processor.py:157} INFO - Started process (PID=82429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:32.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:25:32.710+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:32.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:32.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:25:32.769+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:32.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:25:32.789+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:25:32.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:25:32.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-14T02:26:03.078+0000] {processor.py:157} INFO - Started process (PID=82439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:03.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:26:03.081+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:03.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:03.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:03.131+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:03.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:26:03.148+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:03.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:26:03.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-14T02:26:33.484+0000] {processor.py:157} INFO - Started process (PID=82449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:33.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:26:33.487+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:33.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:33.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:26:33.575+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:33.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:26:33.597+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:26:33.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:26:33.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-14T02:27:03.792+0000] {processor.py:157} INFO - Started process (PID=82459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:03.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:27:03.796+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:03.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:03.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:03.877+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:03.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:27:03.897+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:03.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:27:03.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-14T02:27:34.182+0000] {processor.py:157} INFO - Started process (PID=82469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:34.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:27:34.185+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:34.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:34.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:27:34.242+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:34.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:27:34.260+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:27:34.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:27:34.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-14T02:28:04.458+0000] {processor.py:157} INFO - Started process (PID=82479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:04.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:28:04.462+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:04.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:04.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:04.510+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:04.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:28:04.525+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:04.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:28:04.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-14T02:28:35.009+0000] {processor.py:157} INFO - Started process (PID=82489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:35.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:28:35.011+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:35.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:35.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:28:35.054+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:35.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:28:35.068+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:28:35.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:28:35.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-14T02:29:05.520+0000] {processor.py:157} INFO - Started process (PID=82499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:05.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:29:05.525+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:05.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:05.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:05.648+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:05.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:29:05.666+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:05.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:29:05.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-14T02:29:36.413+0000] {processor.py:157} INFO - Started process (PID=82509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:36.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:29:36.416+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:36.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:36.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:29:36.484+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:36.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:29:36.504+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:29:36.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:29:36.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-14T02:30:06.883+0000] {processor.py:157} INFO - Started process (PID=82519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:06.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:30:06.887+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:06.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:06.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:06.972+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:06.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:30:06.993+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:06.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:30:07.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-14T02:30:37.217+0000] {processor.py:157} INFO - Started process (PID=82528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:37.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-14T02:30:37.226+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:37.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:37.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-14T02:30:37.381+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:37.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-14T02:30:37.435+0000] {logging_mixin.py:151} INFO - [2024-09-14T02:30:37.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-13T01:00:00+00:00, run_after=2024-09-14T01:00:00+00:00
[2024-09-14T02:30:37.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
