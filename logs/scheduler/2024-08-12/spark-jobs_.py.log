[2024-08-12T00:30:06.443+0000] {processor.py:157} INFO - Started process (PID=33191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:06.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T00:30:06.460+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:06.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:06.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:06.564+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:06.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T00:30:06.587+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:06.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-10T01:00:00+00:00, run_after=2024-08-11T01:00:00+00:00
[2024-08-12T00:30:06.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-12T00:30:36.912+0000] {processor.py:157} INFO - Started process (PID=33788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:36.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T00:30:36.919+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:36.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:36.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:30:36.982+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:36.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T00:30:36.995+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:30:36.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-10T01:00:00+00:00, run_after=2024-08-11T01:00:00+00:00
[2024-08-12T00:30:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-12T00:57:20.996+0000] {processor.py:157} INFO - Started process (PID=33798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:21.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T00:57:21.012+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:21.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:21.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:21.088+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:21.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T00:57:21.117+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:21.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-10T01:00:00+00:00, run_after=2024-08-11T01:00:00+00:00
[2024-08-12T00:57:21.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-12T00:57:51.461+0000] {processor.py:157} INFO - Started process (PID=34035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:51.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T00:57:51.467+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:51.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:51.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T00:57:51.524+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:51.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T00:57:51.538+0000] {logging_mixin.py:151} INFO - [2024-08-12T00:57:51.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-10T01:00:00+00:00, run_after=2024-08-11T01:00:00+00:00
[2024-08-12T00:57:51.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-12T01:58:16.926+0000] {processor.py:157} INFO - Started process (PID=34047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:16.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T01:58:16.934+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:16.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:16.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:16.987+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:16.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T01:58:17.002+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:17.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T01:58:17.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T01:58:47.228+0000] {processor.py:157} INFO - Started process (PID=34057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:47.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T01:58:47.235+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:47.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:47.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T01:58:47.272+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:47.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T01:58:47.285+0000] {logging_mixin.py:151} INFO - [2024-08-12T01:58:47.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T01:58:47.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-12T02:59:12.285+0000] {processor.py:157} INFO - Started process (PID=34067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T02:59:12.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T02:59:12.289+0000] {logging_mixin.py:151} INFO - [2024-08-12T02:59:12.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T02:59:12.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T02:59:12.323+0000] {logging_mixin.py:151} INFO - [2024-08-12T02:59:12.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T02:59:12.336+0000] {logging_mixin.py:151} INFO - [2024-08-12T02:59:12.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T02:59:12.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-12T03:15:15.760+0000] {processor.py:157} INFO - Started process (PID=34077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:15:15.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:15:15.772+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:15:15.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:15:15.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:15:15.827+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:15:15.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:15:15.850+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:15:15.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:15:15.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-12T03:28:41.786+0000] {processor.py:157} INFO - Started process (PID=34087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:28:41.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:28:41.791+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:28:41.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:28:41.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:28:41.834+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:28:41.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:28:41.850+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:28:41.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:28:41.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-12T03:46:26.237+0000] {processor.py:157} INFO - Started process (PID=34097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:46:26.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:46:26.243+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:46:26.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:46:26.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:46:26.281+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:46:26.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:46:26.295+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:46:26.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:46:26.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T03:58:15.445+0000] {processor.py:157} INFO - Started process (PID=34108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:15.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:58:15.464+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:15.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:15.530+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:15.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:58:15.551+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:15.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:58:15.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-12T03:58:45.821+0000] {processor.py:157} INFO - Started process (PID=34119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:45.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:58:45.826+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:45.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:45.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:58:45.868+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:45.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:58:45.888+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:58:45.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:58:45.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-12T03:59:17.740+0000] {processor.py:157} INFO - Started process (PID=34129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:17.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:59:17.745+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:17.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:17.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:17.813+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:17.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:59:17.838+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:17.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:59:17.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-12T03:59:48.279+0000] {processor.py:157} INFO - Started process (PID=34139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:48.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T03:59:48.294+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:48.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:48.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T03:59:48.399+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:48.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T03:59:48.419+0000] {logging_mixin.py:151} INFO - [2024-08-12T03:59:48.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T03:59:48.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-12T04:00:18.858+0000] {processor.py:157} INFO - Started process (PID=34149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:18.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:00:18.871+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:18.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:18.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:18.972+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:18.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:00:18.988+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:18.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:00:18.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-12T04:00:49.444+0000] {processor.py:157} INFO - Started process (PID=34159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:49.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:00:49.451+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:49.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:49.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:00:49.508+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:49.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:00:49.538+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:00:49.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:00:49.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-12T04:01:19.963+0000] {processor.py:157} INFO - Started process (PID=34168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:19.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:01:20.042+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:20.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:20.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:20.292+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:20.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:01:20.340+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:20.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:01:20.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.418 seconds
[2024-08-12T04:01:50.698+0000] {processor.py:157} INFO - Started process (PID=34179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:50.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:01:50.708+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:50.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:50.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:01:50.776+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:50.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:01:50.792+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:01:50.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:01:50.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-12T04:02:20.978+0000] {processor.py:157} INFO - Started process (PID=34189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:20.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:02:20.988+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:20.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:21.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:21.363+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:21.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:02:21.453+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:21.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:02:21.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.643 seconds
[2024-08-12T04:02:52.063+0000] {processor.py:157} INFO - Started process (PID=34199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:52.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:02:52.104+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:52.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:52.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:02:52.167+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:52.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:02:52.184+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:02:52.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:02:52.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-12T04:03:22.672+0000] {processor.py:157} INFO - Started process (PID=34209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:22.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:03:22.686+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:22.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:22.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:22.746+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:22.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:03:22.764+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:22.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:03:22.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-12T04:03:53.142+0000] {processor.py:157} INFO - Started process (PID=34219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:53.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:03:53.146+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:53.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:53.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:03:53.185+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:53.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:03:53.199+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:03:53.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:03:53.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-12T04:04:23.548+0000] {processor.py:157} INFO - Started process (PID=34229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:23.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:04:23.556+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:23.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:23.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:23.585+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:23.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:04:23.595+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:23.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:04:23.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-12T04:04:54.000+0000] {processor.py:157} INFO - Started process (PID=34239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:54.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:04:54.006+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:54.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:54.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:04:54.075+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:54.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:04:54.093+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:04:54.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:04:54.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-12T04:05:24.469+0000] {processor.py:157} INFO - Started process (PID=34249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:24.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:05:24.475+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:24.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:24.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:24.527+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:24.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:05:24.543+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:24.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:05:24.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-12T04:05:54.798+0000] {processor.py:157} INFO - Started process (PID=34259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:54.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:05:54.803+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:54.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:54.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:05:54.844+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:54.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:05:54.859+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:05:54.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:05:54.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T04:06:25.166+0000] {processor.py:157} INFO - Started process (PID=34269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:25.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:06:25.168+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:25.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:25.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:25.205+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:25.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:06:25.220+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:25.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:06:25.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-12T04:06:55.579+0000] {processor.py:157} INFO - Started process (PID=34279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:55.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:06:55.596+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:55.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:55.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:06:55.643+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:55.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:06:55.653+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:06:55.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:06:55.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-12T04:07:25.909+0000] {processor.py:157} INFO - Started process (PID=34289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:25.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:07:25.913+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:25.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:25.955+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:25.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:07:25.969+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:25.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:07:25.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-12T04:07:56.277+0000] {processor.py:157} INFO - Started process (PID=34299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:56.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:07:56.282+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:56.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:56.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:07:56.340+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:56.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:07:56.358+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:07:56.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:07:56.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-12T04:08:26.612+0000] {processor.py:157} INFO - Started process (PID=34309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:26.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:08:26.616+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:26.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:26.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:26.643+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:26.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:08:26.655+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:26.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:08:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-12T04:08:57.023+0000] {processor.py:157} INFO - Started process (PID=34319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:57.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:08:57.034+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:57.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:57.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:08:57.073+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:57.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:08:57.087+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:08:57.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:08:57.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-12T04:09:27.378+0000] {processor.py:157} INFO - Started process (PID=34329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:27.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:09:27.394+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:27.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:27.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:27.446+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:27.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:09:27.470+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:27.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:09:27.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-12T04:09:57.689+0000] {processor.py:157} INFO - Started process (PID=34339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:57.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:09:57.693+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:57.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:57.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:09:57.757+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:57.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:09:57.771+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:09:57.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:09:57.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-12T04:10:28.002+0000] {processor.py:157} INFO - Started process (PID=34348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:28.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:10:28.011+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:28.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:28.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:28.046+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:28.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:10:28.059+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:28.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:10:28.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T04:10:58.382+0000] {processor.py:157} INFO - Started process (PID=34359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:58.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:10:58.386+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:58.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:58.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:10:58.426+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:58.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:10:58.443+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:10:58.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:10:58.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-12T04:11:29.100+0000] {processor.py:157} INFO - Started process (PID=34369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:29.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:11:29.110+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:29.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:29.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:29.169+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:29.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:11:29.185+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:29.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:11:29.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-12T04:11:59.428+0000] {processor.py:157} INFO - Started process (PID=34378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:59.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:11:59.433+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:59.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:59.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:11:59.493+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:59.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:11:59.509+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:11:59.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:11:59.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T04:12:29.872+0000] {processor.py:157} INFO - Started process (PID=34389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:12:29.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:12:29.874+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:12:29.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:12:29.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:12:29.904+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:12:29.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:12:29.915+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:12:29.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:12:29.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T04:13:00.177+0000] {processor.py:157} INFO - Started process (PID=34399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:00.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:13:00.183+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:00.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:00.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:00.240+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:00.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:13:00.265+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:00.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:13:00.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-12T04:13:30.516+0000] {processor.py:157} INFO - Started process (PID=34409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:30.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:13:30.521+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:30.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:30.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:13:30.558+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:30.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:13:30.570+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:13:30.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:13:30.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-12T04:14:00.913+0000] {processor.py:157} INFO - Started process (PID=34419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:00.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:14:00.921+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:00.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:00.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:00.953+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:00.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:14:00.965+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:00.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:14:00.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-12T04:14:31.303+0000] {processor.py:157} INFO - Started process (PID=34429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:31.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:14:31.308+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:31.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:31.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:14:31.343+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:31.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:14:31.357+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:14:31.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:14:31.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-12T04:15:01.714+0000] {processor.py:157} INFO - Started process (PID=34439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:01.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:15:01.716+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:01.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:01.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:01.743+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:01.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:15:01.754+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:01.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:15:01.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-12T04:15:32.098+0000] {processor.py:157} INFO - Started process (PID=34449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:32.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:15:32.100+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:32.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:32.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:15:32.133+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:32.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:15:32.144+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:15:32.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:15:32.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-12T04:16:02.446+0000] {processor.py:157} INFO - Started process (PID=34459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:02.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:16:02.449+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:02.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:02.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:02.491+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:02.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:16:02.505+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:02.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:16:02.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-12T04:16:32.779+0000] {processor.py:157} INFO - Started process (PID=34469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:32.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:16:32.785+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:32.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:32.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:16:32.825+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:32.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:16:32.841+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:16:32.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:16:32.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-12T04:17:03.268+0000] {processor.py:157} INFO - Started process (PID=34479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:03.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:17:03.276+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:03.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:03.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:03.318+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:03.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:17:03.333+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:03.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:17:03.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-12T04:17:33.836+0000] {processor.py:157} INFO - Started process (PID=34489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:33.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:17:33.844+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:33.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:33.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:17:33.919+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:33.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:17:33.944+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:17:33.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:17:33.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-12T04:18:04.231+0000] {processor.py:157} INFO - Started process (PID=34499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:04.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:18:04.238+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:04.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:04.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:04.296+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:04.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:18:04.312+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:04.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:18:04.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-12T04:18:34.736+0000] {processor.py:157} INFO - Started process (PID=34509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:34.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:18:34.742+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:34.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:34.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:18:34.797+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:34.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:18:34.813+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:18:34.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:18:34.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-12T04:19:05.197+0000] {processor.py:157} INFO - Started process (PID=34518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:05.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:19:05.204+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:05.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:05.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:05.260+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:05.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:19:05.277+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:05.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:19:05.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-12T04:19:35.609+0000] {processor.py:157} INFO - Started process (PID=34529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:35.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:19:35.620+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:35.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:35.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:19:35.674+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:35.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:19:35.688+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:19:35.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:19:35.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T04:20:06.026+0000] {processor.py:157} INFO - Started process (PID=34539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:06.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:20:06.032+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:06.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:06.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:06.096+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:06.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:20:06.113+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:06.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:20:06.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-12T04:20:36.458+0000] {processor.py:157} INFO - Started process (PID=34549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:36.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:20:36.466+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:36.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:36.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:20:36.508+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:36.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:20:36.523+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:20:36.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:20:36.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T04:21:06.721+0000] {processor.py:157} INFO - Started process (PID=34559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:06.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:21:06.727+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:06.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:06.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:06.772+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:06.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:21:06.790+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:06.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:21:06.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-12T04:21:37.279+0000] {processor.py:157} INFO - Started process (PID=34569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:37.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:21:37.289+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:37.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:37.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:21:37.351+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:37.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:21:37.419+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:21:37.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:21:37.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-12T04:22:07.570+0000] {processor.py:157} INFO - Started process (PID=34579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:07.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:22:07.579+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:07.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:07.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:07.651+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:07.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:22:07.673+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:07.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:22:07.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-12T04:22:38.023+0000] {processor.py:157} INFO - Started process (PID=34589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:38.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:22:38.030+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:38.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:38.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:22:38.081+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:38.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:22:38.093+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:22:38.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:22:38.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-12T04:23:08.477+0000] {processor.py:157} INFO - Started process (PID=34599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:08.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:23:08.483+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:08.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:08.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:08.524+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:08.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:23:08.539+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:08.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:23:08.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T04:23:38.891+0000] {processor.py:157} INFO - Started process (PID=34609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:38.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:23:38.897+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:38.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:38.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:23:38.953+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:38.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:23:38.969+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:23:38.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:23:38.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-12T04:24:09.369+0000] {processor.py:157} INFO - Started process (PID=34619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:09.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:24:09.376+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:09.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:09.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:09.436+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:09.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:24:09.457+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:09.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:24:09.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T04:24:39.863+0000] {processor.py:157} INFO - Started process (PID=34629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:39.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:24:39.870+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:39.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:39.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:24:39.925+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:39.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:24:39.952+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:24:39.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:24:39.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-12T04:25:24.746+0000] {processor.py:157} INFO - Started process (PID=34641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:24.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:25:24.753+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:24.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:24.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:24.820+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:24.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:25:24.838+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:24.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:25:24.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-12T04:25:55.100+0000] {processor.py:157} INFO - Started process (PID=34651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:55.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:25:55.108+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:55.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:55.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:25:55.172+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:55.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:25:55.192+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:25:55.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:25:55.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-12T04:41:52.252+0000] {processor.py:157} INFO - Started process (PID=34663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:41:52.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:41:52.259+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:41:52.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:41:52.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:41:52.318+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:41:52.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:41:52.342+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:41:52.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:41:52.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-12T04:42:22.585+0000] {processor.py:157} INFO - Started process (PID=34673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:22.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:42:22.590+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:22.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:22.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:22.650+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:22.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:42:22.667+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:22.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:42:22.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-12T04:42:52.907+0000] {processor.py:157} INFO - Started process (PID=34683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:52.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:42:52.913+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:52.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:52.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:42:52.933+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:52.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:42:52.944+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:42:52.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T04:42:52.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-12T04:59:59.886+0000] {processor.py:157} INFO - Started process (PID=34693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:59:59.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T04:59:59.891+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:59:59.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:59:59.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T04:59:59.967+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:59:59.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T04:59:59.990+0000] {logging_mixin.py:151} INFO - [2024-08-12T04:59:59.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:00:00.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-12T05:00:37.418+0000] {processor.py:157} INFO - Started process (PID=34703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:00:37.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:00:37.423+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:00:37.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:00:37.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:00:37.473+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:00:37.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:00:37.496+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:00:37.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:00:37.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-12T05:01:07.742+0000] {processor.py:157} INFO - Started process (PID=34713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:01:07.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:01:07.745+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:01:07.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:01:07.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:01:07.773+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:01:07.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:01:07.784+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:01:07.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:01:07.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T05:17:07.996+0000] {processor.py:157} INFO - Started process (PID=34722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:08.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:17:08.009+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:08.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:08.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:08.097+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:08.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:17:08.124+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:08.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:17:08.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-12T05:17:38.551+0000] {processor.py:157} INFO - Started process (PID=34733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:38.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:17:38.557+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:38.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:38.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:17:38.603+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:38.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:17:38.618+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:17:38.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:17:38.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-12T05:18:08.974+0000] {processor.py:157} INFO - Started process (PID=34743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:18:08.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:18:08.977+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:18:08.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:18:08.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:18:09.006+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:18:09.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:18:09.020+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:18:09.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:18:09.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-12T05:30:43.968+0000] {processor.py:157} INFO - Started process (PID=34753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:30:43.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:30:43.980+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:30:43.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:30:44.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:30:44.060+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:30:44.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:30:44.085+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:30:44.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:30:44.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-12T05:32:12.092+0000] {processor.py:157} INFO - Started process (PID=34763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:12.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:32:12.095+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:12.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:12.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:12.141+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:12.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:32:12.159+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:12.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:32:12.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-12T05:32:42.341+0000] {processor.py:157} INFO - Started process (PID=34773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:42.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T05:32:42.343+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:42.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:42.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T05:32:42.370+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:42.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T05:32:42.380+0000] {logging_mixin.py:151} INFO - [2024-08-12T05:32:42.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T05:32:42.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-12T06:25:16.429+0000] {processor.py:157} INFO - Started process (PID=34785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:16.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T06:25:16.441+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:16.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:16.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:16.497+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:16.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T06:25:16.515+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:16.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T06:25:16.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-12T06:25:46.737+0000] {processor.py:157} INFO - Started process (PID=34795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:46.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T06:25:46.746+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:46.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:46.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T06:25:46.796+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:46.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T06:25:46.812+0000] {logging_mixin.py:151} INFO - [2024-08-12T06:25:46.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T06:25:46.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T07:31:22.163+0000] {processor.py:157} INFO - Started process (PID=34804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:31:22.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T07:31:22.169+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:31:22.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:31:22.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:31:22.218+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:31:22.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T07:31:22.234+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:31:22.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T07:31:22.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T07:32:34.907+0000] {processor.py:157} INFO - Started process (PID=34815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:32:34.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T07:32:34.916+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:32:34.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:32:34.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T07:32:34.977+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:32:34.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T07:32:34.997+0000] {logging_mixin.py:151} INFO - [2024-08-12T07:32:34.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T07:32:35.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-12T08:24:30.751+0000] {processor.py:157} INFO - Started process (PID=34825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T08:24:30.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T08:24:30.761+0000] {logging_mixin.py:151} INFO - [2024-08-12T08:24:30.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T08:24:30.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T08:24:30.879+0000] {logging_mixin.py:151} INFO - [2024-08-12T08:24:30.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T08:24:30.915+0000] {logging_mixin.py:151} INFO - [2024-08-12T08:24:30.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T08:24:30.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-08-12T09:45:02.491+0000] {processor.py:157} INFO - Started process (PID=34835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T09:45:02.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T09:45:02.502+0000] {logging_mixin.py:151} INFO - [2024-08-12T09:45:02.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T09:45:02.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T09:45:02.584+0000] {logging_mixin.py:151} INFO - [2024-08-12T09:45:02.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T09:45:02.607+0000] {logging_mixin.py:151} INFO - [2024-08-12T09:45:02.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T09:45:02.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-12T11:23:09.906+0000] {processor.py:157} INFO - Started process (PID=34844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:23:09.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T11:23:09.917+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:23:09.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:23:09.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:23:10.027+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:23:10.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T11:23:10.056+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:23:10.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T11:23:10.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-12T11:38:52.669+0000] {processor.py:157} INFO - Started process (PID=34854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:38:52.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T11:38:52.682+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:38:52.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:38:52.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:38:52.772+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:38:52.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T11:38:52.793+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:38:52.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T11:38:52.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-12T11:41:27.969+0000] {processor.py:157} INFO - Started process (PID=34864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:27.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T11:41:27.976+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:27.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:28.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:28.109+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:28.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T11:41:28.152+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:28.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T11:41:28.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-12T11:41:58.365+0000] {processor.py:157} INFO - Started process (PID=34874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:58.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T11:41:58.386+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:58.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:58.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T11:41:58.442+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:58.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T11:41:58.463+0000] {logging_mixin.py:151} INFO - [2024-08-12T11:41:58.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T11:41:58.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-12T12:02:07.520+0000] {processor.py:157} INFO - Started process (PID=34887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:07.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T12:02:07.528+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:07.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:07.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:07.589+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:07.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T12:02:07.618+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:07.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T12:02:07.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-12T12:02:37.894+0000] {processor.py:157} INFO - Started process (PID=34897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:37.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T12:02:37.900+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:37.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:37.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:02:37.960+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:37.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T12:02:37.975+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:02:37.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T12:02:37.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-12T12:17:13.485+0000] {processor.py:157} INFO - Started process (PID=34907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:17:13.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T12:17:13.491+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:17:13.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:17:13.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:17:13.552+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:17:13.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T12:17:13.582+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:17:13.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T12:17:13.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-12T12:45:33.610+0000] {processor.py:157} INFO - Started process (PID=34916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:45:33.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T12:45:33.623+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:45:33.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:45:33.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:45:33.720+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:45:33.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T12:45:33.753+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:45:33.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T12:45:33.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-12T12:46:04.084+0000] {processor.py:157} INFO - Started process (PID=34926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:46:04.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T12:46:04.090+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:46:04.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:46:04.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T12:46:04.141+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:46:04.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T12:46:04.157+0000] {logging_mixin.py:151} INFO - [2024-08-12T12:46:04.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T12:46:04.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-12T13:03:10.261+0000] {processor.py:157} INFO - Started process (PID=34938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:10.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:03:10.271+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:10.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:10.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:10.313+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:10.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:03:10.328+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:10.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:03:10.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-12T13:03:40.573+0000] {processor.py:157} INFO - Started process (PID=34949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:40.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:03:40.578+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:40.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:40.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:03:40.623+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:40.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:03:40.641+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:03:40.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:03:40.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-12T13:19:58.483+0000] {processor.py:157} INFO - Started process (PID=34958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:19:58.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:19:58.503+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:19:58.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:19:58.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:19:58.578+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:19:58.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:19:58.604+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:19:58.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:19:58.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-12T13:30:12.387+0000] {processor.py:157} INFO - Started process (PID=34968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:12.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:30:12.393+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:12.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:12.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:12.499+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:12.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:30:12.540+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:12.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:30:12.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-12T13:30:42.747+0000] {processor.py:157} INFO - Started process (PID=34978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:42.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:30:42.755+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:42.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:42.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:30:42.804+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:42.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:30:42.820+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:30:42.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:30:42.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T13:36:00.972+0000] {processor.py:157} INFO - Started process (PID=34988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:00.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:36:00.981+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:00.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:01.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:01.058+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:01.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:36:01.097+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:01.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:36:01.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-12T13:36:31.220+0000] {processor.py:157} INFO - Started process (PID=34999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:31.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:36:31.225+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:31.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:31.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:36:31.274+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:31.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:36:31.288+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:36:31.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:36:31.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-12T13:37:01.602+0000] {processor.py:157} INFO - Started process (PID=35009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:01.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:37:01.605+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:01.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:01.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:01.639+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:01.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:37:01.648+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:01.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:37:01.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-12T13:37:31.969+0000] {processor.py:157} INFO - Started process (PID=35019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:31.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:37:31.978+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:31.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:32.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:37:32.052+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:32.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:37:32.078+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:37:32.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:37:32.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-12T13:38:02.243+0000] {processor.py:157} INFO - Started process (PID=35029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:02.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:38:02.246+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:02.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:02.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:02.274+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:02.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:38:02.284+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:02.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:38:02.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T13:38:32.582+0000] {processor.py:157} INFO - Started process (PID=35039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:32.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:38:32.588+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:32.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:32.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:38:32.623+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:32.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:38:32.636+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:38:32.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:38:32.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-12T13:39:02.944+0000] {processor.py:157} INFO - Started process (PID=35049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:02.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:39:02.947+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:02.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:02.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:02.972+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:02.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:39:02.983+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:02.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:39:02.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-12T13:39:33.273+0000] {processor.py:157} INFO - Started process (PID=35059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:33.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:39:33.277+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:33.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:33.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:39:33.307+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:33.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:39:33.318+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:39:33.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:39:33.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-12T13:40:03.628+0000] {processor.py:157} INFO - Started process (PID=35069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:03.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:40:03.634+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:03.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:03.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:03.676+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:03.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:40:03.690+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:03.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:40:03.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T13:40:34.008+0000] {processor.py:157} INFO - Started process (PID=35079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:34.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:40:34.013+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:34.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:34.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:40:34.047+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:34.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:40:34.057+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:40:34.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:40:34.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-12T13:41:04.360+0000] {processor.py:157} INFO - Started process (PID=35089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:04.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:41:04.364+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:04.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:04.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:04.398+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:04.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:41:04.413+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:04.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:41:04.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-12T13:41:34.703+0000] {processor.py:157} INFO - Started process (PID=35099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:34.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:41:34.706+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:34.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:34.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:41:34.733+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:34.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:41:34.743+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:41:34.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:41:34.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T13:42:05.053+0000] {processor.py:157} INFO - Started process (PID=35109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:05.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:42:05.056+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:05.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:05.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:05.119+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:05.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:42:05.158+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:05.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:42:05.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-12T13:42:35.377+0000] {processor.py:157} INFO - Started process (PID=35119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:35.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:42:35.380+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:35.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:35.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:42:35.415+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:35.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:42:35.427+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:42:35.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:42:35.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-12T13:43:05.732+0000] {processor.py:157} INFO - Started process (PID=35129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:05.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:43:05.738+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:05.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:05.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:05.792+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:05.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:43:05.809+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:05.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:43:05.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T13:43:36.112+0000] {processor.py:157} INFO - Started process (PID=35139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:36.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:43:36.138+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:36.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:36.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:43:36.209+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:36.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:43:36.224+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:43:36.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:43:36.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-12T13:44:06.392+0000] {processor.py:157} INFO - Started process (PID=35149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:06.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:44:06.394+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:06.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:06.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:06.423+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:06.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:44:06.432+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:06.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:44:06.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T13:44:36.777+0000] {processor.py:157} INFO - Started process (PID=35159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:36.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:44:36.787+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:36.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:36.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:44:36.838+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:36.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:44:36.853+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:44:36.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:44:36.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-12T13:45:07.102+0000] {processor.py:157} INFO - Started process (PID=35169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:07.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:45:07.107+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:07.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:07.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:07.154+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:07.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:45:07.170+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:07.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:45:07.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T13:45:37.459+0000] {processor.py:157} INFO - Started process (PID=35179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:37.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:45:37.461+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:37.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:37.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:45:37.494+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:37.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:45:37.508+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:45:37.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:45:37.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-12T13:46:07.830+0000] {processor.py:157} INFO - Started process (PID=35189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:07.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:46:07.836+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:07.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:07.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:07.884+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:07.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:46:07.901+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:07.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:46:07.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-12T13:46:38.189+0000] {processor.py:157} INFO - Started process (PID=35199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:38.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:46:38.196+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:38.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:46:38.226+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:38.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:46:38.239+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:46:38.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:46:38.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-12T13:47:08.595+0000] {processor.py:157} INFO - Started process (PID=35209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:08.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:47:08.601+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:08.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:08.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:08.662+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:08.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:47:08.679+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:08.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:47:08.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-12T13:47:38.880+0000] {processor.py:157} INFO - Started process (PID=35219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:38.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:47:38.882+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:38.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:38.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:47:38.908+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:38.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:47:38.919+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:47:38.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:47:38.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T13:48:09.271+0000] {processor.py:157} INFO - Started process (PID=35228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:09.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:48:09.289+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:09.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:09.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:09.335+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:09.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:48:09.348+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:09.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:48:09.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T13:48:39.668+0000] {processor.py:157} INFO - Started process (PID=35239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:39.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:48:39.671+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:39.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:39.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:48:39.700+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:39.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:48:39.711+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:48:39.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:48:39.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-12T13:49:10.021+0000] {processor.py:157} INFO - Started process (PID=35249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:10.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:49:10.025+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:10.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:10.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:10.051+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:10.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:49:10.061+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:10.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:49:10.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-12T13:49:40.389+0000] {processor.py:157} INFO - Started process (PID=35259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:40.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:49:40.398+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:40.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:40.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:49:40.465+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:40.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:49:40.481+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:49:40.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:49:40.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-12T13:50:10.711+0000] {processor.py:157} INFO - Started process (PID=35269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:10.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:50:10.715+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:10.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:10.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:10.741+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:10.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:50:10.753+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:10.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:50:10.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T13:50:41.000+0000] {processor.py:157} INFO - Started process (PID=35279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:41.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:50:41.005+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:41.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:41.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:50:41.041+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:41.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:50:41.054+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:50:41.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:50:41.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-12T13:51:11.361+0000] {processor.py:157} INFO - Started process (PID=35289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:11.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:51:11.365+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:11.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:11.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:11.401+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:11.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:51:11.418+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:11.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:51:11.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T13:51:42.203+0000] {processor.py:157} INFO - Started process (PID=35299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:42.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:51:42.210+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:42.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:42.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:51:42.257+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:42.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:51:42.271+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:51:42.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:51:42.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-12T13:52:12.460+0000] {processor.py:157} INFO - Started process (PID=35309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:12.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:52:12.465+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:12.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:12.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:12.502+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:12.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:52:12.516+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:12.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:52:12.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-12T13:52:42.821+0000] {processor.py:157} INFO - Started process (PID=35319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:42.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:52:42.824+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:42.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:42.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:52:42.853+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:42.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:52:42.865+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:52:42.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:52:42.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-12T13:53:13.198+0000] {processor.py:157} INFO - Started process (PID=35328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:13.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:53:13.204+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:13.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:13.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:13.253+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:13.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:53:13.270+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:13.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:53:13.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-12T13:53:43.544+0000] {processor.py:157} INFO - Started process (PID=35339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:43.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:53:43.551+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:43.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:43.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:53:43.598+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:43.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:53:43.616+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:53:43.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:53:43.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-12T13:54:13.955+0000] {processor.py:157} INFO - Started process (PID=35349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:13.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:54:13.968+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:13.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:13.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:14.033+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:14.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:54:14.048+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:14.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:54:14.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-12T13:54:44.254+0000] {processor.py:157} INFO - Started process (PID=35359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:44.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:54:44.260+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:44.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:44.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:54:44.312+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:44.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:54:44.324+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:54:44.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:54:44.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-12T13:55:14.712+0000] {processor.py:157} INFO - Started process (PID=35368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:14.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:55:14.720+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:14.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:14.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:14.801+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:14.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:55:14.816+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:14.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:55:14.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-12T13:55:45.027+0000] {processor.py:157} INFO - Started process (PID=35379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:45.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:55:45.031+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:45.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:45.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:55:45.095+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:45.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:55:45.109+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:55:45.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:55:45.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T13:56:15.476+0000] {processor.py:157} INFO - Started process (PID=35389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:15.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:56:15.484+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:15.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:15.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:15.543+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:15.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:56:15.560+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:15.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:56:15.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T13:56:45.804+0000] {processor.py:157} INFO - Started process (PID=35399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:45.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:56:45.815+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:45.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:45.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:56:45.919+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:45.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:56:45.943+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:56:45.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:56:45.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-12T13:57:16.194+0000] {processor.py:157} INFO - Started process (PID=35409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:16.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:57:16.205+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:16.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:16.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:16.276+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:16.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:57:16.311+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:16.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:57:16.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-12T13:57:46.535+0000] {processor.py:157} INFO - Started process (PID=35419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:46.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:57:46.548+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:46.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:46.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:57:46.645+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:46.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:57:46.670+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:57:46.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:57:46.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-12T13:58:16.842+0000] {processor.py:157} INFO - Started process (PID=35429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:16.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:58:16.863+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:16.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:16.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:16.908+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:16.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:58:16.922+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:16.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:58:16.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-12T13:58:47.171+0000] {processor.py:157} INFO - Started process (PID=35439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:47.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:58:47.173+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:47.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:47.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:58:47.197+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:47.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:58:47.209+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:58:47.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:58:47.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-12T13:59:17.442+0000] {processor.py:157} INFO - Started process (PID=35449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:17.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:59:17.450+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:17.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:17.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:17.512+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:17.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:59:17.527+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:17.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:59:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-12T13:59:47.733+0000] {processor.py:157} INFO - Started process (PID=35459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:47.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T13:59:47.736+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:47.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:47.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T13:59:47.762+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:47.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T13:59:47.772+0000] {logging_mixin.py:151} INFO - [2024-08-12T13:59:47.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T13:59:47.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-12T14:00:18.161+0000] {processor.py:157} INFO - Started process (PID=35469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:18.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:00:18.168+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:18.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:18.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:18.222+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:18.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:00:18.256+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:18.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:00:18.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-12T14:00:48.568+0000] {processor.py:157} INFO - Started process (PID=35478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:48.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:00:48.590+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:48.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:48.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:00:48.634+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:48.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:00:48.648+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:00:48.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:00:48.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-12T14:01:18.872+0000] {processor.py:157} INFO - Started process (PID=35489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:18.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:01:18.878+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:18.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:18.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:18.915+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:18.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:01:18.930+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:18.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:01:18.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-12T14:01:49.262+0000] {processor.py:157} INFO - Started process (PID=35499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:49.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:01:49.268+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:49.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:49.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:01:49.312+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:49.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:01:49.326+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:01:49.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:01:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T14:02:19.675+0000] {processor.py:157} INFO - Started process (PID=35509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:19.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:02:19.684+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:19.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:19.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:19.752+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:19.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:02:19.767+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:19.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:02:19.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-12T14:02:50.039+0000] {processor.py:157} INFO - Started process (PID=35519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:50.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:02:50.049+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:50.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:50.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:02:50.098+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:50.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:02:50.116+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:02:50.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:02:50.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-12T14:03:20.429+0000] {processor.py:157} INFO - Started process (PID=35529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:20.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:03:20.433+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:20.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:20.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:20.466+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:20.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:03:20.477+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:20.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:03:20.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-12T14:03:50.777+0000] {processor.py:157} INFO - Started process (PID=35539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:50.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:03:50.785+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:50.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:50.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:03:50.849+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:50.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:03:50.883+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:03:50.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:03:50.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-12T14:04:21.162+0000] {processor.py:157} INFO - Started process (PID=35549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:21.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:04:21.169+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:21.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:21.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:21.231+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:21.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:04:21.247+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:21.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:04:21.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T14:04:51.417+0000] {processor.py:157} INFO - Started process (PID=35559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:51.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:04:51.424+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:51.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:51.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:04:51.463+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:51.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:04:51.476+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:04:51.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:04:51.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-12T14:05:21.800+0000] {processor.py:157} INFO - Started process (PID=35569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:21.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:05:21.805+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:21.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:21.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:21.872+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:21.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:05:21.888+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:21.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:05:21.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T14:05:52.105+0000] {processor.py:157} INFO - Started process (PID=35578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:52.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:05:52.113+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:52.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:52.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:05:52.160+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:52.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:05:52.174+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:05:52.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:05:52.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-12T14:06:22.410+0000] {processor.py:157} INFO - Started process (PID=35589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:22.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:06:22.427+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:22.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:22.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:22.478+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:22.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:06:22.493+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:22.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:06:22.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T14:06:52.751+0000] {processor.py:157} INFO - Started process (PID=35599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:52.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:06:52.764+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:52.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:52.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:06:52.866+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:52.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:06:52.907+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:06:52.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:06:52.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-12T14:07:23.105+0000] {processor.py:157} INFO - Started process (PID=35608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:23.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:07:23.111+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:23.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:23.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:23.162+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:23.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:07:23.182+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:23.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:07:23.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-12T14:07:53.460+0000] {processor.py:157} INFO - Started process (PID=35618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:53.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:07:53.467+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:53.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:53.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:07:53.530+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:53.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:07:53.544+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:07:53.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:07:53.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T14:08:24.060+0000] {processor.py:157} INFO - Started process (PID=35628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:24.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:08:24.068+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:24.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:24.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:24.122+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:24.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:08:24.138+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:24.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:08:24.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-12T14:08:54.300+0000] {processor.py:157} INFO - Started process (PID=35639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:54.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:08:54.306+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:54.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:54.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:08:54.335+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:54.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:08:54.348+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:08:54.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:08:54.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-12T14:09:24.655+0000] {processor.py:157} INFO - Started process (PID=35649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:24.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:09:24.662+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:24.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:24.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:24.712+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:24.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:09:24.734+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:24.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:09:24.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-12T14:09:55.091+0000] {processor.py:157} INFO - Started process (PID=35659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:55.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:09:55.103+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:55.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:55.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:09:55.172+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:55.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:09:55.206+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:09:55.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:09:55.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-12T14:10:25.565+0000] {processor.py:157} INFO - Started process (PID=35669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:25.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:10:25.572+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:25.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:25.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:25.614+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:25.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:10:25.627+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:25.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:10:25.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-12T14:10:55.900+0000] {processor.py:157} INFO - Started process (PID=35679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:55.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:10:55.907+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:55.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:55.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:10:55.948+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:55.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:10:55.964+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:10:55.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:10:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-12T14:11:26.286+0000] {processor.py:157} INFO - Started process (PID=35689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:26.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:11:26.294+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:26.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:26.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:26.350+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:26.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:11:26.364+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:26.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:11:26.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T14:11:56.660+0000] {processor.py:157} INFO - Started process (PID=35699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:56.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:11:56.666+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:56.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:56.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:11:56.729+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:56.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:11:56.744+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:11:56.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:11:56.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T14:12:26.994+0000] {processor.py:157} INFO - Started process (PID=35709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:27.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:12:27.025+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:27.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:27.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:27.110+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:27.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:12:27.129+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:27.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:12:27.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-12T14:12:57.331+0000] {processor.py:157} INFO - Started process (PID=35719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:57.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:12:57.341+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:57.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:57.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:12:57.402+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:57.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:12:57.420+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:12:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:12:57.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T14:13:27.637+0000] {processor.py:157} INFO - Started process (PID=35729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:27.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:13:27.644+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:27.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:27.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:27.682+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:27.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:13:27.696+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:27.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:13:27.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-12T14:13:57.997+0000] {processor.py:157} INFO - Started process (PID=35739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:57.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:13:57.999+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:57.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:58.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:13:58.026+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:58.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:13:58.036+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:13:58.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:13:58.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-12T14:14:28.338+0000] {processor.py:157} INFO - Started process (PID=35749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:28.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:14:28.340+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:28.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:28.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:28.362+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:28.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:14:28.373+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:28.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:14:28.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-12T14:14:58.669+0000] {processor.py:157} INFO - Started process (PID=35759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:58.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:14:58.672+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:58.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:58.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:14:58.698+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:58.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:14:58.710+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:14:58.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:14:58.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T14:15:29.106+0000] {processor.py:157} INFO - Started process (PID=35769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:29.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:15:29.120+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:29.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:29.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:29.168+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:29.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:15:29.189+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:29.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:15:29.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-12T14:15:59.351+0000] {processor.py:157} INFO - Started process (PID=35779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:59.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:15:59.354+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:59.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:59.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:15:59.384+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:59.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:15:59.394+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:15:59.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:15:59.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-12T14:16:29.676+0000] {processor.py:157} INFO - Started process (PID=35789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:29.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:16:29.681+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:29.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:29.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:29.715+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:29.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:16:29.727+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:29.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:16:29.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-12T14:16:59.897+0000] {processor.py:157} INFO - Started process (PID=35799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:59.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:16:59.899+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:59.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:59.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:16:59.923+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:59.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:16:59.933+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:16:59.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:16:59.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-12T14:17:30.293+0000] {processor.py:157} INFO - Started process (PID=35809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:17:30.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:17:30.297+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:17:30.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:17:30.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:17:30.359+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:17:30.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:17:30.384+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:17:30.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:17:30.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-12T14:18:00.596+0000] {processor.py:157} INFO - Started process (PID=35819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:00.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:18:00.605+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:00.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:00.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:00.667+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:00.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:18:00.685+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:00.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:18:00.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-12T14:18:30.934+0000] {processor.py:157} INFO - Started process (PID=35829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:30.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:18:30.943+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:30.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:30.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:18:31.009+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:31.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:18:31.033+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:18:31.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:18:31.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-12T14:19:01.286+0000] {processor.py:157} INFO - Started process (PID=35839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:01.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:19:01.301+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:01.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:01.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:01.360+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:01.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:19:01.379+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:01.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:19:01.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-12T14:19:31.633+0000] {processor.py:157} INFO - Started process (PID=35849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:31.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:19:31.653+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:31.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:31.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:19:31.701+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:31.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:19:31.716+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:19:31.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:19:31.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T14:20:01.964+0000] {processor.py:157} INFO - Started process (PID=35859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:01.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:20:01.975+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:01.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:01.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:02.022+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:02.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:20:02.038+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:02.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:20:02.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-12T14:20:32.407+0000] {processor.py:157} INFO - Started process (PID=35869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:32.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:20:32.413+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:32.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:32.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:20:32.458+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:32.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:20:32.472+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:20:32.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:20:32.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-12T14:21:02.817+0000] {processor.py:157} INFO - Started process (PID=35879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:02.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:21:02.837+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:02.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:02.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:02.890+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:02.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:21:02.903+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:02.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:21:02.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-12T14:21:33.410+0000] {processor.py:157} INFO - Started process (PID=35889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:33.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:21:33.420+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:33.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:33.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:21:33.500+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:33.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:21:33.523+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:21:33.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:21:33.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-12T14:22:03.691+0000] {processor.py:157} INFO - Started process (PID=35899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:03.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:22:03.695+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:03.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:03.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:03.733+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:03.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:22:03.747+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:03.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:22:03.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T14:22:34.051+0000] {processor.py:157} INFO - Started process (PID=35909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:34.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:22:34.053+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:34.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:34.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:22:34.081+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:34.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:22:34.091+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:22:34.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:22:34.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T14:32:43.118+0000] {processor.py:157} INFO - Started process (PID=35920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:32:43.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:32:43.146+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:32:43.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:32:43.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:32:43.274+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:32:43.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:32:43.311+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:32:43.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:32:43.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-08-12T14:33:13.592+0000] {processor.py:157} INFO - Started process (PID=35931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:33:13.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T14:33:13.600+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:33:13.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:33:13.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T14:33:13.666+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:33:13.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T14:33:13.693+0000] {logging_mixin.py:151} INFO - [2024-08-12T14:33:13.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T14:33:13.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-12T15:06:27.844+0000] {processor.py:157} INFO - Started process (PID=35941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:27.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:06:27.853+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:27.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:27.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:27.922+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:27.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:06:27.939+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:27.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:06:27.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-12T15:06:58.184+0000] {processor.py:157} INFO - Started process (PID=35951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:58.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:06:58.189+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:58.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:58.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:06:58.249+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:58.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:06:58.274+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:06:58.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:06:58.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T15:07:41.488+0000] {processor.py:157} INFO - Started process (PID=35961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:07:41.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:07:41.495+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:07:41.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:07:41.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:07:41.559+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:07:41.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:07:41.572+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:07:41.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:07:41.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-12T15:08:11.815+0000] {processor.py:157} INFO - Started process (PID=35971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:08:11.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:08:11.819+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:08:11.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:08:11.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:08:11.857+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:08:11.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:08:11.873+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:08:11.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:08:11.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T15:19:25.187+0000] {processor.py:157} INFO - Started process (PID=35982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:19:25.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:19:25.199+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:19:25.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:19:25.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:19:25.281+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:19:25.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:19:25.304+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:19:25.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:19:25.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-12T15:35:56.359+0000] {processor.py:157} INFO - Started process (PID=35992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:35:56.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:35:56.365+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:35:56.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:35:56.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:35:56.452+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:35:56.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:35:56.493+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:35:56.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:35:56.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-12T15:36:26.704+0000] {processor.py:157} INFO - Started process (PID=36003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:36:26.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T15:36:26.713+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:36:26.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:36:26.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T15:36:26.767+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:36:26.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T15:36:26.784+0000] {logging_mixin.py:151} INFO - [2024-08-12T15:36:26.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T15:36:26.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T16:02:52.905+0000] {processor.py:157} INFO - Started process (PID=36014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:02:52.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:02:52.913+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:02:52.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:02:52.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:02:52.984+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:02:52.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:02:53.008+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:02:53.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:02:53.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-12T16:03:23.210+0000] {processor.py:157} INFO - Started process (PID=36025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:03:23.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:03:23.234+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:03:23.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:03:23.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:03:23.299+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:03:23.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:03:23.318+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:03:23.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:03:23.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-12T16:17:11.973+0000] {processor.py:157} INFO - Started process (PID=36035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:17:11.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:17:11.978+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:17:11.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:17:11.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:17:12.035+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:17:12.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:17:12.054+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:17:12.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:17:12.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-12T16:18:34.850+0000] {processor.py:157} INFO - Started process (PID=36045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:18:34.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:18:34.856+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:18:34.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:18:34.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:18:34.913+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:18:34.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:18:34.929+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:18:34.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:18:34.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T16:19:05.263+0000] {processor.py:157} INFO - Started process (PID=36055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:19:05.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:19:05.265+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:19:05.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:19:05.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:19:05.294+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:19:05.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:19:05.306+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:19:05.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:19:05.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-12T16:23:05.296+0000] {processor.py:157} INFO - Started process (PID=36065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:23:05.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:23:05.301+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:23:05.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:23:05.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:23:05.350+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:23:05.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:23:05.365+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:23:05.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:23:05.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-12T16:31:18.904+0000] {processor.py:157} INFO - Started process (PID=36076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:18.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:31:18.918+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:18.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:18.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:18.966+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:18.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:31:18.982+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:18.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:31:19.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-12T16:31:49.194+0000] {processor.py:157} INFO - Started process (PID=36087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:49.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:31:49.201+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:49.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:49.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:31:49.248+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:49.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:31:49.263+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:31:49.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:31:49.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T16:34:36.517+0000] {processor.py:157} INFO - Started process (PID=36096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:34:36.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:34:36.523+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:34:36.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:34:36.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:34:36.595+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:34:36.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:34:36.620+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:34:36.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:34:36.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-12T16:35:07.013+0000] {processor.py:157} INFO - Started process (PID=36107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:35:07.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:35:07.019+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:35:07.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:35:07.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:35:07.064+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:35:07.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:35:07.087+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:35:07.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:35:07.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-12T16:44:29.530+0000] {processor.py:157} INFO - Started process (PID=36119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:44:29.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:44:29.536+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:44:29.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:44:29.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:44:29.598+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:44:29.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:44:29.629+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:44:29.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:44:29.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-12T16:45:34.862+0000] {processor.py:157} INFO - Started process (PID=36129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:45:34.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:45:34.887+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:45:34.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:45:34.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:45:34.922+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:45:34.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:45:34.935+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:45:34.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:45:34.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-12T16:46:05.349+0000] {processor.py:157} INFO - Started process (PID=36139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:46:05.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T16:46:05.354+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:46:05.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:46:05.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T16:46:05.381+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:46:05.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T16:46:05.391+0000] {logging_mixin.py:151} INFO - [2024-08-12T16:46:05.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T16:46:05.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-12T17:30:13.666+0000] {processor.py:157} INFO - Started process (PID=36151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:13.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T17:30:13.675+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:13.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:13.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:13.756+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:13.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T17:30:13.784+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:13.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T17:30:13.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-12T17:30:44.006+0000] {processor.py:157} INFO - Started process (PID=36161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:44.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T17:30:44.013+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:44.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:44.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:30:44.066+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:44.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T17:30:44.083+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:30:44.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T17:30:44.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-12T17:35:47.429+0000] {processor.py:157} INFO - Started process (PID=36170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:35:47.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T17:35:47.437+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:35:47.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:35:47.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:35:47.515+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:35:47.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T17:35:47.538+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:35:47.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T17:35:47.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-12T17:47:06.353+0000] {processor.py:157} INFO - Started process (PID=36180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:06.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T17:47:06.362+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:06.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:06.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:06.413+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:06.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T17:47:06.431+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:06.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T17:47:06.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-12T17:47:36.756+0000] {processor.py:157} INFO - Started process (PID=36191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:36.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T17:47:36.766+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:36.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:36.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T17:47:36.819+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:36.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T17:47:36.833+0000] {logging_mixin.py:151} INFO - [2024-08-12T17:47:36.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T17:47:36.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T18:36:31.904+0000] {processor.py:157} INFO - Started process (PID=36201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:36:31.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T18:36:31.910+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:36:31.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:36:31.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:36:31.954+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:36:31.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T18:36:31.970+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:36:31.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T18:36:31.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-12T18:37:02.301+0000] {processor.py:157} INFO - Started process (PID=36213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:37:02.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T18:37:02.308+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:37:02.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:37:02.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T18:37:02.365+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:37:02.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T18:37:02.388+0000] {logging_mixin.py:151} INFO - [2024-08-12T18:37:02.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T18:37:02.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-12T19:00:19.140+0000] {processor.py:157} INFO - Started process (PID=36222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:00:19.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:00:19.150+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:00:19.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:00:19.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:00:19.235+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:00:19.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:00:19.269+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:00:19.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:00:19.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-12T19:15:53.185+0000] {processor.py:157} INFO - Started process (PID=36233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:15:53.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:15:53.195+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:15:53.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:15:53.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:15:53.350+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:15:53.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:15:53.408+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:15:53.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:15:53.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-08-12T19:16:23.717+0000] {processor.py:157} INFO - Started process (PID=36243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:16:23.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:16:23.725+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:16:23.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:16:23.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:16:23.771+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:16:23.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:16:23.785+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:16:23.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:16:23.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-12T19:17:06.980+0000] {processor.py:157} INFO - Started process (PID=36253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:06.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:17:06.987+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:06.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:07.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:07.041+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:07.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:17:07.057+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:07.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:17:07.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-12T19:17:37.360+0000] {processor.py:157} INFO - Started process (PID=36263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:37.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:17:37.363+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:37.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:37.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:17:37.391+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:37.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:17:37.401+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:17:37.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:17:37.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-12T19:26:28.606+0000] {processor.py:157} INFO - Started process (PID=36273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:26:28.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:26:28.625+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:26:28.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:26:28.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:26:28.706+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:26:28.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:26:28.734+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:26:28.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:26:28.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-12T19:37:31.481+0000] {processor.py:157} INFO - Started process (PID=36283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:37:31.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:37:31.487+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:37:31.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:37:31.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:37:31.549+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:37:31.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:37:31.563+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:37:31.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:37:31.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-12T19:38:01.964+0000] {processor.py:157} INFO - Started process (PID=36293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:38:01.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T19:38:01.969+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:38:01.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:38:01.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T19:38:02.013+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:38:02.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T19:38:02.027+0000] {logging_mixin.py:151} INFO - [2024-08-12T19:38:02.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T19:38:02.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-12T20:02:01.080+0000] {processor.py:157} INFO - Started process (PID=36303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:02:01.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:02:01.095+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:02:01.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:02:01.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:02:01.150+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:02:01.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:02:01.164+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:02:01.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:02:01.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-12T20:19:58.267+0000] {processor.py:157} INFO - Started process (PID=36315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:19:58.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:19:58.274+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:19:58.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:19:58.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:19:58.336+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:19:58.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:19:58.350+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:19:58.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:19:58.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-12T20:35:58.257+0000] {processor.py:157} INFO - Started process (PID=36325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:35:58.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:35:58.263+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:35:58.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:35:58.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:35:58.333+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:35:58.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:35:58.360+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:35:58.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:35:58.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-12T20:38:30.027+0000] {processor.py:157} INFO - Started process (PID=36335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:38:30.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:38:30.032+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:38:30.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:38:30.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:38:30.091+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:38:30.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:38:30.128+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:38:30.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:38:30.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-12T20:39:00.547+0000] {processor.py:157} INFO - Started process (PID=36345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:39:00.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:39:00.558+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:39:00.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:39:00.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:39:00.611+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:39:00.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:39:00.631+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:39:00.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:39:00.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-12T20:49:32.765+0000] {processor.py:157} INFO - Started process (PID=36354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:49:32.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:49:32.772+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:49:32.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:49:32.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:49:32.869+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:49:32.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:49:32.906+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:49:32.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:49:32.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-12T20:51:36.925+0000] {processor.py:157} INFO - Started process (PID=36366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:51:36.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:51:36.942+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:51:36.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:51:36.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:51:37.044+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:51:37.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:51:37.073+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:51:37.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:51:37.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-12T20:52:07.256+0000] {processor.py:157} INFO - Started process (PID=36377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:07.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:52:07.261+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:07.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:07.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:07.319+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:07.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:52:07.338+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:07.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:52:07.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-12T20:52:37.702+0000] {processor.py:157} INFO - Started process (PID=36387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:37.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T20:52:37.710+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:37.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:37.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T20:52:37.747+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:37.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T20:52:37.759+0000] {logging_mixin.py:151} INFO - [2024-08-12T20:52:37.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T20:52:37.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-12T21:23:09.657+0000] {processor.py:157} INFO - Started process (PID=36397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:09.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:23:09.665+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:09.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:09.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:09.700+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:09.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:23:09.714+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:09.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:23:09.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T21:23:39.985+0000] {processor.py:157} INFO - Started process (PID=36407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:39.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:23:39.992+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:39.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:40.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:23:40.048+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:40.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:23:40.065+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:23:40.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:23:40.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-12T21:28:55.460+0000] {processor.py:157} INFO - Started process (PID=36419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:28:55.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:28:55.464+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:28:55.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:28:55.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:28:55.513+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:28:55.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:28:55.528+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:28:55.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:28:55.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-12T21:37:35.691+0000] {processor.py:157} INFO - Started process (PID=36428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:37:35.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:37:35.708+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:37:35.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:37:35.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:37:35.770+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:37:35.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:37:35.783+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:37:35.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:37:35.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-12T21:38:06.056+0000] {processor.py:157} INFO - Started process (PID=36439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:38:06.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:38:06.059+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:38:06.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:38:06.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:38:06.095+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:38:06.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:38:06.108+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:38:06.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:38:06.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-12T21:39:39.126+0000] {processor.py:157} INFO - Started process (PID=36449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:39:39.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:39:39.127+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:39:39.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:39:39.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:39:39.160+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:39:39.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:39:39.174+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:39:39.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:39:39.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-12T21:46:50.586+0000] {processor.py:157} INFO - Started process (PID=36461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:46:50.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:46:50.593+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:46:50.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:46:50.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:46:50.685+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:46:50.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:46:50.708+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:46:50.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:46:50.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-12T21:47:21.069+0000] {processor.py:157} INFO - Started process (PID=36471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:47:21.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:47:21.075+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:47:21.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:47:21.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:47:21.130+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:47:21.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:47:21.144+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:47:21.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:47:21.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-12T21:49:53.967+0000] {processor.py:157} INFO - Started process (PID=36481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:49:53.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:49:53.972+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:49:53.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:49:53.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:49:54.006+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:49:54.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:49:54.016+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:49:54.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:49:54.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-12T21:50:24.360+0000] {processor.py:157} INFO - Started process (PID=36491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:50:24.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:50:24.364+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:50:24.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:50:24.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:50:24.393+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:50:24.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:50:24.405+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:50:24.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:50:24.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-12T21:54:42.533+0000] {processor.py:157} INFO - Started process (PID=36502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:54:42.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:54:42.540+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:54:42.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:54:42.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:54:42.633+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:54:42.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:54:42.666+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:54:42.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:54:42.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-12T21:55:48.925+0000] {processor.py:157} INFO - Started process (PID=36513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:55:48.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:55:48.943+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:55:48.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:55:48.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:55:48.990+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:55:48.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:55:49.014+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:55:49.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:55:49.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-12T21:56:19.412+0000] {processor.py:157} INFO - Started process (PID=36523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:56:19.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T21:56:19.417+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:56:19.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:56:19.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T21:56:19.441+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:56:19.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T21:56:19.453+0000] {logging_mixin.py:151} INFO - [2024-08-12T21:56:19.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T21:56:19.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T22:04:23.235+0000] {processor.py:157} INFO - Started process (PID=36533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:23.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:04:23.239+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:23.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:23.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:23.304+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:23.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:04:23.332+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:23.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:04:23.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-12T22:04:53.726+0000] {processor.py:157} INFO - Started process (PID=36543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:53.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:04:53.739+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:53.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:53.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:04:53.781+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:53.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:04:53.803+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:04:53.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:04:53.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-12T22:06:19.445+0000] {processor.py:157} INFO - Started process (PID=36555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:19.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:06:19.457+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:19.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:19.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:19.514+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:19.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:06:19.529+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:19.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:06:19.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-12T22:06:49.861+0000] {processor.py:157} INFO - Started process (PID=36565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:49.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:06:49.869+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:49.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:49.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:06:49.910+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:49.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:06:49.924+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:06:49.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:06:49.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T22:08:20.961+0000] {processor.py:157} INFO - Started process (PID=36575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:08:20.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:08:20.965+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:08:20.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:08:20.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:08:20.990+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:08:20.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:08:21.001+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:08:21.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:08:21.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-12T22:11:10.420+0000] {processor.py:157} INFO - Started process (PID=36584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:10.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:11:10.424+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:10.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:10.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:10.463+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:10.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:11:10.474+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:10.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:11:10.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-12T22:11:40.810+0000] {processor.py:157} INFO - Started process (PID=36594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:40.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:11:40.818+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:40.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:40.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:11:40.860+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:40.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:11:40.874+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:11:40.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:11:40.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-12T22:12:14.763+0000] {processor.py:157} INFO - Started process (PID=36605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:12:14.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:12:14.765+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:12:14.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:12:14.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:12:14.791+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:12:14.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:12:14.800+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:12:14.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:12:14.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-12T22:15:45.890+0000] {processor.py:157} INFO - Started process (PID=36617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:15:45.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:15:45.894+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:15:45.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:15:45.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:15:45.937+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:15:45.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:15:45.978+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:15:45.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:15:46.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-12T22:16:16.393+0000] {processor.py:157} INFO - Started process (PID=36627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:16:16.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:16:16.399+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:16:16.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:16:16.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:16:16.455+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:16:16.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:16:16.470+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:16:16.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:16:16.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-12T22:18:03.160+0000] {processor.py:157} INFO - Started process (PID=36637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:18:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:18:03.166+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:18:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:18:03.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:18:03.243+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:18:03.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:18:03.270+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:18:03.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:18:03.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-12T22:28:21.855+0000] {processor.py:157} INFO - Started process (PID=36648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:21.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:28:21.862+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:21.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:21.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:21.977+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:21.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:28:22.002+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:22.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:28:22.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-12T22:28:52.235+0000] {processor.py:157} INFO - Started process (PID=36659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:52.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:28:52.242+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:52.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:52.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:28:52.309+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:52.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:28:52.325+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:28:52.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:28:52.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-12T22:29:23.459+0000] {processor.py:157} INFO - Started process (PID=36669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:29:23.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:29:23.467+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:29:23.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:29:23.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:29:23.488+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:29:23.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:29:23.499+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:29:23.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:29:23.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-12T22:40:22.383+0000] {processor.py:157} INFO - Started process (PID=36679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:22.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:40:22.398+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:22.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:22.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:22.488+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:22.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:40:22.517+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:22.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:40:22.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-12T22:40:52.733+0000] {processor.py:157} INFO - Started process (PID=36689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:52.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:40:52.739+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:52.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:52.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:40:52.804+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:52.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:40:52.819+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:40:52.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:40:52.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-12T22:46:21.201+0000] {processor.py:157} INFO - Started process (PID=36701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:21.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:46:21.213+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:21.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:21.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:21.263+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:21.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:46:21.277+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:21.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:46:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-12T22:46:51.507+0000] {processor.py:157} INFO - Started process (PID=36710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:51.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:46:51.513+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:51.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:51.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:46:51.549+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:51.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:46:51.566+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:46:51.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:46:51.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-12T22:53:30.503+0000] {processor.py:157} INFO - Started process (PID=36720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:53:30.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T22:53:30.509+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:53:30.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:53:30.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T22:53:30.608+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:53:30.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T22:53:30.659+0000] {logging_mixin.py:151} INFO - [2024-08-12T22:53:30.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T22:53:30.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-12T23:01:23.605+0000] {processor.py:157} INFO - Started process (PID=36731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:23.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:01:23.611+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:23.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:23.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:23.660+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:23.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:01:23.676+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:23.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:01:23.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-12T23:01:54.026+0000] {processor.py:157} INFO - Started process (PID=36741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:54.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:01:54.051+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:54.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:54.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:01:54.096+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:54.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:01:54.127+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:01:54.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:01:54.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-12T23:05:34.943+0000] {processor.py:157} INFO - Started process (PID=36751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:05:34.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:05:34.947+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:05:34.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:05:34.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:05:35.012+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:05:35.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:05:35.059+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:05:35.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:05:35.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-12T23:09:51.724+0000] {processor.py:157} INFO - Started process (PID=36762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:09:51.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:09:51.727+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:09:51.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:09:51.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:09:51.837+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:09:51.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:09:51.901+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:09:51.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:09:51.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-08-12T23:10:22.294+0000] {processor.py:157} INFO - Started process (PID=36772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:10:22.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:10:22.306+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:10:22.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:10:22.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:10:22.366+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:10:22.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:10:22.380+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:10:22.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:10:22.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-12T23:11:07.253+0000] {processor.py:157} INFO - Started process (PID=36782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:11:07.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:11:07.256+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:11:07.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:11:07.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:11:07.286+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:11:07.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:11:07.296+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:11:07.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:11:07.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-12T23:13:28.282+0000] {processor.py:157} INFO - Started process (PID=36793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:28.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:13:28.296+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:28.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:28.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:28.384+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:28.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:13:28.413+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:28.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:13:28.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-12T23:13:58.793+0000] {processor.py:157} INFO - Started process (PID=36804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:58.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:13:58.798+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:58.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:58.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:13:58.848+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:58.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:13:58.864+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:13:58.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:13:58.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T23:17:56.840+0000] {processor.py:157} INFO - Started process (PID=36814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:17:56.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:17:56.847+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:17:56.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:17:56.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:17:56.943+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:17:56.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:17:56.967+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:17:56.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:17:56.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-12T23:18:27.325+0000] {processor.py:157} INFO - Started process (PID=36823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:18:27.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:18:27.331+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:18:27.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:18:27.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:18:27.385+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:18:27.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:18:27.402+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:18:27.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:18:27.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-12T23:29:53.400+0000] {processor.py:157} INFO - Started process (PID=36836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:29:53.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:29:53.415+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:29:53.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:29:53.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:29:53.488+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:29:53.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:29:53.519+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:29:53.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:29:53.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-12T23:41:32.614+0000] {processor.py:157} INFO - Started process (PID=36846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:41:32.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:41:32.618+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:41:32.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:41:32.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:41:32.709+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:41:32.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:41:32.750+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:41:32.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:41:32.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-12T23:42:03.120+0000] {processor.py:157} INFO - Started process (PID=36856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:42:03.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:42:03.125+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:42:03.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:42:03.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:42:03.168+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:42:03.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:42:03.192+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:42:03.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:42:03.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-12T23:48:44.203+0000] {processor.py:157} INFO - Started process (PID=36865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:48:44.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:48:44.209+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:48:44.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:48:44.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:48:44.272+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:48:44.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:48:44.299+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:48:44.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:48:44.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-12T23:49:16.298+0000] {processor.py:157} INFO - Started process (PID=36876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:16.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:49:16.303+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:16.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:16.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:16.347+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:16.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:49:16.364+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:16.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:49:16.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-12T23:49:46.604+0000] {processor.py:157} INFO - Started process (PID=36886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:46.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-12T23:49:46.606+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:46.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:46.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-12T23:49:46.638+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:46.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-12T23:49:46.651+0000] {logging_mixin.py:151} INFO - [2024-08-12T23:49:46.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-11T01:00:00+00:00, run_after=2024-08-12T01:00:00+00:00
[2024-08-12T23:49:46.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
