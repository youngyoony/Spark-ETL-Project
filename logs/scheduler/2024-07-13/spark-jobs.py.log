[2024-07-13T00:32:03.223+0000] {processor.py:157} INFO - Started process (PID=8498) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:03.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T00:32:03.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:03.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:03.269+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T00:32:03.285+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T00:32:03.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-13T00:32:33.740+0000] {processor.py:157} INFO - Started process (PID=8523) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:33.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T00:32:33.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:33.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T00:32:33.782+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T00:32:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T00:32:33.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T01:22:37.952+0000] {processor.py:157} INFO - Started process (PID=8548) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:22:37.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T01:22:37.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:22:37.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:22:37.983+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:22:37.995+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T01:22:38.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T01:28:43.314+0000] {processor.py:157} INFO - Started process (PID=8962) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:28:43.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T01:28:43.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:28:43.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:28:43.349+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:28:43.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T01:28:43.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T01:29:13.795+0000] {processor.py:157} INFO - Started process (PID=8987) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:29:13.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T01:29:13.799+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:29:13.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:29:13.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:29:13.855+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T01:29:13.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T01:33:30.696+0000] {processor.py:157} INFO - Started process (PID=9013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:33:30.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T01:33:30.699+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:33:30.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T01:33:30.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:33:30.765+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T01:33:30.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-13T02:05:20.124+0000] {processor.py:157} INFO - Started process (PID=9038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:05:20.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:05:20.126+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:05:20.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:05:20.160+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:05:20.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:05:20.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T02:17:11.255+0000] {processor.py:157} INFO - Started process (PID=9063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:17:11.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:17:11.260+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:17:11.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:17:11.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:17:11.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:17:11.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-13T02:34:15.918+0000] {processor.py:157} INFO - Started process (PID=9088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:15.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:34:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:15.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:15.953+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:34:15.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:34:15.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T02:34:46.266+0000] {processor.py:157} INFO - Started process (PID=9113) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:46.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:34:46.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:46.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:34:46.296+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:34:46.306+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:34:46.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T02:40:14.930+0000] {processor.py:157} INFO - Started process (PID=9138) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:40:14.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:40:14.937+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:14.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:40:14.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:40:14.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:14.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:40:15.015+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:15.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:40:15.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-13T02:57:02.595+0000] {processor.py:157} INFO - Started process (PID=9165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:02.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:57:02.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:02.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:02.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:57:02.665+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.665+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:57:02.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-13T02:57:33.037+0000] {processor.py:157} INFO - Started process (PID=9190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:33.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T02:57:33.040+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:33.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T02:57:33.073+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:57:33.084+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T02:57:33.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T03:35:09.561+0000] {processor.py:157} INFO - Started process (PID=9214) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:09.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T03:35:09.565+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:09.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:09.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:35:09.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T03:35:09.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T03:35:40.084+0000] {processor.py:157} INFO - Started process (PID=9240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:40.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T03:35:40.086+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:40.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:35:40.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:35:40.132+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T03:35:40.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T03:50:17.427+0000] {processor.py:157} INFO - Started process (PID=9265) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:50:17.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T03:50:17.430+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:50:17.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T03:50:17.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:50:17.489+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T03:50:17.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T04:07:10.070+0000] {processor.py:157} INFO - Started process (PID=9290) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:07:10.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T04:07:10.073+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:07:10.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:07:10.127+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:07:10.145+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.145+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T04:07:10.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-13T04:22:09.891+0000] {processor.py:157} INFO - Started process (PID=9315) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:22:09.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T04:22:09.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:22:09.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:22:09.950+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:22:09.970+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T04:22:09.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-13T04:32:57.763+0000] {processor.py:157} INFO - Started process (PID=9342) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:32:57.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T04:32:57.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:32:57.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:32:57.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:32:57.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T04:32:57.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-13T04:33:28.197+0000] {processor.py:157} INFO - Started process (PID=9367) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:33:28.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T04:33:28.199+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:33:28.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:33:28.228+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:33:28.238+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T04:33:28.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T04:36:26.691+0000] {processor.py:157} INFO - Started process (PID=9392) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:36:26.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T04:36:26.693+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:36:26.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T04:36:26.722+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:36:26.732+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T04:36:26.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T05:02:10.009+0000] {processor.py:157} INFO - Started process (PID=9417) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:10.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:02:10.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:10.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:10.046+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:02:10.059+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.059+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:02:10.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T05:02:40.247+0000] {processor.py:157} INFO - Started process (PID=9442) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:40.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:02:40.250+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:40.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:02:40.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:02:40.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:02:40.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T05:37:11.402+0000] {processor.py:157} INFO - Started process (PID=9467) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:11.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:37:11.405+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:11.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:11.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:37:11.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:37:11.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T05:37:41.823+0000] {processor.py:157} INFO - Started process (PID=9492) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:41.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:37:41.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:41.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:37:41.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:37:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:37:41.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T05:43:36.478+0000] {processor.py:157} INFO - Started process (PID=9518) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:43:36.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:43:36.484+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:43:36.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:43:36.531+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:43:36.552+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:43:36.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-13T05:58:56.899+0000] {processor.py:157} INFO - Started process (PID=9543) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:58:56.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:58:56.904+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:58:56.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:58:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:58:56.960+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:58:56.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-13T05:59:27.394+0000] {processor.py:157} INFO - Started process (PID=9568) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:59:27.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T05:59:27.396+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:59:27.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T05:59:27.423+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:59:27.435+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.435+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T05:59:27.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T06:38:10.412+0000] {processor.py:157} INFO - Started process (PID=9593) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:10.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T06:38:10.415+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:10.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:10.448+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T06:38:10.461+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.461+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T06:38:10.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T06:38:40.799+0000] {processor.py:157} INFO - Started process (PID=9618) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:40.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T06:38:40.802+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:40.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T06:38:40.836+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T06:38:40.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T06:38:40.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T07:39:07.188+0000] {processor.py:157} INFO - Started process (PID=9643) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:07.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T07:39:07.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:07.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:07.216+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T07:39:07.226+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T07:39:07.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T07:39:37.570+0000] {processor.py:157} INFO - Started process (PID=9670) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:37.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T07:39:37.572+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:37.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T07:39:37.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T07:39:37.613+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T07:39:37.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T08:40:05.202+0000] {processor.py:157} INFO - Started process (PID=9695) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:05.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T08:40:05.205+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:05.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:05.255+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T08:40:05.272+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T08:40:05.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-13T08:40:35.702+0000] {processor.py:157} INFO - Started process (PID=9720) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:35.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T08:40:35.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:35.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T08:40:35.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T08:40:35.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T08:40:35.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T09:01:51.575+0000] {processor.py:157} INFO - Started process (PID=9745) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:01:51.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:01:51.578+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:01:51.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:01:51.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:01:51.628+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:01:51.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-13T09:02:22.178+0000] {processor.py:157} INFO - Started process (PID=9770) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:02:22.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:02:22.182+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:02:22.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:02:22.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:02:22.226+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.226+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:02:22.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T09:41:15.237+0000] {processor.py:157} INFO - Started process (PID=9797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:15.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:41:15.241+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:15.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:15.296+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:41:15.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:41:15.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.108 seconds
[2024-07-13T09:41:45.818+0000] {processor.py:157} INFO - Started process (PID=9821) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:45.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:41:45.820+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:45.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:41:45.846+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:41:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:41:45.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T09:49:13.150+0000] {processor.py:157} INFO - Started process (PID=9847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:13.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:49:13.161+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:13.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:13.256+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:49:13.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:49:13.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.167 seconds
[2024-07-13T09:49:44.790+0000] {processor.py:157} INFO - Started process (PID=9872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:44.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:49:44.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:44.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:49:44.837+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:49:44.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.849+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:49:44.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T09:50:15.208+0000] {processor.py:157} INFO - Started process (PID=9897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:50:15.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:50:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:50:15.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:50:15.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:50:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:50:15.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T09:51:23.007+0000] {processor.py:157} INFO - Started process (PID=9922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:23.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:51:23.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:23.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:23.080+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:51:23.105+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:51:23.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-13T09:51:53.543+0000] {processor.py:157} INFO - Started process (PID=9946) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:53.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:51:53.549+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:53.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:51:53.633+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:51:53.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:51:53.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-13T09:52:24.079+0000] {processor.py:157} INFO - Started process (PID=9972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:24.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:52:24.085+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:24.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:24.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:52:24.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:52:24.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T09:52:54.573+0000] {processor.py:157} INFO - Started process (PID=9997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:54.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:52:54.575+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:54.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:52:54.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:52:54.621+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:52:54.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T09:53:24.989+0000] {processor.py:157} INFO - Started process (PID=10022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:24.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:53:24.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:24.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:25.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:25.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:25.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:53:25.051+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:25.051+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:53:25.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-13T09:53:55.529+0000] {processor.py:157} INFO - Started process (PID=10046) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:55.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:53:55.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:55.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:53:55.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:53:55.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:53:55.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-13T09:54:26.102+0000] {processor.py:157} INFO - Started process (PID=10072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:26.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:54:26.104+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:26.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:26.140+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:54:26.153+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:54:26.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T09:54:56.645+0000] {processor.py:157} INFO - Started process (PID=10097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:56.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:54:56.651+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:56.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:54:56.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:54:56.732+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:54:56.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-13T09:55:27.114+0000] {processor.py:157} INFO - Started process (PID=10122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:27.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:55:27.118+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:27.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:27.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:55:27.158+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:55:27.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T09:55:57.585+0000] {processor.py:157} INFO - Started process (PID=10147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:57.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:55:57.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:57.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:55:57.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:55:57.681+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:55:57.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-13T09:56:28.079+0000] {processor.py:157} INFO - Started process (PID=10172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:28.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:56:28.082+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:28.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:28.111+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:56:28.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:56:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T09:56:58.479+0000] {processor.py:157} INFO - Started process (PID=10197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:58.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:56:58.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:58.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:56:58.527+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:56:58.543+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.543+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:56:58.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-13T09:57:28.937+0000] {processor.py:157} INFO - Started process (PID=10222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:28.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:57:28.942+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:28.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:28.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:57:28.992+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.992+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:57:29.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T09:57:59.420+0000] {processor.py:157} INFO - Started process (PID=10247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:59.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:57:59.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:59.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:57:59.463+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:57:59.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:57:59.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T09:58:29.863+0000] {processor.py:157} INFO - Started process (PID=10272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:58:29.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:58:29.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:58:29.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:58:29.906+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:58:29.919+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:58:29.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T09:59:00.318+0000] {processor.py:157} INFO - Started process (PID=10297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:00.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:59:00.324+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:00.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:00.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:59:00.421+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:59:00.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-13T09:59:30.845+0000] {processor.py:157} INFO - Started process (PID=10322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:30.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T09:59:30.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:30.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T09:59:30.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:59:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T09:59:30.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-13T10:00:01.286+0000] {processor.py:157} INFO - Started process (PID=10347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:01.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:00:01.290+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:01.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:01.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:00:01.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:00:01.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T10:00:31.766+0000] {processor.py:157} INFO - Started process (PID=10372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:31.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:00:31.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:31.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:00:31.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:00:31.819+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:00:31.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T10:01:02.237+0000] {processor.py:157} INFO - Started process (PID=10397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:02.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:01:02.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:02.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:02.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:01:02.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:01:02.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T10:01:32.708+0000] {processor.py:157} INFO - Started process (PID=10422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:32.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:01:32.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:32.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:01:32.741+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:01:32.753+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:01:32.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:02:03.184+0000] {processor.py:157} INFO - Started process (PID=10447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:03.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:02:03.189+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:03.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:03.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:02:03.243+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.243+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:02:03.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T10:02:33.661+0000] {processor.py:157} INFO - Started process (PID=10472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:33.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:02:33.664+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:33.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:02:33.690+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:02:33.704+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:02:33.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:03:04.077+0000] {processor.py:157} INFO - Started process (PID=10497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:04.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:03:04.080+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:04.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:04.114+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:03:04.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:03:04.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T10:03:34.534+0000] {processor.py:157} INFO - Started process (PID=10521) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:34.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:03:34.539+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:34.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:03:34.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:03:34.587+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.587+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:03:34.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T10:04:04.997+0000] {processor.py:157} INFO - Started process (PID=10547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:04.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:04:05.000+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:05.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:05.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:05.032+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:05.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:04:05.043+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:05.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:04:05.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:04:35.460+0000] {processor.py:157} INFO - Started process (PID=10572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:35.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:04:35.469+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:35.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:04:35.494+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:04:35.504+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.504+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:04:35.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:05:05.861+0000] {processor.py:157} INFO - Started process (PID=10597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:05.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:05:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:05.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:05.893+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:05:05.906+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:05:05.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:05:36.284+0000] {processor.py:157} INFO - Started process (PID=10622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:36.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:05:36.287+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:36.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:05:36.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:05:36.339+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:05:36.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T10:06:06.694+0000] {processor.py:157} INFO - Started process (PID=10647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:06.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:06:06.697+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:06.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:06.724+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:06:06.734+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:06:06.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:06:37.141+0000] {processor.py:157} INFO - Started process (PID=10672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:37.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:06:37.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:37.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:06:37.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:06:37.182+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:06:37.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T10:07:07.522+0000] {processor.py:157} INFO - Started process (PID=10697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:07.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:07:07.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:07.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:07.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:07:07.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:07:07.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:07:37.930+0000] {processor.py:157} INFO - Started process (PID=10722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:37.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:07:37.934+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:37.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:07:37.965+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:07:37.974+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:07:37.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:08:08.317+0000] {processor.py:157} INFO - Started process (PID=10747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:08.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:08:08.323+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:08.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:08.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:08:08.353+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:08:08.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-13T10:08:38.712+0000] {processor.py:157} INFO - Started process (PID=10772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:38.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:08:38.716+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:38.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:08:38.745+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:08:38.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.758+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:08:38.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:09:09.153+0000] {processor.py:157} INFO - Started process (PID=10797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:09.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:09:09.156+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:09.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:09.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:09:09.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:09:09.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:09:39.585+0000] {processor.py:157} INFO - Started process (PID=10822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:39.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:09:39.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:39.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:09:39.617+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:09:39.628+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:09:39.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:10:10.051+0000] {processor.py:157} INFO - Started process (PID=10847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:10.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:10:10.062+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:10.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:10.090+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:10:10.100+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.100+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:10:10.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:10:40.470+0000] {processor.py:157} INFO - Started process (PID=10872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:40.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:10:40.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:40.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:10:40.501+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:10:40.511+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:10:40.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:11:10.884+0000] {processor.py:157} INFO - Started process (PID=10897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:10.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:11:10.887+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:10.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:10.914+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:11:10.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:11:10.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:11:41.339+0000] {processor.py:157} INFO - Started process (PID=10922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:41.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:11:41.342+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:41.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:11:41.368+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:11:41.379+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:11:41.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T10:12:11.783+0000] {processor.py:157} INFO - Started process (PID=10947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:11.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:12:11.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:11.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:11.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:12:11.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:12:11.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:12:42.261+0000] {processor.py:157} INFO - Started process (PID=10972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:42.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:12:42.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:42.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:12:42.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:12:42.303+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:12:42.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:13:12.656+0000] {processor.py:157} INFO - Started process (PID=10997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:12.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:13:12.658+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:12.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:12.686+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:13:12.697+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.696+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:13:12.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T10:13:43.085+0000] {processor.py:157} INFO - Started process (PID=11022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:43.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:13:43.087+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:43.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:13:43.116+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:13:43.126+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:13:43.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:14:13.537+0000] {processor.py:157} INFO - Started process (PID=11047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:13.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:14:13.541+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:13.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:13.569+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:14:13.582+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.582+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:14:13.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:14:43.994+0000] {processor.py:157} INFO - Started process (PID=11072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:43.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:14:43.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:43.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:44.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:14:44.032+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:44.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:14:44.044+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:44.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:14:44.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T10:15:14.522+0000] {processor.py:157} INFO - Started process (PID=11097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:14.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:15:14.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:14.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:14.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:15:14.564+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:15:14.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:15:44.877+0000] {processor.py:157} INFO - Started process (PID=11122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:44.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:15:44.880+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:44.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:15:44.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:15:44.920+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:15:44.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:16:15.256+0000] {processor.py:157} INFO - Started process (PID=11147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:15.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:16:15.258+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:15.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:15.286+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:16:15.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:16:15.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:16:45.754+0000] {processor.py:157} INFO - Started process (PID=11172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:45.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:16:45.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:45.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:16:45.787+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:16:45.799+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:16:45.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T10:17:16.158+0000] {processor.py:157} INFO - Started process (PID=11197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:16.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:17:16.160+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:16.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:16.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:17:16.201+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:17:16.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:17:46.631+0000] {processor.py:157} INFO - Started process (PID=11222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:46.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:17:46.639+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:46.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:17:46.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:17:46.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:17:46.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-13T10:18:17.214+0000] {processor.py:157} INFO - Started process (PID=11247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:17.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:18:17.223+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:17.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:17.299+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:18:17.316+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.316+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:18:17.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-13T10:18:47.762+0000] {processor.py:157} INFO - Started process (PID=11272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:47.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:18:47.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:47.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:18:47.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:18:47.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.848+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:18:47.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-13T10:19:18.255+0000] {processor.py:157} INFO - Started process (PID=11297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:18.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:19:18.262+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:18.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:18.314+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:19:18.333+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:19:18.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-13T10:19:48.738+0000] {processor.py:157} INFO - Started process (PID=11322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:48.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:19:48.741+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:48.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:19:48.772+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:19:48.786+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:19:48.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T10:20:19.217+0000] {processor.py:157} INFO - Started process (PID=11347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:19.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:20:19.226+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:19.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:19.289+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:20:19.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:20:19.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-13T10:20:49.778+0000] {processor.py:157} INFO - Started process (PID=11372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:49.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:20:49.780+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:49.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:20:49.813+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:20:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:20:49.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T10:21:20.309+0000] {processor.py:157} INFO - Started process (PID=11397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:20.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:21:20.324+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:20.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:20.383+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:21:20.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:21:20.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-13T10:21:50.840+0000] {processor.py:157} INFO - Started process (PID=11422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:50.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:21:50.847+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:50.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:21:50.906+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:21:50.933+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:21:50.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-13T10:22:21.416+0000] {processor.py:157} INFO - Started process (PID=11447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:21.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:22:21.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:21.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:21.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:22:21.479+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:22:21.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T10:22:51.882+0000] {processor.py:157} INFO - Started process (PID=11472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:51.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:22:51.884+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:51.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:22:51.916+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:22:51.926+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:22:51.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:23:22.331+0000] {processor.py:157} INFO - Started process (PID=11497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:22.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:23:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:22.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:22.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:23:22.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:23:22.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:23:52.751+0000] {processor.py:157} INFO - Started process (PID=11522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:52.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:23:52.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:52.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:23:52.795+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:23:52.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:23:52.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T10:24:23.228+0000] {processor.py:157} INFO - Started process (PID=11547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:23.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:24:23.231+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:23.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:23.264+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:24:23.276+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:24:23.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T10:24:53.640+0000] {processor.py:157} INFO - Started process (PID=11572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:53.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:24:53.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:53.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:24:53.668+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:24:53.678+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:24:53.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:25:24.101+0000] {processor.py:157} INFO - Started process (PID=11597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:24.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:25:24.108+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:24.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:24.131+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:25:24.142+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:25:24.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:25:54.557+0000] {processor.py:157} INFO - Started process (PID=11622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:54.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:25:54.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:54.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:25:54.591+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:25:54.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:25:54.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:26:24.961+0000] {processor.py:157} INFO - Started process (PID=11647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:24.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:26:24.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:24.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:24.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:24.994+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:24.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:26:25.006+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:25.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:26:25.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:26:55.358+0000] {processor.py:157} INFO - Started process (PID=11672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:55.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:26:55.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:55.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:26:55.388+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:26:55.398+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:26:55.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T10:27:25.768+0000] {processor.py:157} INFO - Started process (PID=11697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:25.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:27:25.769+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:25.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:25.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:27:25.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:27:25.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:27:56.142+0000] {processor.py:157} INFO - Started process (PID=11722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:56.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:27:56.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:56.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:27:56.179+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:27:56.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:27:56.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T10:28:26.552+0000] {processor.py:157} INFO - Started process (PID=11747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:26.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:28:26.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:26.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:26.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:28:26.602+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:28:26.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T10:28:56.973+0000] {processor.py:157} INFO - Started process (PID=11772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:56.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:28:56.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:56.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:56.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:28:57.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:57.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:28:57.024+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:57.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:28:57.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T10:29:27.444+0000] {processor.py:157} INFO - Started process (PID=11797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:27.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:29:27.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:27.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:27.478+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:29:27.489+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:29:27.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T10:29:57.860+0000] {processor.py:157} INFO - Started process (PID=11822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:57.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:29:57.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:57.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:29:57.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:29:57.899+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:29:57.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T10:30:28.326+0000] {processor.py:157} INFO - Started process (PID=11847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:28.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:30:28.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:28.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:28.362+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:30:28.372+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:30:28.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:30:58.849+0000] {processor.py:157} INFO - Started process (PID=11872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:58.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:30:58.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:58.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:30:58.880+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:30:58.892+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:30:58.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:31:29.375+0000] {processor.py:157} INFO - Started process (PID=11897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:29.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:31:29.379+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:29.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:29.405+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:31:29.416+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:31:29.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:31:59.855+0000] {processor.py:157} INFO - Started process (PID=11922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:59.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:31:59.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:59.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:31:59.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:31:59.898+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:31:59.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:32:30.326+0000] {processor.py:157} INFO - Started process (PID=11947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:32:30.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:32:30.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:32:30.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:32:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:32:30.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:32:30.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:33:00.678+0000] {processor.py:157} INFO - Started process (PID=11972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:00.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:33:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:00.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:00.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:33:00.718+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:33:00.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T10:33:31.141+0000] {processor.py:157} INFO - Started process (PID=11997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:31.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:33:31.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:31.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:33:31.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:33:31.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.183+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:33:31.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:34:01.574+0000] {processor.py:157} INFO - Started process (PID=12022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:01.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:34:01.577+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:01.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:01.613+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:34:01.625+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:34:01.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T10:34:32.022+0000] {processor.py:157} INFO - Started process (PID=12047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:32.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:34:32.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:32.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:34:32.055+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:34:32.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:34:32.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:35:02.450+0000] {processor.py:157} INFO - Started process (PID=12072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:02.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:35:02.452+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:02.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:02.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:35:02.492+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:35:02.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:35:32.912+0000] {processor.py:157} INFO - Started process (PID=12097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:32.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:35:32.915+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:32.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:35:32.944+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:35:32.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:35:32.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:36:03.337+0000] {processor.py:157} INFO - Started process (PID=12122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:03.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:36:03.340+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:03.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:03.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:36:03.377+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:36:03.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:36:33.755+0000] {processor.py:157} INFO - Started process (PID=12147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:33.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:36:33.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:33.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:36:33.782+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:36:33.791+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.791+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:36:33.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-13T10:37:04.248+0000] {processor.py:157} INFO - Started process (PID=12172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:04.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:37:04.254+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:04.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:04.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:37:04.305+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:37:04.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T10:37:34.732+0000] {processor.py:157} INFO - Started process (PID=12197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:34.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:37:34.735+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:34.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:37:34.763+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:37:34.774+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:37:34.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:38:05.140+0000] {processor.py:157} INFO - Started process (PID=12222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:05.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:38:05.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:05.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:05.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:38:05.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:38:05.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T10:38:35.592+0000] {processor.py:157} INFO - Started process (PID=12247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:35.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:38:35.594+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:35.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:38:35.621+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:38:35.631+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:38:35.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T10:39:05.948+0000] {processor.py:157} INFO - Started process (PID=12272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:05.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:39:05.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:05.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:05.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:39:05.989+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:39:05.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:39:36.384+0000] {processor.py:157} INFO - Started process (PID=12297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:36.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:39:36.387+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:36.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:39:36.415+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:39:36.425+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:39:36.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:40:06.821+0000] {processor.py:157} INFO - Started process (PID=12322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:06.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:40:06.825+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:06.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:06.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:40:06.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:40:06.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:40:37.239+0000] {processor.py:157} INFO - Started process (PID=12347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:37.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:40:37.242+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:37.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:40:37.273+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:40:37.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:40:37.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:41:07.702+0000] {processor.py:157} INFO - Started process (PID=12372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:07.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:41:07.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:07.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:07.730+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:41:07.741+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.741+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:41:07.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T10:41:38.175+0000] {processor.py:157} INFO - Started process (PID=12397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:38.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:41:38.178+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:38.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:41:38.205+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:41:38.216+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:41:38.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:42:08.612+0000] {processor.py:157} INFO - Started process (PID=12422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:08.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:42:08.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:08.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:08.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:42:08.656+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:42:08.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:42:39.071+0000] {processor.py:157} INFO - Started process (PID=12447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:39.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:42:39.074+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:39.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:42:39.100+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:42:39.110+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:42:39.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:43:09.601+0000] {processor.py:157} INFO - Started process (PID=12472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:09.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:43:09.603+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:09.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:09.631+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:43:09.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.642+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:43:09.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:43:40.020+0000] {processor.py:157} INFO - Started process (PID=12497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:40.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:43:40.028+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:40.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:43:40.066+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:43:40.078+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:43:40.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T10:44:10.494+0000] {processor.py:157} INFO - Started process (PID=12522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:10.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:44:10.498+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:10.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:10.527+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:44:10.539+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:44:10.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:44:40.939+0000] {processor.py:157} INFO - Started process (PID=12547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:40.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:44:40.941+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:40.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:44:40.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:44:40.989+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:44:41.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T10:45:11.442+0000] {processor.py:157} INFO - Started process (PID=12572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:11.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:45:11.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:11.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:11.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:45:11.492+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:45:11.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T10:45:41.847+0000] {processor.py:157} INFO - Started process (PID=12597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:41.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:45:41.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:41.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:45:41.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:45:41.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:45:41.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:46:12.235+0000] {processor.py:157} INFO - Started process (PID=12622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:12.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:46:12.238+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:12.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:12.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:46:12.276+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:46:12.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:46:42.664+0000] {processor.py:157} INFO - Started process (PID=12647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:42.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:46:42.667+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:42.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:46:42.699+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:46:42.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:46:42.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T10:47:13.178+0000] {processor.py:157} INFO - Started process (PID=12672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:13.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:47:13.181+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:13.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:13.210+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:47:13.221+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:47:13.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:47:43.631+0000] {processor.py:157} INFO - Started process (PID=12697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:43.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:47:43.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:43.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:47:43.663+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:47:43.676+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:47:43.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:48:14.034+0000] {processor.py:157} INFO - Started process (PID=12722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:14.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:48:14.036+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:14.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:14.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:48:14.080+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.080+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:48:14.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T10:48:44.450+0000] {processor.py:157} INFO - Started process (PID=12747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:44.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:48:44.453+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:44.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:48:44.484+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:48:44.495+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:48:44.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:49:14.857+0000] {processor.py:157} INFO - Started process (PID=12772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:14.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:49:14.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:14.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:14.891+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:49:14.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:49:14.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:49:45.292+0000] {processor.py:157} INFO - Started process (PID=12797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:45.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:49:45.295+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:45.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:49:45.324+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:49:45.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:49:45.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:50:15.732+0000] {processor.py:157} INFO - Started process (PID=12822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:15.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:50:15.736+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:15.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:15.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:50:15.784+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:50:15.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T10:50:46.177+0000] {processor.py:157} INFO - Started process (PID=12847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:46.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:50:46.180+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:46.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:50:46.213+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:50:46.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:50:46.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T10:51:16.527+0000] {processor.py:157} INFO - Started process (PID=12872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:16.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:51:16.530+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:16.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:16.555+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:51:16.565+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.565+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:51:16.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:51:46.995+0000] {processor.py:157} INFO - Started process (PID=12897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:46.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:51:46.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:46.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:47.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:51:47.027+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:47.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:51:47.039+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:47.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:51:47.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:52:17.484+0000] {processor.py:157} INFO - Started process (PID=12922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:17.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:52:17.487+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:17.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:17.516+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:52:17.526+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.526+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:52:17.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T10:52:47.952+0000] {processor.py:157} INFO - Started process (PID=12947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:47.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:52:47.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:47.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:52:47.984+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:52:47.995+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:52:48.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T10:53:18.452+0000] {processor.py:157} INFO - Started process (PID=12972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:18.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:53:18.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:18.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:18.488+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:53:18.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:53:18.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T10:53:48.935+0000] {processor.py:157} INFO - Started process (PID=12997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:48.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:53:48.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:48.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:53:48.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:53:48.983+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:53:48.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T10:54:19.407+0000] {processor.py:157} INFO - Started process (PID=13022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:19.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:54:19.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:19.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:19.440+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:54:19.450+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:54:19.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T10:54:49.833+0000] {processor.py:157} INFO - Started process (PID=13047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:49.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:54:49.837+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:49.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:54:49.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:54:49.881+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:54:49.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:55:20.266+0000] {processor.py:157} INFO - Started process (PID=13072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:20.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:55:20.269+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:20.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:20.304+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:55:20.314+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:55:20.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T10:55:50.731+0000] {processor.py:157} INFO - Started process (PID=13097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:50.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:55:50.734+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:50.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:55:50.764+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:55:50.777+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.776+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:55:50.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:56:21.152+0000] {processor.py:157} INFO - Started process (PID=13122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:21.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:56:21.159+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:21.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:21.185+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:56:21.195+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.195+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:56:21.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:56:51.593+0000] {processor.py:157} INFO - Started process (PID=13147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:51.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:56:51.597+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:51.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:56:51.623+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:56:51.637+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:56:51.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T10:57:22.072+0000] {processor.py:157} INFO - Started process (PID=13172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:22.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:57:22.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:22.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:22.105+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:57:22.118+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:57:22.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T10:57:52.490+0000] {processor.py:157} INFO - Started process (PID=13197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:52.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:57:52.493+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:52.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:57:52.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:57:52.531+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:57:52.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T10:58:22.920+0000] {processor.py:157} INFO - Started process (PID=13222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:22.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:58:22.925+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:22.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:22.954+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:58:22.966+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:58:22.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T10:58:53.363+0000] {processor.py:157} INFO - Started process (PID=13247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:53.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:58:53.367+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:53.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:58:53.398+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:58:53.408+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:58:53.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T10:59:23.825+0000] {processor.py:157} INFO - Started process (PID=13272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:23.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:59:23.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:23.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:23.853+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:59:23.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:59:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T10:59:54.286+0000] {processor.py:157} INFO - Started process (PID=13297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:54.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T10:59:54.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:54.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T10:59:54.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:59:54.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T10:59:54.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:00:24.808+0000] {processor.py:157} INFO - Started process (PID=13322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:24.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:00:24.822+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:24.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:24.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:00:24.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:00:24.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-13T11:00:55.264+0000] {processor.py:157} INFO - Started process (PID=13347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:55.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:00:55.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:55.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:00:55.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:00:55.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:00:55.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:01:25.690+0000] {processor.py:157} INFO - Started process (PID=13372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:25.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:01:25.693+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:25.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:25.725+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:01:25.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.737+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:01:25.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:01:56.062+0000] {processor.py:157} INFO - Started process (PID=13397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:56.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:01:56.065+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:56.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:01:56.093+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:01:56.107+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:01:56.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:02:26.477+0000] {processor.py:157} INFO - Started process (PID=13422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:26.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:02:26.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:26.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:26.508+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:02:26.518+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:02:26.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:02:56.968+0000] {processor.py:157} INFO - Started process (PID=13447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:56.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:02:56.970+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:56.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:56.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:02:56.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:56.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:02:57.009+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:57.009+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:02:57.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:03:27.424+0000] {processor.py:157} INFO - Started process (PID=13472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:27.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:03:27.428+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:27.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:27.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:03:27.467+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:03:27.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:03:57.887+0000] {processor.py:157} INFO - Started process (PID=13497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:57.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:03:57.890+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:57.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:03:57.922+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:03:57.935+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.935+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:03:57.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:04:28.303+0000] {processor.py:157} INFO - Started process (PID=13522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:28.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:04:28.306+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:28.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:28.333+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:04:28.345+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.344+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:04:28.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:04:58.711+0000] {processor.py:157} INFO - Started process (PID=13547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:58.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:04:58.714+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:58.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:04:58.743+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:04:58.754+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:04:58.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:05:29.139+0000] {processor.py:157} INFO - Started process (PID=13572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:29.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:05:29.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:29.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:29.167+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:05:29.181+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:05:29.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:05:59.544+0000] {processor.py:157} INFO - Started process (PID=13597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:59.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:05:59.549+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:59.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:05:59.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:05:59.586+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:05:59.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:06:29.971+0000] {processor.py:157} INFO - Started process (PID=13622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:06:29.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:06:29.974+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:29.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:06:29.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:06:30.005+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:30.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:06:30.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:30.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:06:30.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T11:07:00.430+0000] {processor.py:157} INFO - Started process (PID=13647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:00.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:07:00.435+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:00.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:00.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:07:00.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:07:00.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T11:07:30.884+0000] {processor.py:157} INFO - Started process (PID=13672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:30.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:07:30.887+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:30.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:07:30.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:07:30.926+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:07:30.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:08:01.304+0000] {processor.py:157} INFO - Started process (PID=13697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:01.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:08:01.306+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:01.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:01.337+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:08:01.348+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:08:01.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:08:31.808+0000] {processor.py:157} INFO - Started process (PID=13722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:31.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:08:31.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:31.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:08:31.850+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:08:31.860+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:08:31.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T11:09:02.245+0000] {processor.py:157} INFO - Started process (PID=13747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:02.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:09:02.249+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:02.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:02.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:09:02.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.291+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:09:02.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:09:32.739+0000] {processor.py:157} INFO - Started process (PID=13772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:32.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:09:32.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:32.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:09:32.796+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:09:32.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:09:32.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-13T11:10:03.277+0000] {processor.py:157} INFO - Started process (PID=13797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:03.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:10:03.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:03.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:03.310+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:10:03.320+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:10:03.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:10:33.757+0000] {processor.py:157} INFO - Started process (PID=13822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:33.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:10:33.759+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:33.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:10:33.787+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:10:33.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:10:33.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:11:04.170+0000] {processor.py:157} INFO - Started process (PID=13847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:04.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:11:04.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:04.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:04.206+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:11:04.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:11:04.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:11:34.638+0000] {processor.py:157} INFO - Started process (PID=13872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:34.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:11:34.642+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:34.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:11:34.671+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:11:34.683+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.683+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:11:34.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:12:05.065+0000] {processor.py:157} INFO - Started process (PID=13897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:05.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:12:05.068+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:05.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:05.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:12:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:12:05.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:12:35.521+0000] {processor.py:157} INFO - Started process (PID=13922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:35.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:12:35.524+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:35.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:12:35.551+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:12:35.561+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:12:35.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:13:05.907+0000] {processor.py:157} INFO - Started process (PID=13947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:05.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:13:05.910+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:05.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:05.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:13:05.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.951+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:13:05.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:13:36.447+0000] {processor.py:157} INFO - Started process (PID=13972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:36.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:13:36.451+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:36.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:13:36.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:13:36.496+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:13:36.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:14:06.932+0000] {processor.py:157} INFO - Started process (PID=13997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:06.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:14:06.935+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:06.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:06.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:14:06.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:14:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:14:37.440+0000] {processor.py:157} INFO - Started process (PID=14022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:37.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:14:37.442+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:37.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:14:37.470+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:14:37.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:14:37.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T11:15:07.936+0000] {processor.py:157} INFO - Started process (PID=14047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:07.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:15:07.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:07.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:07.971+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:15:07.982+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:15:07.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T11:15:38.417+0000] {processor.py:157} INFO - Started process (PID=14072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:38.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:15:38.419+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:38.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:15:38.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:15:38.459+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:15:38.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:16:08.836+0000] {processor.py:157} INFO - Started process (PID=14097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:08.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:16:08.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:08.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:08.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:16:08.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.893+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:16:08.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T11:16:39.272+0000] {processor.py:157} INFO - Started process (PID=14122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:39.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:16:39.275+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:39.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:16:39.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:16:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:16:39.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:17:09.727+0000] {processor.py:157} INFO - Started process (PID=14147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:09.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:17:09.729+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:09.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:09.763+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:17:09.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.773+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:17:09.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:17:40.216+0000] {processor.py:157} INFO - Started process (PID=14172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:40.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:17:40.219+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:40.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:17:40.251+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:17:40.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:17:40.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T11:18:10.712+0000] {processor.py:157} INFO - Started process (PID=14197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:10.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:18:10.714+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:10.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:10.739+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:18:10.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:18:10.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T11:18:41.188+0000] {processor.py:157} INFO - Started process (PID=14222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:41.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:18:41.193+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:41.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:18:41.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:18:41.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:18:41.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T11:19:11.638+0000] {processor.py:157} INFO - Started process (PID=14247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:11.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:19:11.641+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:11.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:11.669+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:19:11.679+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:19:11.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T11:19:42.115+0000] {processor.py:157} INFO - Started process (PID=14272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:42.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:19:42.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:42.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:19:42.148+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:19:42.160+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:19:42.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:20:12.517+0000] {processor.py:157} INFO - Started process (PID=14297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:12.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:20:12.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:12.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:12.549+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:20:12.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:20:12.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:20:42.863+0000] {processor.py:157} INFO - Started process (PID=14322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:42.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:20:42.865+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:42.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:20:42.891+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:20:42.902+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:20:42.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T11:21:13.288+0000] {processor.py:157} INFO - Started process (PID=14347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:13.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:21:13.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:13.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:13.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:21:13.337+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:21:13.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T11:21:43.726+0000] {processor.py:157} INFO - Started process (PID=14372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:43.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:21:43.729+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:43.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:21:43.763+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:21:43.774+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:21:43.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T11:22:14.188+0000] {processor.py:157} INFO - Started process (PID=14397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:14.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:22:14.192+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:14.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:14.222+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:22:14.233+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:22:14.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:22:44.625+0000] {processor.py:157} INFO - Started process (PID=14422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:44.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:22:44.628+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:44.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:22:44.656+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:22:44.666+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:22:44.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:23:15.027+0000] {processor.py:157} INFO - Started process (PID=14447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:15.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:23:15.031+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:15.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:15.061+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:23:15.071+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.071+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:23:15.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:23:45.487+0000] {processor.py:157} INFO - Started process (PID=14472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:45.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:23:45.491+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:45.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:23:45.519+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:23:45.532+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:23:45.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:24:15.903+0000] {processor.py:157} INFO - Started process (PID=14497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:15.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:24:15.905+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:15.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:15.935+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:24:15.945+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:24:15.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:24:46.404+0000] {processor.py:157} INFO - Started process (PID=14522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:46.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:24:46.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:46.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:24:46.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:24:46.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.449+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:24:46.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:25:16.827+0000] {processor.py:157} INFO - Started process (PID=14547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:16.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:25:16.829+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:16.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:16.865+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:25:16.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:25:16.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T11:25:47.335+0000] {processor.py:157} INFO - Started process (PID=14572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:47.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:25:47.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:47.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:25:47.369+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:25:47.379+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:25:47.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:26:17.788+0000] {processor.py:157} INFO - Started process (PID=14597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:17.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:26:17.791+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:17.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:17.824+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:26:17.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:26:17.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:26:48.251+0000] {processor.py:157} INFO - Started process (PID=14622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:48.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:26:48.256+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:48.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:26:48.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:26:48.304+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.304+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:26:48.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T11:27:18.747+0000] {processor.py:157} INFO - Started process (PID=14647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:18.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:27:18.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:18.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:18.779+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:27:18.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:27:18.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:27:49.145+0000] {processor.py:157} INFO - Started process (PID=14672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:49.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:27:49.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:49.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:27:49.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:27:49.187+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.187+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:27:49.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:28:19.608+0000] {processor.py:157} INFO - Started process (PID=14697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:19.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:28:19.610+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:19.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:19.641+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:28:19.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:28:19.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:28:50.051+0000] {processor.py:157} INFO - Started process (PID=14722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:50.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:28:50.054+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:50.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:28:50.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:28:50.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:28:50.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:29:20.499+0000] {processor.py:157} INFO - Started process (PID=14747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:20.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:29:20.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:20.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:20.531+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:29:20.542+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:29:20.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:29:50.929+0000] {processor.py:157} INFO - Started process (PID=14772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:50.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:29:50.932+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:50.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:29:50.960+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:29:50.970+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:29:50.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T11:30:21.368+0000] {processor.py:157} INFO - Started process (PID=14797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:21.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:30:21.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:21.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:21.399+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:30:21.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.412+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:30:21.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:30:51.831+0000] {processor.py:157} INFO - Started process (PID=14822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:51.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:30:51.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:51.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:30:51.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:30:51.881+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:30:51.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T11:31:22.331+0000] {processor.py:157} INFO - Started process (PID=14847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:22.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:31:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:22.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:22.364+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:31:22.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:31:22.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:31:52.703+0000] {processor.py:157} INFO - Started process (PID=14872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:52.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:31:52.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:52.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:31:52.735+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:31:52.745+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:31:52.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:32:23.146+0000] {processor.py:157} INFO - Started process (PID=14897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:23.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:32:23.149+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:23.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:23.178+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:32:23.188+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.188+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:32:23.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:32:53.637+0000] {processor.py:157} INFO - Started process (PID=14922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:53.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:32:53.641+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:53.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:32:53.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:32:53.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:32:53.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T11:33:24.097+0000] {processor.py:157} INFO - Started process (PID=14947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:24.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:33:24.100+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:24.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:24.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:33:24.140+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:33:24.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T11:33:54.547+0000] {processor.py:157} INFO - Started process (PID=14972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:54.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:33:54.550+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:54.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:33:54.585+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:33:54.597+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.597+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:33:54.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T11:34:25.045+0000] {processor.py:157} INFO - Started process (PID=14997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:25.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:34:25.047+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:25.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:25.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:34:25.085+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:34:25.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:34:55.480+0000] {processor.py:157} INFO - Started process (PID=15022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:55.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:34:55.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:55.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:34:55.513+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:34:55.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:34:55.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:35:25.961+0000] {processor.py:157} INFO - Started process (PID=15047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:25.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:35:25.964+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:25.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:25.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:25.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:25.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:35:26.008+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:26.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:35:26.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:35:56.374+0000] {processor.py:157} INFO - Started process (PID=15072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:56.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:35:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:56.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:35:56.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:35:56.413+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:35:56.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:36:26.801+0000] {processor.py:157} INFO - Started process (PID=15097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:26.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:36:26.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:26.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:26.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:36:26.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.858+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:36:26.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T11:36:57.308+0000] {processor.py:157} INFO - Started process (PID=15122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:57.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:36:57.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:57.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:36:57.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:36:57.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:36:57.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T11:37:27.741+0000] {processor.py:157} INFO - Started process (PID=15147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:27.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:37:27.743+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:27.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:27.771+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:37:27.781+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:37:27.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T11:37:58.234+0000] {processor.py:157} INFO - Started process (PID=15172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:58.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:37:58.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:58.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:37:58.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:37:58.282+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:37:58.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T11:38:28.653+0000] {processor.py:157} INFO - Started process (PID=15197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:28.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:38:28.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:28.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:28.684+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:38:28.697+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.697+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:38:28.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:38:59.169+0000] {processor.py:157} INFO - Started process (PID=15222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:59.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:38:59.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:59.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:38:59.209+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:38:59.223+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:38:59.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T11:39:29.643+0000] {processor.py:157} INFO - Started process (PID=15247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:39:29.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:39:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:39:29.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:39:29.673+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:39:29.684+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.684+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:39:29.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:40:00.063+0000] {processor.py:157} INFO - Started process (PID=15272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:00.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:40:00.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:00.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:00.102+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:40:00.115+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:40:00.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T11:40:30.483+0000] {processor.py:157} INFO - Started process (PID=15297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:30.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:40:30.488+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:30.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:40:30.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:40:30.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:40:30.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T11:41:00.948+0000] {processor.py:157} INFO - Started process (PID=15322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:00.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:41:00.956+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:00.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:00.982+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:41:00.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:41:01.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:41:31.355+0000] {processor.py:157} INFO - Started process (PID=15347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:31.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:41:31.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:31.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:41:31.393+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:41:31.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:41:31.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T11:42:01.778+0000] {processor.py:157} INFO - Started process (PID=15372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:01.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:42:01.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:01.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:01.823+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:42:01.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:42:01.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T11:42:32.225+0000] {processor.py:157} INFO - Started process (PID=15397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:32.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:42:32.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:32.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:42:32.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:42:32.278+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:42:32.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T11:43:02.692+0000] {processor.py:157} INFO - Started process (PID=15422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:02.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:43:02.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:02.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:02.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:43:02.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:43:02.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:43:33.141+0000] {processor.py:157} INFO - Started process (PID=15447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:33.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:43:33.145+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:33.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:43:33.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:43:33.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:43:33.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T11:44:03.627+0000] {processor.py:157} INFO - Started process (PID=15472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:03.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:44:03.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:03.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:03.660+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:44:03.672+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:44:03.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:44:34.118+0000] {processor.py:157} INFO - Started process (PID=15497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:34.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:44:34.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:34.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:44:34.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:44:34.159+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:44:34.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:45:04.594+0000] {processor.py:157} INFO - Started process (PID=15522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:04.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:45:04.596+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:04.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:04.626+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:45:04.639+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.639+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:45:04.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:45:35.000+0000] {processor.py:157} INFO - Started process (PID=15547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:35.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:45:35.003+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:35.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:45:35.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:45:35.045+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:45:35.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:46:05.490+0000] {processor.py:157} INFO - Started process (PID=15572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:05.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:46:05.493+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:05.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:05.524+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:46:05.534+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:46:05.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T11:46:35.884+0000] {processor.py:157} INFO - Started process (PID=15597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:35.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:46:35.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:35.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:46:35.917+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:46:35.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:46:35.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:47:06.296+0000] {processor.py:157} INFO - Started process (PID=15622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:06.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:47:06.300+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:06.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:06.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:47:06.340+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.340+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:47:06.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:47:36.741+0000] {processor.py:157} INFO - Started process (PID=15647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:36.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:47:36.745+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:36.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:47:36.778+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:47:36.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.789+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:47:36.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T11:48:07.186+0000] {processor.py:157} INFO - Started process (PID=15672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:07.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:48:07.190+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:07.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:07.219+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:48:07.232+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:48:07.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:48:37.554+0000] {processor.py:157} INFO - Started process (PID=15697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:37.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:48:37.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:37.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:48:37.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:48:37.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.600+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:48:37.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T11:49:07.983+0000] {processor.py:157} INFO - Started process (PID=15722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:07.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:49:07.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:07.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:08.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:08.022+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:08.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:49:08.033+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:08.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:49:08.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:49:38.476+0000] {processor.py:157} INFO - Started process (PID=15747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:38.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:49:38.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:38.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:49:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:49:38.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:49:38.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T11:50:08.935+0000] {processor.py:157} INFO - Started process (PID=15772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:08.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:50:08.938+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:08.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:08.964+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:50:08.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.975+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:50:08.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T11:50:39.373+0000] {processor.py:157} INFO - Started process (PID=15797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:39.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:50:39.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:39.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:50:39.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:50:39.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:50:39.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T11:51:09.772+0000] {processor.py:157} INFO - Started process (PID=15822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:09.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:51:09.775+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:09.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:09.802+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:51:09.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:51:09.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T11:51:40.167+0000] {processor.py:157} INFO - Started process (PID=15847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:40.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:51:40.171+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:40.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:51:40.205+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:51:40.216+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.216+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:51:40.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:52:10.593+0000] {processor.py:157} INFO - Started process (PID=15872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:10.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:52:10.596+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:10.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:10.626+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:52:10.637+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:52:10.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T11:52:41.032+0000] {processor.py:157} INFO - Started process (PID=15897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:41.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:52:41.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:41.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:52:41.073+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:52:41.093+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:52:41.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-13T11:53:11.469+0000] {processor.py:157} INFO - Started process (PID=15922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:11.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:53:11.474+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:11.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:11.510+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:53:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:53:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T11:53:41.978+0000] {processor.py:157} INFO - Started process (PID=15947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:41.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:53:41.983+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:41.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:41.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:53:42.019+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:42.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:53:42.034+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:42.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:53:42.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T11:54:12.375+0000] {processor.py:157} INFO - Started process (PID=15972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:12.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:54:12.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:12.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:12.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:54:12.417+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:54:12.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T11:54:42.841+0000] {processor.py:157} INFO - Started process (PID=15997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:42.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:54:42.844+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:42.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:54:42.875+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:54:42.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.889+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:54:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T11:55:13.295+0000] {processor.py:157} INFO - Started process (PID=16022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:13.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:55:13.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:13.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:13.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:55:13.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:55:13.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T11:55:43.764+0000] {processor.py:157} INFO - Started process (PID=16047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:43.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:55:43.766+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:43.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:55:43.796+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:55:43.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:55:43.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T11:56:14.259+0000] {processor.py:157} INFO - Started process (PID=16072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:14.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:56:14.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:14.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:14.347+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:56:14.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:56:14.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.168 seconds
[2024-07-13T11:56:44.803+0000] {processor.py:157} INFO - Started process (PID=16097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:44.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:56:44.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:44.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:56:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:56:44.854+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:56:44.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T11:57:15.235+0000] {processor.py:157} INFO - Started process (PID=16122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:15.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:57:15.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:15.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:15.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:57:15.275+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:57:15.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T11:57:45.702+0000] {processor.py:157} INFO - Started process (PID=16147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:45.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:57:45.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:45.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:57:45.746+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:57:45.761+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:57:45.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T11:58:16.259+0000] {processor.py:157} INFO - Started process (PID=16172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:16.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:58:16.270+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:16.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:16.379+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:58:16.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:58:16.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.168 seconds
[2024-07-13T11:58:46.920+0000] {processor.py:157} INFO - Started process (PID=16197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:46.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:58:46.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:46.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:46.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:58:46.988+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:46.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:58:47.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:47.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:58:47.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-13T11:59:17.472+0000] {processor.py:157} INFO - Started process (PID=16222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:17.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:59:17.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:17.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:17.559+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:59:17.595+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:59:17.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-13T11:59:48.055+0000] {processor.py:157} INFO - Started process (PID=16247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:48.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T11:59:48.059+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:48.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T11:59:48.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:59:48.105+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T11:59:48.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T12:00:18.465+0000] {processor.py:157} INFO - Started process (PID=16272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:18.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:00:18.469+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:18.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:18.496+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:00:18.508+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.508+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:00:18.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:00:48.843+0000] {processor.py:157} INFO - Started process (PID=16297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:48.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:00:48.853+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:48.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:00:48.879+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:00:48.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.889+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:00:48.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T12:01:19.236+0000] {processor.py:157} INFO - Started process (PID=16322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:19.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:01:19.239+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:19.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:19.269+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:01:19.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.279+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:01:19.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:01:49.642+0000] {processor.py:157} INFO - Started process (PID=16347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:49.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:01:49.646+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:49.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:01:49.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:01:49.689+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:01:49.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:02:20.103+0000] {processor.py:157} INFO - Started process (PID=16372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:20.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:02:20.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:20.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:20.134+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:02:20.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:02:20.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:02:50.533+0000] {processor.py:157} INFO - Started process (PID=16397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:50.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:02:50.536+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:50.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:02:50.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:02:50.574+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:02:50.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:03:21.008+0000] {processor.py:157} INFO - Started process (PID=16422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:21.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:03:21.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:21.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:21.049+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:03:21.061+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.061+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:03:21.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T12:03:51.410+0000] {processor.py:157} INFO - Started process (PID=16447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:51.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:03:51.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:51.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:03:51.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:03:51.461+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:03:51.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T12:04:21.797+0000] {processor.py:157} INFO - Started process (PID=16472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:21.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:04:21.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:21.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:21.831+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:04:21.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:04:21.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:04:52.268+0000] {processor.py:157} INFO - Started process (PID=16497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:52.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:04:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:52.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:04:52.299+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:04:52.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.311+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:04:52.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:05:22.681+0000] {processor.py:157} INFO - Started process (PID=16522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:22.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:05:22.685+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:22.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:22.713+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:05:22.723+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:05:22.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:05:53.109+0000] {processor.py:157} INFO - Started process (PID=16547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:53.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:05:53.113+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:53.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:05:53.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:05:53.154+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:05:53.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:06:23.547+0000] {processor.py:157} INFO - Started process (PID=16572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:23.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:06:23.550+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:23.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:23.578+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:06:23.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.588+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:06:23.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:06:54.002+0000] {processor.py:157} INFO - Started process (PID=16597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:54.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:06:54.005+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:54.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:06:54.037+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:06:54.048+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:06:54.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:07:24.472+0000] {processor.py:157} INFO - Started process (PID=16622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:24.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:07:24.475+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:24.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:24.506+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:07:24.518+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.517+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:07:24.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:07:54.924+0000] {processor.py:157} INFO - Started process (PID=16647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:54.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:07:54.926+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:54.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:07:54.957+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:07:54.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:07:54.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:08:25.348+0000] {processor.py:157} INFO - Started process (PID=16672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:25.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:08:25.353+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:25.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:25.380+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:08:25.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.390+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:08:25.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:08:55.825+0000] {processor.py:157} INFO - Started process (PID=16697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:55.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:08:55.830+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:55.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:08:55.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:08:55.872+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:08:55.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:09:26.316+0000] {processor.py:157} INFO - Started process (PID=16722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:26.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:09:26.319+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:26.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:26.348+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:09:26.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:09:26.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:09:56.726+0000] {processor.py:157} INFO - Started process (PID=16747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:56.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:09:56.728+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:56.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:09:56.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:09:56.759+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:09:56.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-13T12:10:27.165+0000] {processor.py:157} INFO - Started process (PID=16772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:27.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:10:27.168+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:27.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:27.201+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:10:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:10:27.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:10:57.570+0000] {processor.py:157} INFO - Started process (PID=16797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:57.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:10:57.572+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:57.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:10:57.604+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:10:57.615+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:10:57.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:11:28.007+0000] {processor.py:157} INFO - Started process (PID=16822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:28.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:11:28.011+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:28.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:28.049+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:11:28.062+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:11:28.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T12:11:58.516+0000] {processor.py:157} INFO - Started process (PID=16847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:58.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:11:58.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:58.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:11:58.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:11:58.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.573+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:11:58.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T12:12:28.990+0000] {processor.py:157} INFO - Started process (PID=16872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:28.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:12:28.994+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:28.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:29.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:29.024+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:29.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:12:29.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:29.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:12:29.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:12:59.389+0000] {processor.py:157} INFO - Started process (PID=16897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:59.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:12:59.392+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:59.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:12:59.421+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:12:59.431+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:12:59.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T12:13:29.849+0000] {processor.py:157} INFO - Started process (PID=16922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:13:29.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:13:29.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:13:29.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:13:29.880+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:13:29.892+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:13:29.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:14:00.275+0000] {processor.py:157} INFO - Started process (PID=16947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:00.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:14:00.283+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:00.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:00.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:14:00.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:14:00.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:14:30.720+0000] {processor.py:157} INFO - Started process (PID=16972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:30.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:14:30.724+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:30.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:14:30.752+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:14:30.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:14:30.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T12:15:01.123+0000] {processor.py:157} INFO - Started process (PID=16997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:01.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:15:01.127+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:01.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:01.156+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:15:01.167+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:15:01.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:15:31.602+0000] {processor.py:157} INFO - Started process (PID=17022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:31.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:15:31.607+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:31.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:15:31.633+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:15:31.644+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:15:31.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:16:01.995+0000] {processor.py:157} INFO - Started process (PID=17047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:01.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:16:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:01.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:02.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:02.026+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:02.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:16:02.038+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:02.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:16:02.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:16:32.437+0000] {processor.py:157} INFO - Started process (PID=17072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:32.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:16:32.441+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:32.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:16:32.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:16:32.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:16:32.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:17:02.958+0000] {processor.py:157} INFO - Started process (PID=17097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:02.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:17:02.960+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:02.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:02.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:02.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:02.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:17:03.001+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:03.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:17:03.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:17:33.451+0000] {processor.py:157} INFO - Started process (PID=17122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:33.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:17:33.454+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:33.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:17:33.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:17:33.490+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:17:33.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T12:18:03.908+0000] {processor.py:157} INFO - Started process (PID=17147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:03.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:18:03.910+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:03.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:03.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:18:03.948+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:18:03.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T12:18:34.352+0000] {processor.py:157} INFO - Started process (PID=17172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:34.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:18:34.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:34.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:18:34.382+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:18:34.395+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.394+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:18:34.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:19:04.811+0000] {processor.py:157} INFO - Started process (PID=17197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:04.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:19:04.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:04.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:04.846+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:19:04.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:19:04.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:19:35.289+0000] {processor.py:157} INFO - Started process (PID=17222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:35.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:19:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:35.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:19:35.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:19:35.336+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:19:35.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:20:05.718+0000] {processor.py:157} INFO - Started process (PID=17247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:05.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:20:05.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:05.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:05.752+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:20:05.761+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:20:05.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:20:36.172+0000] {processor.py:157} INFO - Started process (PID=17272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:36.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:20:36.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:36.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:20:36.203+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:20:36.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:20:36.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:21:06.666+0000] {processor.py:157} INFO - Started process (PID=17297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:06.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:21:06.668+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:06.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:06.696+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:21:06.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:21:06.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:21:37.077+0000] {processor.py:157} INFO - Started process (PID=17322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:37.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:21:37.080+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:37.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:21:37.111+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:21:37.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:21:37.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:22:07.560+0000] {processor.py:157} INFO - Started process (PID=17347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:07.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:22:07.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:07.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:22:07.604+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.603+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:22:07.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:22:37.981+0000] {processor.py:157} INFO - Started process (PID=17372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:37.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:22:37.984+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:37.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:38.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:22:38.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:38.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:22:38.026+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:38.026+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:22:38.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:23:08.440+0000] {processor.py:157} INFO - Started process (PID=17397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:08.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:23:08.444+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:08.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:08.475+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:23:08.484+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:23:08.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:23:38.906+0000] {processor.py:157} INFO - Started process (PID=17422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:38.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:23:38.912+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:38.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:23:38.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:23:38.963+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.963+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:23:38.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T12:24:09.377+0000] {processor.py:157} INFO - Started process (PID=17447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:09.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:24:09.379+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:09.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:09.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:24:09.420+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.420+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:24:09.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:24:39.915+0000] {processor.py:157} INFO - Started process (PID=17472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:39.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:24:39.922+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:39.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:24:39.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:24:39.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.991+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:24:40.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-13T12:25:10.418+0000] {processor.py:157} INFO - Started process (PID=17497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:10.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:25:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:10.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:10.448+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:25:10.458+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.458+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:25:10.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:25:40.863+0000] {processor.py:157} INFO - Started process (PID=17522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:40.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:25:40.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:40.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:25:40.898+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:25:40.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:25:40.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T12:26:11.338+0000] {processor.py:157} INFO - Started process (PID=17547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:11.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:26:11.343+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:11.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:11.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:26:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.388+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:26:11.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T12:26:41.818+0000] {processor.py:157} INFO - Started process (PID=17572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:41.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:26:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:41.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:26:41.852+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:26:41.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:26:41.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:27:12.225+0000] {processor.py:157} INFO - Started process (PID=17597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:12.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:27:12.228+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:12.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:12.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:27:12.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:27:12.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:27:42.678+0000] {processor.py:157} INFO - Started process (PID=17622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:42.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:27:42.681+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:42.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:27:42.715+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:27:42.728+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:27:42.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T12:28:13.112+0000] {processor.py:157} INFO - Started process (PID=17647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:13.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:28:13.114+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:13.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:13.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:28:13.157+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:28:13.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:28:43.550+0000] {processor.py:157} INFO - Started process (PID=17672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:43.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:28:43.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:43.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:28:43.584+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:28:43.592+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:28:43.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:29:13.925+0000] {processor.py:157} INFO - Started process (PID=17697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:13.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:29:13.928+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:13.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:13.957+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:29:13.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:29:13.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:29:44.316+0000] {processor.py:157} INFO - Started process (PID=17722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:44.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:29:44.319+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:44.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:29:44.346+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:29:44.355+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:29:44.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T12:30:14.700+0000] {processor.py:157} INFO - Started process (PID=17747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:14.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:30:14.703+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:14.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:30:14.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:30:14.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:30:45.117+0000] {processor.py:157} INFO - Started process (PID=17772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:45.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:30:45.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:45.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:30:45.154+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:30:45.165+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:30:45.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T12:31:15.570+0000] {processor.py:157} INFO - Started process (PID=17797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:15.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:31:15.574+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:15.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:15.613+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:31:15.623+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:31:15.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T12:31:46.039+0000] {processor.py:157} INFO - Started process (PID=17822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:46.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:31:46.042+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:46.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:31:46.072+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:31:46.085+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:31:46.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:32:16.492+0000] {processor.py:157} INFO - Started process (PID=17847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:16.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:32:16.495+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:16.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:16.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:32:16.534+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:32:16.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:32:46.934+0000] {processor.py:157} INFO - Started process (PID=17872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:46.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:32:46.937+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:46.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:32:46.967+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:32:46.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:32:46.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:33:17.388+0000] {processor.py:157} INFO - Started process (PID=17897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:17.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:33:17.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:17.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:17.420+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:33:17.431+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:33:17.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:33:47.790+0000] {processor.py:157} INFO - Started process (PID=17922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:47.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:33:47.794+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:47.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:33:47.829+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:33:47.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.841+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:33:47.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T12:34:18.275+0000] {processor.py:157} INFO - Started process (PID=17947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:18.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:34:18.279+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:18.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:18.309+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:34:18.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:34:18.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T12:34:48.720+0000] {processor.py:157} INFO - Started process (PID=17972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:48.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:34:48.722+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:48.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:34:48.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:34:48.760+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:34:48.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T12:35:19.146+0000] {processor.py:157} INFO - Started process (PID=17997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:19.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:35:19.148+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:19.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:19.174+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:35:19.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:35:19.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:35:49.611+0000] {processor.py:157} INFO - Started process (PID=18022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:49.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:35:49.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:49.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:35:49.644+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:35:49.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:35:49.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:36:20.063+0000] {processor.py:157} INFO - Started process (PID=18047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:20.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:36:20.065+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:20.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:20.091+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:36:20.101+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.101+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:36:20.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T12:36:50.518+0000] {processor.py:157} INFO - Started process (PID=18072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:50.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:36:50.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:50.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:36:50.550+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:36:50.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:36:50.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:37:20.892+0000] {processor.py:157} INFO - Started process (PID=18097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:20.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:37:20.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:20.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:20.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:37:20.933+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:37:20.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T12:37:51.333+0000] {processor.py:157} INFO - Started process (PID=18122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:51.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:37:51.337+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:51.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:37:51.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:37:51.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:37:51.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:38:21.790+0000] {processor.py:157} INFO - Started process (PID=18147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:21.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:38:21.795+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:21.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:21.831+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:38:21.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.845+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:38:21.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T12:38:52.321+0000] {processor.py:157} INFO - Started process (PID=18172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:52.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:38:52.330+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:52.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:38:52.392+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:38:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.406+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:38:52.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-13T12:39:22.833+0000] {processor.py:157} INFO - Started process (PID=18197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:22.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:39:22.837+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:22.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:22.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:39:22.881+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:39:22.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T12:39:53.279+0000] {processor.py:157} INFO - Started process (PID=18222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:53.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:39:53.283+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:53.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:39:53.330+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:39:53.356+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:39:53.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-13T12:40:23.801+0000] {processor.py:157} INFO - Started process (PID=18247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:23.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:40:23.808+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:23.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:23.850+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:40:23.863+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:40:23.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T12:40:54.328+0000] {processor.py:157} INFO - Started process (PID=18272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:54.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:40:54.332+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:54.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:40:54.372+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:40:54.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:40:54.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T12:41:24.804+0000] {processor.py:157} INFO - Started process (PID=18297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:24.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:41:24.809+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:24.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:24.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:41:24.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:41:24.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-13T12:41:55.269+0000] {processor.py:157} INFO - Started process (PID=18322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:55.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:41:55.273+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:55.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:41:55.302+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:41:55.312+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:41:55.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:42:25.647+0000] {processor.py:157} INFO - Started process (PID=18347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:25.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:42:25.651+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:25.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:25.682+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:42:25.692+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:42:25.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:42:56.013+0000] {processor.py:157} INFO - Started process (PID=18372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:56.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:42:56.015+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:56.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:42:56.044+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:42:56.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:42:56.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T12:43:26.482+0000] {processor.py:157} INFO - Started process (PID=18397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:26.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:43:26.486+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:26.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:26.514+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:43:26.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.523+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:43:26.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:43:56.937+0000] {processor.py:157} INFO - Started process (PID=18422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:56.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:43:56.940+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:56.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:43:56.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:43:56.980+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.980+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:43:56.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:44:27.412+0000] {processor.py:157} INFO - Started process (PID=18447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:27.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:44:27.415+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:27.441+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:44:27.451+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:44:27.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T12:44:57.855+0000] {processor.py:157} INFO - Started process (PID=18472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:57.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:44:57.859+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:57.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:44:57.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:44:57.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.896+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:44:57.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T12:45:28.314+0000] {processor.py:157} INFO - Started process (PID=18497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:28.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:45:28.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:28.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:28.349+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:45:28.359+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:45:28.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:45:58.772+0000] {processor.py:157} INFO - Started process (PID=18522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:58.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:45:58.775+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:58.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:45:58.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:45:58.815+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:45:58.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:46:29.201+0000] {processor.py:157} INFO - Started process (PID=18547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:29.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:46:29.203+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:29.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:29.231+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:46:29.242+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.242+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:46:29.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T12:46:59.614+0000] {processor.py:157} INFO - Started process (PID=18572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:59.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:46:59.617+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:59.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:46:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:46:59.658+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.658+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:46:59.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:47:30.026+0000] {processor.py:157} INFO - Started process (PID=18597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:47:30.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:47:30.028+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:47:30.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:47:30.063+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:47:30.073+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:47:30.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T12:48:00.464+0000] {processor.py:157} INFO - Started process (PID=18622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:00.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:48:00.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:00.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:00.503+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:48:00.512+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:48:00.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:48:30.877+0000] {processor.py:157} INFO - Started process (PID=18647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:30.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:48:30.881+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:30.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:48:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:48:30.926+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:48:30.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T12:49:01.294+0000] {processor.py:157} INFO - Started process (PID=18672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:01.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:49:01.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:01.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:01.336+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:49:01.348+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:49:01.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T12:49:31.790+0000] {processor.py:157} INFO - Started process (PID=18697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:31.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:49:31.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:31.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:49:31.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:49:31.831+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:49:31.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T12:50:02.225+0000] {processor.py:157} INFO - Started process (PID=18722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:02.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:50:02.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:02.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:02.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:50:02.274+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.274+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:50:02.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T12:50:32.666+0000] {processor.py:157} INFO - Started process (PID=18747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:32.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:50:32.669+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:32.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:50:32.698+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:50:32.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:50:32.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:51:03.091+0000] {processor.py:157} INFO - Started process (PID=18772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:03.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:51:03.093+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:03.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:03.120+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:51:03.129+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:51:03.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T12:51:33.523+0000] {processor.py:157} INFO - Started process (PID=18797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:33.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:51:33.531+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:33.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:51:33.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:51:33.562+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:51:33.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T12:52:04.011+0000] {processor.py:157} INFO - Started process (PID=18822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:04.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:52:04.014+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:04.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:04.042+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:52:04.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:52:04.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:52:34.403+0000] {processor.py:157} INFO - Started process (PID=18847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:34.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:52:34.407+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:34.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:52:34.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:52:34.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:52:34.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T12:53:04.822+0000] {processor.py:157} INFO - Started process (PID=18872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:04.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:53:04.825+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:04.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:04.854+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:53:04.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:53:04.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:53:35.282+0000] {processor.py:157} INFO - Started process (PID=18897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:35.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:53:35.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:35.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:53:35.315+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:53:35.326+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.326+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:53:35.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:54:05.709+0000] {processor.py:157} INFO - Started process (PID=18922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:05.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:54:05.712+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:05.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:05.740+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:54:05.752+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:54:05.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T12:54:36.147+0000] {processor.py:157} INFO - Started process (PID=18947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:36.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:54:36.150+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:36.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:54:36.182+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:54:36.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:54:36.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:55:06.562+0000] {processor.py:157} INFO - Started process (PID=18972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:06.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:55:06.564+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:06.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:06.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:55:06.604+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.604+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:55:06.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:55:36.982+0000] {processor.py:157} INFO - Started process (PID=18997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:36.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:55:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:36.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:36.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:55:37.011+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:37.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:55:37.024+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:37.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:55:37.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:56:07.438+0000] {processor.py:157} INFO - Started process (PID=19022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:07.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:56:07.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:07.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:07.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:56:07.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:56:07.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T12:56:37.829+0000] {processor.py:157} INFO - Started process (PID=19047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:37.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:56:37.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:37.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:56:37.867+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:56:37.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:56:37.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T12:57:08.310+0000] {processor.py:157} INFO - Started process (PID=19072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:08.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:57:08.313+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:08.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:08.341+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:57:08.350+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:57:08.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T12:57:38.747+0000] {processor.py:157} INFO - Started process (PID=19097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:38.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:57:38.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:38.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:57:38.774+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:57:38.786+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.786+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:57:38.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T12:58:09.182+0000] {processor.py:157} INFO - Started process (PID=19122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:09.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:58:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:09.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:09.213+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:58:09.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:58:09.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T12:58:39.610+0000] {processor.py:157} INFO - Started process (PID=19147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:39.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:58:39.618+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:39.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:58:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:58:39.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:58:39.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T12:59:10.101+0000] {processor.py:157} INFO - Started process (PID=19172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:10.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:59:10.104+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:10.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:10.131+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:59:10.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:59:10.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T12:59:40.579+0000] {processor.py:157} INFO - Started process (PID=19197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:40.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T12:59:40.582+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:40.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T12:59:40.610+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:59:40.620+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T12:59:40.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:00:10.955+0000] {processor.py:157} INFO - Started process (PID=19222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:10.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:00:10.959+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:10.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:10.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:10.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:10.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:00:11.003+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:11.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:00:11.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T13:00:41.382+0000] {processor.py:157} INFO - Started process (PID=19247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:41.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:00:41.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:41.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:00:41.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:00:41.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:00:41.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T13:01:11.831+0000] {processor.py:157} INFO - Started process (PID=19272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:11.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:01:11.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:11.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:11.872+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:01:11.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:01:11.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T13:01:42.298+0000] {processor.py:157} INFO - Started process (PID=19297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:42.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:01:42.302+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:42.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:01:42.339+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:01:42.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:01:42.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T13:02:12.786+0000] {processor.py:157} INFO - Started process (PID=19322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:12.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:02:12.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:12.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:12.821+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:02:12.834+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:02:12.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:02:43.242+0000] {processor.py:157} INFO - Started process (PID=19347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:43.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:02:43.247+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:43.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:02:43.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:02:43.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:02:43.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-13T13:03:13.646+0000] {processor.py:157} INFO - Started process (PID=19372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:13.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:03:13.650+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:13.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:13.678+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:03:13.688+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:03:13.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:03:44.068+0000] {processor.py:157} INFO - Started process (PID=19397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:44.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:03:44.070+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:44.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:03:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:03:44.107+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:03:44.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T13:04:14.464+0000] {processor.py:157} INFO - Started process (PID=19422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:14.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:04:14.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:14.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:14.494+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:04:14.505+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:04:14.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:04:44.885+0000] {processor.py:157} INFO - Started process (PID=19447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:44.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:04:44.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:44.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:04:44.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:04:44.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.924+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:04:44.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-13T13:05:15.344+0000] {processor.py:157} INFO - Started process (PID=19472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:15.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:05:15.347+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:15.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:15.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:05:15.386+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:05:15.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:05:45.812+0000] {processor.py:157} INFO - Started process (PID=19497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:45.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:05:45.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:45.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:05:45.859+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:05:45.872+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:05:45.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T13:06:16.304+0000] {processor.py:157} INFO - Started process (PID=19522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:16.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:06:16.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:16.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:16.337+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:06:16.346+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:06:16.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:06:46.759+0000] {processor.py:157} INFO - Started process (PID=19547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:46.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:06:46.763+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:46.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:06:46.794+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:06:46.805+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:06:46.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:07:17.168+0000] {processor.py:157} INFO - Started process (PID=19572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:17.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:07:17.177+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:17.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:17.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:07:17.211+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.211+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:07:17.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:07:47.568+0000] {processor.py:157} INFO - Started process (PID=19597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:47.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:07:47.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:47.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:07:47.602+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:07:47.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:07:47.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:08:17.991+0000] {processor.py:157} INFO - Started process (PID=19622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:17.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:08:17.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:17.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:18.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:18.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:08:18.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:18.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:08:18.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-13T13:08:48.404+0000] {processor.py:157} INFO - Started process (PID=19647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:48.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:08:48.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:48.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:08:48.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:08:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:08:48.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:09:18.862+0000] {processor.py:157} INFO - Started process (PID=19672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:18.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:09:18.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:18.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:18.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:09:18.904+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:09:18.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:09:49.336+0000] {processor.py:157} INFO - Started process (PID=19697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:49.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:09:49.341+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:49.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:09:49.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:09:49.400+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:09:49.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-13T13:10:19.845+0000] {processor.py:157} INFO - Started process (PID=19722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:19.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:10:19.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:19.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:19.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:10:19.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:10:19.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:10:50.286+0000] {processor.py:157} INFO - Started process (PID=19747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:50.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:10:50.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:50.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:10:50.319+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:10:50.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.331+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:10:50.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T13:11:20.701+0000] {processor.py:157} INFO - Started process (PID=19772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:20.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:11:20.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:20.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:20.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:11:20.743+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:11:20.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:11:51.225+0000] {processor.py:157} INFO - Started process (PID=19797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:51.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:11:51.233+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:51.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:11:51.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:11:51.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:11:51.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-13T13:12:21.755+0000] {processor.py:157} INFO - Started process (PID=19822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:21.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:12:21.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:21.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:21.791+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:12:21.806+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:12:21.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-13T13:12:52.270+0000] {processor.py:157} INFO - Started process (PID=19847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:52.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:12:52.278+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:52.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:12:52.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:12:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:12:52.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-13T13:13:22.809+0000] {processor.py:157} INFO - Started process (PID=19872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:22.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:13:22.813+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:22.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:22.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:13:22.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:13:22.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T13:13:53.378+0000] {processor.py:157} INFO - Started process (PID=19896) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:53.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:13:53.387+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:53.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:13:53.459+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:13:53.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:13:53.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-13T13:14:23.944+0000] {processor.py:157} INFO - Started process (PID=19921) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:23.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:14:23.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:23.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:24.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:24.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:24.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:14:24.082+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:24.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:14:24.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.160 seconds
[2024-07-13T13:14:54.566+0000] {processor.py:157} INFO - Started process (PID=19947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:54.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:14:54.569+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:54.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:14:54.599+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:14:54.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:14:54.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T13:15:25.017+0000] {processor.py:157} INFO - Started process (PID=19972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:25.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:15:25.020+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:25.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:25.048+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:15:25.058+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:15:25.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T13:15:55.468+0000] {processor.py:157} INFO - Started process (PID=19997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:55.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:15:55.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:55.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:15:55.512+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:15:55.526+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:15:55.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T13:16:25.963+0000] {processor.py:157} INFO - Started process (PID=20022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:25.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:16:25.967+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:25.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:25.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:25.997+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:25.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:16:26.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:26.010+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:16:26.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T13:16:56.401+0000] {processor.py:157} INFO - Started process (PID=20047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:56.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:16:56.404+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:56.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:16:56.432+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:16:56.442+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:16:56.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:17:26.800+0000] {processor.py:157} INFO - Started process (PID=20072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:26.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:17:26.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:26.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:26.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:17:26.842+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.842+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:17:26.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:17:57.209+0000] {processor.py:157} INFO - Started process (PID=20097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:57.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:17:57.212+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:57.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:17:57.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:17:57.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.247+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:17:57.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T13:18:27.552+0000] {processor.py:157} INFO - Started process (PID=20122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:27.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:18:27.555+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:27.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:27.584+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:18:27.594+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.594+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:18:27.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T13:18:57.993+0000] {processor.py:157} INFO - Started process (PID=20147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:57.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:18:57.997+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:57.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:58.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:18:58.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:58.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:18:58.038+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:58.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:18:58.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:19:28.435+0000] {processor.py:157} INFO - Started process (PID=20172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:28.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:19:28.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:28.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:28.468+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:19:28.479+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.479+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:19:28.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:19:58.858+0000] {processor.py:157} INFO - Started process (PID=20197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:58.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:19:58.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:58.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:19:58.890+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:19:58.902+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:19:58.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:20:29.327+0000] {processor.py:157} INFO - Started process (PID=20222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:29.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:20:29.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:29.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:29.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:20:29.368+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:20:29.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T13:20:59.717+0000] {processor.py:157} INFO - Started process (PID=20247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:59.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:20:59.722+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:59.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:20:59.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:20:59.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:20:59.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:21:30.215+0000] {processor.py:157} INFO - Started process (PID=20272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:21:30.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:21:30.220+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:21:30.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:21:30.252+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:21:30.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:21:30.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:22:00.695+0000] {processor.py:157} INFO - Started process (PID=20297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:00.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:22:00.698+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:00.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:00.726+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:22:00.738+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:22:00.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:22:31.097+0000] {processor.py:157} INFO - Started process (PID=20322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:31.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:22:31.099+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:31.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:22:31.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:22:31.140+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.140+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:22:31.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:23:01.614+0000] {processor.py:157} INFO - Started process (PID=20347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:01.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:23:01.616+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:01.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:01.647+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:23:01.660+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.660+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:23:01.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T13:23:32.029+0000] {processor.py:157} INFO - Started process (PID=20372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:32.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:23:32.034+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:32.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:23:32.071+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:23:32.084+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:23:32.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T13:24:02.491+0000] {processor.py:157} INFO - Started process (PID=20397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:02.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:24:02.494+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:02.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:02.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:24:02.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:24:02.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:24:32.873+0000] {processor.py:157} INFO - Started process (PID=20422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:32.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:24:32.876+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:32.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:24:32.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:24:32.916+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:24:32.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:25:03.351+0000] {processor.py:157} INFO - Started process (PID=20447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:03.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:25:03.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:03.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:03.383+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:25:03.394+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.394+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:25:03.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:25:33.801+0000] {processor.py:157} INFO - Started process (PID=20472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:33.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:25:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:33.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:25:33.828+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:25:33.838+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:25:33.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T13:26:04.212+0000] {processor.py:157} INFO - Started process (PID=20497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:04.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:26:04.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:04.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:04.245+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:26:04.254+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:26:04.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:26:34.712+0000] {processor.py:157} INFO - Started process (PID=20522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:34.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:26:34.715+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:34.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:26:34.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:26:34.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.758+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:26:34.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:27:05.128+0000] {processor.py:157} INFO - Started process (PID=20547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:05.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:27:05.131+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:05.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:05.164+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:27:05.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:27:05.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T13:27:35.644+0000] {processor.py:157} INFO - Started process (PID=20572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:35.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:27:35.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:35.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:27:35.678+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:27:35.688+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:27:35.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:28:06.087+0000] {processor.py:157} INFO - Started process (PID=20597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:06.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:28:06.089+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:06.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:06.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:28:06.132+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:28:06.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:28:36.524+0000] {processor.py:157} INFO - Started process (PID=20622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:36.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:28:36.529+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:36.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:28:36.557+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:28:36.567+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:28:36.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:29:06.949+0000] {processor.py:157} INFO - Started process (PID=20647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:06.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:29:06.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:06.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:06.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:29:06.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.985+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:29:06.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-13T13:29:37.440+0000] {processor.py:157} INFO - Started process (PID=20672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:37.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:29:37.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:37.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:29:37.474+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:29:37.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:29:37.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:30:07.836+0000] {processor.py:157} INFO - Started process (PID=20697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:07.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:30:07.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:07.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:07.868+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:30:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:30:07.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:30:38.276+0000] {processor.py:157} INFO - Started process (PID=20722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:38.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:30:38.281+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:38.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:30:38.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:30:38.321+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:30:38.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:31:08.759+0000] {processor.py:157} INFO - Started process (PID=20747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:08.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:31:08.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:08.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:08.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:31:08.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:31:08.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T13:31:39.280+0000] {processor.py:157} INFO - Started process (PID=20772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:39.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:31:39.289+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:39.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:31:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:31:39.360+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:31:39.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-13T13:32:09.715+0000] {processor.py:157} INFO - Started process (PID=20797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:09.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:32:09.717+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:09.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:09.745+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:32:09.755+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:32:09.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T13:32:40.168+0000] {processor.py:157} INFO - Started process (PID=20822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:40.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:32:40.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:40.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:32:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:32:40.232+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:32:40.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-13T13:33:10.666+0000] {processor.py:157} INFO - Started process (PID=20847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:10.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:33:10.667+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:10.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:10.696+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:33:10.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:33:10.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:33:41.069+0000] {processor.py:157} INFO - Started process (PID=20872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:41.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:33:41.072+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:41.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:33:41.111+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:33:41.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:33:41.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T13:34:11.568+0000] {processor.py:157} INFO - Started process (PID=20897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:11.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:34:11.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:11.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:11.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:34:11.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:34:11.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:34:41.975+0000] {processor.py:157} INFO - Started process (PID=20922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:41.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:34:41.979+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:41.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:41.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:34:42.006+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:42.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:34:42.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:42.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:34:42.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:35:12.360+0000] {processor.py:157} INFO - Started process (PID=20947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:12.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:35:12.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:12.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:12.393+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:35:12.407+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:35:12.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T13:35:42.778+0000] {processor.py:157} INFO - Started process (PID=20972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:42.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:35:42.787+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:42.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:35:42.808+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:35:42.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:35:42.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:36:13.167+0000] {processor.py:157} INFO - Started process (PID=20997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:13.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:36:13.170+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:13.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:13.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:36:13.219+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:36:13.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T13:36:43.677+0000] {processor.py:157} INFO - Started process (PID=21022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:43.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:36:43.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:43.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:36:43.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:36:43.720+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:36:43.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:37:14.097+0000] {processor.py:157} INFO - Started process (PID=21047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:14.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:37:14.099+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:14.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:14.131+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:37:14.142+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:37:14.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:37:44.518+0000] {processor.py:157} INFO - Started process (PID=21072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:44.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:37:44.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:44.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:37:44.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:37:44.564+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:37:44.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:38:14.972+0000] {processor.py:157} INFO - Started process (PID=21097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:14.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:38:14.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:14.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:14.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:15.006+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:15.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:38:15.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:15.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:38:15.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:38:45.392+0000] {processor.py:157} INFO - Started process (PID=21122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:45.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:38:45.397+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:45.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:38:45.435+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:38:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.447+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:38:45.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T13:39:15.840+0000] {processor.py:157} INFO - Started process (PID=21147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:15.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:39:15.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:15.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:15.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:39:15.881+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.881+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:39:15.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:39:46.308+0000] {processor.py:157} INFO - Started process (PID=21172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:46.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:39:46.310+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:46.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:39:46.339+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:39:46.349+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:39:46.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:40:16.756+0000] {processor.py:157} INFO - Started process (PID=21197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:16.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:40:16.759+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:16.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:16.788+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:40:16.799+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:40:16.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:40:47.207+0000] {processor.py:157} INFO - Started process (PID=21222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:47.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:40:47.209+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:47.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:40:47.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:40:47.250+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:40:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:41:17.665+0000] {processor.py:157} INFO - Started process (PID=21247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:17.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:41:17.669+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:17.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:17.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:41:17.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.705+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:41:17.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:41:48.133+0000] {processor.py:157} INFO - Started process (PID=21272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:48.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:41:48.136+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:48.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:41:48.163+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:41:48.174+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.174+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:41:48.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:42:18.535+0000] {processor.py:157} INFO - Started process (PID=21297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:18.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:42:18.540+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:18.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:18.570+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:42:18.580+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.580+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:42:18.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:42:48.960+0000] {processor.py:157} INFO - Started process (PID=21322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:48.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:42:48.963+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:48.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:48.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:42:49.000+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:49.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:42:49.011+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:49.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:42:49.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T13:43:19.437+0000] {processor.py:157} INFO - Started process (PID=21347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:19.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:43:19.439+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:19.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:19.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:43:19.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:43:19.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:43:49.854+0000] {processor.py:157} INFO - Started process (PID=21372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:49.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:43:49.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:49.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:43:49.886+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:43:49.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:43:49.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:44:20.322+0000] {processor.py:157} INFO - Started process (PID=21397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:20.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:44:20.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:20.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:20.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:44:20.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:44:20.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T13:44:50.807+0000] {processor.py:157} INFO - Started process (PID=21422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:50.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:44:50.809+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:50.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:44:50.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:44:50.860+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.860+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:44:50.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-13T13:45:21.307+0000] {processor.py:157} INFO - Started process (PID=21447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:21.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:45:21.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:21.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:21.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:45:21.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:45:21.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T13:45:51.720+0000] {processor.py:157} INFO - Started process (PID=21472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:51.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:45:51.723+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:51.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:45:51.751+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:45:51.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:45:51.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:46:22.190+0000] {processor.py:157} INFO - Started process (PID=21497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:22.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:46:22.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:22.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:22.217+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:46:22.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:46:22.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-13T13:46:52.604+0000] {processor.py:157} INFO - Started process (PID=21522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:52.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:46:52.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:52.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:46:52.636+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:46:52.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:46:52.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:47:23.064+0000] {processor.py:157} INFO - Started process (PID=21547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:23.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:47:23.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:23.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:23.098+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:47:23.110+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:47:23.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:47:53.544+0000] {processor.py:157} INFO - Started process (PID=21572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:53.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:47:53.547+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:53.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:47:53.577+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:47:53.586+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:47:53.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:48:23.972+0000] {processor.py:157} INFO - Started process (PID=21597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:23.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:48:23.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:23.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:23.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:24.002+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:24.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:48:24.015+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:24.015+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:48:24.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:48:54.362+0000] {processor.py:157} INFO - Started process (PID=21622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:54.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:48:54.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:54.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:48:54.391+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:48:54.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.403+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:48:54.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T13:49:24.765+0000] {processor.py:157} INFO - Started process (PID=21647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:24.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:49:24.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:24.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:24.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:49:24.815+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:49:24.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T13:49:55.239+0000] {processor.py:157} INFO - Started process (PID=21672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:55.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:49:55.242+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:55.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:49:55.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:49:55.281+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:49:55.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:50:25.648+0000] {processor.py:157} INFO - Started process (PID=21697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:25.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:50:25.649+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:25.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:25.674+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:50:25.686+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:50:25.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-13T13:50:56.091+0000] {processor.py:157} INFO - Started process (PID=21722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:56.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:50:56.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:56.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:50:56.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:50:56.133+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.133+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:50:56.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:51:26.534+0000] {processor.py:157} INFO - Started process (PID=21747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:26.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:51:26.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:26.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:26.570+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:51:26.581+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.581+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:51:26.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T13:51:56.974+0000] {processor.py:157} INFO - Started process (PID=21772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:56.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:51:56.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:56.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:56.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:51:57.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:57.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:51:57.020+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:57.020+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:51:57.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T13:52:27.380+0000] {processor.py:157} INFO - Started process (PID=21797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:27.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:52:27.383+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:27.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:27.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:52:27.424+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:52:27.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:52:57.801+0000] {processor.py:157} INFO - Started process (PID=21822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:57.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:52:57.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:57.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:52:57.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:52:57.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:52:57.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-13T13:53:28.213+0000] {processor.py:157} INFO - Started process (PID=21847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:28.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:53:28.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:28.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:28.256+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:53:28.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:53:28.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T13:53:58.689+0000] {processor.py:157} INFO - Started process (PID=21872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:58.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:53:58.692+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:58.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:53:58.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:53:58.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:53:58.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:54:28.977+0000] {processor.py:157} INFO - Started process (PID=21897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:28.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:54:28.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:28.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:28.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:29.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:54:29.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:54:29.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:54:59.407+0000] {processor.py:157} INFO - Started process (PID=21922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:59.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:54:59.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:59.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:54:59.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:54:59.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.448+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:54:59.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T13:55:29.829+0000] {processor.py:157} INFO - Started process (PID=21947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:55:29.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:55:29.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:55:29.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:55:29.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:55:29.874+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:55:29.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T13:56:00.284+0000] {processor.py:157} INFO - Started process (PID=21972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:00.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:56:00.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:00.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:00.315+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:56:00.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:56:00.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T13:56:30.735+0000] {processor.py:157} INFO - Started process (PID=21997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:30.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:56:30.739+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:30.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:56:30.768+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:56:30.781+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:56:30.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:57:01.161+0000] {processor.py:157} INFO - Started process (PID=22022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:01.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:57:01.163+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:01.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:01.195+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:57:01.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:57:01.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T13:57:31.575+0000] {processor.py:157} INFO - Started process (PID=22047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:31.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:57:31.578+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:31.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:57:31.607+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:57:31.619+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.619+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:57:31.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:58:02.025+0000] {processor.py:157} INFO - Started process (PID=22072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:02.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:58:02.028+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:02.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:02.057+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:58:02.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.067+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:58:02.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:58:32.436+0000] {processor.py:157} INFO - Started process (PID=22097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:32.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:58:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:32.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:58:32.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:58:32.476+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:58:32.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T13:59:02.886+0000] {processor.py:157} INFO - Started process (PID=22122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:02.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:59:02.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:02.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:02.917+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:59:02.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:59:02.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T13:59:33.336+0000] {processor.py:157} INFO - Started process (PID=22147) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:33.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T13:59:33.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:33.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T13:59:33.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:59:33.377+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T13:59:33.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:00:03.744+0000] {processor.py:157} INFO - Started process (PID=22172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:03.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:00:03.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:03.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:03.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:00:03.784+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.784+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:00:03.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T14:00:34.130+0000] {processor.py:157} INFO - Started process (PID=22197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:34.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:00:34.137+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:34.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:00:34.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:00:34.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.204+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:00:34.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-13T14:01:04.673+0000] {processor.py:157} INFO - Started process (PID=22222) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:04.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:01:04.676+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:04.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:04.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:01:04.720+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:01:04.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T14:01:35.141+0000] {processor.py:157} INFO - Started process (PID=22247) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:35.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:01:35.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:35.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:01:35.185+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:01:35.197+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:01:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T14:02:05.569+0000] {processor.py:157} INFO - Started process (PID=22272) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:05.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:02:05.572+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:05.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:05.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:02:05.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.612+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:02:05.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T14:02:35.943+0000] {processor.py:157} INFO - Started process (PID=22297) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:35.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:02:35.948+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:35.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:02:35.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:02:35.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:02:35.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T14:03:06.353+0000] {processor.py:157} INFO - Started process (PID=22322) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:06.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:03:06.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:06.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:06.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:03:06.396+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:03:06.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T14:03:36.837+0000] {processor.py:157} INFO - Started process (PID=22347) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:36.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:03:36.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:36.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:03:36.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:03:36.880+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.880+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:03:36.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T14:04:07.220+0000] {processor.py:157} INFO - Started process (PID=22372) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:07.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:04:07.225+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:07.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:07.255+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:04:07.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.266+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:04:07.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T14:04:37.706+0000] {processor.py:157} INFO - Started process (PID=22397) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:37.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:04:37.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:37.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:04:37.740+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:04:37.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.750+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:04:37.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:05:08.079+0000] {processor.py:157} INFO - Started process (PID=22422) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:08.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:05:08.081+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:08.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:08.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:05:08.116+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:05:08.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-13T14:05:38.491+0000] {processor.py:157} INFO - Started process (PID=22447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:38.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:05:38.494+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:38.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:05:38.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:05:38.535+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.535+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:05:38.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:06:08.973+0000] {processor.py:157} INFO - Started process (PID=22472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:08.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:06:08.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:08.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:08.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:09.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:09.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:06:09.031+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:09.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:06:09.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T14:06:39.428+0000] {processor.py:157} INFO - Started process (PID=22497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:39.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:06:39.431+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:39.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:06:39.457+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:06:39.467+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.467+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:06:39.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-13T14:07:09.891+0000] {processor.py:157} INFO - Started process (PID=22522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:09.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:07:09.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:09.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:09.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:07:09.936+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:07:09.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T14:07:40.276+0000] {processor.py:157} INFO - Started process (PID=22547) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:40.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:07:40.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:40.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:07:40.309+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:07:40.320+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:07:40.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-13T14:08:10.707+0000] {processor.py:157} INFO - Started process (PID=22572) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:10.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:08:10.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:10.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:10.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:08:10.748+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:08:10.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-13T14:08:41.133+0000] {processor.py:157} INFO - Started process (PID=22597) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:41.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:08:41.136+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:41.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:08:41.165+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:08:41.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:08:41.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:09:11.501+0000] {processor.py:157} INFO - Started process (PID=22622) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:11.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:09:11.505+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:11.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:11.532+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:09:11.542+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.542+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:09:11.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-13T14:09:41.968+0000] {processor.py:157} INFO - Started process (PID=22647) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:41.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:09:41.970+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:41.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:41.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:09:42.003+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:42.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:09:42.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:42.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:09:42.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:10:12.424+0000] {processor.py:157} INFO - Started process (PID=22672) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:12.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:10:12.427+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:12.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:12.457+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:10:12.469+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:10:12.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T14:10:42.896+0000] {processor.py:157} INFO - Started process (PID=22697) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:42.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:10:42.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:42.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:10:42.932+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:10:42.943+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.943+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:10:42.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T14:11:13.362+0000] {processor.py:157} INFO - Started process (PID=22722) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:13.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:11:13.369+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:13.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:13.405+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:11:13.417+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:11:13.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-13T14:11:43.866+0000] {processor.py:157} INFO - Started process (PID=22747) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:43.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:11:43.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:43.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:11:43.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:11:43.908+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:11:43.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:12:14.358+0000] {processor.py:157} INFO - Started process (PID=22772) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:14.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:12:14.359+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:14.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:14.387+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:12:14.396+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.396+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:12:14.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-13T14:12:44.803+0000] {processor.py:157} INFO - Started process (PID=22797) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:44.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:12:44.806+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:44.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:12:44.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:12:44.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.848+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:12:44.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T14:13:15.259+0000] {processor.py:157} INFO - Started process (PID=22822) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:15.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:13:15.262+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:15.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:15.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:13:15.305+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:13:15.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T14:13:45.668+0000] {processor.py:157} INFO - Started process (PID=22847) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:45.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:13:45.672+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:45.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:13:45.703+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:13:45.714+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:13:45.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T14:14:16.083+0000] {processor.py:157} INFO - Started process (PID=22872) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:16.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:14:16.085+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:16.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:16.111+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:14:16.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.123+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:14:16.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:14:46.476+0000] {processor.py:157} INFO - Started process (PID=22897) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:46.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:14:46.479+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:46.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:14:46.506+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:14:46.518+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.518+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:14:46.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:15:16.957+0000] {processor.py:157} INFO - Started process (PID=22922) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:16.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:15:16.959+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:16.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:16.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:16.986+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:16.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:15:16.997+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:16.997+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:15:17.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:15:47.449+0000] {processor.py:157} INFO - Started process (PID=22947) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:47.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:15:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:47.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:15:47.499+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:15:47.513+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.513+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:15:47.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-13T14:16:17.941+0000] {processor.py:157} INFO - Started process (PID=22972) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:17.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:16:17.945+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:17.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:17.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:16:17.989+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:16:17.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T14:16:48.379+0000] {processor.py:157} INFO - Started process (PID=22997) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:48.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:16:48.382+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:48.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:16:48.409+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:16:48.424+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.424+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:16:48.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T14:17:18.790+0000] {processor.py:157} INFO - Started process (PID=23022) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:18.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:17:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:18.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:18.823+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:17:18.834+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:17:18.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T14:17:49.311+0000] {processor.py:157} INFO - Started process (PID=23047) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:49.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:17:49.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:49.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:17:49.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:17:49.369+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:17:49.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T14:18:19.725+0000] {processor.py:157} INFO - Started process (PID=23072) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:19.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:18:19.728+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:19.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:19.758+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:18:19.768+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.768+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:18:19.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-13T14:18:50.209+0000] {processor.py:157} INFO - Started process (PID=23097) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:50.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:18:50.215+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:50.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:18:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:18:50.259+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:18:50.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T14:19:20.669+0000] {processor.py:157} INFO - Started process (PID=23122) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:20.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:19:20.671+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:20.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:20.699+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:19:20.713+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:19:20.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:19:51.175+0000] {processor.py:157} INFO - Started process (PID=23146) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:51.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:19:51.180+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:51.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:19:51.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:19:51.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:19:51.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-13T14:20:21.686+0000] {processor.py:157} INFO - Started process (PID=23172) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:21.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:20:21.696+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:21.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:21.718+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:20:21.731+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:20:21.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T14:20:53.527+0000] {processor.py:157} INFO - Started process (PID=23197) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:53.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:20:53.528+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:53.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:20:53.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:20:53.562+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:20:53.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-13T14:41:58.345+0000] {processor.py:157} INFO - Started process (PID=23226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:41:58.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:41:58.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:41:58.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:41:58.409+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:41:58.425+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:41:58.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-13T14:42:28.871+0000] {processor.py:157} INFO - Started process (PID=23251) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:42:28.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T14:42:28.876+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:42:28.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T14:42:28.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:42:28.937+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T14:42:28.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-13T15:49:25.435+0000] {processor.py:157} INFO - Started process (PID=23278) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T15:49:25.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T15:49:25.440+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T15:49:25.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T15:49:25.509+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T15:49:25.534+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T15:49:25.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-13T16:03:49.092+0000] {processor.py:157} INFO - Started process (PID=23305) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:03:49.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T16:03:49.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:03:49.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:03:49.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T16:03:49.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T16:03:49.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T16:36:57.149+0000] {processor.py:157} INFO - Started process (PID=23330) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:36:57.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T16:36:57.154+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:36:57.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T16:36:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T16:36:57.211+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T16:36:57.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T17:32:58.396+0000] {processor.py:157} INFO - Started process (PID=23355) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:32:58.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T17:32:58.399+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:32:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:32:58.463+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T17:32:58.476+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T17:32:58.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-13T17:33:28.861+0000] {processor.py:157} INFO - Started process (PID=23380) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:33:28.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T17:33:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:33:28.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T17:33:28.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T17:33:28.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T17:33:28.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-13T18:57:51.199+0000] {processor.py:157} INFO - Started process (PID=23406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T18:57:51.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T18:57:51.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T18:57:51.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T18:57:51.255+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T18:57:51.276+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T18:57:51.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-13T20:33:33.618+0000] {processor.py:157} INFO - Started process (PID=23431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:33:33.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T20:33:33.623+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:33:33.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:33:33.664+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:33:33.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T20:33:33.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-13T20:34:04.079+0000] {processor.py:157} INFO - Started process (PID=23457) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:34:04.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T20:34:04.082+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:34:04.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:34:04.114+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:34:04.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T20:34:04.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T20:55:21.238+0000] {processor.py:157} INFO - Started process (PID=23482) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:21.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T20:55:21.242+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:21.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:21.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:55:21.312+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.312+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T20:55:21.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-13T20:55:51.814+0000] {processor.py:157} INFO - Started process (PID=23507) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:51.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T20:55:51.816+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:51.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T20:55:51.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:55:51.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.861+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T20:55:51.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T21:35:13.604+0000] {processor.py:157} INFO - Started process (PID=23534) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:13.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T21:35:13.611+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:13.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:13.647+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T21:35:13.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T21:35:13.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-13T21:35:43.965+0000] {processor.py:157} INFO - Started process (PID=23559) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:43.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T21:35:43.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:43.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:43.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T21:35:44.002+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:44.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T21:35:44.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:44.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T21:35:44.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T22:30:08.845+0000] {processor.py:157} INFO - Started process (PID=23584) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:08.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T22:30:08.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:08.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:08.903+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T22:30:08.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T22:30:08.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-13T22:30:39.356+0000] {processor.py:157} INFO - Started process (PID=23609) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:39.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T22:30:39.359+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:39.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T22:30:39.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T22:30:39.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T22:30:39.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-13T23:01:06.944+0000] {processor.py:157} INFO - Started process (PID=23636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:06.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:01:06.947+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:06.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:06.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:06.986+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:06.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:01:07.004+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:07.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:01:07.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T23:01:37.312+0000] {processor.py:157} INFO - Started process (PID=23661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:37.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:01:37.315+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:37.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:01:37.345+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:01:37.359+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.358+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:01:37.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T23:02:11.490+0000] {processor.py:157} INFO - Started process (PID=23686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:11.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:02:11.498+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:11.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:11.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:02:11.592+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:02:11.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-13T23:02:42.035+0000] {processor.py:157} INFO - Started process (PID=23711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:42.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:02:42.045+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:42.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:02:42.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:02:42.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.122+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:02:42.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-13T23:03:12.443+0000] {processor.py:157} INFO - Started process (PID=23735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:12.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:03:12.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:12.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:12.476+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:03:12.490+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:03:12.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T23:03:42.992+0000] {processor.py:157} INFO - Started process (PID=23761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:42.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:03:43.001+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:43.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:43.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:03:43.077+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:43.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:03:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:43.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:03:43.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-13T23:04:13.554+0000] {processor.py:157} INFO - Started process (PID=23786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:13.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:04:13.557+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:13.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:04:13.607+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:04:13.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T23:04:44.094+0000] {processor.py:157} INFO - Started process (PID=23811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:44.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:04:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:44.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:04:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:04:44.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:04:44.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T23:05:14.463+0000] {processor.py:157} INFO - Started process (PID=23836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:14.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:05:14.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:14.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:14.508+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:05:14.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:05:14.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-13T23:05:44.975+0000] {processor.py:157} INFO - Started process (PID=23861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:44.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:05:44.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:44.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:44.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:05:45.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:45.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:05:45.026+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:45.025+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:05:45.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T23:06:15.441+0000] {processor.py:157} INFO - Started process (PID=23886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:15.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:06:15.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:15.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:15.489+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:06:15.500+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.500+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:06:15.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-13T23:06:45.869+0000] {processor.py:157} INFO - Started process (PID=23911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:45.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:06:45.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:45.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:06:45.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:06:45.911+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:06:45.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-13T23:07:16.363+0000] {processor.py:157} INFO - Started process (PID=23936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:16.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:07:16.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:16.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:16.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:07:16.426+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.426+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:07:16.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-13T23:07:46.861+0000] {processor.py:157} INFO - Started process (PID=23961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:46.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:07:46.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:46.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:07:46.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:07:46.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:07:46.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T23:08:17.364+0000] {processor.py:157} INFO - Started process (PID=23986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:17.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:08:17.367+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:17.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:17.402+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:08:17.414+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:08:17.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T23:08:47.865+0000] {processor.py:157} INFO - Started process (PID=24011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:47.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:08:47.868+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:47.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:08:47.903+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:08:47.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.913+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:08:47.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T23:09:18.351+0000] {processor.py:157} INFO - Started process (PID=24036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:18.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:09:18.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:18.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:18.388+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:09:18.402+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:09:18.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T23:09:48.816+0000] {processor.py:157} INFO - Started process (PID=24061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:48.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:09:48.821+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:48.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:09:48.855+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:09:48.870+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:09:48.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-13T23:10:19.304+0000] {processor.py:157} INFO - Started process (PID=24086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:19.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:10:19.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:19.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:19.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:10:19.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:10:19.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-13T23:10:49.774+0000] {processor.py:157} INFO - Started process (PID=24111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:49.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:10:49.784+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:49.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:10:49.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:10:49.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:10:49.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T23:11:20.239+0000] {processor.py:157} INFO - Started process (PID=24136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:20.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:11:20.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:20.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:20.287+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:11:20.299+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:11:20.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-13T23:11:50.651+0000] {processor.py:157} INFO - Started process (PID=24161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:50.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:11:50.654+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:50.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:11:50.683+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:11:50.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.695+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:11:50.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T23:12:21.147+0000] {processor.py:157} INFO - Started process (PID=24186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:21.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:12:21.152+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:21.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:21.190+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:12:21.202+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:12:21.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T23:12:51.679+0000] {processor.py:157} INFO - Started process (PID=24211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:51.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:12:51.682+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:51.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:12:51.717+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:12:51.729+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.729+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:12:51.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:13:22.177+0000] {processor.py:157} INFO - Started process (PID=24236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:22.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:13:22.179+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:22.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:22.210+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:13:22.225+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.225+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:13:22.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-13T23:13:52.690+0000] {processor.py:157} INFO - Started process (PID=24261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:52.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:13:52.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:52.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:13:52.725+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:13:52.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:13:52.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:14:23.145+0000] {processor.py:157} INFO - Started process (PID=24286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:23.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:14:23.150+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:23.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:23.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:14:23.199+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.198+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:14:23.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T23:14:53.616+0000] {processor.py:157} INFO - Started process (PID=24311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:53.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:14:53.619+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:53.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:14:53.653+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:14:53.667+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:14:53.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T23:15:24.146+0000] {processor.py:157} INFO - Started process (PID=24336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:24.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:15:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:24.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:24.182+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:15:24.195+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.194+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:15:24.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T23:15:54.579+0000] {processor.py:157} INFO - Started process (PID=24361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:54.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:15:54.583+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:54.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:15:54.616+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:15:54.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:15:54.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T23:16:24.990+0000] {processor.py:157} INFO - Started process (PID=24386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:24.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:16:24.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:24.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:25.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:25.027+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:25.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:16:25.040+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:25.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:16:25.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T23:16:55.481+0000] {processor.py:157} INFO - Started process (PID=24411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:55.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:16:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:55.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:16:55.513+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:16:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:16:55.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-13T23:17:25.936+0000] {processor.py:157} INFO - Started process (PID=24436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:25.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:17:25.940+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:25.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:25.972+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:17:25.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:17:25.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-13T23:17:56.393+0000] {processor.py:157} INFO - Started process (PID=24461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:56.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:17:56.400+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:56.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:17:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:17:56.450+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:17:56.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T23:18:26.921+0000] {processor.py:157} INFO - Started process (PID=24486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:26.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:18:26.925+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:26.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:26.954+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:18:26.965+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:18:26.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-13T23:18:57.470+0000] {processor.py:157} INFO - Started process (PID=24511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:57.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:18:57.473+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:57.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:18:57.513+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:18:57.527+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.527+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:18:57.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-13T23:19:27.988+0000] {processor.py:157} INFO - Started process (PID=24536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:27.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:19:27.992+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:27.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:28.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:28.029+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:28.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:19:28.040+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:28.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:19:28.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-13T23:19:58.416+0000] {processor.py:157} INFO - Started process (PID=24561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:58.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:19:58.419+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:58.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:19:58.453+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:19:58.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.465+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:19:58.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T23:20:28.885+0000] {processor.py:157} INFO - Started process (PID=24586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:28.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:20:28.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:28.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:28.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:20:28.936+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:20:28.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:20:59.290+0000] {processor.py:157} INFO - Started process (PID=24611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:59.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:20:59.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:59.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:20:59.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:20:59.343+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.343+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:20:59.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-13T23:21:29.750+0000] {processor.py:157} INFO - Started process (PID=24636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:21:29.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:21:29.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:21:29.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:21:29.786+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:21:29.798+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:21:29.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T23:22:00.154+0000] {processor.py:157} INFO - Started process (PID=24661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:00.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:22:00.157+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:00.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:00.188+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:22:00.202+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.202+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:22:00.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:22:30.564+0000] {processor.py:157} INFO - Started process (PID=24686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:30.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:22:30.566+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:30.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:22:30.603+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:22:30.615+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:22:30.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T23:23:01.058+0000] {processor.py:157} INFO - Started process (PID=24711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:01.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:23:01.061+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:01.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:01.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:23:01.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:23:01.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:23:31.551+0000] {processor.py:157} INFO - Started process (PID=24736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:31.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:23:31.555+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:31.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:23:31.590+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:23:31.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.601+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:23:31.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-13T23:24:02.048+0000] {processor.py:157} INFO - Started process (PID=24761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:02.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:24:02.055+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:02.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:02.086+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:24:02.098+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:24:02.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-13T23:24:32.528+0000] {processor.py:157} INFO - Started process (PID=24786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:32.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:24:32.532+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:32.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:24:32.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:24:32.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:24:32.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-13T23:25:03.027+0000] {processor.py:157} INFO - Started process (PID=24811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:03.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:25:03.033+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:03.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:03.069+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:25:03.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.082+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:25:03.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T23:25:33.555+0000] {processor.py:157} INFO - Started process (PID=24836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:33.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:25:33.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:33.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:25:33.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:25:33.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.614+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:25:33.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-13T23:26:04.036+0000] {processor.py:157} INFO - Started process (PID=24861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:04.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:26:04.041+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:04.088+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:26:04.102+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:26:04.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-13T23:26:34.666+0000] {processor.py:157} INFO - Started process (PID=24886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:34.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:26:34.668+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:34.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:26:34.699+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:26:34.717+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.717+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:26:34.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-13T23:27:05.124+0000] {processor.py:157} INFO - Started process (PID=24911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:27:05.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:27:05.129+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:27:05.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:27:05.161+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:27:05.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.175+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:27:05.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-13T23:28:30.485+0000] {processor.py:157} INFO - Started process (PID=24936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:28:30.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:28:30.491+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:28:30.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:28:30.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:28:30.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:28:30.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-13T23:29:01.107+0000] {processor.py:157} INFO - Started process (PID=24963) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:29:01.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-13T23:29:01.109+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:29:01.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-13T23:29:01.134+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:29:01.150+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-12T00:30:00+00:00, run_after=2024-07-13T00:30:00+00:00
[2024-07-13T23:29:01.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
