[2024-07-13T00:32:03.223+0000] {processor.py:157} INFO - Started process (PID=8495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:03.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T00:32:03.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:03.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:03.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T00:32:03.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:03.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-13T00:32:03.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-13T00:32:33.733+0000] {processor.py:157} INFO - Started process (PID=8520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:33.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T00:32:33.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:33.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T00:32:33.775+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T00:32:33.790+0000] {logging_mixin.py:151} INFO - [2024-07-13T00:32:33.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-13T00:32:33.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T01:22:37.952+0000] {processor.py:157} INFO - Started process (PID=8545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:22:37.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T01:22:37.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:22:37.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:22:37.980+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:22:37.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:22:37.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-12T01:00:00+00:00, run_after=2024-07-13T01:00:00+00:00
[2024-07-13T01:22:38.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T01:28:43.313+0000] {processor.py:157} INFO - Started process (PID=8959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:28:43.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T01:28:43.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:28:43.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:28:43.349+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:28:43.360+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:28:43.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T01:28:43.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T01:29:13.794+0000] {processor.py:157} INFO - Started process (PID=8984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:29:13.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T01:29:13.799+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:29:13.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:29:13.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:29:13.855+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:29:13.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T01:29:13.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T01:33:30.696+0000] {processor.py:157} INFO - Started process (PID=9010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:33:30.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T01:33:30.700+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:33:30.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T01:33:30.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T01:33:30.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T01:33:30.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T01:33:30.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-13T02:05:20.118+0000] {processor.py:157} INFO - Started process (PID=9035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:05:20.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:05:20.122+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:05:20.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:05:20.160+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:05:20.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:05:20.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:05:20.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T02:17:11.256+0000] {processor.py:157} INFO - Started process (PID=9060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:17:11.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:17:11.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:17:11.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:17:11.309+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:17:11.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:17:11.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:17:11.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-13T02:34:15.917+0000] {processor.py:157} INFO - Started process (PID=9085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:15.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:34:15.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:15.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:15.953+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:34:15.966+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:15.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:34:15.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T02:34:46.263+0000] {processor.py:157} INFO - Started process (PID=9110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:46.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:34:46.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:46.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:34:46.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:34:46.304+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:34:46.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:34:46.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T02:40:14.929+0000] {processor.py:157} INFO - Started process (PID=9135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:40:14.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:40:14.936+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:14.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:40:14.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:40:14.994+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:14.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:40:15.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:40:15.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:40:15.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-13T02:57:02.589+0000] {processor.py:157} INFO - Started process (PID=9162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:02.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:57:02.594+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:02.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:02.642+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:57:02.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:02.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:57:02.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-13T02:57:33.034+0000] {processor.py:157} INFO - Started process (PID=9187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:33.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T02:57:33.037+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:33.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T02:57:33.064+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T02:57:33.082+0000] {logging_mixin.py:151} INFO - [2024-07-13T02:57:33.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T02:57:33.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T03:35:09.561+0000] {processor.py:157} INFO - Started process (PID=9212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:09.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T03:35:09.565+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:09.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:09.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:35:09.603+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:09.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T03:35:09.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T03:35:40.081+0000] {processor.py:157} INFO - Started process (PID=9237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:40.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T03:35:40.084+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:40.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:35:40.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:35:40.135+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:35:40.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T03:35:40.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T03:50:17.422+0000] {processor.py:157} INFO - Started process (PID=9262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:50:17.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T03:50:17.428+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:50:17.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T03:50:17.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T03:50:17.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T03:50:17.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T03:50:17.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-13T04:07:10.065+0000] {processor.py:157} INFO - Started process (PID=9287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:07:10.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T04:07:10.069+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:07:10.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:07:10.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:07:10.152+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:07:10.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T04:07:10.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-13T04:22:09.889+0000] {processor.py:157} INFO - Started process (PID=9312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:22:09.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T04:22:09.893+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:22:09.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:22:09.934+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:22:09.947+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:22:09.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T04:22:09.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-13T04:32:57.762+0000] {processor.py:157} INFO - Started process (PID=9339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:32:57.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T04:32:57.769+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:32:57.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:32:57.805+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:32:57.825+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:32:57.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T04:32:57.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-13T04:33:28.193+0000] {processor.py:157} INFO - Started process (PID=9364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:33:28.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T04:33:28.197+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:33:28.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:33:28.222+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:33:28.238+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:33:28.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T04:33:28.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T04:36:26.688+0000] {processor.py:157} INFO - Started process (PID=9389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:36:26.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T04:36:26.691+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:36:26.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T04:36:26.719+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T04:36:26.729+0000] {logging_mixin.py:151} INFO - [2024-07-13T04:36:26.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T04:36:26.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T05:02:10.008+0000] {processor.py:157} INFO - Started process (PID=9414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:10.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:02:10.011+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:10.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:10.046+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:02:10.059+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:10.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:02:10.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T05:02:40.247+0000] {processor.py:157} INFO - Started process (PID=9439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:40.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:02:40.250+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:40.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:02:40.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:02:40.302+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:02:40.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:02:40.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T05:37:11.401+0000] {processor.py:157} INFO - Started process (PID=9464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:11.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:37:11.404+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:11.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:11.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:37:11.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:11.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:37:11.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T05:37:41.823+0000] {processor.py:157} INFO - Started process (PID=9489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:41.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:37:41.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:41.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:37:41.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:37:41.867+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:37:41.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:37:41.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T05:43:36.479+0000] {processor.py:157} INFO - Started process (PID=9515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:43:36.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:43:36.487+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:43:36.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:43:36.535+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:43:36.559+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:43:36.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:43:36.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-13T05:58:56.899+0000] {processor.py:157} INFO - Started process (PID=9540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:58:56.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:58:56.904+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:58:56.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:58:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:58:56.960+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:58:56.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:58:56.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-13T05:59:27.392+0000] {processor.py:157} INFO - Started process (PID=9565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:59:27.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T05:59:27.394+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:59:27.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T05:59:27.424+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T05:59:27.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T05:59:27.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T05:59:27.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T06:38:10.411+0000] {processor.py:157} INFO - Started process (PID=9590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:10.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T06:38:10.414+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:10.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:10.448+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T06:38:10.461+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:10.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T06:38:10.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T06:38:40.797+0000] {processor.py:157} INFO - Started process (PID=9615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:40.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T06:38:40.802+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:40.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T06:38:40.836+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T06:38:40.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T06:38:40.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T06:38:40.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T07:39:07.188+0000] {processor.py:157} INFO - Started process (PID=9641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:07.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T07:39:07.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:07.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:07.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T07:39:07.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:07.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T07:39:07.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T07:39:37.568+0000] {processor.py:157} INFO - Started process (PID=9667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:37.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T07:39:37.570+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:37.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T07:39:37.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T07:39:37.610+0000] {logging_mixin.py:151} INFO - [2024-07-13T07:39:37.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T07:39:37.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T08:40:05.199+0000] {processor.py:157} INFO - Started process (PID=9692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:05.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T08:40:05.205+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:05.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:05.251+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T08:40:05.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:05.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T08:40:05.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-13T08:40:35.702+0000] {processor.py:157} INFO - Started process (PID=9717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:35.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T08:40:35.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:35.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T08:40:35.734+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T08:40:35.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T08:40:35.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T08:40:35.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T09:01:51.570+0000] {processor.py:157} INFO - Started process (PID=9742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:01:51.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:01:51.574+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:01:51.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:01:51.615+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:01:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:01:51.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:01:51.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-13T09:02:22.178+0000] {processor.py:157} INFO - Started process (PID=9767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:02:22.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:02:22.182+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:02:22.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:02:22.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:02:22.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:02:22.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:02:22.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T09:41:15.233+0000] {processor.py:157} INFO - Started process (PID=9794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:15.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:41:15.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:15.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:15.296+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:41:15.316+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:15.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:41:15.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-13T09:41:45.818+0000] {processor.py:157} INFO - Started process (PID=9819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:45.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:41:45.820+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:45.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:41:45.847+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:41:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:41:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:41:45.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T09:49:13.119+0000] {processor.py:157} INFO - Started process (PID=9844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:13.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:49:13.154+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:13.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:13.256+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:49:13.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:13.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:49:13.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-07-13T09:49:44.788+0000] {processor.py:157} INFO - Started process (PID=9869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:44.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:49:44.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:44.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:49:44.824+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:49:44.837+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:49:44.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:49:44.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T09:50:15.208+0000] {processor.py:157} INFO - Started process (PID=9894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:50:15.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:50:15.211+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:50:15.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:50:15.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:50:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:50:15.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:50:15.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T09:51:23.007+0000] {processor.py:157} INFO - Started process (PID=9919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:23.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:51:23.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:23.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:23.079+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:51:23.105+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:23.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:51:23.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-13T09:51:53.542+0000] {processor.py:157} INFO - Started process (PID=9944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:53.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:51:53.549+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:53.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:51:53.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:51:53.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:51:53.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:51:53.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-13T09:52:24.078+0000] {processor.py:157} INFO - Started process (PID=9969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:24.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:52:24.084+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:24.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:24.127+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:52:24.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:24.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:52:24.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-13T09:52:54.568+0000] {processor.py:157} INFO - Started process (PID=9994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:54.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:52:54.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:54.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:52:54.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:52:54.620+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:52:54.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:52:54.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T09:53:24.988+0000] {processor.py:157} INFO - Started process (PID=10019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:24.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:53:24.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:24.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:25.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:25.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:25.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:53:25.050+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:25.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:53:25.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-13T09:53:55.529+0000] {processor.py:157} INFO - Started process (PID=10044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:55.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:53:55.538+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:55.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:53:55.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:53:55.630+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:53:55.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:53:55.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-13T09:54:26.100+0000] {processor.py:157} INFO - Started process (PID=10069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:26.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:54:26.103+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:26.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:26.135+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:54:26.151+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:26.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:54:26.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T09:54:56.643+0000] {processor.py:157} INFO - Started process (PID=10094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:56.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:54:56.651+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:56.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:54:56.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:54:56.732+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:54:56.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:54:56.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-13T09:55:27.112+0000] {processor.py:157} INFO - Started process (PID=10119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:27.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:55:27.116+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:27.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:27.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:55:27.157+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:27.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:55:27.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T09:55:57.585+0000] {processor.py:157} INFO - Started process (PID=10144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:57.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:55:57.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:57.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:55:57.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:55:57.681+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:55:57.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:55:57.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-13T09:56:28.079+0000] {processor.py:157} INFO - Started process (PID=10169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:28.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:56:28.081+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:28.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:28.104+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:56:28.119+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:28.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:56:28.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T09:56:58.478+0000] {processor.py:157} INFO - Started process (PID=10194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:58.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:56:58.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:58.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:56:58.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:56:58.541+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:56:58.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:56:58.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-13T09:57:28.937+0000] {processor.py:157} INFO - Started process (PID=10219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:28.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:57:28.941+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:28.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:28.979+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:57:28.989+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:28.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:57:28.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T09:57:59.420+0000] {processor.py:157} INFO - Started process (PID=10244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:59.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:57:59.423+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:59.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:57:59.463+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:57:59.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:57:59.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:57:59.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-13T09:58:29.862+0000] {processor.py:157} INFO - Started process (PID=10269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:58:29.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:58:29.869+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:58:29.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:58:29.906+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:58:29.920+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:58:29.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:58:29.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T09:59:00.313+0000] {processor.py:157} INFO - Started process (PID=10294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:00.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:59:00.323+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:00.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:00.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:59:00.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:00.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:59:00.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-13T09:59:30.842+0000] {processor.py:157} INFO - Started process (PID=10319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:30.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T09:59:30.847+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:30.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T09:59:30.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T09:59:30.914+0000] {logging_mixin.py:151} INFO - [2024-07-13T09:59:30.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T09:59:30.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-13T10:00:01.286+0000] {processor.py:157} INFO - Started process (PID=10344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:01.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:00:01.290+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:01.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:01.321+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:00:01.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:01.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:00:01.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:00:31.763+0000] {processor.py:157} INFO - Started process (PID=10369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:31.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:00:31.771+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:31.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:00:31.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:00:31.817+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:00:31.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:00:31.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T10:01:02.236+0000] {processor.py:157} INFO - Started process (PID=10394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:02.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:01:02.239+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:02.270+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:01:02.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:02.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:01:02.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:01:32.706+0000] {processor.py:157} INFO - Started process (PID=10419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:32.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:01:32.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:32.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:01:32.738+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:01:32.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:01:32.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:01:32.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:02:03.184+0000] {processor.py:157} INFO - Started process (PID=10444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:03.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:02:03.189+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:03.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:03.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:02:03.242+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:03.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:02:03.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T10:02:33.657+0000] {processor.py:157} INFO - Started process (PID=10469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:33.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:02:33.661+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:33.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:02:33.690+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:02:33.700+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:02:33.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:02:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:03:04.074+0000] {processor.py:157} INFO - Started process (PID=10494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:04.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:03:04.077+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:04.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:04.112+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:03:04.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:04.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:03:04.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:03:34.534+0000] {processor.py:157} INFO - Started process (PID=10519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:34.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:03:34.538+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:34.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:03:34.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:03:34.586+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:03:34.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:03:34.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T10:04:04.995+0000] {processor.py:157} INFO - Started process (PID=10544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:04.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:04:04.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:04.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:05.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:05.032+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:05.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:04:05.042+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:05.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:04:05.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T10:04:35.455+0000] {processor.py:157} INFO - Started process (PID=10569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:35.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:04:35.458+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:35.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:04:35.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:04:35.493+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:04:35.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:04:35.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T10:05:05.860+0000] {processor.py:157} INFO - Started process (PID=10594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:05.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:05:05.863+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:05.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:05.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:05:05.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:05.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:05:05.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:05:36.282+0000] {processor.py:157} INFO - Started process (PID=10619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:36.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:05:36.287+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:36.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:05:36.321+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:05:36.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:05:36.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:05:36.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T10:06:06.692+0000] {processor.py:157} INFO - Started process (PID=10644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:06.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:06:06.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:06.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:06.723+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:06:06.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:06.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:06:06.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:06:37.138+0000] {processor.py:157} INFO - Started process (PID=10669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:37.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:06:37.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:37.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:06:37.167+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:06:37.179+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:06:37.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:06:37.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:07:07.520+0000] {processor.py:157} INFO - Started process (PID=10694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:07.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:07:07.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:07.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:07.547+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:07:07.561+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:07.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:07:07.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:07:37.926+0000] {processor.py:157} INFO - Started process (PID=10719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:37.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:07:37.934+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:37.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:07:37.961+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:07:37.971+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:07:37.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:07:37.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:08:08.314+0000] {processor.py:157} INFO - Started process (PID=10744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:08.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:08:08.316+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:08.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:08.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:08:08.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:08.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:08:08.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-13T10:08:38.710+0000] {processor.py:157} INFO - Started process (PID=10769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:38.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:08:38.713+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:38.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:08:38.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:08:38.755+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:08:38.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:08:38.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:09:09.152+0000] {processor.py:157} INFO - Started process (PID=10794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:09.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:09:09.155+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:09.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:09:09.197+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:09.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:09:09.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:09:39.582+0000] {processor.py:157} INFO - Started process (PID=10819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:39.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:09:39.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:39.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:09:39.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:09:39.626+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:09:39.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:09:39.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T10:10:10.044+0000] {processor.py:157} INFO - Started process (PID=10844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:10.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:10:10.048+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:10.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:10.079+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:10:10.090+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:10.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:10:10.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:10:40.466+0000] {processor.py:157} INFO - Started process (PID=10869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:40.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:10:40.470+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:40.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:10:40.499+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:10:40.508+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:10:40.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:10:40.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:11:10.882+0000] {processor.py:157} INFO - Started process (PID=10894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:10.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:11:10.886+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:10.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:10.915+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:11:10.929+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:10.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:11:10.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:11:41.338+0000] {processor.py:157} INFO - Started process (PID=10919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:41.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:11:41.341+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:41.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:11:41.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:11:41.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:11:41.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:11:41.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-13T10:12:11.782+0000] {processor.py:157} INFO - Started process (PID=10944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:11.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:12:11.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:11.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:11.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:12:11.822+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:11.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:12:11.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:12:42.257+0000] {processor.py:157} INFO - Started process (PID=10969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:42.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:12:42.260+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:42.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:12:42.286+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:12:42.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:12:42.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:12:42.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:13:12.654+0000] {processor.py:157} INFO - Started process (PID=10994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:12.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:13:12.656+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:12.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:12.683+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:13:12.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:12.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:13:12.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:13:43.084+0000] {processor.py:157} INFO - Started process (PID=11019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:43.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:13:43.087+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:43.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:13:43.112+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:13:43.123+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:13:43.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:13:43.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T10:14:13.535+0000] {processor.py:157} INFO - Started process (PID=11044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:13.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:14:13.540+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:13.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:13.569+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:14:13.579+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:13.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:14:13.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:14:43.992+0000] {processor.py:157} INFO - Started process (PID=11069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:43.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:14:43.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:43.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:44.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:14:44.033+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:44.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:14:44.046+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:14:44.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:14:44.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T10:15:14.521+0000] {processor.py:157} INFO - Started process (PID=11094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:14.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:15:14.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:14.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:14.550+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:15:14.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:14.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:15:14.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:15:44.876+0000] {processor.py:157} INFO - Started process (PID=11119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:44.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:15:44.879+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:44.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:15:44.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:15:44.917+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:15:44.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:15:44.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:16:15.252+0000] {processor.py:157} INFO - Started process (PID=11144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:15.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:16:15.255+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:15.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:15.285+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:16:15.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:15.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:16:15.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:16:45.752+0000] {processor.py:157} INFO - Started process (PID=11169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:45.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:16:45.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:45.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:16:45.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:16:45.796+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:16:45.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:16:45.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:17:16.153+0000] {processor.py:157} INFO - Started process (PID=11194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:16.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:17:16.158+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:16.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:16.194+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:17:16.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:16.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:17:16.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:17:46.629+0000] {processor.py:157} INFO - Started process (PID=11219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:46.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:17:46.639+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:46.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:17:46.710+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:17:46.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:17:46.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:17:46.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-13T10:18:17.214+0000] {processor.py:157} INFO - Started process (PID=11244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:17.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:18:17.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:17.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:17.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:18:17.316+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:17.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:18:17.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-13T10:18:47.761+0000] {processor.py:157} INFO - Started process (PID=11269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:47.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:18:47.784+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:47.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:18:47.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:18:47.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:18:47.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:18:47.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-13T10:19:18.255+0000] {processor.py:157} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:18.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:19:18.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:18.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:18.313+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:19:18.330+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:18.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:19:18.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-13T10:19:48.737+0000] {processor.py:157} INFO - Started process (PID=11319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:48.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:19:48.740+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:48.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:19:48.772+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:19:48.787+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:19:48.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:19:48.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T10:20:19.216+0000] {processor.py:157} INFO - Started process (PID=11344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:19.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:20:19.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:19.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:19.289+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:20:19.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:19.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:20:19.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-13T10:20:49.776+0000] {processor.py:157} INFO - Started process (PID=11369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:49.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:20:49.780+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:49.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:20:49.813+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:20:49.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:20:49.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:20:49.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T10:21:20.309+0000] {processor.py:157} INFO - Started process (PID=11394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:20.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:21:20.324+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:20.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:20.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:21:20.405+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:20.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:21:20.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-13T10:21:50.834+0000] {processor.py:157} INFO - Started process (PID=11419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:50.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:21:50.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:50.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:21:50.906+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:21:50.934+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:21:50.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:21:50.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-13T10:22:21.416+0000] {processor.py:157} INFO - Started process (PID=11444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:21.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:22:21.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:21.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:21.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:22:21.479+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:21.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:22:21.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-13T10:22:51.880+0000] {processor.py:157} INFO - Started process (PID=11469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:51.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:22:51.882+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:51.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:22:51.909+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:22:51.925+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:22:51.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:22:51.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:23:22.329+0000] {processor.py:157} INFO - Started process (PID=11494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:22.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:23:22.332+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:22.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:22.360+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:23:22.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:22.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:23:22.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:23:52.750+0000] {processor.py:157} INFO - Started process (PID=11519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:52.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:23:52.756+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:52.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:23:52.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:23:52.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:23:52.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:23:52.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T10:24:23.227+0000] {processor.py:157} INFO - Started process (PID=11544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:23.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:24:23.230+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:23.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:23.264+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:24:23.276+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:23.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:24:23.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:24:53.640+0000] {processor.py:157} INFO - Started process (PID=11569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:53.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:24:53.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:53.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:24:53.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:24:53.681+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:24:53.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:24:53.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:25:24.096+0000] {processor.py:157} INFO - Started process (PID=11594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:24.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:25:24.099+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:24.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:24.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:25:24.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:24.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:25:24.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:25:54.553+0000] {processor.py:157} INFO - Started process (PID=11619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:54.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:25:54.556+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:54.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:25:54.586+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:25:54.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:25:54.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:25:54.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T10:26:24.956+0000] {processor.py:157} INFO - Started process (PID=11644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:24.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:26:24.959+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:24.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:24.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:24.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:26:24.994+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:24.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:26:25.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T10:26:55.355+0000] {processor.py:157} INFO - Started process (PID=11669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:55.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:26:55.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:55.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:26:55.389+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:26:55.402+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:26:55.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:26:55.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T10:27:25.766+0000] {processor.py:157} INFO - Started process (PID=11694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:25.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:27:25.768+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:25.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:25.794+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:27:25.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:25.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:27:25.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:27:56.142+0000] {processor.py:157} INFO - Started process (PID=11719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:56.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:27:56.145+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:56.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:27:56.174+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:27:56.187+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:27:56.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:27:56.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:28:26.551+0000] {processor.py:157} INFO - Started process (PID=11744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:26.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:28:26.557+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:26.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:26.589+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:28:26.599+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:26.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:28:26.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T10:28:56.972+0000] {processor.py:157} INFO - Started process (PID=11769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:56.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:28:56.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:56.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:56.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:28:57.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:57.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:28:57.023+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:28:57.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:28:57.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T10:29:27.442+0000] {processor.py:157} INFO - Started process (PID=11794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:27.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:29:27.444+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:27.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:27.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:29:27.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:27.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:29:27.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:29:57.859+0000] {processor.py:157} INFO - Started process (PID=11819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:57.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:29:57.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:57.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:29:57.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:29:57.899+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:29:57.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:29:57.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:30:28.320+0000] {processor.py:157} INFO - Started process (PID=11844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:28.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:30:28.323+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:28.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:28.359+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:30:28.370+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:28.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:30:28.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T10:30:58.849+0000] {processor.py:157} INFO - Started process (PID=11869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:58.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:30:58.853+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:58.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:30:58.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:30:58.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:30:58.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:30:58.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:31:29.373+0000] {processor.py:157} INFO - Started process (PID=11894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:29.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:31:29.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:29.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:29.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:31:29.413+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:29.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:31:29.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:31:59.854+0000] {processor.py:157} INFO - Started process (PID=11919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:59.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:31:59.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:59.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:31:59.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:31:59.898+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:31:59.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:31:59.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:32:30.325+0000] {processor.py:157} INFO - Started process (PID=11944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:32:30.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:32:30.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:32:30.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:32:30.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:32:30.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:32:30.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:32:30.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:33:00.677+0000] {processor.py:157} INFO - Started process (PID=11969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:00.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:33:00.679+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:00.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:00.703+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:33:00.717+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:00.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:33:00.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:33:31.140+0000] {processor.py:157} INFO - Started process (PID=11994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:31.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:33:31.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:31.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:33:31.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:33:31.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:33:31.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:33:31.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T10:34:01.572+0000] {processor.py:157} INFO - Started process (PID=12019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:01.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:34:01.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:01.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:01.608+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:34:01.621+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:01.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:34:01.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:34:32.018+0000] {processor.py:157} INFO - Started process (PID=12044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:32.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:34:32.022+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:32.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:34:32.054+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:34:32.064+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:34:32.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:34:32.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:35:02.446+0000] {processor.py:157} INFO - Started process (PID=12069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:02.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:35:02.450+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:02.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:02.478+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:35:02.488+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:02.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:35:02.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:35:32.910+0000] {processor.py:157} INFO - Started process (PID=12094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:32.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:35:32.915+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:32.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:35:32.943+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:35:32.952+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:35:32.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:35:32.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:36:03.335+0000] {processor.py:157} INFO - Started process (PID=12119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:03.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:36:03.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:03.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:03.364+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:36:03.374+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:03.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:36:03.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:36:33.754+0000] {processor.py:157} INFO - Started process (PID=12144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:33.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:36:33.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:33.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:36:33.779+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:36:33.792+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:36:33.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:36:33.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-13T10:37:04.247+0000] {processor.py:157} INFO - Started process (PID=12169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:04.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:37:04.252+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:04.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:04.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:37:04.305+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:04.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:37:04.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T10:37:34.732+0000] {processor.py:157} INFO - Started process (PID=12194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:34.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:37:34.735+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:34.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:37:34.760+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:37:34.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:37:34.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:37:34.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T10:38:05.138+0000] {processor.py:157} INFO - Started process (PID=12219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:05.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:38:05.142+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:05.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:05.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:38:05.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:05.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:38:05.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:38:35.590+0000] {processor.py:157} INFO - Started process (PID=12244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:35.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:38:35.594+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:35.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:38:35.622+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:38:35.635+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:38:35.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:38:35.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:39:05.948+0000] {processor.py:157} INFO - Started process (PID=12269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:05.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:39:05.952+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:05.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:05.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:39:05.986+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:05.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:39:05.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T10:39:36.382+0000] {processor.py:157} INFO - Started process (PID=12294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:36.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:39:36.387+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:36.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:39:36.416+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:39:36.429+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:39:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:39:36.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:40:06.820+0000] {processor.py:157} INFO - Started process (PID=12319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:06.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:40:06.825+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:06.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:06.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:40:06.870+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:06.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:40:06.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T10:40:37.236+0000] {processor.py:157} INFO - Started process (PID=12344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:37.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:40:37.239+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:37.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:40:37.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:40:37.282+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:40:37.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:40:37.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:41:07.701+0000] {processor.py:157} INFO - Started process (PID=12369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:07.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:41:07.704+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:07.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:07.731+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:41:07.740+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:07.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:41:07.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:41:38.174+0000] {processor.py:157} INFO - Started process (PID=12394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:38.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:41:38.177+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:38.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:41:38.206+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:41:38.219+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:41:38.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:41:38.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:42:08.608+0000] {processor.py:157} INFO - Started process (PID=12419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:08.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:42:08.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:08.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:08.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:42:08.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:08.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:42:08.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T10:42:39.071+0000] {processor.py:157} INFO - Started process (PID=12444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:39.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:42:39.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:39.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:42:39.101+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:42:39.114+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:42:39.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:42:39.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:43:09.599+0000] {processor.py:157} INFO - Started process (PID=12469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:09.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:43:09.601+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:09.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:09.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:43:09.638+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:09.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:43:09.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:43:40.018+0000] {processor.py:157} INFO - Started process (PID=12494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:40.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:43:40.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:40.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:43:40.064+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:43:40.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:43:40.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:43:40.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T10:44:10.492+0000] {processor.py:157} INFO - Started process (PID=12519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:10.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:44:10.497+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:10.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:10.527+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:44:10.536+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:10.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:44:10.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T10:44:40.936+0000] {processor.py:157} INFO - Started process (PID=12544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:40.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:44:40.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:40.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:44:40.974+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:44:40.986+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:44:40.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:44:40.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T10:45:11.441+0000] {processor.py:157} INFO - Started process (PID=12569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:11.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:45:11.445+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:11.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:11.473+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:45:11.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:11.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:45:11.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T10:45:41.847+0000] {processor.py:157} INFO - Started process (PID=12594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:41.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:45:41.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:41.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:45:41.879+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:45:41.891+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:45:41.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:45:41.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:46:12.234+0000] {processor.py:157} INFO - Started process (PID=12619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:12.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:46:12.238+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:12.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:12.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:46:12.273+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:12.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:46:12.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:46:42.661+0000] {processor.py:157} INFO - Started process (PID=12644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:42.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:46:42.666+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:42.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:46:42.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:46:42.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:46:42.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:46:42.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T10:47:13.177+0000] {processor.py:157} INFO - Started process (PID=12669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:13.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:47:13.181+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:13.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:13.208+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:47:13.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:13.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:47:13.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:47:43.630+0000] {processor.py:157} INFO - Started process (PID=12694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:43.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:47:43.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:43.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:47:43.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:47:43.672+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:47:43.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:47:43.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T10:48:14.030+0000] {processor.py:157} INFO - Started process (PID=12719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:14.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:48:14.034+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:14.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:14.066+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:48:14.077+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:14.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:48:14.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T10:48:44.449+0000] {processor.py:157} INFO - Started process (PID=12744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:44.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:48:44.452+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:44.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:48:44.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:48:44.490+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:48:44.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:48:44.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:49:14.856+0000] {processor.py:157} INFO - Started process (PID=12769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:14.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:49:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:14.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:14.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:49:14.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:14.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:49:14.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:49:45.291+0000] {processor.py:157} INFO - Started process (PID=12794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:45.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:49:45.294+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:45.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:49:45.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:49:45.332+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:49:45.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:49:45.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:50:15.732+0000] {processor.py:157} INFO - Started process (PID=12819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:15.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:50:15.738+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:15.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:15.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:50:15.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:15.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:50:15.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T10:50:46.172+0000] {processor.py:157} INFO - Started process (PID=12844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:46.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:50:46.178+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:46.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:50:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:50:46.213+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:50:46.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:50:46.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:51:16.527+0000] {processor.py:157} INFO - Started process (PID=12869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:16.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:51:16.530+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:16.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:16.556+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:51:16.569+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:16.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:51:16.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:51:46.993+0000] {processor.py:157} INFO - Started process (PID=12894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:46.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:51:46.996+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:46.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:47.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:51:47.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:47.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:51:47.036+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:51:47.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:51:47.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:52:17.481+0000] {processor.py:157} INFO - Started process (PID=12919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:17.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:52:17.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:17.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:17.511+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:52:17.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:17.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:52:17.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:52:47.952+0000] {processor.py:157} INFO - Started process (PID=12944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:47.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:52:47.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:47.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:52:47.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:52:47.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:52:47.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:52:48.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T10:53:18.451+0000] {processor.py:157} INFO - Started process (PID=12969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:18.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:53:18.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:18.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:18.487+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:53:18.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:18.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:53:18.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T10:53:48.933+0000] {processor.py:157} INFO - Started process (PID=12994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:48.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:53:48.938+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:48.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:53:48.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:53:48.980+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:53:48.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:53:48.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T10:54:19.405+0000] {processor.py:157} INFO - Started process (PID=13019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:19.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:54:19.408+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:19.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:19.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:54:19.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:19.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:54:19.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T10:54:49.832+0000] {processor.py:157} INFO - Started process (PID=13044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:49.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:54:49.836+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:49.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:54:49.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:54:49.874+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:54:49.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:54:49.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T10:55:20.264+0000] {processor.py:157} INFO - Started process (PID=13069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:20.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:55:20.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:20.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:20.296+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:55:20.314+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:20.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:55:20.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T10:55:50.729+0000] {processor.py:157} INFO - Started process (PID=13094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:50.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:55:50.732+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:50.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:55:50.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:55:50.772+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:55:50.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:55:50.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T10:56:21.145+0000] {processor.py:157} INFO - Started process (PID=13119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:21.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:56:21.149+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:21.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:21.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:56:21.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:21.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:56:21.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T10:56:51.591+0000] {processor.py:157} INFO - Started process (PID=13144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:51.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:56:51.596+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:51.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:56:51.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:56:51.638+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:56:51.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:56:51.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:57:22.070+0000] {processor.py:157} INFO - Started process (PID=13169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:22.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:57:22.073+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:22.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:22.104+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:57:22.114+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:22.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:57:22.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T10:57:52.488+0000] {processor.py:157} INFO - Started process (PID=13194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:52.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:57:52.493+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:52.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:57:52.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:57:52.534+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:57:52.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:57:52.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T10:58:22.918+0000] {processor.py:157} INFO - Started process (PID=13219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:22.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:58:22.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:22.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:22.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:58:22.966+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:22.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:58:22.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T10:58:53.363+0000] {processor.py:157} INFO - Started process (PID=13244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:53.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:58:53.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:53.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:58:53.398+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:58:53.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:58:53.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:58:53.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T10:59:23.824+0000] {processor.py:157} INFO - Started process (PID=13269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:23.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:59:23.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:23.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:23.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:59:23.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:23.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:59:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T10:59:54.284+0000] {processor.py:157} INFO - Started process (PID=13294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:54.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T10:59:54.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:54.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T10:59:54.315+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T10:59:54.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T10:59:54.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T10:59:54.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T11:00:24.808+0000] {processor.py:157} INFO - Started process (PID=13319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:24.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:00:24.821+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:24.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:24.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:00:24.870+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:24.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:00:24.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-13T11:00:55.263+0000] {processor.py:157} INFO - Started process (PID=13344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:55.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:00:55.267+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:55.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:00:55.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:00:55.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:00:55.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:00:55.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T11:01:25.688+0000] {processor.py:157} INFO - Started process (PID=13369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:25.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:01:25.693+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:25.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:25.724+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:01:25.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:25.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:01:25.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T11:01:56.061+0000] {processor.py:157} INFO - Started process (PID=13394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:56.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:01:56.064+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:56.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:01:56.092+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:01:56.103+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:01:56.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:01:56.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T11:02:26.477+0000] {processor.py:157} INFO - Started process (PID=13419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:26.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:02:26.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:26.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:26.512+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:02:26.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:26.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:02:26.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T11:02:56.966+0000] {processor.py:157} INFO - Started process (PID=13444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:56.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:02:56.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:56.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:56.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:02:56.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:56.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:02:57.008+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:02:57.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:02:57.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:03:27.423+0000] {processor.py:157} INFO - Started process (PID=13469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:27.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:03:27.427+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:27.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:27.453+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:03:27.464+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:27.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:03:27.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T11:03:57.887+0000] {processor.py:157} INFO - Started process (PID=13494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:57.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:03:57.890+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:57.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:03:57.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:03:57.932+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:03:57.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:03:57.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:04:28.301+0000] {processor.py:157} INFO - Started process (PID=13519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:28.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:04:28.305+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:28.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:28.333+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:04:28.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:28.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:04:28.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:04:58.710+0000] {processor.py:157} INFO - Started process (PID=13544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:58.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:04:58.713+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:58.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:04:58.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:04:58.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:04:58.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:04:58.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:05:29.137+0000] {processor.py:157} INFO - Started process (PID=13569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:29.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:05:29.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:29.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:29.167+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:05:29.178+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:29.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:05:29.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T11:05:59.543+0000] {processor.py:157} INFO - Started process (PID=13594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:59.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:05:59.548+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:59.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:05:59.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:05:59.585+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:05:59.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:05:59.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:06:29.970+0000] {processor.py:157} INFO - Started process (PID=13619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:06:29.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:06:29.973+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:29.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:06:29.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:06:30.000+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:30.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:06:30.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:06:30.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:06:30.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:07:00.429+0000] {processor.py:157} INFO - Started process (PID=13644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:00.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:07:00.434+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:00.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:00.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:07:00.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:00.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:07:00.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T11:07:30.882+0000] {processor.py:157} INFO - Started process (PID=13669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:30.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:07:30.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:30.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:07:30.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:07:30.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:07:30.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:07:30.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T11:08:01.301+0000] {processor.py:157} INFO - Started process (PID=13694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:01.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:08:01.304+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:01.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:01.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:08:01.345+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:01.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:08:01.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:08:31.806+0000] {processor.py:157} INFO - Started process (PID=13719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:31.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:08:31.809+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:31.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:08:31.837+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:08:31.847+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:08:31.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:08:31.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:09:02.243+0000] {processor.py:157} INFO - Started process (PID=13744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:02.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:09:02.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:02.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:02.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:09:02.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:02.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:09:02.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:09:32.737+0000] {processor.py:157} INFO - Started process (PID=13769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:32.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:09:32.746+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:32.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:09:32.796+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:09:32.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:09:32.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:09:32.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-13T11:10:03.276+0000] {processor.py:157} INFO - Started process (PID=13794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:03.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:10:03.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:03.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:03.313+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:10:03.324+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:03.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:10:03.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T11:10:33.753+0000] {processor.py:157} INFO - Started process (PID=13819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:33.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:10:33.756+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:33.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:10:33.787+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:10:33.797+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:10:33.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:10:33.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:11:04.168+0000] {processor.py:157} INFO - Started process (PID=13844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:04.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:11:04.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:04.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:04.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:11:04.211+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:04.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:11:04.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:11:34.637+0000] {processor.py:157} INFO - Started process (PID=13869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:34.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:11:34.642+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:34.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:11:34.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:11:34.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:11:34.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:11:34.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:12:05.064+0000] {processor.py:157} INFO - Started process (PID=13894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:05.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:12:05.068+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:05.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:05.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:12:05.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:05.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:12:05.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:12:35.519+0000] {processor.py:157} INFO - Started process (PID=13919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:35.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:12:35.524+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:35.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:12:35.552+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:12:35.564+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:12:35.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:12:35.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T11:13:05.904+0000] {processor.py:157} INFO - Started process (PID=13944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:05.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:13:05.910+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:05.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:05.944+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:13:05.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:05.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:13:05.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:13:36.446+0000] {processor.py:157} INFO - Started process (PID=13969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:36.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:13:36.451+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:36.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:13:36.485+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:13:36.496+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:13:36.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:13:36.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:14:06.931+0000] {processor.py:157} INFO - Started process (PID=13994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:06.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:14:06.934+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:06.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:06.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:14:06.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:06.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:14:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:14:37.438+0000] {processor.py:157} INFO - Started process (PID=14019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:37.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:14:37.440+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:37.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:14:37.470+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:14:37.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:14:37.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:14:37.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:15:07.932+0000] {processor.py:157} INFO - Started process (PID=14044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:07.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:15:07.937+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:07.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:07.967+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:15:07.979+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:07.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:15:07.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T11:15:38.413+0000] {processor.py:157} INFO - Started process (PID=14069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:38.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:15:38.416+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:38.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:15:38.446+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:15:38.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:15:38.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:15:38.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:16:08.834+0000] {processor.py:157} INFO - Started process (PID=14094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:08.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:16:08.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:08.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:08.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:16:08.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:08.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:16:08.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-13T11:16:39.267+0000] {processor.py:157} INFO - Started process (PID=14119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:39.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:16:39.271+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:39.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:16:39.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:16:39.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:16:39.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:16:39.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T11:17:09.722+0000] {processor.py:157} INFO - Started process (PID=14144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:09.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:17:09.726+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:09.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:09.756+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:17:09.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:09.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:17:09.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T11:17:40.213+0000] {processor.py:157} INFO - Started process (PID=14169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:40.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:17:40.217+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:40.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:17:40.250+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:17:40.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:17:40.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:17:40.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:18:10.710+0000] {processor.py:157} INFO - Started process (PID=14194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:10.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:18:10.714+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:10.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:10.739+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:18:10.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:10.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:18:10.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T11:18:41.185+0000] {processor.py:157} INFO - Started process (PID=14219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:41.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:18:41.192+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:41.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:18:41.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:18:41.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:18:41.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:18:41.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T11:19:11.635+0000] {processor.py:157} INFO - Started process (PID=14244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:11.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:19:11.638+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:11.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:11.664+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:19:11.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:11.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:19:11.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:19:42.108+0000] {processor.py:157} INFO - Started process (PID=14269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:42.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:19:42.111+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:42.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:19:42.139+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:19:42.149+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:19:42.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:19:42.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T11:20:12.516+0000] {processor.py:157} INFO - Started process (PID=14294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:12.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:20:12.519+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:12.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:12.545+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:20:12.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:12.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:20:12.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:20:42.860+0000] {processor.py:157} INFO - Started process (PID=14319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:42.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:20:42.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:42.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:20:42.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:20:42.898+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:20:42.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:20:42.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T11:21:13.287+0000] {processor.py:157} INFO - Started process (PID=14344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:13.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:21:13.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:13.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:13.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:21:13.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:13.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:21:13.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:21:43.726+0000] {processor.py:157} INFO - Started process (PID=14369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:43.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:21:43.730+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:43.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:21:43.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:21:43.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:21:43.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:21:43.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T11:22:14.187+0000] {processor.py:157} INFO - Started process (PID=14394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:14.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:22:14.191+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:14.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:14.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:22:14.228+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:14.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:22:14.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:22:44.625+0000] {processor.py:157} INFO - Started process (PID=14419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:44.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:22:44.629+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:44.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:22:44.660+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:22:44.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:22:44.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:22:44.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:23:15.027+0000] {processor.py:157} INFO - Started process (PID=14444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:15.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:23:15.030+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:15.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:15.059+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:23:15.069+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:15.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:23:15.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T11:23:45.485+0000] {processor.py:157} INFO - Started process (PID=14469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:45.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:23:45.488+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:45.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:23:45.518+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:23:45.528+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:23:45.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:23:45.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:24:15.901+0000] {processor.py:157} INFO - Started process (PID=14494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:15.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:24:15.903+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:15.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:15.930+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:24:15.942+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:15.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:24:15.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:24:46.403+0000] {processor.py:157} INFO - Started process (PID=14519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:46.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:24:46.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:46.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:24:46.435+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:24:46.445+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:24:46.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:24:46.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:25:16.822+0000] {processor.py:157} INFO - Started process (PID=14544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:16.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:25:16.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:16.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:16.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:25:16.873+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:16.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:25:16.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T11:25:47.331+0000] {processor.py:157} INFO - Started process (PID=14569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:47.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:25:47.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:47.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:25:47.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:25:47.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:25:47.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:25:47.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T11:26:17.786+0000] {processor.py:157} INFO - Started process (PID=14594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:17.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:26:17.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:17.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:17.819+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:26:17.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:17.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:26:17.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T11:26:48.250+0000] {processor.py:157} INFO - Started process (PID=14619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:48.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:26:48.256+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:48.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:26:48.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:26:48.303+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:26:48.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:26:48.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T11:27:18.746+0000] {processor.py:157} INFO - Started process (PID=14644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:18.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:27:18.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:18.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:18.779+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:27:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:18.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:27:18.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T11:27:49.140+0000] {processor.py:157} INFO - Started process (PID=14669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:49.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:27:49.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:49.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:27:49.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:27:49.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:27:49.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:27:49.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:28:19.605+0000] {processor.py:157} INFO - Started process (PID=14694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:19.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:28:19.608+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:19.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:19.640+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:28:19.651+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:19.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:28:19.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T11:28:50.050+0000] {processor.py:157} INFO - Started process (PID=14719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:50.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:28:50.053+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:50.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:28:50.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:28:50.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:28:50.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:28:50.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:29:20.496+0000] {processor.py:157} INFO - Started process (PID=14744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:20.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:29:20.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:20.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:20.530+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:29:20.539+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:20.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:29:20.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:29:50.926+0000] {processor.py:157} INFO - Started process (PID=14769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:50.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:29:50.929+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:50.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:29:50.962+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:29:50.973+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:29:50.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:29:50.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:30:21.367+0000] {processor.py:157} INFO - Started process (PID=14794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:21.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:30:21.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:21.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:21.397+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:30:21.408+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:21.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:30:21.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:30:51.829+0000] {processor.py:157} INFO - Started process (PID=14819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:51.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:30:51.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:51.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:30:51.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:30:51.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:30:51.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:30:51.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T11:31:22.329+0000] {processor.py:157} INFO - Started process (PID=14844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:22.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:31:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:22.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:22.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:31:22.371+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:22.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:31:22.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:31:52.701+0000] {processor.py:157} INFO - Started process (PID=14869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:52.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:31:52.703+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:52.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:31:52.729+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:31:52.741+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:31:52.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:31:52.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T11:32:23.141+0000] {processor.py:157} INFO - Started process (PID=14894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:23.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:32:23.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:23.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:23.178+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:32:23.188+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:23.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:32:23.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:32:53.636+0000] {processor.py:157} INFO - Started process (PID=14919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:53.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:32:53.641+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:53.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:32:53.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:32:53.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:32:53.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:32:53.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:33:24.096+0000] {processor.py:157} INFO - Started process (PID=14944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:24.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:33:24.100+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:24.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:24.126+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:33:24.136+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:24.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:33:24.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T11:33:54.545+0000] {processor.py:157} INFO - Started process (PID=14969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:54.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:33:54.549+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:54.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:33:54.577+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:33:54.595+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:33:54.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:33:54.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T11:34:25.043+0000] {processor.py:157} INFO - Started process (PID=14994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:25.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:34:25.046+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:25.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:25.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:34:25.088+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:25.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:34:25.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T11:34:55.478+0000] {processor.py:157} INFO - Started process (PID=15019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:55.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:34:55.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:34:55.510+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:34:55.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:34:55.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:34:55.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:35:25.958+0000] {processor.py:157} INFO - Started process (PID=15044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:25.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:35:25.962+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:25.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:25.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:25.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:25.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:35:26.003+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:26.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:35:26.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:35:56.370+0000] {processor.py:157} INFO - Started process (PID=15069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:56.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:35:56.373+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:56.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:35:56.399+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:35:56.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:35:56.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:35:56.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T11:36:26.799+0000] {processor.py:157} INFO - Started process (PID=15094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:26.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:36:26.805+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:26.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:26.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:36:26.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:26.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:36:26.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T11:36:57.306+0000] {processor.py:157} INFO - Started process (PID=15119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:57.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:36:57.310+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:57.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:36:57.339+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:36:57.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:36:57.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:36:57.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T11:37:27.739+0000] {processor.py:157} INFO - Started process (PID=15144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:27.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:37:27.742+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:27.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:27.766+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:37:27.776+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:27.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:37:27.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T11:37:58.233+0000] {processor.py:157} INFO - Started process (PID=15169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:58.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:37:58.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:58.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:37:58.266+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:37:58.277+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:37:58.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:37:58.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:38:28.652+0000] {processor.py:157} INFO - Started process (PID=15194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:28.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:38:28.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:28.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:28.683+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:38:28.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:28.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:38:28.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:38:59.169+0000] {processor.py:157} INFO - Started process (PID=15219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:59.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:38:59.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:59.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:38:59.206+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:38:59.220+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:38:59.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:38:59.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T11:39:29.641+0000] {processor.py:157} INFO - Started process (PID=15244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:39:29.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:39:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:39:29.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:39:29.674+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:39:29.685+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:39:29.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:39:29.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:40:00.061+0000] {processor.py:157} INFO - Started process (PID=15269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:00.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:40:00.065+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:00.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:00.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:40:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:00.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:40:00.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T11:40:30.483+0000] {processor.py:157} INFO - Started process (PID=15294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:30.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:40:30.488+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:30.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:40:30.524+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:40:30.537+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:40:30.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:40:30.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T11:41:00.943+0000] {processor.py:157} INFO - Started process (PID=15319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:00.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:41:00.946+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:00.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:00.973+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:41:00.986+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:00.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:41:00.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:41:31.354+0000] {processor.py:157} INFO - Started process (PID=15344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:31.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:41:31.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:31.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:41:31.386+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:41:31.400+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:41:31.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:41:31.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T11:42:01.771+0000] {processor.py:157} INFO - Started process (PID=15369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:01.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:42:01.774+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:01.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:01.811+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:42:01.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:01.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:42:01.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T11:42:32.224+0000] {processor.py:157} INFO - Started process (PID=15394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:32.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:42:32.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:32.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:42:32.265+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:42:32.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:42:32.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:42:32.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T11:43:02.691+0000] {processor.py:157} INFO - Started process (PID=15419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:02.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:43:02.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:02.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:02.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:43:02.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:02.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:43:02.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:43:33.139+0000] {processor.py:157} INFO - Started process (PID=15444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:33.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:43:33.144+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:33.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:43:33.171+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:43:33.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:43:33.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:43:33.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:44:03.623+0000] {processor.py:157} INFO - Started process (PID=15469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:03.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:44:03.627+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:03.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:03.653+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:44:03.670+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:03.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:44:03.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T11:44:34.117+0000] {processor.py:157} INFO - Started process (PID=15494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:34.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:44:34.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:34.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:44:34.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:44:34.159+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:44:34.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:44:34.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:45:04.589+0000] {processor.py:157} INFO - Started process (PID=15519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:04.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:45:04.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:04.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:04.624+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:45:04.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:04.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:45:04.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T11:45:34.999+0000] {processor.py:157} INFO - Started process (PID=15544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:34.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:45:35.001+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:35.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:45:35.029+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:45:35.043+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:45:35.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:45:35.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:46:05.487+0000] {processor.py:157} INFO - Started process (PID=15569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:05.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:46:05.490+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:05.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:05.519+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:46:05.529+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:05.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:46:05.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T11:46:35.884+0000] {processor.py:157} INFO - Started process (PID=15594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:35.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:46:35.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:35.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:46:35.915+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:46:35.925+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:46:35.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:46:35.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T11:47:06.294+0000] {processor.py:157} INFO - Started process (PID=15619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:06.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:47:06.298+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:06.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:06.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:47:06.337+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:06.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:47:06.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:47:36.740+0000] {processor.py:157} INFO - Started process (PID=15644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:36.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:47:36.744+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:36.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:47:36.769+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:47:36.781+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:47:36.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:47:36.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T11:48:07.186+0000] {processor.py:157} INFO - Started process (PID=15669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:07.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:48:07.189+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:07.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:07.216+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:48:07.229+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:07.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:48:07.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:48:37.554+0000] {processor.py:157} INFO - Started process (PID=15694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:37.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:48:37.558+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:37.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:48:37.586+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:48:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:48:37.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:48:37.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:49:07.982+0000] {processor.py:157} INFO - Started process (PID=15719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:07.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:49:07.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:07.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:08.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:08.022+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:08.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:49:08.034+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:08.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:49:08.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T11:49:38.473+0000] {processor.py:157} INFO - Started process (PID=15744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:38.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:49:38.479+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:38.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:49:38.509+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:49:38.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:49:38.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:49:38.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T11:50:08.934+0000] {processor.py:157} INFO - Started process (PID=15769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:08.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:50:08.938+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:08.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:08.964+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:50:08.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:08.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:50:08.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:50:39.371+0000] {processor.py:157} INFO - Started process (PID=15794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:39.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:50:39.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:39.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:50:39.404+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:50:39.415+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:50:39.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:50:39.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T11:51:09.771+0000] {processor.py:157} INFO - Started process (PID=15819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:09.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:51:09.775+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:09.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:09.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:51:09.816+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:09.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:51:09.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T11:51:40.167+0000] {processor.py:157} INFO - Started process (PID=15844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:40.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:51:40.171+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:40.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:51:40.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:51:40.212+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:51:40.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:51:40.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T11:52:10.590+0000] {processor.py:157} INFO - Started process (PID=15869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:10.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:52:10.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:10.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:10.623+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:52:10.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:10.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:52:10.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:52:41.030+0000] {processor.py:157} INFO - Started process (PID=15894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:41.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:52:41.035+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:41.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:52:41.072+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:52:41.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:52:41.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:52:41.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T11:53:11.469+0000] {processor.py:157} INFO - Started process (PID=15919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:11.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:53:11.474+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:11.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:11.510+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:53:11.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:11.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:53:11.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T11:53:41.976+0000] {processor.py:157} INFO - Started process (PID=15944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:41.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:53:41.982+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:41.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:41.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:53:42.019+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:42.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:53:42.032+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:53:42.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:53:42.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T11:54:12.374+0000] {processor.py:157} INFO - Started process (PID=15969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:12.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:54:12.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:12.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:12.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:54:12.416+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:12.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:54:12.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T11:54:42.840+0000] {processor.py:157} INFO - Started process (PID=15994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:42.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:54:42.843+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:42.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:54:42.873+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:54:42.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:54:42.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:54:42.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T11:55:13.291+0000] {processor.py:157} INFO - Started process (PID=16019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:13.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:55:13.295+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:13.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:13.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:55:13.352+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:13.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:55:13.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T11:55:43.761+0000] {processor.py:157} INFO - Started process (PID=16044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:43.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:55:43.763+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:43.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:55:43.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:55:43.805+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:55:43.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:55:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T11:56:14.252+0000] {processor.py:157} INFO - Started process (PID=16069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:14.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:56:14.267+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:14.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:14.347+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:56:14.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:14.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:56:14.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-07-13T11:56:44.801+0000] {processor.py:157} INFO - Started process (PID=16094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:44.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:56:44.804+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:44.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:56:44.836+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:56:44.849+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:56:44.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:56:44.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T11:57:15.234+0000] {processor.py:157} INFO - Started process (PID=16119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:15.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:57:15.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:15.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:15.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:57:15.272+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:15.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:57:15.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T11:57:45.698+0000] {processor.py:157} INFO - Started process (PID=16144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:45.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:57:45.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:45.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:57:45.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:57:45.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:57:45.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:57:45.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-13T11:58:16.251+0000] {processor.py:157} INFO - Started process (PID=16169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:16.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:58:16.269+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:16.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:16.380+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:58:16.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:16.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:58:16.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-13T11:58:46.920+0000] {processor.py:157} INFO - Started process (PID=16194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:46.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:58:46.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:46.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:46.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:58:46.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:46.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:58:47.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:58:47.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:58:47.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-13T11:59:17.472+0000] {processor.py:157} INFO - Started process (PID=16219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:17.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:59:17.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:17.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:17.559+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:59:17.596+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:17.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:59:17.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-13T11:59:48.054+0000] {processor.py:157} INFO - Started process (PID=16244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:48.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T11:59:48.058+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:48.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T11:59:48.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T11:59:48.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T11:59:48.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T11:59:48.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T12:00:18.465+0000] {processor.py:157} INFO - Started process (PID=16269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:18.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:00:18.468+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:18.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:18.495+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:00:18.505+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:18.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:00:18.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:00:48.838+0000] {processor.py:157} INFO - Started process (PID=16294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:48.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:00:48.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:48.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:00:48.868+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:00:48.879+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:00:48.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:00:48.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:01:19.233+0000] {processor.py:157} INFO - Started process (PID=16319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:19.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:01:19.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:19.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:19.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:01:19.274+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:19.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:01:19.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:01:49.641+0000] {processor.py:157} INFO - Started process (PID=16344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:49.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:01:49.646+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:49.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:01:49.674+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:01:49.689+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:01:49.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:01:49.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T12:02:20.101+0000] {processor.py:157} INFO - Started process (PID=16369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:20.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:02:20.105+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:20.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:20.133+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:02:20.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:20.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:02:20.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T12:02:50.533+0000] {processor.py:157} INFO - Started process (PID=16394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:50.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:02:50.536+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:50.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:02:50.562+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:02:50.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:02:50.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:02:50.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T12:03:21.006+0000] {processor.py:157} INFO - Started process (PID=16419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:21.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:03:21.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:21.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:21.048+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:03:21.058+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:21.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:03:21.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T12:03:51.407+0000] {processor.py:157} INFO - Started process (PID=16444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:51.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:03:51.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:51.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:03:51.442+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:03:51.461+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:03:51.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:03:51.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T12:04:21.796+0000] {processor.py:157} INFO - Started process (PID=16469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:21.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:04:21.800+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:21.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:21.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:04:21.840+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:21.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:04:21.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:04:52.265+0000] {processor.py:157} INFO - Started process (PID=16494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:52.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:04:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:52.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:04:52.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:04:52.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:04:52.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:04:52.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:05:22.678+0000] {processor.py:157} INFO - Started process (PID=16519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:22.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:05:22.684+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:22.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:22.710+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:05:22.720+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:22.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:05:22.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:05:53.109+0000] {processor.py:157} INFO - Started process (PID=16544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:53.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:05:53.112+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:53.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:05:53.137+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:05:53.151+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:05:53.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:05:53.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:06:23.543+0000] {processor.py:157} INFO - Started process (PID=16569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:23.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:06:23.547+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:23.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:23.575+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:06:23.585+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:23.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:06:23.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:06:54.001+0000] {processor.py:157} INFO - Started process (PID=16594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:54.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:06:54.004+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:54.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:06:54.030+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:06:54.047+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:06:54.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:06:54.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:07:24.467+0000] {processor.py:157} INFO - Started process (PID=16619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:24.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:07:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:24.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:24.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:07:24.514+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:24.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:07:24.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T12:07:54.920+0000] {processor.py:157} INFO - Started process (PID=16644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:54.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:07:54.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:54.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:07:54.952+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:07:54.962+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:07:54.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:07:54.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:08:25.348+0000] {processor.py:157} INFO - Started process (PID=16669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:25.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:08:25.352+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:25.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:25.380+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:08:25.389+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:25.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:08:25.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:08:55.824+0000] {processor.py:157} INFO - Started process (PID=16694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:55.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:08:55.828+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:55.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:08:55.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:08:55.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:08:55.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:08:55.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:09:26.314+0000] {processor.py:157} INFO - Started process (PID=16719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:26.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:09:26.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:26.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:26.343+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:09:26.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:26.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:09:26.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:09:56.726+0000] {processor.py:157} INFO - Started process (PID=16744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:56.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:09:56.728+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:56.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:09:56.754+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:09:56.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:09:56.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:09:56.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T12:10:27.160+0000] {processor.py:157} INFO - Started process (PID=16769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:27.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:10:27.164+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:27.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:27.193+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:10:27.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:27.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:10:27.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:10:57.567+0000] {processor.py:157} INFO - Started process (PID=16794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:57.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:10:57.570+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:57.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:10:57.602+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:10:57.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:10:57.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:10:57.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:11:28.007+0000] {processor.py:157} INFO - Started process (PID=16819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:28.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:11:28.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:28.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:28.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:11:28.066+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:28.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:11:28.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-13T12:11:58.514+0000] {processor.py:157} INFO - Started process (PID=16844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:58.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:11:58.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:58.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:11:58.559+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:11:58.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:11:58.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:11:58.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T12:12:28.989+0000] {processor.py:157} INFO - Started process (PID=16869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:28.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:12:28.992+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:28.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:29.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:29.022+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:29.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:12:29.032+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:29.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:12:29.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:12:59.386+0000] {processor.py:157} INFO - Started process (PID=16894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:59.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:12:59.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:59.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:12:59.416+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:12:59.430+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:12:59.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:12:59.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:13:29.848+0000] {processor.py:157} INFO - Started process (PID=16919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:13:29.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:13:29.851+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:13:29.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:13:29.876+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:13:29.889+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:13:29.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:13:29.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:14:00.269+0000] {processor.py:157} INFO - Started process (PID=16944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:00.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:14:00.272+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:00.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:00.299+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:14:00.309+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:00.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:14:00.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:14:30.719+0000] {processor.py:157} INFO - Started process (PID=16969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:30.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:14:30.722+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:30.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:14:30.753+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:14:30.765+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:14:30.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:14:30.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:15:01.122+0000] {processor.py:157} INFO - Started process (PID=16994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:01.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:15:01.126+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:01.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:01.157+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:15:01.167+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:01.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:15:01.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:15:31.600+0000] {processor.py:157} INFO - Started process (PID=17019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:31.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:15:31.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:31.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:15:31.632+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:15:31.643+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:15:31.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:15:31.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:16:01.993+0000] {processor.py:157} INFO - Started process (PID=17044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:01.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:16:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:01.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:02.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:02.024+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:02.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:16:02.034+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:02.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:16:02.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:16:32.433+0000] {processor.py:157} INFO - Started process (PID=17069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:32.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:16:32.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:32.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:16:32.468+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:16:32.478+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:16:32.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:16:32.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:17:02.955+0000] {processor.py:157} INFO - Started process (PID=17094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:02.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:17:02.958+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:02.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:02.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:02.988+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:02.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:17:02.998+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:02.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:17:03.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:17:33.449+0000] {processor.py:157} INFO - Started process (PID=17119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:33.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:17:33.453+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:33.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:17:33.481+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:17:33.491+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:17:33.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:17:33.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:18:03.903+0000] {processor.py:157} INFO - Started process (PID=17144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:03.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:18:03.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:03.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:03.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:18:03.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:03.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:18:03.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:18:34.350+0000] {processor.py:157} INFO - Started process (PID=17169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:34.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:18:34.353+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:34.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:18:34.382+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:18:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:18:34.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:18:34.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:19:04.810+0000] {processor.py:157} INFO - Started process (PID=17194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:04.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:19:04.815+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:04.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:04.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:19:04.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:04.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:19:04.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:19:35.288+0000] {processor.py:157} INFO - Started process (PID=17219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:35.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:19:35.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:35.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:19:35.319+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:19:35.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:19:35.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:19:35.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T12:20:05.714+0000] {processor.py:157} INFO - Started process (PID=17244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:05.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:20:05.718+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:05.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:20:05.761+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:05.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:20:05.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T12:20:36.171+0000] {processor.py:157} INFO - Started process (PID=17269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:36.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:20:36.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:36.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:20:36.203+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:20:36.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:20:36.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:20:36.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:21:06.665+0000] {processor.py:157} INFO - Started process (PID=17294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:06.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:21:06.668+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:06.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:06.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:21:06.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:06.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:21:06.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:21:37.074+0000] {processor.py:157} INFO - Started process (PID=17319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:37.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:21:37.076+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:37.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:21:37.103+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:21:37.120+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:21:37.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:21:37.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:22:07.559+0000] {processor.py:157} INFO - Started process (PID=17344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:07.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:22:07.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:07.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:22:07.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:07.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:22:07.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:22:37.979+0000] {processor.py:157} INFO - Started process (PID=17369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:37.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:22:37.982+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:37.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:37.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:22:38.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:38.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:22:38.023+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:22:38.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:22:38.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:23:08.437+0000] {processor.py:157} INFO - Started process (PID=17394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:08.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:23:08.443+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:08.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:08.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:23:08.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:08.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:23:08.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:23:38.904+0000] {processor.py:157} INFO - Started process (PID=17419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:38.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:23:38.911+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:38.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:23:38.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:23:38.963+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:23:38.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:23:38.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T12:24:09.374+0000] {processor.py:157} INFO - Started process (PID=17444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:09.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:24:09.377+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:09.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:09.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:24:09.420+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:09.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:24:09.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:24:39.915+0000] {processor.py:157} INFO - Started process (PID=17469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:39.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:24:39.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:39.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:24:39.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:24:39.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:24:39.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:24:40.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-13T12:25:10.418+0000] {processor.py:157} INFO - Started process (PID=17494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:10.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:25:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:10.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:10.450+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:25:10.462+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:10.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:25:10.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:25:40.861+0000] {processor.py:157} INFO - Started process (PID=17519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:40.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:25:40.864+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:40.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:25:40.897+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:25:40.909+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:25:40.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:25:40.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T12:26:11.337+0000] {processor.py:157} INFO - Started process (PID=17544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:11.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:26:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:11.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:11.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:26:11.387+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:11.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:26:11.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T12:26:41.816+0000] {processor.py:157} INFO - Started process (PID=17569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:41.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:26:41.821+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:41.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:26:41.852+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:26:41.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:26:41.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:26:41.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:27:12.222+0000] {processor.py:157} INFO - Started process (PID=17594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:12.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:27:12.225+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:12.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:12.257+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:27:12.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:12.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:27:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:27:42.675+0000] {processor.py:157} INFO - Started process (PID=17619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:42.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:27:42.678+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:42.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:27:42.714+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:27:42.728+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:27:42.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:27:42.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T12:28:13.109+0000] {processor.py:157} INFO - Started process (PID=17644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:13.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:28:13.112+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:13.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:13.143+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:28:13.153+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:13.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:28:13.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:28:43.548+0000] {processor.py:157} INFO - Started process (PID=17669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:43.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:28:43.551+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:43.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:28:43.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:28:43.590+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:28:43.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:28:43.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:29:13.922+0000] {processor.py:157} INFO - Started process (PID=17694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:13.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:29:13.925+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:13.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:13.955+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:29:13.965+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:13.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:29:13.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:29:44.314+0000] {processor.py:157} INFO - Started process (PID=17719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:44.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:29:44.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:44.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:29:44.345+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:29:44.355+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:29:44.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:29:44.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:30:14.698+0000] {processor.py:157} INFO - Started process (PID=17744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:14.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:30:14.703+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:14.731+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:30:14.741+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:14.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:30:14.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:30:45.115+0000] {processor.py:157} INFO - Started process (PID=17769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:45.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:30:45.121+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:45.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:30:45.151+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:30:45.162+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:30:45.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:30:45.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:31:15.568+0000] {processor.py:157} INFO - Started process (PID=17794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:15.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:31:15.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:15.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:15.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:31:15.623+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:15.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:31:15.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T12:31:46.035+0000] {processor.py:157} INFO - Started process (PID=17819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:46.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:31:46.038+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:46.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:31:46.071+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:31:46.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:31:46.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:31:46.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:32:16.491+0000] {processor.py:157} INFO - Started process (PID=17844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:16.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:32:16.495+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:16.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:16.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:32:16.535+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:16.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:32:16.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:32:46.930+0000] {processor.py:157} INFO - Started process (PID=17869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:46.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:32:46.933+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:46.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:32:46.960+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:32:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:32:46.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:32:46.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:33:17.385+0000] {processor.py:157} INFO - Started process (PID=17894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:17.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:33:17.388+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:17.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:17.421+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:33:17.432+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:17.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:33:17.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T12:33:47.788+0000] {processor.py:157} INFO - Started process (PID=17919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:47.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:33:47.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:47.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:33:47.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:33:47.838+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:33:47.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:33:47.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T12:34:18.274+0000] {processor.py:157} INFO - Started process (PID=17944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:18.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:34:18.278+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:18.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:18.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:34:18.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:18.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:34:18.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:34:48.719+0000] {processor.py:157} INFO - Started process (PID=17969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:48.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:34:48.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:48.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:34:48.747+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:34:48.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:34:48.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:34:48.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-13T12:35:19.144+0000] {processor.py:157} INFO - Started process (PID=17994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:19.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:35:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:19.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:19.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:35:19.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:19.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:35:19.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T12:35:49.610+0000] {processor.py:157} INFO - Started process (PID=18019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:49.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:35:49.613+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:49.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:35:49.640+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:35:49.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:35:49.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:35:49.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:36:20.062+0000] {processor.py:157} INFO - Started process (PID=18044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:20.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:36:20.065+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:20.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:20.091+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:36:20.101+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:20.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:36:20.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:36:50.513+0000] {processor.py:157} INFO - Started process (PID=18069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:50.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:36:50.516+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:50.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:36:50.550+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:36:50.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:36:50.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:36:50.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:37:20.890+0000] {processor.py:157} INFO - Started process (PID=18094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:20.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:37:20.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:20.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:20.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:37:20.937+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:20.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:37:20.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:37:51.330+0000] {processor.py:157} INFO - Started process (PID=18119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:51.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:37:51.334+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:51.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:37:51.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:37:51.376+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:37:51.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:37:51.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:38:21.787+0000] {processor.py:157} INFO - Started process (PID=18144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:21.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:38:21.795+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:21.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:21.831+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:38:21.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:21.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:38:21.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T12:38:52.318+0000] {processor.py:157} INFO - Started process (PID=18169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:52.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:38:52.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:52.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:38:52.392+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:38:52.406+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:38:52.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:38:52.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-13T12:39:22.832+0000] {processor.py:157} INFO - Started process (PID=18194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:22.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:39:22.836+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:22.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:22.867+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:39:22.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:22.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:39:22.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:39:53.277+0000] {processor.py:157} INFO - Started process (PID=18219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:53.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:39:53.282+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:53.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:39:53.330+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:39:53.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:39:53.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:39:53.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-13T12:40:23.801+0000] {processor.py:157} INFO - Started process (PID=18244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:23.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:40:23.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:23.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:23.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:40:23.859+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:23.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:40:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T12:40:54.324+0000] {processor.py:157} INFO - Started process (PID=18269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:54.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:40:54.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:54.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:40:54.369+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:40:54.382+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:40:54.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:40:54.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-13T12:41:24.801+0000] {processor.py:157} INFO - Started process (PID=18294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:24.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:41:24.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:24.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:24.855+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:41:24.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:24.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:41:24.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-13T12:41:55.266+0000] {processor.py:157} INFO - Started process (PID=18319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:55.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:41:55.270+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:55.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:41:55.302+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:41:55.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:41:55.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:41:55.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T12:42:25.644+0000] {processor.py:157} INFO - Started process (PID=18344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:25.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:42:25.650+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:25.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:25.679+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:42:25.690+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:25.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:42:25.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:42:56.011+0000] {processor.py:157} INFO - Started process (PID=18369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:56.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:42:56.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:56.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:42:56.038+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:42:56.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:42:56.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:42:56.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:43:26.481+0000] {processor.py:157} INFO - Started process (PID=18394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:26.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:43:26.486+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:26.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:26.514+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:43:26.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:26.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:43:26.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:43:56.936+0000] {processor.py:157} INFO - Started process (PID=18419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:56.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:43:56.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:56.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:43:56.969+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:43:56.979+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:43:56.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:43:56.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:44:27.411+0000] {processor.py:157} INFO - Started process (PID=18444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:27.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:44:27.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:27.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:27.441+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:44:27.451+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:27.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:44:27.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:44:57.855+0000] {processor.py:157} INFO - Started process (PID=18469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:57.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:44:57.859+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:57.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:44:57.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:44:57.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:44:57.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:44:57.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:45:28.312+0000] {processor.py:157} INFO - Started process (PID=18494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:28.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:45:28.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:28.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:28.343+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:45:28.356+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:28.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:45:28.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:45:58.771+0000] {processor.py:157} INFO - Started process (PID=18519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:58.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:45:58.775+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:58.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:45:58.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:45:58.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:45:58.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:45:58.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:46:29.198+0000] {processor.py:157} INFO - Started process (PID=18544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:29.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:46:29.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:29.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:29.226+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:46:29.236+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:29.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:46:29.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T12:46:59.613+0000] {processor.py:157} INFO - Started process (PID=18569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:59.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:46:59.617+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:59.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:46:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:46:59.655+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:46:59.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:46:59.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:47:30.022+0000] {processor.py:157} INFO - Started process (PID=18594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:47:30.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:47:30.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:47:30.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:47:30.063+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:47:30.075+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:47:30.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:47:30.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T12:48:00.460+0000] {processor.py:157} INFO - Started process (PID=18619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:00.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:48:00.463+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:00.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:00.489+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:48:00.499+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:00.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:48:00.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:48:30.874+0000] {processor.py:157} INFO - Started process (PID=18644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:30.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:48:30.880+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:30.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:48:30.912+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:48:30.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:48:30.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:48:30.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T12:49:01.291+0000] {processor.py:157} INFO - Started process (PID=18669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:01.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:49:01.297+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:01.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:01.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:49:01.348+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:01.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:49:01.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-13T12:49:31.785+0000] {processor.py:157} INFO - Started process (PID=18694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:31.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:49:31.790+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:31.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:49:31.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:49:31.827+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:49:31.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:49:31.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:50:02.224+0000] {processor.py:157} INFO - Started process (PID=18719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:02.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:50:02.227+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:02.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:02.251+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:50:02.262+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:02.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:50:02.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-13T12:50:32.664+0000] {processor.py:157} INFO - Started process (PID=18744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:32.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:50:32.667+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:32.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:50:32.694+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:50:32.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:50:32.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:50:32.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:51:03.089+0000] {processor.py:157} INFO - Started process (PID=18769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:03.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:51:03.091+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:03.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:03.120+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:51:03.130+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:03.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:51:03.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:51:33.516+0000] {processor.py:157} INFO - Started process (PID=18794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:33.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:51:33.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:33.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:51:33.546+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:51:33.560+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:51:33.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:51:33.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:52:04.008+0000] {processor.py:157} INFO - Started process (PID=18819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:04.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:52:04.011+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:04.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:04.039+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:52:04.049+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:04.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:52:04.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:52:34.402+0000] {processor.py:157} INFO - Started process (PID=18844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:34.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:52:34.407+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:34.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:52:34.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:52:34.449+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:52:34.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:52:34.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T12:53:04.818+0000] {processor.py:157} INFO - Started process (PID=18869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:04.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:53:04.822+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:04.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:04.850+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:53:04.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:04.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:53:04.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T12:53:35.280+0000] {processor.py:157} INFO - Started process (PID=18894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:35.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:53:35.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:35.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:53:35.310+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:53:35.322+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:53:35.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:53:35.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T12:54:05.708+0000] {processor.py:157} INFO - Started process (PID=18919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:05.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:54:05.712+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:05.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:05.739+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:54:05.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:05.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:54:05.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:54:36.142+0000] {processor.py:157} INFO - Started process (PID=18944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:36.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:54:36.147+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:36.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:54:36.179+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:54:36.189+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:54:36.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:54:36.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T12:55:06.557+0000] {processor.py:157} INFO - Started process (PID=18969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:06.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:55:06.561+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:06.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:06.587+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:55:06.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:06.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:55:06.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T12:55:36.980+0000] {processor.py:157} INFO - Started process (PID=18994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:36.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:55:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:36.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:36.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:55:37.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:37.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:55:37.021+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:55:37.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:55:37.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T12:56:07.432+0000] {processor.py:157} INFO - Started process (PID=19019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:07.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:56:07.435+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:07.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:56:07.478+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:07.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:56:07.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:56:37.828+0000] {processor.py:157} INFO - Started process (PID=19044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:37.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:56:37.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:37.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:56:37.862+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:56:37.875+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:56:37.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:56:37.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T12:57:08.304+0000] {processor.py:157} INFO - Started process (PID=19069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:08.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:57:08.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:08.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:08.341+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:57:08.350+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:08.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:57:08.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T12:57:38.746+0000] {processor.py:157} INFO - Started process (PID=19094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:38.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:57:38.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:38.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:57:38.773+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:57:38.782+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:57:38.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:57:38.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-13T12:58:09.181+0000] {processor.py:157} INFO - Started process (PID=19119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:09.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:58:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:09.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:09.213+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:58:09.223+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:09.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:58:09.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T12:58:39.610+0000] {processor.py:157} INFO - Started process (PID=19144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:39.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:58:39.617+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:39.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:58:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:58:39.661+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:58:39.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:58:39.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T12:59:10.099+0000] {processor.py:157} INFO - Started process (PID=19169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:10.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:59:10.104+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:10.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:10.129+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:59:10.139+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:10.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:59:10.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T12:59:40.577+0000] {processor.py:157} INFO - Started process (PID=19194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:40.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T12:59:40.581+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:40.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T12:59:40.610+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T12:59:40.620+0000] {logging_mixin.py:151} INFO - [2024-07-13T12:59:40.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T12:59:40.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:00:10.955+0000] {processor.py:157} INFO - Started process (PID=19219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:10.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:00:10.958+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:10.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:10.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:10.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:10.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:00:10.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:10.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:00:11.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:00:41.379+0000] {processor.py:157} INFO - Started process (PID=19244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:41.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:00:41.382+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:41.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:00:41.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:00:41.422+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:00:41.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:00:41.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:01:11.830+0000] {processor.py:157} INFO - Started process (PID=19269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:11.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:01:11.834+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:11.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:11.872+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:01:11.884+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:11.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:01:11.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T13:01:42.296+0000] {processor.py:157} INFO - Started process (PID=19294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:42.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:01:42.299+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:42.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:01:42.336+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:01:42.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:01:42.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:01:42.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T13:02:12.782+0000] {processor.py:157} INFO - Started process (PID=19319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:12.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:02:12.785+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:12.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:12.815+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:02:12.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:12.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:02:12.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:02:43.239+0000] {processor.py:157} INFO - Started process (PID=19344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:43.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:02:43.245+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:43.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:02:43.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:02:43.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:02:43.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:02:43.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T13:03:13.646+0000] {processor.py:157} INFO - Started process (PID=19369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:13.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:03:13.650+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:13.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:13.678+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:03:13.687+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:13.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:03:13.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:03:44.064+0000] {processor.py:157} INFO - Started process (PID=19394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:44.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:03:44.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:44.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:03:44.096+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:03:44.107+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:03:44.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:03:44.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:04:14.458+0000] {processor.py:157} INFO - Started process (PID=19419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:14.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:04:14.463+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:14.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:14.492+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:04:14.502+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:14.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:04:14.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:04:44.885+0000] {processor.py:157} INFO - Started process (PID=19444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:44.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:04:44.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:44.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:04:44.913+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:04:44.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:04:44.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:04:44.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-13T13:05:15.342+0000] {processor.py:157} INFO - Started process (PID=19469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:15.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:05:15.347+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:15.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:15.375+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:05:15.386+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:15.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:05:15.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:05:45.810+0000] {processor.py:157} INFO - Started process (PID=19494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:45.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:05:45.818+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:45.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:05:45.859+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:05:45.873+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:05:45.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:05:45.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T13:06:16.301+0000] {processor.py:157} INFO - Started process (PID=19519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:16.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:06:16.304+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:16.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:16.332+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:06:16.345+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:16.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:06:16.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:06:46.758+0000] {processor.py:157} INFO - Started process (PID=19544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:46.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:06:46.762+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:46.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:06:46.789+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:06:46.800+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:06:46.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:06:46.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:07:17.163+0000] {processor.py:157} INFO - Started process (PID=19569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:17.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:07:17.166+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:17.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:17.190+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:07:17.201+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:17.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:07:17.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:07:47.567+0000] {processor.py:157} INFO - Started process (PID=19594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:47.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:07:47.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:47.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:07:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:07:47.609+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:07:47.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:07:47.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:08:17.990+0000] {processor.py:157} INFO - Started process (PID=19619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:17.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:08:17.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:17.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:18.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:18.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:08:18.026+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:18.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:08:18.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-13T13:08:48.401+0000] {processor.py:157} INFO - Started process (PID=19644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:48.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:08:48.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:48.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:08:48.430+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:08:48.445+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:08:48.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:08:48.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:09:18.860+0000] {processor.py:157} INFO - Started process (PID=19669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:18.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:09:18.866+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:18.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:18.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:09:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:18.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:09:18.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:09:49.332+0000] {processor.py:157} INFO - Started process (PID=19694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:49.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:09:49.339+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:49.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:09:49.385+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:09:49.400+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:09:49.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:09:49.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-13T13:10:19.843+0000] {processor.py:157} INFO - Started process (PID=19719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:19.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:10:19.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:19.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:19.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:10:19.888+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:19.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:10:19.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:10:50.283+0000] {processor.py:157} INFO - Started process (PID=19744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:50.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:10:50.286+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:50.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:10:50.318+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:10:50.328+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:10:50.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:10:50.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T13:11:20.701+0000] {processor.py:157} INFO - Started process (PID=19769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:20.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:11:20.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:20.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:20.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:11:20.743+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:20.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:11:20.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:11:51.225+0000] {processor.py:157} INFO - Started process (PID=19794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:51.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:11:51.233+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:51.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:11:51.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:11:51.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:11:51.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:11:51.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-13T13:12:21.748+0000] {processor.py:157} INFO - Started process (PID=19819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:21.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:12:21.755+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:21.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:21.790+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:12:21.802+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:21.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:12:21.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T13:12:52.268+0000] {processor.py:157} INFO - Started process (PID=19844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:52.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:12:52.277+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:52.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:12:52.356+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:12:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:12:52.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:12:52.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-13T13:13:22.809+0000] {processor.py:157} INFO - Started process (PID=19869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:22.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:13:22.813+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:22.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:22.845+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:13:22.858+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:22.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:13:22.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:13:53.378+0000] {processor.py:157} INFO - Started process (PID=19894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:53.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:13:53.386+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:53.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:13:53.458+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:13:53.477+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:13:53.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:13:53.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-13T13:14:23.944+0000] {processor.py:157} INFO - Started process (PID=19919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:23.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:14:23.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:23.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:24.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:24.052+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:24.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:14:24.082+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:24.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:14:24.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-07-13T13:14:54.564+0000] {processor.py:157} INFO - Started process (PID=19944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:54.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:14:54.567+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:54.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:14:54.597+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:14:54.608+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:14:54.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:14:54.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:15:25.015+0000] {processor.py:157} INFO - Started process (PID=19969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:25.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:15:25.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:25.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:25.048+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:15:25.058+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:25.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:15:25.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:15:55.465+0000] {processor.py:157} INFO - Started process (PID=19994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:55.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:15:55.471+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:55.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:15:55.512+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:15:55.526+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:15:55.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:15:55.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-13T13:16:25.962+0000] {processor.py:157} INFO - Started process (PID=20019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:25.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:16:25.967+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:25.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:25.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:25.995+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:25.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:16:26.006+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:26.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:16:26.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T13:16:56.400+0000] {processor.py:157} INFO - Started process (PID=20044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:56.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:16:56.404+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:56.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:16:56.429+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:16:56.439+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:16:56.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:16:56.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T13:17:26.797+0000] {processor.py:157} INFO - Started process (PID=20069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:26.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:17:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:26.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:26.829+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:17:26.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:26.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:17:26.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:17:57.209+0000] {processor.py:157} INFO - Started process (PID=20094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:57.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:17:57.212+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:57.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:17:57.237+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:17:57.247+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:17:57.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:17:57.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T13:18:27.548+0000] {processor.py:157} INFO - Started process (PID=20119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:27.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:18:27.552+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:27.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:27.579+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:18:27.591+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:27.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:18:27.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:18:57.992+0000] {processor.py:157} INFO - Started process (PID=20144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:57.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:18:57.996+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:57.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:58.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:18:58.025+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:58.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:18:58.036+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:18:58.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:18:58.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:19:28.433+0000] {processor.py:157} INFO - Started process (PID=20169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:28.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:19:28.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:28.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:28.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:19:28.475+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:28.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:19:28.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:19:58.851+0000] {processor.py:157} INFO - Started process (PID=20194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:58.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:19:58.854+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:58.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:19:58.883+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:19:58.899+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:19:58.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:19:58.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:20:29.326+0000] {processor.py:157} INFO - Started process (PID=20219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:29.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:20:29.331+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:29.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:29.356+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:20:29.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:29.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:20:29.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:20:59.710+0000] {processor.py:157} INFO - Started process (PID=20244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:59.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:20:59.713+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:59.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:20:59.739+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:20:59.753+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:20:59.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:20:59.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:21:30.214+0000] {processor.py:157} INFO - Started process (PID=20269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:21:30.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:21:30.219+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:21:30.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:21:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:21:30.257+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:21:30.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:21:30.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:22:00.693+0000] {processor.py:157} INFO - Started process (PID=20294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:00.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:22:00.696+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:00.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:00.723+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:22:00.734+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:00.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:22:00.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T13:22:31.096+0000] {processor.py:157} INFO - Started process (PID=20319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:31.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:22:31.099+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:31.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:22:31.127+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:22:31.137+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:22:31.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:22:31.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:23:01.610+0000] {processor.py:157} INFO - Started process (PID=20344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:01.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:23:01.613+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:01.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:01.647+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:23:01.657+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:01.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:23:01.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T13:23:32.029+0000] {processor.py:157} INFO - Started process (PID=20369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:32.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:23:32.033+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:32.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:23:32.070+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:23:32.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:23:32.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:23:32.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T13:24:02.490+0000] {processor.py:157} INFO - Started process (PID=20394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:02.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:24:02.494+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:02.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:02.520+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:24:02.530+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:02.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:24:02.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T13:24:32.870+0000] {processor.py:157} INFO - Started process (PID=20419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:32.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:24:32.875+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:32.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:24:32.900+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:24:32.916+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:24:32.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:24:32.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:25:03.347+0000] {processor.py:157} INFO - Started process (PID=20444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:03.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:25:03.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:03.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:03.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:25:03.391+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:03.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:25:03.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:25:33.801+0000] {processor.py:157} INFO - Started process (PID=20469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:33.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:25:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:33.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:25:33.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:25:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:25:33.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:25:33.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-13T13:26:04.210+0000] {processor.py:157} INFO - Started process (PID=20494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:04.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:26:04.214+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:04.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:04.241+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:26:04.251+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:04.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:26:04.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:26:34.711+0000] {processor.py:157} INFO - Started process (PID=20519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:34.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:26:34.715+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:34.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:26:34.740+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:26:34.751+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:26:34.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:26:34.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:27:05.126+0000] {processor.py:157} INFO - Started process (PID=20544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:05.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:27:05.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:05.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:05.158+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:27:05.172+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:05.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:27:05.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:27:35.643+0000] {processor.py:157} INFO - Started process (PID=20569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:35.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:27:35.647+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:35.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:27:35.673+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:27:35.684+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:27:35.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:27:35.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:28:06.082+0000] {processor.py:157} INFO - Started process (PID=20594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:06.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:28:06.086+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:06.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:06.113+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:28:06.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:06.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:28:06.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:28:36.524+0000] {processor.py:157} INFO - Started process (PID=20619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:36.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:28:36.528+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:36.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:28:36.557+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:28:36.570+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:28:36.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:28:36.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:29:06.948+0000] {processor.py:157} INFO - Started process (PID=20644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:06.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:29:06.951+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:06.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:06.972+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:29:06.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:06.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:29:06.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-13T13:29:37.435+0000] {processor.py:157} INFO - Started process (PID=20669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:37.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:29:37.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:37.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:29:37.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:29:37.475+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:29:37.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:29:37.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:30:07.834+0000] {processor.py:157} INFO - Started process (PID=20694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:07.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:30:07.838+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:07.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:07.865+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:30:07.877+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:07.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:30:07.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:30:38.275+0000] {processor.py:157} INFO - Started process (PID=20719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:38.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:30:38.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:38.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:30:38.311+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:30:38.325+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:30:38.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:30:38.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T13:31:08.756+0000] {processor.py:157} INFO - Started process (PID=20744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:08.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:31:08.759+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:08.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:08.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:31:08.810+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:08.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:31:08.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T13:31:39.279+0000] {processor.py:157} INFO - Started process (PID=20769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:39.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:31:39.288+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:39.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:31:39.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:31:39.361+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:31:39.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:31:39.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-13T13:32:09.713+0000] {processor.py:157} INFO - Started process (PID=20794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:09.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:32:09.715+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:09.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:09.742+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:32:09.752+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:09.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:32:09.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T13:32:40.168+0000] {processor.py:157} INFO - Started process (PID=20819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:40.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:32:40.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:40.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:32:40.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:32:40.232+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:32:40.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:32:40.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-13T13:33:10.663+0000] {processor.py:157} INFO - Started process (PID=20844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:10.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:33:10.666+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:10.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:10.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:33:10.705+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:10.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:33:10.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:33:41.067+0000] {processor.py:157} INFO - Started process (PID=20869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:41.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:33:41.071+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:41.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:33:41.110+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:33:41.122+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:33:41.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:33:41.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-13T13:34:11.566+0000] {processor.py:157} INFO - Started process (PID=20894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:11.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:34:11.569+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:11.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:11.599+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:34:11.609+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:11.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:34:11.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:34:41.974+0000] {processor.py:157} INFO - Started process (PID=20919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:41.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:34:41.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:41.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:41.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:34:42.003+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:42.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:34:42.013+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:34:42.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:34:42.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:35:12.357+0000] {processor.py:157} INFO - Started process (PID=20944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:12.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:35:12.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:12.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:12.392+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:35:12.403+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:12.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:35:12.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:35:42.773+0000] {processor.py:157} INFO - Started process (PID=20969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:42.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:35:42.776+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:42.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:35:42.802+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:35:42.815+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:35:42.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:35:42.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:36:13.166+0000] {processor.py:157} INFO - Started process (PID=20994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:13.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:36:13.170+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:13.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:13.203+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:36:13.215+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:13.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:36:13.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T13:36:43.676+0000] {processor.py:157} INFO - Started process (PID=21019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:43.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:36:43.680+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:43.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:36:43.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:36:43.723+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:36:43.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:36:43.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:37:14.094+0000] {processor.py:157} INFO - Started process (PID=21044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:14.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:37:14.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:14.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:14.131+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:37:14.141+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:14.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:37:14.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:37:44.515+0000] {processor.py:157} INFO - Started process (PID=21069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:44.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:37:44.518+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:44.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:37:44.546+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:37:44.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:37:44.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:37:44.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T13:38:14.972+0000] {processor.py:157} INFO - Started process (PID=21094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:14.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:38:14.976+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:14.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:14.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:15.007+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:15.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:38:15.018+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:15.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:38:15.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T13:38:45.388+0000] {processor.py:157} INFO - Started process (PID=21119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:45.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:38:45.393+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:45.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:38:45.434+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:38:45.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:38:45.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:38:45.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T13:39:15.838+0000] {processor.py:157} INFO - Started process (PID=21144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:15.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:39:15.842+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:15.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:15.872+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:39:15.884+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:15.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:39:15.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:39:46.306+0000] {processor.py:157} INFO - Started process (PID=21169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:46.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:39:46.308+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:46.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:39:46.335+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:39:46.346+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:39:46.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:39:46.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:40:16.754+0000] {processor.py:157} INFO - Started process (PID=21194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:16.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:40:16.757+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:16.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:16.786+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:40:16.796+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:16.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:40:16.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:40:47.205+0000] {processor.py:157} INFO - Started process (PID=21219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:47.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:40:47.209+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:47.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:40:47.236+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:40:47.247+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:40:47.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:40:47.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:41:17.664+0000] {processor.py:157} INFO - Started process (PID=21244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:17.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:41:17.667+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:17.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:17.696+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:41:17.709+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:17.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:41:17.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:41:48.131+0000] {processor.py:157} INFO - Started process (PID=21269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:48.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:41:48.136+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:48.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:41:48.163+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:41:48.174+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:41:48.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:41:48.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:42:18.534+0000] {processor.py:157} INFO - Started process (PID=21294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:18.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:42:18.539+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:18.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:18.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:42:18.584+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:18.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:42:18.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T13:42:48.958+0000] {processor.py:157} INFO - Started process (PID=21319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:48.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:42:48.963+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:48.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:48.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:42:48.997+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:48.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:42:49.009+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:42:49.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:42:49.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T13:43:19.435+0000] {processor.py:157} INFO - Started process (PID=21344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:19.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:43:19.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:19.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:19.461+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:43:19.475+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:19.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:43:19.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:43:49.852+0000] {processor.py:157} INFO - Started process (PID=21369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:49.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:43:49.857+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:49.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:43:49.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:43:49.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:43:49.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:43:49.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:44:20.321+0000] {processor.py:157} INFO - Started process (PID=21394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:20.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:44:20.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:20.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:20.365+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:44:20.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:20.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:44:20.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T13:44:50.804+0000] {processor.py:157} INFO - Started process (PID=21419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:50.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:44:50.807+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:50.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:44:50.844+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:44:50.856+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:44:50.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:44:50.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T13:45:21.305+0000] {processor.py:157} INFO - Started process (PID=21444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:21.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:45:21.310+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:21.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:21.342+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:45:21.355+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:21.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:45:21.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T13:45:51.715+0000] {processor.py:157} INFO - Started process (PID=21469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:51.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:45:51.719+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:51.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:45:51.750+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:45:51.760+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:45:51.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:45:51.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:46:22.188+0000] {processor.py:157} INFO - Started process (PID=21494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:22.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:46:22.190+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:22.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:22.215+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:46:22.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:22.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:46:22.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-13T13:46:52.601+0000] {processor.py:157} INFO - Started process (PID=21519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:52.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:46:52.604+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:52.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:46:52.634+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:46:52.644+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:46:52.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:46:52.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:47:23.063+0000] {processor.py:157} INFO - Started process (PID=21544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:23.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:47:23.067+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:23.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:23.098+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:47:23.109+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:23.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:47:23.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T13:47:53.542+0000] {processor.py:157} INFO - Started process (PID=21569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:53.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:47:53.545+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:53.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:47:53.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:47:53.583+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:47:53.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:47:53.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:48:23.971+0000] {processor.py:157} INFO - Started process (PID=21594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:23.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:48:23.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:23.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:23.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:24.001+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:24.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:48:24.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:24.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:48:24.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:48:54.360+0000] {processor.py:157} INFO - Started process (PID=21619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:54.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:48:54.364+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:54.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:48:54.390+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:48:54.400+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:48:54.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:48:54.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:49:24.765+0000] {processor.py:157} INFO - Started process (PID=21644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:24.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:49:24.769+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:24.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:24.801+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:49:24.812+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:24.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:49:24.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:49:55.237+0000] {processor.py:157} INFO - Started process (PID=21669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:55.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:49:55.240+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:55.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:49:55.265+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:49:55.278+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:49:55.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:49:55.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:50:25.646+0000] {processor.py:157} INFO - Started process (PID=21694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:25.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:50:25.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:25.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:25.672+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:50:25.682+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:25.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:50:25.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-13T13:50:56.090+0000] {processor.py:157} INFO - Started process (PID=21719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:56.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:50:56.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:56.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:50:56.120+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:50:56.130+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:50:56.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:50:56.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T13:51:26.531+0000] {processor.py:157} INFO - Started process (PID=21744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:26.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:51:26.535+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:26.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:26.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:51:26.577+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:26.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:51:26.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:51:56.974+0000] {processor.py:157} INFO - Started process (PID=21769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:56.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:51:56.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:56.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:56.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:51:57.007+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:57.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:51:57.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:51:57.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:51:57.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:52:27.377+0000] {processor.py:157} INFO - Started process (PID=21794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:27.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:52:27.381+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:27.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:27.410+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:52:27.421+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:27.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:52:27.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T13:52:57.800+0000] {processor.py:157} INFO - Started process (PID=21819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:57.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:52:57.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:57.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:52:57.826+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:52:57.841+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:52:57.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:52:57.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T13:53:28.210+0000] {processor.py:157} INFO - Started process (PID=21844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:28.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:53:28.218+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:28.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:28.257+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:53:28.268+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:28.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:53:28.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T13:53:58.688+0000] {processor.py:157} INFO - Started process (PID=21869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:58.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:53:58.691+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:58.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:53:58.720+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:53:58.730+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:53:58.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:53:58.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:54:28.977+0000] {processor.py:157} INFO - Started process (PID=21894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:28.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:54:28.981+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:28.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:28.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:29.007+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:29.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:54:29.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:29.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:54:29.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-13T13:54:59.407+0000] {processor.py:157} INFO - Started process (PID=21919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:59.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:54:59.411+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:59.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:54:59.437+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:54:59.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:54:59.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:54:59.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T13:55:29.828+0000] {processor.py:157} INFO - Started process (PID=21944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:55:29.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:55:29.832+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:55:29.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:55:29.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:55:29.871+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:55:29.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:55:29.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T13:56:00.283+0000] {processor.py:157} INFO - Started process (PID=21969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:00.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:56:00.287+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:00.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:00.315+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:56:00.329+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:00.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:56:00.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T13:56:30.733+0000] {processor.py:157} INFO - Started process (PID=21994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:30.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:56:30.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:30.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:56:30.766+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:56:30.776+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:56:30.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:56:30.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:57:01.159+0000] {processor.py:157} INFO - Started process (PID=22019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:01.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:57:01.163+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:01.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:01.190+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:57:01.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:01.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:57:01.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T13:57:31.570+0000] {processor.py:157} INFO - Started process (PID=22044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:31.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:57:31.574+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:31.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:57:31.606+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:57:31.616+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:57:31.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:57:31.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T13:58:02.024+0000] {processor.py:157} INFO - Started process (PID=22069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:02.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:58:02.028+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:02.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:02.058+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:58:02.070+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:02.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:58:02.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T13:58:32.435+0000] {processor.py:157} INFO - Started process (PID=22094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:32.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:58:32.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:32.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:58:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:58:32.480+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:58:32.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:58:32.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T13:59:02.881+0000] {processor.py:157} INFO - Started process (PID=22119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:02.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:59:02.885+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:02.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:02.917+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:59:02.927+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:02.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:59:02.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T13:59:33.334+0000] {processor.py:157} INFO - Started process (PID=22144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:33.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T13:59:33.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:33.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T13:59:33.363+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T13:59:33.373+0000] {logging_mixin.py:151} INFO - [2024-07-13T13:59:33.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T13:59:33.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-13T14:00:03.743+0000] {processor.py:157} INFO - Started process (PID=22169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:03.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:00:03.746+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:03.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:03.771+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:00:03.780+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:03.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:00:03.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-13T14:00:34.130+0000] {processor.py:157} INFO - Started process (PID=22194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:34.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:00:34.137+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:34.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:00:34.192+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:00:34.204+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:00:34.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:00:34.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-13T14:01:04.670+0000] {processor.py:157} INFO - Started process (PID=22219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:04.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:01:04.676+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:04.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:04.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:01:04.721+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:04.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:01:04.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T14:01:35.140+0000] {processor.py:157} INFO - Started process (PID=22244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:35.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:01:35.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:35.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:01:35.185+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:01:35.201+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:01:35.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:01:35.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T14:02:05.568+0000] {processor.py:157} INFO - Started process (PID=22269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:05.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:02:05.571+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:05.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:05.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:02:05.609+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:05.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:02:05.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:02:35.942+0000] {processor.py:157} INFO - Started process (PID=22294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:35.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:02:35.946+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:35.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:02:35.975+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:02:35.985+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:02:35.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:02:35.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:03:06.352+0000] {processor.py:157} INFO - Started process (PID=22319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:06.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:03:06.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:06.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:06.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:03:06.396+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:06.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:03:06.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T14:03:36.836+0000] {processor.py:157} INFO - Started process (PID=22344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:36.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:03:36.839+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:36.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:03:36.868+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:03:36.878+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:03:36.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:03:36.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:04:07.219+0000] {processor.py:157} INFO - Started process (PID=22369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:07.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:04:07.224+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:07.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:07.252+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:04:07.262+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:07.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:04:07.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:04:37.704+0000] {processor.py:157} INFO - Started process (PID=22394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:37.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:04:37.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:37.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:04:37.733+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:04:37.749+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:04:37.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:04:37.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:05:08.076+0000] {processor.py:157} INFO - Started process (PID=22419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:08.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:05:08.079+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:08.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:08.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:05:08.115+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:08.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:05:08.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T14:05:38.489+0000] {processor.py:157} INFO - Started process (PID=22444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:38.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:05:38.492+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:38.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:05:38.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:05:38.531+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:05:38.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:05:38.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:06:08.972+0000] {processor.py:157} INFO - Started process (PID=22469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:08.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:06:08.978+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:08.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:08.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:09.017+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:09.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:06:09.030+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:09.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:06:09.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-13T14:06:39.423+0000] {processor.py:157} INFO - Started process (PID=22494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:39.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:06:39.428+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:39.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:06:39.457+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:06:39.468+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:06:39.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:06:39.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:07:09.889+0000] {processor.py:157} INFO - Started process (PID=22519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:09.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:07:09.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:09.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:09.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:07:09.932+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:09.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:07:09.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:07:40.274+0000] {processor.py:157} INFO - Started process (PID=22544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:40.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:07:40.278+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:40.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:07:40.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:07:40.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:07:40.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:07:40.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:08:10.706+0000] {processor.py:157} INFO - Started process (PID=22569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:10.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:08:10.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:10.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:10.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:08:10.751+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:10.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:08:10.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T14:08:41.132+0000] {processor.py:157} INFO - Started process (PID=22594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:41.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:08:41.135+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:41.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:08:41.165+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:08:41.175+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:08:41.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:08:41.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:09:11.500+0000] {processor.py:157} INFO - Started process (PID=22619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:11.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:09:11.505+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:11.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:11.533+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:09:11.545+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:11.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:09:11.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T14:09:41.964+0000] {processor.py:157} INFO - Started process (PID=22644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:41.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:09:41.968+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:41.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:41.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:09:41.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:41.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:09:42.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:09:42.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:09:42.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T14:10:12.421+0000] {processor.py:157} INFO - Started process (PID=22669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:12.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:10:12.425+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:12.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:12.450+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:10:12.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:12.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:10:12.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T14:10:42.895+0000] {processor.py:157} INFO - Started process (PID=22694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:42.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:10:42.899+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:42.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:10:42.932+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:10:42.946+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:10:42.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:10:42.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T14:11:13.360+0000] {processor.py:157} INFO - Started process (PID=22719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:13.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:11:13.368+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:13.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:13.405+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:11:13.418+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:13.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:11:13.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T14:11:43.866+0000] {processor.py:157} INFO - Started process (PID=22744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:43.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:11:43.870+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:43.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:11:43.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:11:43.905+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:11:43.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:11:43.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T14:12:14.355+0000] {processor.py:157} INFO - Started process (PID=22769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:14.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:12:14.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:14.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:12:14.393+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:14.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:12:14.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-13T14:12:44.802+0000] {processor.py:157} INFO - Started process (PID=22794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:44.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:12:44.805+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:44.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:12:44.833+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:12:44.844+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:12:44.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:12:44.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-13T14:13:15.257+0000] {processor.py:157} INFO - Started process (PID=22819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:15.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:13:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:15.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:15.291+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:13:15.302+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:15.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:13:15.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T14:13:45.667+0000] {processor.py:157} INFO - Started process (PID=22844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:45.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:13:45.672+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:45.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:13:45.700+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:13:45.710+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:13:45.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:13:45.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:14:16.078+0000] {processor.py:157} INFO - Started process (PID=22869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:16.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:14:16.083+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:16.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:16.110+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:14:16.119+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:16.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:14:16.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T14:14:46.474+0000] {processor.py:157} INFO - Started process (PID=22894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:46.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:14:46.477+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:46.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:14:46.505+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:14:46.515+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:14:46.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:14:46.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-13T14:15:16.955+0000] {processor.py:157} INFO - Started process (PID=22919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:16.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:15:16.959+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:16.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:16.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:16.987+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:16.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:15:17.002+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:17.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:15:17.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T14:15:47.448+0000] {processor.py:157} INFO - Started process (PID=22944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:47.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:15:47.455+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:47.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:15:47.500+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:15:47.514+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:15:47.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:15:47.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-13T14:16:17.940+0000] {processor.py:157} INFO - Started process (PID=22969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:17.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:16:17.944+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:17.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:17.972+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:16:17.984+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:17.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:16:17.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T14:16:48.374+0000] {processor.py:157} INFO - Started process (PID=22994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:48.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:16:48.378+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:48.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:16:48.409+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:16:48.421+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:16:48.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:16:48.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T14:17:18.787+0000] {processor.py:157} INFO - Started process (PID=23019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:18.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:17:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:18.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:18.823+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:17:18.835+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:18.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:17:18.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T14:17:49.308+0000] {processor.py:157} INFO - Started process (PID=23044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:49.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:17:49.316+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:49.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:17:49.354+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:17:49.367+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:17:49.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:17:49.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-13T14:18:19.722+0000] {processor.py:157} INFO - Started process (PID=23069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:19.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:18:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:19.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:19.755+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:18:19.767+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:19.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:18:19.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-13T14:18:50.206+0000] {processor.py:157} INFO - Started process (PID=23094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:50.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:18:50.215+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:50.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:18:50.248+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:18:50.259+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:18:50.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:18:50.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-13T14:19:20.667+0000] {processor.py:157} INFO - Started process (PID=23119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:20.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:19:20.669+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:20.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:20.693+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:19:20.708+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:20.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:19:20.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T14:19:51.175+0000] {processor.py:157} INFO - Started process (PID=23144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:51.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:19:51.180+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:51.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:19:51.280+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:19:51.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:19:51.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:19:51.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-13T14:20:21.682+0000] {processor.py:157} INFO - Started process (PID=23169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:21.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:20:21.684+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:21.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:21.712+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:20:21.730+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:21.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:20:21.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T14:20:53.524+0000] {processor.py:157} INFO - Started process (PID=23194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:53.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:20:53.527+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:53.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:20:53.553+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:20:53.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:20:53.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:20:53.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-13T14:41:58.344+0000] {processor.py:157} INFO - Started process (PID=23223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:41:58.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:41:58.350+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:41:58.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:41:58.401+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:41:58.418+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:41:58.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:41:58.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-13T14:42:28.871+0000] {processor.py:157} INFO - Started process (PID=23248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:42:28.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T14:42:28.876+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:42:28.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T14:42:28.923+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T14:42:28.936+0000] {logging_mixin.py:151} INFO - [2024-07-13T14:42:28.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T14:42:28.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-13T15:49:25.426+0000] {processor.py:157} INFO - Started process (PID=23274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T15:49:25.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T15:49:25.436+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T15:49:25.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T15:49:25.496+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T15:49:25.523+0000] {logging_mixin.py:151} INFO - [2024-07-13T15:49:25.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T15:49:25.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-13T16:03:49.091+0000] {processor.py:157} INFO - Started process (PID=23302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:03:49.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T16:03:49.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:03:49.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:03:49.125+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T16:03:49.142+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:03:49.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T16:03:49.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T16:36:57.148+0000] {processor.py:157} INFO - Started process (PID=23327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:36:57.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T16:36:57.154+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:36:57.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T16:36:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T16:36:57.211+0000] {logging_mixin.py:151} INFO - [2024-07-13T16:36:57.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T16:36:57.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T17:32:58.379+0000] {processor.py:157} INFO - Started process (PID=23352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:32:58.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T17:32:58.389+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:32:58.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:32:58.442+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T17:32:58.456+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:32:58.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T17:32:58.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-13T17:33:28.861+0000] {processor.py:157} INFO - Started process (PID=23377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:33:28.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T17:33:28.867+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:33:28.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T17:33:28.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T17:33:28.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T17:33:28.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T17:33:28.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T18:57:51.194+0000] {processor.py:157} INFO - Started process (PID=23404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T18:57:51.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T18:57:51.200+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T18:57:51.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T18:57:51.263+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T18:57:51.290+0000] {logging_mixin.py:151} INFO - [2024-07-13T18:57:51.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T18:57:51.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-13T20:33:33.618+0000] {processor.py:157} INFO - Started process (PID=23429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:33:33.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T20:33:33.622+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:33:33.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:33:33.663+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:33:33.686+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:33:33.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T20:33:33.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-13T20:34:04.077+0000] {processor.py:157} INFO - Started process (PID=23454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:34:04.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T20:34:04.081+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:34:04.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:34:04.109+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:34:04.122+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:34:04.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T20:34:04.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T20:55:21.235+0000] {processor.py:157} INFO - Started process (PID=23479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:21.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T20:55:21.239+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:21.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:21.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:55:21.317+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:21.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T20:55:21.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-13T20:55:51.812+0000] {processor.py:157} INFO - Started process (PID=23504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:51.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T20:55:51.813+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:51.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T20:55:51.840+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T20:55:51.853+0000] {logging_mixin.py:151} INFO - [2024-07-13T20:55:51.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T20:55:51.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-13T21:35:13.602+0000] {processor.py:157} INFO - Started process (PID=23531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:13.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T21:35:13.610+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:13.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:13.648+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T21:35:13.662+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:13.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T21:35:13.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-13T21:35:43.962+0000] {processor.py:157} INFO - Started process (PID=23556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:43.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T21:35:43.966+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:43.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:43.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T21:35:44.000+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:43.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T21:35:44.012+0000] {logging_mixin.py:151} INFO - [2024-07-13T21:35:44.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T21:35:44.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T22:30:08.843+0000] {processor.py:157} INFO - Started process (PID=23581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:08.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T22:30:08.848+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:08.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:08.902+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T22:30:08.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:08.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T22:30:08.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-13T22:30:39.353+0000] {processor.py:157} INFO - Started process (PID=23606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:39.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T22:30:39.357+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:39.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T22:30:39.385+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T22:30:39.399+0000] {logging_mixin.py:151} INFO - [2024-07-13T22:30:39.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T22:30:39.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T23:01:06.938+0000] {processor.py:157} INFO - Started process (PID=23633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:06.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:01:06.944+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:06.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:06.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:06.982+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:06.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:01:06.999+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:06.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:01:07.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-13T23:01:37.308+0000] {processor.py:157} INFO - Started process (PID=23658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:37.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:01:37.312+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:37.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:01:37.343+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:01:37.358+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:01:37.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:01:37.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T23:02:11.490+0000] {processor.py:157} INFO - Started process (PID=23683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:11.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:02:11.498+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:11.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:11.573+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:02:11.593+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:11.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:02:11.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-13T23:02:42.029+0000] {processor.py:157} INFO - Started process (PID=23708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:42.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:02:42.033+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:42.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:02:42.084+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:02:42.108+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:02:42.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:02:42.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-13T23:03:12.443+0000] {processor.py:157} INFO - Started process (PID=23733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:12.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:03:12.447+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:12.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:12.476+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:03:12.487+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:12.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:03:12.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T23:03:42.989+0000] {processor.py:157} INFO - Started process (PID=23758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:42.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:03:43.000+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:42.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:43.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:03:43.077+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:43.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:03:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:03:43.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:03:43.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-13T23:04:13.550+0000] {processor.py:157} INFO - Started process (PID=23783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:13.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:04:13.554+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:13.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:13.591+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:04:13.604+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:13.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:04:13.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T23:04:44.093+0000] {processor.py:157} INFO - Started process (PID=23808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:44.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:04:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:44.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:04:44.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:04:44.140+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:04:44.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:04:44.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T23:05:14.461+0000] {processor.py:157} INFO - Started process (PID=23833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:14.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:05:14.466+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:14.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:14.508+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:05:14.525+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:14.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:05:14.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-13T23:05:44.972+0000] {processor.py:157} INFO - Started process (PID=23858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:44.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:05:44.977+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:44.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:44.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:05:45.010+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:45.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:05:45.022+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:05:45.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:05:45.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T23:06:15.440+0000] {processor.py:157} INFO - Started process (PID=23883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:15.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:06:15.445+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:15.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:15.482+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:06:15.497+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:15.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:06:15.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-13T23:06:45.864+0000] {processor.py:157} INFO - Started process (PID=23908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:45.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:06:45.868+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:45.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:06:45.896+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:06:45.907+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:06:45.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:06:45.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-13T23:07:16.362+0000] {processor.py:157} INFO - Started process (PID=23933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:16.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:07:16.368+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:16.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:16.412+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:07:16.426+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:16.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:07:16.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-13T23:07:46.858+0000] {processor.py:157} INFO - Started process (PID=23958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:46.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:07:46.861+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:46.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:07:46.895+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:07:46.908+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:07:46.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:07:46.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T23:08:17.362+0000] {processor.py:157} INFO - Started process (PID=23983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:17.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:08:17.366+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:17.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:17.402+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:08:17.414+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:17.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:08:17.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T23:08:47.860+0000] {processor.py:157} INFO - Started process (PID=24008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:47.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:08:47.863+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:47.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:08:47.894+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:08:47.911+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:08:47.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:08:47.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T23:09:18.349+0000] {processor.py:157} INFO - Started process (PID=24033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:18.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:09:18.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:18.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:18.383+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:09:18.398+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:18.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:09:18.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T23:09:48.815+0000] {processor.py:157} INFO - Started process (PID=24058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:48.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:09:48.821+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:48.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:09:48.855+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:09:48.874+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:09:48.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:09:48.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-13T23:10:19.301+0000] {processor.py:157} INFO - Started process (PID=24083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:19.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:10:19.307+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:19.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:19.338+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:10:19.351+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:19.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:10:19.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T23:10:49.766+0000] {processor.py:157} INFO - Started process (PID=24108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:49.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:10:49.770+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:49.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:10:49.803+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:10:49.814+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:10:49.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:10:49.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T23:11:20.239+0000] {processor.py:157} INFO - Started process (PID=24133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:20.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:11:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:20.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:20.284+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:11:20.295+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:20.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:11:20.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T23:11:50.649+0000] {processor.py:157} INFO - Started process (PID=24158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:50.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:11:50.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:50.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:11:50.683+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:11:50.695+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:11:50.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:11:50.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-13T23:12:21.146+0000] {processor.py:157} INFO - Started process (PID=24183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:21.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:12:21.152+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:21.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:21.189+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:12:21.202+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:21.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:12:21.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-13T23:12:51.675+0000] {processor.py:157} INFO - Started process (PID=24208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:51.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:12:51.679+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:51.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:12:51.711+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:12:51.724+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:12:51.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:12:51.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T23:13:22.175+0000] {processor.py:157} INFO - Started process (PID=24233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:22.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:13:22.179+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:22.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:22.209+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:13:22.221+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:22.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:13:22.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T23:13:52.689+0000] {processor.py:157} INFO - Started process (PID=24258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:52.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:13:52.693+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:52.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:13:52.725+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:13:52.737+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:13:52.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:13:52.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T23:14:23.144+0000] {processor.py:157} INFO - Started process (PID=24283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:23.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:14:23.150+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:23.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:23.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:14:23.198+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:23.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:14:23.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T23:14:53.615+0000] {processor.py:157} INFO - Started process (PID=24308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:53.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:14:53.619+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:53.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:14:53.652+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:14:53.664+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:14:53.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:14:53.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-13T23:15:24.144+0000] {processor.py:157} INFO - Started process (PID=24333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:24.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:15:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:24.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:24.183+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:15:24.198+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:24.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:15:24.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T23:15:54.578+0000] {processor.py:157} INFO - Started process (PID=24358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:54.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:15:54.583+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:54.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:15:54.616+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:15:54.630+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:15:54.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:15:54.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T23:16:24.989+0000] {processor.py:157} INFO - Started process (PID=24383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:24.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:16:24.993+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:24.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:25.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:25.027+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:25.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:16:25.040+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:25.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:16:25.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T23:16:55.479+0000] {processor.py:157} INFO - Started process (PID=24408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:55.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:16:55.483+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:55.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:16:55.510+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:16:55.521+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:16:55.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:16:55.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-13T23:17:25.936+0000] {processor.py:157} INFO - Started process (PID=24433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:25.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:17:25.939+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:25.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:25.972+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:17:25.983+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:25.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:17:25.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-13T23:17:56.391+0000] {processor.py:157} INFO - Started process (PID=24458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:56.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:17:56.398+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:56.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:17:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:17:56.454+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:17:56.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:17:56.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-13T23:18:26.920+0000] {processor.py:157} INFO - Started process (PID=24483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:26.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:18:26.924+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:26.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:26.953+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:18:26.966+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:26.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:18:26.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-13T23:18:57.468+0000] {processor.py:157} INFO - Started process (PID=24508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:57.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:18:57.472+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:57.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:18:57.513+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:18:57.528+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:18:57.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:18:57.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-13T23:19:27.986+0000] {processor.py:157} INFO - Started process (PID=24533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:27.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:19:27.991+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:27.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:28.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:28.024+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:28.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:19:28.040+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:28.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:19:28.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T23:19:58.415+0000] {processor.py:157} INFO - Started process (PID=24558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:58.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:19:58.419+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:58.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:19:58.453+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:19:58.465+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:19:58.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:19:58.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-13T23:20:28.883+0000] {processor.py:157} INFO - Started process (PID=24583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:28.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:20:28.886+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:28.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:28.921+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:20:28.933+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:28.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:20:28.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T23:20:59.288+0000] {processor.py:157} INFO - Started process (PID=24608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:59.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:20:59.293+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:59.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:20:59.327+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:20:59.344+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:20:59.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:20:59.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-13T23:21:29.741+0000] {processor.py:157} INFO - Started process (PID=24633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:21:29.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:21:29.746+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:21:29.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:21:29.777+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:21:29.798+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:21:29.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:21:29.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-13T23:22:00.151+0000] {processor.py:157} INFO - Started process (PID=24658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:00.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:22:00.157+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:00.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:00.185+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:22:00.198+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:00.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:22:00.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-13T23:22:30.560+0000] {processor.py:157} INFO - Started process (PID=24683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:30.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:22:30.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:30.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:22:30.598+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:22:30.614+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:22:30.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:22:30.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-13T23:23:01.057+0000] {processor.py:157} INFO - Started process (PID=24708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:01.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:23:01.061+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:01.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:01.094+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:23:01.106+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:01.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:23:01.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-13T23:23:31.548+0000] {processor.py:157} INFO - Started process (PID=24733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:31.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:23:31.552+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:31.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:23:31.587+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:23:31.599+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:23:31.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:23:31.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T23:24:02.042+0000] {processor.py:157} INFO - Started process (PID=24758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:02.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:24:02.045+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:02.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:02.078+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:24:02.095+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:02.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:24:02.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-13T23:24:32.526+0000] {processor.py:157} INFO - Started process (PID=24783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:32.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:24:32.532+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:32.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:24:32.563+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:24:32.576+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:24:32.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:24:32.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-13T23:25:03.027+0000] {processor.py:157} INFO - Started process (PID=24808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:03.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:25:03.031+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:03.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:03.063+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:25:03.077+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:03.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:25:03.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-13T23:25:33.553+0000] {processor.py:157} INFO - Started process (PID=24833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:33.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:25:33.561+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:33.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:25:33.600+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:25:33.612+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:25:33.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:25:33.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-13T23:26:04.035+0000] {processor.py:157} INFO - Started process (PID=24858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:04.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:26:04.041+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:04.088+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:26:04.102+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:04.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:26:04.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-13T23:26:34.666+0000] {processor.py:157} INFO - Started process (PID=24883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:34.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:26:34.669+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:34.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:26:34.706+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:26:34.718+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:26:34.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:26:34.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-13T23:27:05.124+0000] {processor.py:157} INFO - Started process (PID=24908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:27:05.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:27:05.128+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:27:05.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:27:05.161+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:27:05.173+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:27:05.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:27:05.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-13T23:28:30.480+0000] {processor.py:157} INFO - Started process (PID=24933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:28:30.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:28:30.484+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:28:30.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:28:30.532+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:28:30.557+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:28:30.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:28:30.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-13T23:29:01.106+0000] {processor.py:157} INFO - Started process (PID=24960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:29:01.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-13T23:29:01.108+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:29:01.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-13T23:29:01.134+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-13T23:29:01.146+0000] {logging_mixin.py:151} INFO - [2024-07-13T23:29:01.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-13T01:00:00+00:00, run_after=2024-07-14T01:00:00+00:00
[2024-07-13T23:29:01.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
