[2024-08-22T00:09:33.688+0000] {processor.py:157} INFO - Started process (PID=91835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:09:33.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:09:33.693+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:09:33.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:09:33.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:09:33.752+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:09:33.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:09:33.776+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:09:33.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:09:33.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T00:10:04.148+0000] {processor.py:157} INFO - Started process (PID=91845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:10:04.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:10:04.156+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:10:04.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:10:04.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:10:04.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:10:04.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:10:04.244+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:10:04.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:10:04.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T00:35:24.877+0000] {processor.py:157} INFO - Started process (PID=91861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:35:24.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:35:24.885+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:35:24.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:35:24.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:35:24.968+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:35:24.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:35:25.001+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:35:25.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:35:25.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T00:37:11.521+0000] {processor.py:157} INFO - Started process (PID=92445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:11.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:37:11.531+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:11.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:11.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:11.592+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:11.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:37:11.606+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:11.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:37:11.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T00:37:41.906+0000] {processor.py:157} INFO - Started process (PID=92624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:41.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:37:41.914+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:41.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:41.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:37:41.984+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:41.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:37:41.996+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:37:41.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:37:42.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T00:39:46.271+0000] {processor.py:157} INFO - Started process (PID=92636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:39:46.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:39:46.278+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:39:46.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:39:46.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:39:46.327+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:39:46.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:39:46.341+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:39:46.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:39:46.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T00:41:33.923+0000] {processor.py:157} INFO - Started process (PID=92645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:41:33.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:41:33.930+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:41:33.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:41:33.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:41:34.010+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:41:34.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:41:34.029+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:41:34.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:41:34.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T00:42:04.214+0000] {processor.py:157} INFO - Started process (PID=92656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:42:04.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T00:42:04.222+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:42:04.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:42:04.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T00:42:04.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:42:04.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T00:42:04.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T00:42:04.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-22T00:42:04.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T01:04:27.943+0000] {processor.py:157} INFO - Started process (PID=92665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:27.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:04:27.948+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:27.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:27.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:28.035+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:28.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:04:28.058+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:28.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:04:28.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-22T01:04:58.282+0000] {processor.py:157} INFO - Started process (PID=92676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:58.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:04:58.295+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:58.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:58.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:04:58.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:58.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:04:58.437+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:04:58.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:04:58.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-22T01:05:35.884+0000] {processor.py:157} INFO - Started process (PID=92685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:05:35.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:05:35.895+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:05:35.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:05:35.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:05:35.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:05:35.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:05:35.972+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:05:35.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:05:35.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-22T01:06:12.209+0000] {processor.py:157} INFO - Started process (PID=92696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:12.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:06:12.214+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:12.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:12.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:12.254+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:12.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:06:12.267+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:12.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:06:12.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T01:06:42.639+0000] {processor.py:157} INFO - Started process (PID=92705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:42.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:06:42.647+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:42.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:42.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:06:42.712+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:42.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:06:42.728+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:06:42.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:06:42.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T01:23:25.129+0000] {processor.py:157} INFO - Started process (PID=92715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:25.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:23:25.139+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:25.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:25.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:25.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:25.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:23:25.261+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:25.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:23:25.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T01:23:55.397+0000] {processor.py:157} INFO - Started process (PID=92726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:55.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:23:55.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:55.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:55.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:23:55.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:55.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:23:55.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:23:55.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:23:55.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T01:24:42.756+0000] {processor.py:157} INFO - Started process (PID=92738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:24:42.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:24:42.765+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:24:42.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:24:42.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:24:42.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:24:42.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:24:42.837+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:24:42.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:24:42.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T01:25:13.168+0000] {processor.py:157} INFO - Started process (PID=92748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:13.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:25:13.172+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:13.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:13.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:13.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:13.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:25:13.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:13.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:25:13.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T01:25:43.575+0000] {processor.py:157} INFO - Started process (PID=92758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:43.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:25:43.579+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:43.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:43.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:25:43.638+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:43.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:25:43.654+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:25:43.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:25:43.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T01:26:13.891+0000] {processor.py:157} INFO - Started process (PID=92768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:13.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:26:13.894+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:13.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:13.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:13.927+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:13.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:26:13.938+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:13.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:26:13.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T01:26:44.293+0000] {processor.py:157} INFO - Started process (PID=92778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:44.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:26:44.316+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:44.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:44.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:26:44.385+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:44.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:26:44.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:26:44.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:26:44.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-22T01:42:28.071+0000] {processor.py:157} INFO - Started process (PID=92788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:28.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:42:28.089+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:28.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:28.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:28.168+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:28.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:42:28.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:28.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:42:28.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-22T01:42:58.490+0000] {processor.py:157} INFO - Started process (PID=92800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:58.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T01:42:58.495+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:58.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:58.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T01:42:58.572+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:58.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T01:42:58.587+0000] {logging_mixin.py:151} INFO - [2024-08-22T01:42:58.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T01:42:58.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T02:00:07.025+0000] {processor.py:157} INFO - Started process (PID=92810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:07.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:00:07.032+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:07.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:07.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:07.085+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:07.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:00:07.103+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:07.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:00:07.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T02:00:37.509+0000] {processor.py:157} INFO - Started process (PID=92819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:37.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:00:37.518+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:37.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:37.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:00:37.587+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:37.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:00:37.601+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:00:37.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:00:37.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T02:01:07.812+0000] {processor.py:157} INFO - Started process (PID=92830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:07.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:01:07.827+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:07.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:07.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:07.855+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:07.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:01:07.865+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:07.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:01:07.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T02:01:38.173+0000] {processor.py:157} INFO - Started process (PID=92840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:38.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:01:38.180+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:38.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:38.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:01:38.220+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:38.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:01:38.233+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:01:38.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:01:38.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T02:03:14.062+0000] {processor.py:157} INFO - Started process (PID=92851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:14.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:03:14.138+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:14.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:14.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:14.335+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:14.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:03:14.382+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:14.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:03:14.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.362 seconds
[2024-08-22T02:03:44.505+0000] {processor.py:157} INFO - Started process (PID=92862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:44.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:03:44.516+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:44.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:44.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:03:44.590+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:44.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:03:44.607+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:03:44.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:03:44.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-22T02:04:14.894+0000] {processor.py:157} INFO - Started process (PID=92872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:14.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:04:14.925+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:14.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:14.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:15.007+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:15.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:04:15.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:15.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:04:15.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-22T02:04:45.278+0000] {processor.py:157} INFO - Started process (PID=92882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:45.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:04:45.288+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:45.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:45.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:04:45.393+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:45.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:04:45.412+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:04:45.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:04:45.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-22T02:05:15.698+0000] {processor.py:157} INFO - Started process (PID=92892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:15.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:05:15.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:15.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:15.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:15.759+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:15.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:05:15.774+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:15.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:05:15.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T02:05:46.158+0000] {processor.py:157} INFO - Started process (PID=92902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:46.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:05:46.245+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:46.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:46.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:05:46.422+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:46.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:05:46.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:05:46.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:05:46.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-08-22T02:06:16.578+0000] {processor.py:157} INFO - Started process (PID=92912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:16.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:06:16.588+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:16.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:16.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:16.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:16.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:06:16.669+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:16.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:06:16.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-22T02:06:46.970+0000] {processor.py:157} INFO - Started process (PID=92922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:46.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:06:46.978+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:46.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:46.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:06:47.042+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:47.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:06:47.057+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:06:47.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:06:47.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T02:07:17.346+0000] {processor.py:157} INFO - Started process (PID=92932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:17.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:07:17.353+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:17.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:17.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:17.407+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:17.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:07:17.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:17.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:07:17.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T02:07:47.895+0000] {processor.py:157} INFO - Started process (PID=92942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:47.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:07:47.917+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:47.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:47.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:07:48.008+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:48.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:07:48.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:07:48.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:07:48.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-22T02:08:18.369+0000] {processor.py:157} INFO - Started process (PID=92952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:18.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:08:18.376+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:18.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:18.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:18.447+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:18.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:08:18.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:18.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:08:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T02:08:48.672+0000] {processor.py:157} INFO - Started process (PID=92962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:48.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:08:48.677+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:48.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:48.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:08:48.719+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:48.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:08:48.732+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:08:48.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:08:48.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T02:09:19.169+0000] {processor.py:157} INFO - Started process (PID=92972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:19.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:09:19.176+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:19.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:19.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:19.225+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:19.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:09:19.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:19.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:09:19.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T02:09:49.496+0000] {processor.py:157} INFO - Started process (PID=92982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:49.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:09:49.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:49.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:49.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:09:49.560+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:49.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:09:49.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:09:49.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:09:49.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T02:10:19.830+0000] {processor.py:157} INFO - Started process (PID=92992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:19.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:10:19.833+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:19.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:19.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:19.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:19.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:10:19.871+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:19.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:10:19.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T02:10:50.230+0000] {processor.py:157} INFO - Started process (PID=93002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:50.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:10:50.237+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:50.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:50.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:10:50.297+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:50.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:10:50.323+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:10:50.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:10:50.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T02:11:20.516+0000] {processor.py:157} INFO - Started process (PID=93012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:20.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:11:20.518+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:20.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:20.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:20.551+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:20.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:11:20.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:20.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:11:20.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T02:11:50.933+0000] {processor.py:157} INFO - Started process (PID=93021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:50.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:11:50.939+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:50.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:50.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:11:50.993+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:50.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:11:51.006+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:11:51.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:11:51.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T02:12:21.300+0000] {processor.py:157} INFO - Started process (PID=93032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:21.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:12:21.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:21.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:21.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:21.374+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:21.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:12:21.391+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:21.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:12:21.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T02:12:51.770+0000] {processor.py:157} INFO - Started process (PID=93041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:51.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:12:51.776+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:51.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:51.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:12:51.834+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:51.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:12:51.856+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:12:51.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:12:51.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-22T02:13:22.114+0000] {processor.py:157} INFO - Started process (PID=93051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:22.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:13:22.123+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:22.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:22.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:22.189+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:22.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:13:22.204+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:22.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:13:22.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T02:13:52.415+0000] {processor.py:157} INFO - Started process (PID=93062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:52.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:13:52.421+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:52.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:52.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:13:52.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:52.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:13:52.469+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:13:52.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:13:52.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T02:14:22.852+0000] {processor.py:157} INFO - Started process (PID=93072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:22.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:14:22.868+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:22.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:22.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:22.905+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:22.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:14:22.918+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:22.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:14:22.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T02:14:53.173+0000] {processor.py:157} INFO - Started process (PID=93082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:53.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:14:53.206+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:53.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:53.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:14:53.256+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:53.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:14:53.272+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:14:53.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:14:53.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T02:15:23.524+0000] {processor.py:157} INFO - Started process (PID=93092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:23.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:15:23.528+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:23.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:23.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:23.568+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:23.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:15:23.580+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:23.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:15:23.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T02:15:53.916+0000] {processor.py:157} INFO - Started process (PID=93102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:53.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:15:53.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:53.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:53.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:15:53.987+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:53.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:15:54.004+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:15:54.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:15:54.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T02:16:24.285+0000] {processor.py:157} INFO - Started process (PID=93112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:24.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:16:24.295+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:24.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:24.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:24.346+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:24.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:16:24.376+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:24.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:16:24.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T02:16:54.568+0000] {processor.py:157} INFO - Started process (PID=93122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:54.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:16:54.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:54.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:54.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:16:54.615+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:54.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:16:54.629+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:16:54.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:16:54.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T02:17:24.920+0000] {processor.py:157} INFO - Started process (PID=93131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:24.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:17:24.929+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:24.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:24.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:24.970+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:24.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:17:24.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:24.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:17:24.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-22T02:17:55.329+0000] {processor.py:157} INFO - Started process (PID=93142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:55.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:17:55.335+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:55.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:55.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:17:55.385+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:55.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:17:55.402+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:17:55.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:17:55.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T02:18:25.730+0000] {processor.py:157} INFO - Started process (PID=93152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:25.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:18:25.739+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:25.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:25.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:25.777+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:25.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:18:25.791+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:25.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:18:25.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T02:18:56.178+0000] {processor.py:157} INFO - Started process (PID=93162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:56.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:18:56.184+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:56.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:56.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:18:56.228+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:56.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:18:56.245+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:18:56.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:18:56.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T02:19:26.962+0000] {processor.py:157} INFO - Started process (PID=93171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:26.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:19:26.969+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:26.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:26.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:27.015+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:27.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:19:27.030+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:27.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:19:27.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T02:19:57.307+0000] {processor.py:157} INFO - Started process (PID=93182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:57.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:19:57.312+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:57.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:57.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:19:57.360+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:57.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:19:57.378+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:19:57.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:19:57.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T02:20:27.739+0000] {processor.py:157} INFO - Started process (PID=93192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:27.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:20:27.747+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:27.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:27.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:27.801+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:27.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:20:27.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:27.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:20:27.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T02:20:58.198+0000] {processor.py:157} INFO - Started process (PID=93200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:58.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:20:58.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:58.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:58.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:20:58.303+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:58.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:20:58.322+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:20:58.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:20:58.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-22T02:21:28.514+0000] {processor.py:157} INFO - Started process (PID=93212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:28.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:21:28.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:28.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:28.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:28.562+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:28.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:21:28.576+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:28.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:21:28.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T02:21:58.905+0000] {processor.py:157} INFO - Started process (PID=93222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:58.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:21:58.932+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:58.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:58.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:21:59.005+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:59.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:21:59.025+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:21:59.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:21:59.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T02:22:29.262+0000] {processor.py:157} INFO - Started process (PID=93230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:29.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:22:29.269+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:29.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:29.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:29.327+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:29.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:22:29.342+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:29.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:22:29.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T02:22:59.609+0000] {processor.py:157} INFO - Started process (PID=93242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:59.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:22:59.621+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:59.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:59.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:22:59.720+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:59.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:22:59.739+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:22:59.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:22:59.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T02:23:29.934+0000] {processor.py:157} INFO - Started process (PID=93251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:23:29.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:23:29.945+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:23:29.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:23:30.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:23:30.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:23:30.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:23:30.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:23:30.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:23:30.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T02:24:00.328+0000] {processor.py:157} INFO - Started process (PID=93261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:00.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:24:00.334+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:00.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:00.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:00.391+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:00.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:24:00.407+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:00.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:24:00.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T02:24:30.716+0000] {processor.py:157} INFO - Started process (PID=93272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:30.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:24:30.725+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:30.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:30.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:24:30.794+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:30.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:24:30.809+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:24:30.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:24:30.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T02:25:01.006+0000] {processor.py:157} INFO - Started process (PID=93282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:01.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:25:01.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:01.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:01.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:01.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:01.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:25:01.136+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:01.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:25:01.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-22T02:25:31.449+0000] {processor.py:157} INFO - Started process (PID=93292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:31.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:25:31.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:31.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:31.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:25:31.538+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:31.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:25:31.554+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:25:31.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:25:31.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T02:26:01.928+0000] {processor.py:157} INFO - Started process (PID=93302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:01.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:26:01.939+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:01.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:01.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:02.019+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:02.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:26:02.035+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:02.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:26:02.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-22T02:26:32.294+0000] {processor.py:157} INFO - Started process (PID=93312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:32.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:26:32.306+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:32.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:32.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:26:32.390+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:32.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:26:32.416+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:26:32.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:26:32.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-22T02:27:02.670+0000] {processor.py:157} INFO - Started process (PID=93322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:02.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:27:02.676+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:02.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:02.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:02.731+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:02.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:27:02.745+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:02.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:27:02.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-22T02:27:32.991+0000] {processor.py:157} INFO - Started process (PID=93332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:32.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:27:32.998+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:32.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:33.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:27:33.058+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:33.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:27:33.071+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:27:33.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:27:33.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T02:28:03.443+0000] {processor.py:157} INFO - Started process (PID=93342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:03.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:28:03.451+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:03.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:03.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:03.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:03.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:28:03.581+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:03.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:28:03.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T02:28:33.765+0000] {processor.py:157} INFO - Started process (PID=93352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:33.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:28:33.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:33.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:33.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:28:33.865+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:33.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:28:33.884+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:28:33.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:28:33.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T02:29:04.158+0000] {processor.py:157} INFO - Started process (PID=93361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:04.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:29:04.165+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:04.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:04.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:04.216+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:04.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:29:04.230+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:04.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:29:04.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T02:29:34.582+0000] {processor.py:157} INFO - Started process (PID=93372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:34.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:29:34.590+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:34.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:34.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:29:34.641+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:34.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:29:34.659+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:29:34.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:29:34.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T02:30:04.864+0000] {processor.py:157} INFO - Started process (PID=93382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:04.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:30:04.866+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:04.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:04.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:04.902+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:04.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:30:04.915+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:04.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:30:04.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T02:30:35.177+0000] {processor.py:157} INFO - Started process (PID=93392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:35.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:30:35.184+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:35.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:35.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:30:35.210+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:35.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:30:35.220+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:30:35.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:30:35.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T02:31:05.625+0000] {processor.py:157} INFO - Started process (PID=93402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:05.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:31:05.632+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:05.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:05.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:05.693+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:05.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:31:05.708+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:05.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:31:05.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T02:31:36.068+0000] {processor.py:157} INFO - Started process (PID=93411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:36.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:31:36.077+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:36.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:36.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:31:36.141+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:36.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:31:36.157+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:31:36.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:31:36.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T02:32:06.409+0000] {processor.py:157} INFO - Started process (PID=93422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:06.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:32:06.418+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:06.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:06.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:06.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:06.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:32:06.489+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:06.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:32:06.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T02:32:36.810+0000] {processor.py:157} INFO - Started process (PID=93432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:36.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:32:36.820+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:36.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:36.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:32:36.913+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:36.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:32:36.929+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:32:36.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:32:36.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T02:33:07.149+0000] {processor.py:157} INFO - Started process (PID=93442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:07.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:33:07.166+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:07.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:07.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:07.228+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:07.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:33:07.244+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:07.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:33:07.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T02:33:37.511+0000] {processor.py:157} INFO - Started process (PID=93452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:37.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:33:37.519+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:37.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:37.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:33:37.580+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:37.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:33:37.594+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:33:37.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:33:37.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T02:34:08.016+0000] {processor.py:157} INFO - Started process (PID=93462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:08.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:34:08.023+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:08.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:08.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:08.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:08.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:34:08.137+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:08.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:34:08.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-22T02:34:38.486+0000] {processor.py:157} INFO - Started process (PID=93472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:38.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:34:38.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:38.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:38.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:34:38.552+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:38.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:34:38.566+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:34:38.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:34:38.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T02:35:08.925+0000] {processor.py:157} INFO - Started process (PID=93482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:08.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:35:08.939+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:08.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:08.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:09.034+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:09.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:35:09.055+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:09.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:35:09.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-22T02:35:39.241+0000] {processor.py:157} INFO - Started process (PID=93492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:39.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:35:39.249+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:39.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:39.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:35:39.297+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:39.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:35:39.319+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:35:39.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:35:39.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T02:36:09.709+0000] {processor.py:157} INFO - Started process (PID=93502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:09.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:36:09.718+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:09.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:09.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:09.819+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:09.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:36:09.836+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:09.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:36:09.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-22T02:36:40.102+0000] {processor.py:157} INFO - Started process (PID=93512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:40.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:36:40.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:40.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:40.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:36:40.158+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:40.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:36:40.171+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:36:40.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:36:40.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T02:37:10.463+0000] {processor.py:157} INFO - Started process (PID=93522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:10.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:37:10.478+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:10.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:10.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:10.552+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:10.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:37:10.567+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:10.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:37:10.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-22T02:37:40.881+0000] {processor.py:157} INFO - Started process (PID=93532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:40.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:37:40.890+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:40.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:40.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:37:40.941+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:40.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:37:40.957+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:37:40.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:37:40.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T02:38:11.201+0000] {processor.py:157} INFO - Started process (PID=93542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:11.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:38:11.210+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:11.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:11.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:11.286+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:11.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:38:11.304+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:11.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:38:11.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T02:38:41.723+0000] {processor.py:157} INFO - Started process (PID=93552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:41.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:38:41.736+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:41.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:41.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:38:41.802+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:41.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:38:41.818+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:38:41.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:38:41.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T02:39:12.190+0000] {processor.py:157} INFO - Started process (PID=93562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:12.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:39:12.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:12.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:12.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:12.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:12.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:39:12.296+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:12.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:39:12.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-22T02:39:42.545+0000] {processor.py:157} INFO - Started process (PID=93572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:42.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:39:42.549+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:42.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:42.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:39:42.595+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:42.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:39:42.622+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:39:42.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:39:42.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T02:40:12.925+0000] {processor.py:157} INFO - Started process (PID=93582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:12.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:40:12.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:12.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:12.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:12.998+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:12.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:40:13.021+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:13.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:40:13.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T02:40:43.202+0000] {processor.py:157} INFO - Started process (PID=93592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:43.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:40:43.204+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:43.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:43.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:40:43.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:43.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:40:43.241+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:40:43.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:40:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T02:41:13.560+0000] {processor.py:157} INFO - Started process (PID=93601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:13.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:41:13.565+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:13.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:13.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:13.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:13.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:41:13.661+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:13.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:41:13.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T02:41:43.899+0000] {processor.py:157} INFO - Started process (PID=93612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:43.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:41:43.906+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:43.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:43.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:41:43.947+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:43.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:41:43.962+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:41:43.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:41:43.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T02:42:14.260+0000] {processor.py:157} INFO - Started process (PID=93622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:14.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:42:14.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:14.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:14.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:14.305+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:14.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:42:14.320+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:14.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:42:14.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T02:42:44.680+0000] {processor.py:157} INFO - Started process (PID=93632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:44.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:42:44.685+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:44.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:44.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:42:44.757+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:44.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:42:44.771+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:42:44.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:42:44.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T02:43:14.969+0000] {processor.py:157} INFO - Started process (PID=93642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:14.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:43:14.974+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:14.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:14.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:15.013+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:15.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:43:15.027+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:15.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:43:15.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T02:43:45.277+0000] {processor.py:157} INFO - Started process (PID=93652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:45.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:43:45.279+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:45.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:45.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:43:45.307+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:45.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:43:45.318+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:43:45.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:43:45.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T02:44:15.649+0000] {processor.py:157} INFO - Started process (PID=93662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:15.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:44:15.662+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:15.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:15.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:15.713+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:15.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:44:15.726+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:15.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:44:15.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T02:44:45.976+0000] {processor.py:157} INFO - Started process (PID=93672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:45.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:44:45.979+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:45.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:45.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:44:46.022+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:46.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:44:46.038+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:44:46.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:44:46.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T02:45:16.435+0000] {processor.py:157} INFO - Started process (PID=93682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:16.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:45:16.446+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:16.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:16.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:16.527+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:16.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:45:16.544+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:16.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:45:16.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T02:45:46.765+0000] {processor.py:157} INFO - Started process (PID=93692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:46.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:45:46.772+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:46.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:46.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:45:46.816+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:46.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:45:46.831+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:45:46.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:45:46.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T02:46:17.120+0000] {processor.py:157} INFO - Started process (PID=93702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:17.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:46:17.128+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:17.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:17.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:17.194+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:17.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:46:17.210+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:17.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:46:17.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T02:46:47.514+0000] {processor.py:157} INFO - Started process (PID=93712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:47.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:46:47.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:47.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:47.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:46:47.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:47.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:46:47.588+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:46:47.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:46:47.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-22T02:47:17.844+0000] {processor.py:157} INFO - Started process (PID=93722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:17.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:47:17.849+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:17.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:17.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:17.889+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:17.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:47:17.904+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:17.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:47:17.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T02:47:48.166+0000] {processor.py:157} INFO - Started process (PID=93732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:48.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:47:48.170+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:48.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:48.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:47:48.199+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:48.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:47:48.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:47:48.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:47:48.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T02:48:18.477+0000] {processor.py:157} INFO - Started process (PID=93742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:18.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:48:18.481+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:18.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:18.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:18.528+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:18.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:48:18.562+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:18.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:48:18.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T02:48:48.761+0000] {processor.py:157} INFO - Started process (PID=93752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:48.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:48:48.766+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:48.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:48.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:48:48.801+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:48.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:48:48.816+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:48:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:48:48.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-22T02:49:19.068+0000] {processor.py:157} INFO - Started process (PID=93762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:19.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:49:19.072+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:19.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:19.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:19.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:19.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:49:19.127+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:19.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:49:19.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T02:49:49.332+0000] {processor.py:157} INFO - Started process (PID=93772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:49.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:49:49.336+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:49.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:49.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:49:49.362+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:49.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:49:49.371+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:49:49.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:49:49.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T02:50:19.735+0000] {processor.py:157} INFO - Started process (PID=93782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:19.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:50:19.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:19.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:19.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:19.810+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:19.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:50:19.823+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:19.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:50:19.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T02:50:50.116+0000] {processor.py:157} INFO - Started process (PID=93791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:50.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:50:50.131+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:50.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:50.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:50:50.187+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:50.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:50:50.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:50:50.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:50:50.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T02:51:20.449+0000] {processor.py:157} INFO - Started process (PID=93802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:20.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:51:20.455+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:20.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:20.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:20.492+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:20.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:51:20.505+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:20.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:51:20.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T02:51:50.731+0000] {processor.py:157} INFO - Started process (PID=93812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:50.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:51:50.734+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:50.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:50.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:51:50.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:50.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:51:50.785+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:51:50.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:51:50.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T02:52:21.145+0000] {processor.py:157} INFO - Started process (PID=93822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:21.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:52:21.151+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:21.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:21.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:21.216+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:21.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:52:21.230+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:21.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:52:21.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T02:52:51.623+0000] {processor.py:157} INFO - Started process (PID=93832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:51.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:52:51.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:51.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:51.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:52:51.694+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:51.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:52:51.709+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:52:51.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:52:51.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T02:53:21.937+0000] {processor.py:157} INFO - Started process (PID=93841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:21.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:53:21.943+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:21.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:21.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:21.992+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:21.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:53:22.006+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:22.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:53:22.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T02:53:52.275+0000] {processor.py:157} INFO - Started process (PID=93852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:52.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:53:52.280+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:52.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:52.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:53:52.318+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:52.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:53:52.339+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:53:52.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:53:52.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-22T02:54:22.775+0000] {processor.py:157} INFO - Started process (PID=93862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:22.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:54:22.783+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:22.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:22.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:22.857+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:22.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:54:22.874+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:22.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:54:22.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T02:54:53.106+0000] {processor.py:157} INFO - Started process (PID=93870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:53.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:54:53.115+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:53.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:53.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:54:53.181+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:53.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:54:53.200+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:54:53.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:54:53.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T02:55:23.447+0000] {processor.py:157} INFO - Started process (PID=93882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:23.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:55:23.453+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:23.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:23.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:23.506+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:23.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:55:23.524+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:23.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:55:23.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T02:55:53.787+0000] {processor.py:157} INFO - Started process (PID=93892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:53.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:55:53.818+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:53.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:53.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:55:53.908+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:53.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:55:53.927+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:55:53.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:55:53.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-22T02:56:24.324+0000] {processor.py:157} INFO - Started process (PID=93902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:24.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:56:24.333+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:24.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:24.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:24.394+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:24.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:56:24.412+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:24.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:56:24.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T02:56:55.058+0000] {processor.py:157} INFO - Started process (PID=93912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:55.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:56:55.074+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:55.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:55.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:56:55.144+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:55.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:56:55.164+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:56:55.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:56:55.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-22T02:57:25.336+0000] {processor.py:157} INFO - Started process (PID=93922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:25.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:57:25.341+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:25.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:25.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:25.384+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:25.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:57:25.398+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:25.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:57:25.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T02:57:55.709+0000] {processor.py:157} INFO - Started process (PID=93932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:55.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:57:55.713+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:55.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:55.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:57:55.744+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:55.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:57:55.762+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:57:55.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:57:55.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-22T02:58:26.076+0000] {processor.py:157} INFO - Started process (PID=93942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:26.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:58:26.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:26.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:26.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:26.121+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:26.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:58:26.136+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:26.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:58:26.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T02:58:56.451+0000] {processor.py:157} INFO - Started process (PID=93952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:56.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:58:56.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:56.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:56.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:58:56.526+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:56.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:58:56.538+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:58:56.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:58:56.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T02:59:26.775+0000] {processor.py:157} INFO - Started process (PID=93962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:26.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:59:26.778+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:26.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:26.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:26.807+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:26.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:59:26.820+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:26.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:59:26.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T02:59:57.132+0000] {processor.py:157} INFO - Started process (PID=93972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:57.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T02:59:57.138+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:57.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:57.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T02:59:57.189+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:57.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T02:59:57.201+0000] {logging_mixin.py:151} INFO - [2024-08-22T02:59:57.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T02:59:57.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T03:00:27.475+0000] {processor.py:157} INFO - Started process (PID=93982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:27.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:00:27.482+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:27.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:27.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:27.520+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:27.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:00:27.534+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:27.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:00:27.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:00:57.793+0000] {processor.py:157} INFO - Started process (PID=93992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:57.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:00:57.796+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:57.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:57.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:00:57.827+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:57.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:00:57.840+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:00:57.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:00:57.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T03:01:28.135+0000] {processor.py:157} INFO - Started process (PID=94002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:28.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:01:28.140+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:28.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:28.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:28.178+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:28.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:01:28.195+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:28.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:01:28.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:01:58.488+0000] {processor.py:157} INFO - Started process (PID=94012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:58.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:01:58.491+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:58.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:58.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:01:58.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:58.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:01:58.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:01:58.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:01:58.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T03:02:28.817+0000] {processor.py:157} INFO - Started process (PID=94022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:28.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:02:28.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:28.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:28.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:28.859+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:28.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:02:28.872+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:28.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:02:28.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T03:02:59.156+0000] {processor.py:157} INFO - Started process (PID=94032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:59.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:02:59.160+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:59.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:59.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:02:59.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:59.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:02:59.242+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:02:59.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:02:59.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T03:03:29.595+0000] {processor.py:157} INFO - Started process (PID=94042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:03:29.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:03:29.600+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:03:29.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:03:29.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:03:29.632+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:03:29.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:03:29.641+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:03:29.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:03:29.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T03:03:59.975+0000] {processor.py:157} INFO - Started process (PID=94052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:03:59.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:03:59.980+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:03:59.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:04:00.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:04:00.053+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:04:00.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:04:00.066+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:04:00.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:04:00.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T03:04:30.314+0000] {processor.py:157} INFO - Started process (PID=94062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:04:30.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:04:30.321+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:04:30.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:04:30.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:04:30.396+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:04:30.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:04:30.414+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:04:30.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:04:30.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-22T03:05:00.662+0000] {processor.py:157} INFO - Started process (PID=94072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:00.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:05:00.668+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:00.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:00.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:00.721+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:00.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:05:00.735+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:00.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:05:00.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T03:05:31.009+0000] {processor.py:157} INFO - Started process (PID=94082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:31.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:05:31.014+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:31.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:31.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:05:31.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:31.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:05:31.070+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:05:31.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:05:31.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T03:06:01.380+0000] {processor.py:157} INFO - Started process (PID=94092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:01.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:06:01.385+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:01.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:01.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:01.456+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:01.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:06:01.469+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:01.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:06:01.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T03:06:31.674+0000] {processor.py:157} INFO - Started process (PID=94102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:31.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:06:31.679+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:31.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:31.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:06:31.710+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:31.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:06:31.720+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:06:31.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:06:31.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T03:07:01.996+0000] {processor.py:157} INFO - Started process (PID=94112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:01.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:07:02.002+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:02.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:02.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:02.067+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:02.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:07:02.084+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:02.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:07:02.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-22T03:07:32.257+0000] {processor.py:157} INFO - Started process (PID=94122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:32.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:07:32.272+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:32.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:32.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:07:32.305+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:32.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:07:32.314+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:07:32.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:07:32.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T03:08:02.640+0000] {processor.py:157} INFO - Started process (PID=94132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:02.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:08:02.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:02.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:02.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:02.686+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:02.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:08:02.699+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:02.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:08:02.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T03:08:32.972+0000] {processor.py:157} INFO - Started process (PID=94142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:32.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:08:32.979+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:32.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:32.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:08:33.014+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:33.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:08:33.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:08:33.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:08:33.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T03:09:03.253+0000] {processor.py:157} INFO - Started process (PID=94152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:03.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:09:03.257+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:03.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:03.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:03.292+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:03.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:09:03.305+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:03.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:09:03.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-22T03:09:33.545+0000] {processor.py:157} INFO - Started process (PID=94162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:33.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:09:33.549+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:33.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:33.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:09:33.577+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:33.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:09:33.590+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:09:33.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:09:33.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T03:10:03.926+0000] {processor.py:157} INFO - Started process (PID=94172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:03.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:10:03.948+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:03.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:03.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:03.987+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:03.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:10:04.007+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:04.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:10:04.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-22T03:10:34.293+0000] {processor.py:157} INFO - Started process (PID=94181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:34.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:10:34.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:34.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:34.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:10:34.339+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:34.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:10:34.352+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:10:34.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:10:34.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T03:11:04.717+0000] {processor.py:157} INFO - Started process (PID=94192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:04.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:11:04.720+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:04.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:04.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:04.744+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:04.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:11:04.756+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:04.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:11:04.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T03:11:35.099+0000] {processor.py:157} INFO - Started process (PID=94202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:35.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:11:35.111+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:35.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:35.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:11:35.169+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:35.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:11:35.191+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:11:35.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:11:35.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T03:12:05.493+0000] {processor.py:157} INFO - Started process (PID=94212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:05.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:12:05.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:05.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:05.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:05.535+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:05.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:12:05.545+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:05.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:12:05.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T03:12:35.878+0000] {processor.py:157} INFO - Started process (PID=94222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:35.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:12:35.882+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:35.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:35.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:12:35.933+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:35.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:12:35.953+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:12:35.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:12:35.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T03:13:06.250+0000] {processor.py:157} INFO - Started process (PID=94232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:06.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:13:06.261+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:06.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:06.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:06.315+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:06.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:13:06.330+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:06.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:13:06.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T03:13:36.530+0000] {processor.py:157} INFO - Started process (PID=94242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:36.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:13:36.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:36.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:36.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:13:36.558+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:36.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:13:36.570+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:13:36.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:13:36.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T03:14:06.965+0000] {processor.py:157} INFO - Started process (PID=94252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:06.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:14:06.967+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:06.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:07.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:07.048+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:07.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:14:07.062+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:07.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:14:07.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-22T03:14:37.331+0000] {processor.py:157} INFO - Started process (PID=94262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:37.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:14:37.335+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:37.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:37.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:14:37.368+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:37.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:14:37.383+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:14:37.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:14:37.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T03:15:07.640+0000] {processor.py:157} INFO - Started process (PID=94272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:07.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:15:07.644+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:07.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:07.684+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:07.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:15:07.697+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:07.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:15:07.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T03:15:37.981+0000] {processor.py:157} INFO - Started process (PID=94282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:37.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:15:37.984+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:37.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:37.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:15:38.014+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:38.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:15:38.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:15:38.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:15:38.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T03:16:08.293+0000] {processor.py:157} INFO - Started process (PID=94292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:08.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:16:08.297+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:08.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:08.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:08.336+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:08.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:16:08.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:08.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:16:08.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T03:16:38.655+0000] {processor.py:157} INFO - Started process (PID=94302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:38.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:16:38.663+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:38.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:38.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:16:38.712+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:38.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:16:38.727+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:16:38.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:16:38.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T03:17:08.982+0000] {processor.py:157} INFO - Started process (PID=94312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:08.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:17:08.984+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:08.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:08.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:09.013+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:09.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:17:09.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:09.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:17:09.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:17:39.354+0000] {processor.py:157} INFO - Started process (PID=94322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:39.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:17:39.361+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:39.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:39.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:17:39.398+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:39.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:17:39.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:17:39.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:17:39.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T03:18:09.643+0000] {processor.py:157} INFO - Started process (PID=94332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:09.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:18:09.649+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:09.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:09.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:09.682+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:09.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:18:09.693+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:09.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:18:09.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T03:18:40.035+0000] {processor.py:157} INFO - Started process (PID=94341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:40.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:18:40.040+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:40.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:40.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:18:40.105+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:40.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:18:40.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:18:40.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:18:40.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T03:19:10.468+0000] {processor.py:157} INFO - Started process (PID=94352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:10.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:19:10.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:10.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:10.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:10.497+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:10.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:19:10.507+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:10.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:19:10.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:19:40.843+0000] {processor.py:157} INFO - Started process (PID=94362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:40.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:19:40.849+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:40.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:40.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:19:40.898+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:40.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:19:40.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:19:40.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:19:40.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T03:20:11.177+0000] {processor.py:157} INFO - Started process (PID=94370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:11.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:20:11.182+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:11.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:11.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:11.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:11.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:20:11.253+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:11.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:20:11.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T03:20:41.498+0000] {processor.py:157} INFO - Started process (PID=94382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:41.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:20:41.501+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:41.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:41.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:20:41.530+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:41.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:20:41.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:20:41.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:20:41.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:21:11.854+0000] {processor.py:157} INFO - Started process (PID=94392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:11.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:21:11.880+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:11.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:11.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:11.951+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:11.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:21:11.965+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:11.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:21:11.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T03:21:42.149+0000] {processor.py:157} INFO - Started process (PID=94402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:42.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:21:42.155+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:42.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:42.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:21:42.186+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:42.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:21:42.196+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:21:42.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:21:42.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T03:22:12.565+0000] {processor.py:157} INFO - Started process (PID=94412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:12.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:22:12.571+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:12.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:12.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:12.629+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:12.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:22:12.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:12.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:22:12.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T03:22:42.887+0000] {processor.py:157} INFO - Started process (PID=94422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:42.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:22:42.892+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:42.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:42.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:22:42.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:42.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:22:42.968+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:22:42.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:22:42.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T03:23:13.138+0000] {processor.py:157} INFO - Started process (PID=94432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:13.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:23:13.142+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:13.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:13.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:13.184+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:13.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:23:13.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:13.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:23:13.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T03:23:43.587+0000] {processor.py:157} INFO - Started process (PID=94442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:43.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:23:43.594+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:43.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:43.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:23:43.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:43.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:23:43.671+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:23:43.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:23:43.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T03:24:13.880+0000] {processor.py:157} INFO - Started process (PID=94452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:13.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:24:13.883+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:13.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:13.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:13.912+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:13.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:24:13.922+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:13.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:24:13.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T03:24:44.246+0000] {processor.py:157} INFO - Started process (PID=94462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:44.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:24:44.251+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:44.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:44.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:24:44.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:44.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:24:44.315+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:24:44.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:24:44.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T03:25:14.609+0000] {processor.py:157} INFO - Started process (PID=94472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:14.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:25:14.614+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:14.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:14.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:14.663+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:14.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:25:14.677+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:14.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:25:14.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T03:25:44.914+0000] {processor.py:157} INFO - Started process (PID=94482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:44.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:25:44.917+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:44.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:44.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:25:44.944+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:44.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:25:44.955+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:25:44.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:25:44.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:26:15.285+0000] {processor.py:157} INFO - Started process (PID=94492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:15.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:26:15.288+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:15.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:15.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:15.333+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:15.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:26:15.347+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:15.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:26:15.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T03:26:45.588+0000] {processor.py:157} INFO - Started process (PID=94502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:45.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:26:45.591+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:45.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:45.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:26:45.623+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:45.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:26:45.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:26:45.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:26:45.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T03:27:15.959+0000] {processor.py:157} INFO - Started process (PID=94512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:15.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:27:15.965+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:15.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:16.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:16.027+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:16.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:27:16.040+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:16.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:27:16.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T03:27:46.272+0000] {processor.py:157} INFO - Started process (PID=94522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:46.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:27:46.278+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:46.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:46.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:27:46.331+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:46.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:27:46.352+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:27:46.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:27:46.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T03:28:16.612+0000] {processor.py:157} INFO - Started process (PID=94532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:16.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:28:16.617+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:16.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:16.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:16.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:16.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:28:16.662+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:16.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:28:16.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T03:28:46.945+0000] {processor.py:157} INFO - Started process (PID=94542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:46.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:28:46.948+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:46.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:46.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:28:46.996+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:46.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:28:47.010+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:28:47.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:28:47.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T03:29:17.186+0000] {processor.py:157} INFO - Started process (PID=94552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:17.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:29:17.194+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:17.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:17.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:17.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:17.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:29:17.241+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:17.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:29:17.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T03:29:47.583+0000] {processor.py:157} INFO - Started process (PID=94562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:47.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:29:47.587+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:47.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:47.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:29:47.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:47.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:29:47.657+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:29:47.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:29:47.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T03:30:17.961+0000] {processor.py:157} INFO - Started process (PID=94572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:17.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:30:17.966+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:17.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:17.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:17.996+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:17.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:30:18.009+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:18.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:30:18.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T03:30:48.346+0000] {processor.py:157} INFO - Started process (PID=94582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:48.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:30:48.353+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:48.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:48.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:30:48.420+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:48.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:30:48.436+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:30:48.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:30:48.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-22T03:31:18.694+0000] {processor.py:157} INFO - Started process (PID=94592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:18.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:31:18.698+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:18.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:18.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:18.729+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:18.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:31:18.739+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:18.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:31:18.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T03:31:49.098+0000] {processor.py:157} INFO - Started process (PID=94602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:49.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:31:49.105+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:49.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:49.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:31:49.166+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:49.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:31:49.180+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:31:49.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:31:49.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T03:32:19.412+0000] {processor.py:157} INFO - Started process (PID=94612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:19.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:32:19.416+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:19.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:19.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:19.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:19.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:32:19.452+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:19.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:32:19.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T03:32:49.844+0000] {processor.py:157} INFO - Started process (PID=94622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:49.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:32:49.849+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:49.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:49.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:32:49.899+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:49.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:32:49.918+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:32:49.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:32:49.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T03:33:20.261+0000] {processor.py:157} INFO - Started process (PID=94632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:20.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:33:20.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:20.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:20.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:20.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:20.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:33:20.308+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:20.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:33:20.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T03:33:50.648+0000] {processor.py:157} INFO - Started process (PID=94641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:50.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:33:50.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:50.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:50.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:33:50.707+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:50.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:33:50.721+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:33:50.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:33:50.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T03:34:20.966+0000] {processor.py:157} INFO - Started process (PID=94652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:20.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:34:20.971+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:20.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:20.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:20.998+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:20.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:34:21.009+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:21.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:34:21.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:34:51.336+0000] {processor.py:157} INFO - Started process (PID=94662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:51.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:34:51.342+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:51.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:51.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:34:51.383+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:51.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:34:51.397+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:34:51.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:34:51.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:35:21.673+0000] {processor.py:157} INFO - Started process (PID=94672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:21.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:35:21.676+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:21.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:21.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:21.710+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:21.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:35:21.725+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:21.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:35:21.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-22T03:35:52.079+0000] {processor.py:157} INFO - Started process (PID=94681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:52.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:35:52.083+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:52.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:52.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:35:52.137+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:52.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:35:52.151+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:35:52.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:35:52.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T03:36:22.450+0000] {processor.py:157} INFO - Started process (PID=94692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:22.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:36:22.453+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:22.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:22.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:22.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:36:22.485+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:22.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:36:22.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-22T03:36:52.838+0000] {processor.py:157} INFO - Started process (PID=94702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:52.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:36:52.842+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:52.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:52.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:36:52.879+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:52.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:36:52.892+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:36:52.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:36:52.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T03:37:23.190+0000] {processor.py:157} INFO - Started process (PID=94712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:23.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:37:23.200+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:23.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:23.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:23.246+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:23.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:37:23.256+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:23.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:37:23.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T03:37:53.567+0000] {processor.py:157} INFO - Started process (PID=94722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:53.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:37:53.571+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:53.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:53.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:37:53.611+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:53.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:37:53.626+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:37:53.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:37:53.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T03:38:23.871+0000] {processor.py:157} INFO - Started process (PID=94732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:23.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:38:23.880+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:23.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:23.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:23.922+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:23.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:38:23.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:23.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:38:23.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T03:38:54.219+0000] {processor.py:157} INFO - Started process (PID=94740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:54.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:38:54.225+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:54.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:54.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:38:54.266+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:54.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:38:54.278+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:38:54.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:38:54.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:39:24.527+0000] {processor.py:157} INFO - Started process (PID=94752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:24.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:39:24.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:24.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:24.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:24.567+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:24.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:39:24.578+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:24.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:39:24.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T03:39:54.978+0000] {processor.py:157} INFO - Started process (PID=94762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:54.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:39:54.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:54.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:55.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:39:55.050+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:55.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:39:55.063+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:39:55.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:39:55.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T03:40:25.442+0000] {processor.py:157} INFO - Started process (PID=94772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:25.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:40:25.446+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:25.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:25.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:25.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:25.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:40:25.482+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:25.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:40:25.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T03:40:55.836+0000] {processor.py:157} INFO - Started process (PID=94780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:55.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:40:55.843+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:55.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:55.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:40:55.913+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:55.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:40:55.927+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:40:55.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:40:55.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T03:41:26.198+0000] {processor.py:157} INFO - Started process (PID=94792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:26.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:41:26.202+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:26.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:26.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:26.233+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:26.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:41:26.243+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:26.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:41:26.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T03:41:56.593+0000] {processor.py:157} INFO - Started process (PID=94802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:56.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:41:56.599+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:56.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:56.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:41:56.668+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:56.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:41:56.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:41:56.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:41:56.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T03:42:26.889+0000] {processor.py:157} INFO - Started process (PID=94812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:26.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:42:26.897+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:26.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:26.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:26.938+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:26.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:42:26.952+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:26.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:42:26.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T03:42:57.282+0000] {processor.py:157} INFO - Started process (PID=94822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:57.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:42:57.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:57.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:57.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:42:57.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:57.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:42:57.321+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:42:57.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:42:57.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T03:43:27.669+0000] {processor.py:157} INFO - Started process (PID=94832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:27.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:43:27.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:27.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:27.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:27.731+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:27.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:43:27.745+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:27.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:43:27.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T03:43:58.047+0000] {processor.py:157} INFO - Started process (PID=94842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:58.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:43:58.052+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:58.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:58.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:43:58.095+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:58.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:43:58.110+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:43:58.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:43:58.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T03:44:28.474+0000] {processor.py:157} INFO - Started process (PID=94852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:28.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:44:28.480+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:28.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:28.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:28.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:28.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:44:28.534+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:28.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:44:28.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:44:58.735+0000] {processor.py:157} INFO - Started process (PID=94862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:58.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:44:58.737+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:58.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:58.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:44:58.759+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:58.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:44:58.769+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:44:58.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:44:58.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-22T03:45:29.157+0000] {processor.py:157} INFO - Started process (PID=94872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:29.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:45:29.164+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:29.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:29.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:29.222+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:29.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:45:29.238+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:29.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:45:29.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T03:45:59.591+0000] {processor.py:157} INFO - Started process (PID=94882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:59.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:45:59.600+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:59.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:59.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:45:59.663+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:59.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:45:59.684+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:45:59.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:45:59.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T03:46:30.017+0000] {processor.py:157} INFO - Started process (PID=94892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:46:30.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:46:30.020+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:46:30.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:46:30.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:46:30.063+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:46:30.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:46:30.077+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:46:30.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:46:30.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T03:47:00.377+0000] {processor.py:157} INFO - Started process (PID=94902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:00.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:47:00.380+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:00.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:00.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:00.414+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:00.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:47:00.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:00.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:47:00.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T03:47:30.702+0000] {processor.py:157} INFO - Started process (PID=94912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:30.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:47:30.708+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:30.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:30.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:47:30.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:30.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:47:30.791+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:47:30.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:47:30.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T03:48:01.076+0000] {processor.py:157} INFO - Started process (PID=94922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:01.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:48:01.078+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:01.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:01.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:01.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:01.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:48:01.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:01.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:48:01.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T03:48:31.368+0000] {processor.py:157} INFO - Started process (PID=94932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:31.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:48:31.372+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:31.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:31.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:48:31.410+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:31.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:48:31.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:48:31.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:48:31.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T03:49:01.737+0000] {processor.py:157} INFO - Started process (PID=94942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:01.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:49:01.741+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:01.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:01.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:01.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:01.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:49:01.790+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:01.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:49:01.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T03:49:32.012+0000] {processor.py:157} INFO - Started process (PID=94952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:32.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:49:32.018+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:32.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:32.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:49:32.071+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:32.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:49:32.086+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:49:32.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:49:32.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T03:50:02.298+0000] {processor.py:157} INFO - Started process (PID=94962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:02.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:50:02.301+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:02.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:02.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:02.331+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:02.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:50:02.342+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:02.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:50:02.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T03:50:32.664+0000] {processor.py:157} INFO - Started process (PID=94971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:32.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:50:32.669+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:32.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:32.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:50:32.733+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:32.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:50:32.746+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:50:32.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:50:32.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T03:51:03.050+0000] {processor.py:157} INFO - Started process (PID=94982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:03.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:51:03.054+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:03.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:03.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:03.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:03.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:51:03.092+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:03.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:51:03.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T03:51:33.401+0000] {processor.py:157} INFO - Started process (PID=94992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:33.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:51:33.409+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:33.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:33.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:51:33.474+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:33.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:51:33.488+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:51:33.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:51:33.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T03:52:03.729+0000] {processor.py:157} INFO - Started process (PID=95002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:03.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:52:03.734+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:03.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:03.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:03.768+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:03.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:52:03.778+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:03.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:52:03.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T03:52:33.999+0000] {processor.py:157} INFO - Started process (PID=95012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:34.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:52:34.004+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:34.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:34.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:52:34.052+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:34.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:52:34.065+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:52:34.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:52:34.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T03:53:04.268+0000] {processor.py:157} INFO - Started process (PID=95022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:04.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:53:04.270+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:04.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:04.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:04.300+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:04.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:53:04.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:04.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:53:04.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T03:53:34.615+0000] {processor.py:157} INFO - Started process (PID=95032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:34.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:53:34.624+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:34.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:53:34.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:34.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:53:34.695+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:53:34.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:53:34.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T03:54:04.911+0000] {processor.py:157} INFO - Started process (PID=95042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:04.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:54:04.914+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:04.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:04.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:04.944+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:04.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:54:04.957+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:04.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:54:04.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T03:54:35.202+0000] {processor.py:157} INFO - Started process (PID=95051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:35.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:54:35.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:35.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:35.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:54:35.272+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:35.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:54:35.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:54:35.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:54:35.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T03:55:05.509+0000] {processor.py:157} INFO - Started process (PID=95062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:05.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:55:05.513+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:05.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:05.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:05.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:05.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:55:05.554+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:05.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:55:05.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-22T03:55:35.881+0000] {processor.py:157} INFO - Started process (PID=95072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:35.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:55:35.904+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:35.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:35.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:55:35.951+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:35.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:55:35.977+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:55:35.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:55:35.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T03:56:06.258+0000] {processor.py:157} INFO - Started process (PID=95082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:06.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:56:06.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:06.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:06.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:06.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:06.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:56:06.363+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:06.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:56:06.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-22T03:56:36.750+0000] {processor.py:157} INFO - Started process (PID=95092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:36.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:56:36.754+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:36.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:36.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:56:36.831+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:36.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:56:36.875+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:56:36.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:56:36.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T03:57:07.047+0000] {processor.py:157} INFO - Started process (PID=95102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:07.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:57:07.055+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:07.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:07.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:07.122+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:07.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:57:07.138+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:07.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:57:07.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T03:57:37.397+0000] {processor.py:157} INFO - Started process (PID=95112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:37.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:57:37.404+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:37.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:37.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:57:37.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:37.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:57:37.456+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:57:37.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:57:37.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T03:58:07.742+0000] {processor.py:157} INFO - Started process (PID=95122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:07.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:58:07.743+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:07.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:07.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:07.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:07.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:58:07.784+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:07.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:58:07.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T03:58:38.108+0000] {processor.py:157} INFO - Started process (PID=95132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:38.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:58:38.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:38.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:38.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:58:38.152+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:38.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:58:38.165+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:58:38.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:58:38.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T03:59:08.489+0000] {processor.py:157} INFO - Started process (PID=95142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:08.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:59:08.495+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:08.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:08.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:08.543+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:08.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:59:08.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:08.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:59:08.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T03:59:38.900+0000] {processor.py:157} INFO - Started process (PID=95152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:38.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T03:59:38.906+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:38.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:38.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T03:59:38.945+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:38.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T03:59:38.958+0000] {logging_mixin.py:151} INFO - [2024-08-22T03:59:38.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T03:59:38.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T04:00:09.293+0000] {processor.py:157} INFO - Started process (PID=95162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:09.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:00:09.308+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:09.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:09.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:09.347+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:09.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:00:09.360+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:09.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:00:09.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T04:00:39.599+0000] {processor.py:157} INFO - Started process (PID=95172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:39.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:00:39.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:39.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:39.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:00:39.636+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:39.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:00:39.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:00:39.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:00:39.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T04:01:10.024+0000] {processor.py:157} INFO - Started process (PID=95182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:10.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:01:10.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:10.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:10.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:10.084+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:10.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:01:10.097+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:10.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:01:10.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T04:01:40.413+0000] {processor.py:157} INFO - Started process (PID=95192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:40.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:01:40.416+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:40.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:40.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:01:40.466+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:40.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:01:40.480+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:01:40.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:01:40.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T04:02:10.695+0000] {processor.py:157} INFO - Started process (PID=95202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:10.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:02:10.697+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:10.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:10.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:10.725+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:10.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:02:10.735+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:10.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:02:10.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T04:02:41.017+0000] {processor.py:157} INFO - Started process (PID=95212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:41.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:02:41.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:41.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:41.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:02:41.096+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:41.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:02:41.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:02:41.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:02:41.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-22T04:03:11.387+0000] {processor.py:157} INFO - Started process (PID=95222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:11.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:03:11.390+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:11.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:11.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:11.416+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:11.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:03:11.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:11.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:03:11.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-22T04:03:41.761+0000] {processor.py:157} INFO - Started process (PID=95231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:41.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:03:41.766+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:41.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:41.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:03:41.816+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:41.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:03:41.832+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:03:41.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:03:41.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T04:04:12.164+0000] {processor.py:157} INFO - Started process (PID=95242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:12.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:04:12.168+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:12.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:12.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:12.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:12.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:04:12.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:12.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:04:12.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T04:04:42.468+0000] {processor.py:157} INFO - Started process (PID=95252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:42.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:04:42.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:42.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:42.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:04:42.550+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:42.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:04:42.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:04:42.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:04:42.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T04:05:12.799+0000] {processor.py:157} INFO - Started process (PID=95262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:12.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:05:12.803+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:12.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:12.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:12.831+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:12.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:05:12.843+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:12.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:05:12.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T04:05:43.263+0000] {processor.py:157} INFO - Started process (PID=95272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:43.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:05:43.275+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:43.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:43.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:05:43.323+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:43.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:05:43.336+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:05:43.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:05:43.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T04:06:13.550+0000] {processor.py:157} INFO - Started process (PID=95282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:13.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:06:13.554+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:13.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:13.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:13.586+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:13.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:06:13.603+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:13.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:06:13.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T04:06:43.838+0000] {processor.py:157} INFO - Started process (PID=95292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:43.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:06:43.844+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:43.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:43.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:06:43.910+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:43.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:06:43.924+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:06:43.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:06:43.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T04:07:14.152+0000] {processor.py:157} INFO - Started process (PID=95302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:14.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:07:14.158+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:14.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:14.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:14.199+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:14.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:07:14.214+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:14.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:07:14.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T04:07:44.417+0000] {processor.py:157} INFO - Started process (PID=95312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:44.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:07:44.420+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:44.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:44.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:07:44.450+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:44.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:07:44.462+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:07:44.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:07:44.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T04:08:14.741+0000] {processor.py:157} INFO - Started process (PID=95322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:14.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:08:14.745+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:14.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:14.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:14.781+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:14.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:08:14.790+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:14.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:08:14.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T04:08:45.194+0000] {processor.py:157} INFO - Started process (PID=95332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:45.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:08:45.198+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:45.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:45.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:08:45.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:45.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:08:45.280+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:08:45.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:08:45.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T04:09:15.525+0000] {processor.py:157} INFO - Started process (PID=95342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:15.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:09:15.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:15.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:15.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:15.562+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:15.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:09:15.572+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:15.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:09:15.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T04:09:45.905+0000] {processor.py:157} INFO - Started process (PID=95352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:45.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:09:45.910+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:45.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:45.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:09:45.953+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:45.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:09:45.987+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:09:45.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:09:45.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T04:10:16.324+0000] {processor.py:157} INFO - Started process (PID=95362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:16.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:10:16.331+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:16.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:16.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:16.361+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:16.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:10:16.371+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:16.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:10:16.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T04:10:46.672+0000] {processor.py:157} INFO - Started process (PID=95372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:46.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:10:46.683+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:46.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:46.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:10:46.714+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:46.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:10:46.726+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:10:46.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:10:46.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-22T04:11:16.981+0000] {processor.py:157} INFO - Started process (PID=95382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:16.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:11:16.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:16.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:16.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:17.018+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:17.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:11:17.028+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:17.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:11:17.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T04:11:47.320+0000] {processor.py:157} INFO - Started process (PID=95392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:47.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:11:47.325+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:47.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:47.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:11:47.361+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:47.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:11:47.374+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:11:47.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:11:47.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T04:12:17.681+0000] {processor.py:157} INFO - Started process (PID=95402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:17.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:12:17.685+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:17.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:17.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:17.712+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:17.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:12:17.724+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:17.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:12:17.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T04:12:48.018+0000] {processor.py:157} INFO - Started process (PID=95412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:48.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:12:48.022+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:48.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:48.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:12:48.048+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:48.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:12:48.059+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:12:48.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:12:48.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T04:13:18.352+0000] {processor.py:157} INFO - Started process (PID=95422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:18.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:13:18.355+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:18.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:18.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:18.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:18.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:13:18.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:18.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:13:18.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T04:13:48.775+0000] {processor.py:157} INFO - Started process (PID=95432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:48.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:13:48.780+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:48.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:48.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:13:48.812+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:48.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:13:48.826+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:13:48.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:13:48.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T04:14:19.237+0000] {processor.py:157} INFO - Started process (PID=95442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:19.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:14:19.242+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:19.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:19.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:19.285+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:19.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:14:19.297+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:19.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:14:19.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T04:14:49.585+0000] {processor.py:157} INFO - Started process (PID=95452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:49.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:14:49.590+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:49.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:49.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:14:49.623+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:49.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:14:49.637+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:14:49.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:14:49.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-22T04:15:19.989+0000] {processor.py:157} INFO - Started process (PID=95462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:19.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:15:19.993+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:19.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:20.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:20.029+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:20.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:15:20.047+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:20.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:15:20.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T04:15:50.419+0000] {processor.py:157} INFO - Started process (PID=95471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:50.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:15:50.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:50.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:50.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:15:50.483+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:50.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:15:50.497+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:15:50.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:15:50.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T04:16:20.858+0000] {processor.py:157} INFO - Started process (PID=95482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:20.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:16:20.863+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:20.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:20.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:20.923+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:20.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:16:20.940+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:20.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:16:20.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T04:16:51.327+0000] {processor.py:157} INFO - Started process (PID=95492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:51.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:16:51.332+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:51.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:51.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:16:51.378+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:51.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:16:51.390+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:16:51.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:16:51.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T04:17:21.746+0000] {processor.py:157} INFO - Started process (PID=95502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:21.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:17:21.750+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:21.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:21.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:21.798+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:17:21.814+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:21.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:17:21.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T04:17:52.085+0000] {processor.py:157} INFO - Started process (PID=95512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:52.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:17:52.093+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:52.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:52.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:17:52.122+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:52.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:17:52.132+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:17:52.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:17:52.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T04:18:22.528+0000] {processor.py:157} INFO - Started process (PID=95522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:22.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:18:22.536+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:22.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:22.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:22.608+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:22.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:18:22.621+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:22.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:18:22.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T04:18:52.893+0000] {processor.py:157} INFO - Started process (PID=95531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:52.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:18:52.900+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:52.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:52.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:18:52.941+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:52.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:18:52.957+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:18:52.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:18:52.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T04:19:23.200+0000] {processor.py:157} INFO - Started process (PID=95542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:23.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:19:23.204+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:23.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:23.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:23.248+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:23.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:19:23.266+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:23.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:19:23.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T04:19:53.639+0000] {processor.py:157} INFO - Started process (PID=95551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:53.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:19:53.644+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:53.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:53.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:19:53.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:53.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:19:53.708+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:19:53.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:19:53.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T04:20:23.966+0000] {processor.py:157} INFO - Started process (PID=95562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:23.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:20:23.971+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:23.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:23.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:24.021+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:24.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:20:24.036+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:24.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:20:24.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T04:20:54.219+0000] {processor.py:157} INFO - Started process (PID=95572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:54.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:20:54.224+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:54.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:54.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:20:54.256+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:54.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:20:54.269+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:20:54.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:20:54.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T04:21:24.582+0000] {processor.py:157} INFO - Started process (PID=95582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:24.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:21:24.586+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:24.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:24.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:24.622+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:24.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:21:24.635+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:24.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:21:24.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T04:21:54.886+0000] {processor.py:157} INFO - Started process (PID=95592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:54.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:21:54.889+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:54.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:54.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:21:54.940+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:54.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:21:54.953+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:21:54.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:21:54.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T04:22:25.149+0000] {processor.py:157} INFO - Started process (PID=95602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:25.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:22:25.154+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:25.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:25.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:25.187+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:25.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:22:25.202+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:25.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:22:25.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T04:22:55.484+0000] {processor.py:157} INFO - Started process (PID=95612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:55.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:22:55.487+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:55.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:55.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:22:55.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:55.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:22:55.530+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:22:55.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:22:55.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T04:23:25.862+0000] {processor.py:157} INFO - Started process (PID=95622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:25.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:23:25.867+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:25.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:25.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:25.930+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:25.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:23:25.944+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:25.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:23:25.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T04:23:56.180+0000] {processor.py:157} INFO - Started process (PID=95632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:56.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:23:56.185+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:56.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:56.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:23:56.221+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:56.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:23:56.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:23:56.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:23:56.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T04:24:26.570+0000] {processor.py:157} INFO - Started process (PID=95642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:26.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:24:26.575+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:26.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:26.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:26.637+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:26.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:24:26.651+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:26.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:24:26.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T04:24:56.985+0000] {processor.py:157} INFO - Started process (PID=95652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:56.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:24:56.988+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:56.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:57.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:24:57.023+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:57.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:24:57.033+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:24:57.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:24:57.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T04:25:27.299+0000] {processor.py:157} INFO - Started process (PID=95660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:27.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:25:27.304+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:27.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:27.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:27.363+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:27.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:25:27.377+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:27.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:25:27.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-22T04:25:57.618+0000] {processor.py:157} INFO - Started process (PID=95672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:57.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:25:57.623+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:57.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:57.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:25:57.656+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:57.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:25:57.665+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:25:57.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:25:57.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T04:26:27.954+0000] {processor.py:157} INFO - Started process (PID=95682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:27.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:26:27.958+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:27.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:28.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:28.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:28.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:26:28.040+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:28.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:26:28.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T04:26:58.269+0000] {processor.py:157} INFO - Started process (PID=95692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:58.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:26:58.276+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:58.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:58.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:26:58.334+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:58.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:26:58.355+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:26:58.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:26:58.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T04:27:28.698+0000] {processor.py:157} INFO - Started process (PID=95702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:28.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:27:28.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:28.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:28.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:28.748+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:28.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:27:28.762+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:28.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:27:28.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T04:27:59.027+0000] {processor.py:157} INFO - Started process (PID=95712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:59.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:27:59.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:59.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:59.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:27:59.064+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:59.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:27:59.074+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:27:59.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:27:59.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T04:28:42.968+0000] {processor.py:157} INFO - Started process (PID=95722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:28:42.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:28:42.977+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:28:42.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:28:42.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:28:43.028+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:28:43.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:28:43.045+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:28:43.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:28:43.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T04:29:13.417+0000] {processor.py:157} INFO - Started process (PID=95734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:29:13.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:29:13.420+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:29:13.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:29:13.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:29:13.449+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:29:13.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:29:13.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:29:13.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:29:13.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T04:31:51.464+0000] {processor.py:157} INFO - Started process (PID=95743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:31:51.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:31:51.470+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:31:51.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:31:51.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:31:51.591+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:31:51.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:31:51.630+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:31:51.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:31:51.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-22T04:32:50.499+0000] {processor.py:157} INFO - Started process (PID=95756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:32:50.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:32:50.511+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:32:50.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:32:50.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:32:50.568+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:32:50.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:32:50.584+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:32:50.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:32:50.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T04:33:20.901+0000] {processor.py:157} INFO - Started process (PID=95766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:33:20.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:33:20.905+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:33:20.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:33:20.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:33:20.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:33:20.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:33:20.945+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:33:20.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:33:20.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T04:39:13.701+0000] {processor.py:157} INFO - Started process (PID=95775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:13.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:39:13.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:13.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:13.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:13.754+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:13.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:39:13.771+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:13.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:39:13.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T04:39:44.225+0000] {processor.py:157} INFO - Started process (PID=95786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:44.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:39:44.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:44.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:44.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:39:44.282+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:44.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:39:44.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:39:44.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:39:44.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T04:56:54.190+0000] {processor.py:157} INFO - Started process (PID=95797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:56:54.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T04:56:54.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:56:54.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:56:54.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T04:56:54.275+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:56:54.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T04:56:54.306+0000] {logging_mixin.py:151} INFO - [2024-08-22T04:56:54.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T04:56:54.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-22T05:13:18.517+0000] {processor.py:157} INFO - Started process (PID=95808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:18.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:13:18.521+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:18.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:18.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:18.594+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:18.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:13:18.614+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:18.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:13:18.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T05:13:49.026+0000] {processor.py:157} INFO - Started process (PID=95818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:49.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:13:49.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:49.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:49.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:13:49.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:49.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:13:49.096+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:13:49.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:13:49.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T05:14:19.413+0000] {processor.py:157} INFO - Started process (PID=95828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:19.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:14:19.415+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:19.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:19.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:19.447+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:19.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:14:19.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:19.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:14:19.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T05:14:49.803+0000] {processor.py:157} INFO - Started process (PID=95838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:49.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:14:49.809+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:49.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:49.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:14:49.846+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:49.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:14:49.859+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:14:49.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:14:49.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T05:15:20.175+0000] {processor.py:157} INFO - Started process (PID=95848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:15:20.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:15:20.178+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:15:20.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:15:20.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:15:20.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:15:20.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:15:20.228+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:15:20.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:15:20.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T05:19:23.452+0000] {processor.py:157} INFO - Started process (PID=95859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:23.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:19:23.462+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:23.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:23.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:23.555+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:23.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:19:23.588+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:23.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:19:23.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-22T05:19:53.916+0000] {processor.py:157} INFO - Started process (PID=95870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:53.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:19:53.921+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:53.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:53.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:19:53.961+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:53.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:19:53.977+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:19:53.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:19:53.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T05:20:24.308+0000] {processor.py:157} INFO - Started process (PID=95880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:24.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:20:24.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:24.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:24.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:24.344+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:24.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:20:24.356+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:24.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:20:24.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T05:20:54.761+0000] {processor.py:157} INFO - Started process (PID=95890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:54.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:20:54.766+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:54.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:54.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:20:54.800+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:54.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:20:54.812+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:20:54.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:20:54.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T05:36:36.691+0000] {processor.py:157} INFO - Started process (PID=95901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:36:36.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:36:36.700+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:36:36.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:36:36.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:36:36.794+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:36:36.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:36:36.824+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:36:36.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:36:36.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T05:37:07.153+0000] {processor.py:157} INFO - Started process (PID=95912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:07.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:37:07.173+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:07.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:07.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:07.227+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:07.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:37:07.247+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:07.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:37:07.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T05:37:37.432+0000] {processor.py:157} INFO - Started process (PID=95922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:37.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:37:37.435+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:37.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:37.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:37:37.464+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:37.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:37:37.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:37:37.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:37:37.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T05:38:07.742+0000] {processor.py:157} INFO - Started process (PID=95932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:07.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:38:07.747+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:07.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:07.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:07.782+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:07.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:38:07.795+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:07.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:38:07.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-22T05:38:38.049+0000] {processor.py:157} INFO - Started process (PID=95942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:38.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:38:38.053+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:38.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:38.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:38:38.090+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:38.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:38:38.110+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:38:38.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:38:38.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T05:39:08.338+0000] {processor.py:157} INFO - Started process (PID=95952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:08.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:39:08.342+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:08.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:08.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:08.368+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:08.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:39:08.378+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:08.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:39:08.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T05:39:38.676+0000] {processor.py:157} INFO - Started process (PID=95962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:38.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:39:38.679+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:38.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:38.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:39:38.705+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:38.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:39:38.714+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:39:38.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:39:38.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T05:40:09.013+0000] {processor.py:157} INFO - Started process (PID=95972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:09.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:40:09.016+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:09.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:09.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:09.054+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:09.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:40:09.067+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:09.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:40:09.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T05:40:39.421+0000] {processor.py:157} INFO - Started process (PID=95982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:39.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:40:39.428+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:39.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:39.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:40:39.476+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:39.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:40:39.490+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:40:39.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:40:39.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T05:41:09.730+0000] {processor.py:157} INFO - Started process (PID=95992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:41:09.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:41:09.733+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:41:09.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:41:09.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:41:09.764+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:41:09.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:41:09.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:41:09.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:41:09.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T05:58:35.025+0000] {processor.py:157} INFO - Started process (PID=96004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:58:35.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:58:35.029+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:58:35.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:58:35.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:58:35.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:58:35.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:58:35.129+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:58:35.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:58:35.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-22T05:59:05.316+0000] {processor.py:157} INFO - Started process (PID=96013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:05.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:59:05.329+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:05.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:05.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:05.406+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:05.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:59:05.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:05.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:59:05.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T05:59:35.752+0000] {processor.py:157} INFO - Started process (PID=96024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:35.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T05:59:35.754+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:35.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:35.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T05:59:35.777+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:35.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T05:59:35.787+0000] {logging_mixin.py:151} INFO - [2024-08-22T05:59:35.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T05:59:35.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-22T06:00:06.096+0000] {processor.py:157} INFO - Started process (PID=96034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:06.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:00:06.101+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:06.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:06.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:06.128+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:06.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:00:06.140+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:06.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:00:06.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T06:00:36.456+0000] {processor.py:157} INFO - Started process (PID=96044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:36.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:00:36.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:36.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:36.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:00:36.481+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:36.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:00:36.492+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:00:36.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:00:36.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-22T06:01:06.813+0000] {processor.py:157} INFO - Started process (PID=96054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:01:06.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:01:06.822+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:01:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:01:06.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:01:06.902+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:01:06.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:01:06.939+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:01:06.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:01:06.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T06:03:41.594+0000] {processor.py:157} INFO - Started process (PID=96064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:03:41.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:03:41.597+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:03:41.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:03:41.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:03:41.637+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:03:41.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:03:41.650+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:03:41.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:03:41.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T06:12:41.006+0000] {processor.py:157} INFO - Started process (PID=96075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:12:41.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:12:41.016+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:12:41.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:12:41.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:12:41.170+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:12:41.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:12:41.203+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:12:41.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:12:41.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-22T06:13:11.345+0000] {processor.py:157} INFO - Started process (PID=96086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:13:11.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:13:11.352+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:13:11.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:13:11.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:13:11.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:13:11.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:13:11.418+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:13:11.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:13:11.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T06:24:51.300+0000] {processor.py:157} INFO - Started process (PID=96098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:24:51.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:24:51.303+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:24:51.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:24:51.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:24:51.328+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:24:51.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:24:51.338+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:24:51.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:24:51.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-22T06:25:21.855+0000] {processor.py:157} INFO - Started process (PID=96107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:25:21.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:25:21.862+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:25:21.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:25:21.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:25:21.931+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:25:21.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:25:21.947+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:25:21.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:25:21.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T06:41:41.722+0000] {processor.py:157} INFO - Started process (PID=96118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:41:41.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:41:41.731+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:41:41.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:41:41.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:41:41.789+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:41:41.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:41:41.816+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:41:41.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:41:41.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T06:42:12.102+0000] {processor.py:157} INFO - Started process (PID=96128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:12.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:42:12.111+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:12.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:12.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:12.156+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:12.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:42:12.169+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:12.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:42:12.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T06:42:42.401+0000] {processor.py:157} INFO - Started process (PID=96138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:42.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:42:42.404+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:42.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:42.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:42:42.430+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:42.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:42:42.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:42:42.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:42:42.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T06:43:12.722+0000] {processor.py:157} INFO - Started process (PID=96148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:12.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:43:12.727+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:12.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:12.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:12.756+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:12.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:43:12.766+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:12.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:43:12.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T06:43:43.093+0000] {processor.py:157} INFO - Started process (PID=96158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:43.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T06:43:43.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:43.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:43.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T06:43:43.133+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:43.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T06:43:43.143+0000] {logging_mixin.py:151} INFO - [2024-08-22T06:43:43.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T06:43:43.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T07:02:03.528+0000] {processor.py:157} INFO - Started process (PID=96168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:03.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:02:03.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:03.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:03.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:03.575+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:03.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:02:03.588+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:03.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:02:03.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T07:02:33.942+0000] {processor.py:157} INFO - Started process (PID=96178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:33.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:02:33.948+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:33.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:33.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:02:34.001+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:34.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:02:34.018+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:02:34.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:02:34.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T07:19:03.372+0000] {processor.py:157} INFO - Started process (PID=96190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:03.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:19:03.392+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:03.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:03.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:03.449+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:03.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:19:03.466+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:03.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:19:03.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T07:19:33.689+0000] {processor.py:157} INFO - Started process (PID=96200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:33.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:19:33.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:33.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:33.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:19:33.758+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:33.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:19:33.771+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:19:33.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:19:33.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T07:20:04.009+0000] {processor.py:157} INFO - Started process (PID=96210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:04.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:20:04.014+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:04.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:04.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:04.046+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:04.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:20:04.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:04.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:20:04.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T07:20:34.348+0000] {processor.py:157} INFO - Started process (PID=96220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:34.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:20:34.352+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:34.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:34.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:20:34.389+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:34.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:20:34.403+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:20:34.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:20:34.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T07:36:30.504+0000] {processor.py:157} INFO - Started process (PID=96230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:36:30.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:36:30.510+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:36:30.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:36:30.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:36:30.575+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:36:30.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:36:30.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:36:30.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:36:30.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T07:37:00.976+0000] {processor.py:157} INFO - Started process (PID=96240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:00.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:37:00.981+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:00.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:00.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:01.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:01.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:37:01.042+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:01.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:37:01.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T07:37:31.354+0000] {processor.py:157} INFO - Started process (PID=96250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:31.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:37:31.359+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:31.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:31.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:37:31.394+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:31.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:37:31.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:37:31.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:37:31.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T07:38:01.780+0000] {processor.py:157} INFO - Started process (PID=96260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:38:01.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:38:01.791+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:38:01.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:38:01.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:38:01.839+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:38:01.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:38:01.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:38:01.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:38:01.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-22T07:53:42.118+0000] {processor.py:157} INFO - Started process (PID=96270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:53:42.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T07:53:42.124+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:53:42.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:53:42.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T07:53:42.220+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:53:42.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T07:53:42.234+0000] {logging_mixin.py:151} INFO - [2024-08-22T07:53:42.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T07:53:42.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T08:09:55.514+0000] {processor.py:157} INFO - Started process (PID=96280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:09:55.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:09:55.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:09:55.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:09:55.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:09:55.620+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:09:55.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:09:55.656+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:09:55.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:09:55.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T08:10:26.041+0000] {processor.py:157} INFO - Started process (PID=96290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:26.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:10:26.047+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:26.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:26.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:26.110+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:26.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:10:26.129+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:26.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:10:26.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T08:10:56.387+0000] {processor.py:157} INFO - Started process (PID=96300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:56.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:10:56.392+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:56.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:56.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:10:56.418+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:56.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:10:56.428+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:10:56.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:10:56.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T08:11:26.745+0000] {processor.py:157} INFO - Started process (PID=96310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:26.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:11:26.752+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:26.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:26.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:26.793+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:26.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:11:26.807+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:26.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:11:26.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T08:11:57.055+0000] {processor.py:157} INFO - Started process (PID=96320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:57.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:11:57.057+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:57.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:57.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:11:57.086+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:57.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:11:57.100+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:11:57.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:11:57.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T08:28:03.044+0000] {processor.py:157} INFO - Started process (PID=96330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:03.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:28:03.050+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:03.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:03.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:03.104+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:03.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:28:03.125+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:03.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:28:03.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T08:28:33.464+0000] {processor.py:157} INFO - Started process (PID=96340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:33.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:28:33.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:33.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:33.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:28:33.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:33.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:28:33.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:28:33.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:28:33.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T08:45:46.723+0000] {processor.py:157} INFO - Started process (PID=96351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:45:46.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:45:46.727+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:45:46.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:45:46.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:45:46.771+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:45:46.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:45:46.784+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:45:46.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:45:46.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T08:46:17.125+0000] {processor.py:157} INFO - Started process (PID=96362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:17.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:46:17.139+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:17.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:17.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:17.187+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:17.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:46:17.216+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:17.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:46:17.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T08:46:47.428+0000] {processor.py:157} INFO - Started process (PID=96372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:47.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:46:47.437+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:47.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:47.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:46:47.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:47.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:46:47.473+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:46:47.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:46:47.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T08:47:17.783+0000] {processor.py:157} INFO - Started process (PID=96382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:47:17.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T08:47:17.787+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:47:17.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:47:17.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T08:47:17.817+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:47:17.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T08:47:17.828+0000] {logging_mixin.py:151} INFO - [2024-08-22T08:47:17.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T08:47:17.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T09:02:55.449+0000] {processor.py:157} INFO - Started process (PID=96392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:02:55.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:02:55.479+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:02:55.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:02:55.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:02:55.571+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:02:55.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:02:55.601+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:02:55.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:02:55.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-22T09:03:26.026+0000] {processor.py:157} INFO - Started process (PID=96401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:03:26.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:03:26.033+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:03:26.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:03:26.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:03:26.096+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:03:26.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:03:26.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:03:26.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:03:26.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T09:19:46.768+0000] {processor.py:157} INFO - Started process (PID=96413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:19:46.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:19:46.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:19:46.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:19:46.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:19:46.848+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:19:46.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:19:46.873+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:19:46.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:19:46.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-22T09:20:17.145+0000] {processor.py:157} INFO - Started process (PID=96423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:17.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:20:17.157+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:17.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:17.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:17.219+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:17.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:20:17.234+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:17.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:20:17.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-22T09:20:47.424+0000] {processor.py:157} INFO - Started process (PID=96434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:47.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:20:47.427+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:47.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:47.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:20:47.457+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:47.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:20:47.467+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:20:47.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:20:47.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T09:21:17.750+0000] {processor.py:157} INFO - Started process (PID=96444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:17.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:21:17.757+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:17.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:17.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:17.789+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:17.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:21:17.799+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:17.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:21:17.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T09:21:48.118+0000] {processor.py:157} INFO - Started process (PID=96454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:48.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:21:48.120+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:48.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:48.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:21:48.153+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:48.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:21:48.165+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:21:48.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:21:48.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T09:38:06.629+0000] {processor.py:157} INFO - Started process (PID=96464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:06.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:38:06.638+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:06.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:06.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:06.690+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:06.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:38:06.710+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:06.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:38:06.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T09:38:37.087+0000] {processor.py:157} INFO - Started process (PID=96476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:37.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:38:37.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:37.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:37.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:38:37.166+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:37.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:38:37.181+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:38:37.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:38:37.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T09:39:07.400+0000] {processor.py:157} INFO - Started process (PID=96486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:07.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:39:07.408+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:07.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:07.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:07.432+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:07.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:39:07.442+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:07.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:39:07.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T09:39:37.798+0000] {processor.py:157} INFO - Started process (PID=96496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:37.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:39:37.802+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:37.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:37.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:39:37.842+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:37.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:39:37.858+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:39:37.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:39:37.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T09:40:08.260+0000] {processor.py:157} INFO - Started process (PID=96506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:40:08.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:40:08.263+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:40:08.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:40:08.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:40:08.290+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:40:08.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:40:08.300+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:40:08.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:40:08.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T09:57:00.281+0000] {processor.py:157} INFO - Started process (PID=96516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:00.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:57:00.288+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:00.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:00.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:00.383+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:00.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:57:00.410+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:00.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:57:00.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T09:57:30.597+0000] {processor.py:157} INFO - Started process (PID=96527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:30.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:57:30.603+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:30.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:30.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:57:30.665+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:30.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:57:30.684+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:57:30.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:57:30.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T09:58:00.995+0000] {processor.py:157} INFO - Started process (PID=96538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:00.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:58:00.999+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:00.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:01.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:01.035+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:01.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:58:01.046+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:01.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:58:01.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T09:58:31.372+0000] {processor.py:157} INFO - Started process (PID=96548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:31.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:58:31.378+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:31.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:31.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:58:31.421+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:31.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:58:31.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:58:31.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:58:31.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T09:59:01.717+0000] {processor.py:157} INFO - Started process (PID=96558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:59:01.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T09:59:01.721+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:59:01.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:59:01.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T09:59:01.750+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:59:01.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T09:59:01.761+0000] {logging_mixin.py:151} INFO - [2024-08-22T09:59:01.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T09:59:01.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T10:14:39.599+0000] {processor.py:157} INFO - Started process (PID=96568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:14:39.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:14:39.613+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:14:39.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:14:39.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:14:39.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:14:39.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:14:39.724+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:14:39.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:14:39.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-22T10:15:09.972+0000] {processor.py:157} INFO - Started process (PID=96579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:09.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:15:09.979+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:09.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:10.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:10.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:10.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:15:10.051+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:10.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:15:10.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T10:15:40.282+0000] {processor.py:157} INFO - Started process (PID=96590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:40.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:15:40.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:40.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:40.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:15:40.312+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:40.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:15:40.321+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:15:40.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:15:40.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T10:16:10.738+0000] {processor.py:157} INFO - Started process (PID=96600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:10.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:16:10.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:10.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:10.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:10.769+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:10.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:16:10.779+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:10.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:16:10.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T10:16:41.171+0000] {processor.py:157} INFO - Started process (PID=96610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:41.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:16:41.186+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:41.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:41.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:16:41.325+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:41.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:16:41.369+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:16:41.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:16:41.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-08-22T10:33:27.383+0000] {processor.py:157} INFO - Started process (PID=96620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:33:27.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:33:27.392+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:33:27.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:33:27.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:33:27.476+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:33:27.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:33:27.500+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:33:27.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:33:27.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-08-22T10:39:05.036+0000] {processor.py:157} INFO - Started process (PID=96632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:05.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:39:05.047+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:05.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:05.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:05.159+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:05.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:39:05.201+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:05.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:39:05.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-22T10:39:35.419+0000] {processor.py:157} INFO - Started process (PID=96642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:35.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:39:35.426+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:35.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:35.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:39:35.480+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:35.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:39:35.494+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:39:35.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:39:35.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T10:40:05.880+0000] {processor.py:157} INFO - Started process (PID=96652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:05.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:40:05.886+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:05.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:05.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:05.914+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:05.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:40:05.926+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:05.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:40:05.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T10:40:36.223+0000] {processor.py:157} INFO - Started process (PID=96662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:36.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:40:36.230+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:36.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:36.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:40:36.270+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:36.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:40:36.283+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:40:36.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:40:36.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T10:41:06.601+0000] {processor.py:157} INFO - Started process (PID=96672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:06.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:41:06.605+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:06.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:06.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:06.633+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:06.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:41:06.642+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:06.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:41:06.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T10:41:36.973+0000] {processor.py:157} INFO - Started process (PID=96682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:36.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:41:36.975+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:36.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:36.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:41:37.002+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:37.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:41:37.015+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:41:37.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:41:37.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T10:42:07.334+0000] {processor.py:157} INFO - Started process (PID=96692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:07.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:42:07.338+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:07.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:07.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:07.378+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:07.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:42:07.392+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:07.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:42:07.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T10:42:37.663+0000] {processor.py:157} INFO - Started process (PID=96702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:37.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:42:37.666+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:37.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:37.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:42:37.701+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:37.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:42:37.711+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:42:37.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:42:37.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T10:43:08.056+0000] {processor.py:157} INFO - Started process (PID=96712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:43:08.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:43:08.060+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:43:08.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:43:08.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:43:08.103+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:43:08.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:43:08.116+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:43:08.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:43:08.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T10:59:34.774+0000] {processor.py:157} INFO - Started process (PID=96724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:59:34.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T10:59:34.779+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:59:34.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:59:34.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T10:59:34.844+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:59:34.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T10:59:34.867+0000] {logging_mixin.py:151} INFO - [2024-08-22T10:59:34.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T10:59:34.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T11:00:05.096+0000] {processor.py:157} INFO - Started process (PID=96734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:05.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:00:05.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:05.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:05.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:05.180+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:05.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:00:05.195+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:05.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:00:05.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T11:00:35.503+0000] {processor.py:157} INFO - Started process (PID=96744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:35.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:00:35.505+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:35.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:35.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:00:35.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:35.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:00:35.540+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:00:35.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:00:35.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-22T11:01:05.761+0000] {processor.py:157} INFO - Started process (PID=96754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:01:05.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:01:05.763+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:01:05.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:01:05.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:01:05.796+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:01:05.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:01:05.808+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:01:05.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:01:05.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T11:18:00.632+0000] {processor.py:157} INFO - Started process (PID=96764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:00.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:18:00.637+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:00.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:00.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:00.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:00.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:18:00.830+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:00.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:18:00.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-08-22T11:18:31.140+0000] {processor.py:157} INFO - Started process (PID=96773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:31.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:18:31.153+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:31.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:31.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:18:31.231+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:31.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:18:31.247+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:18:31.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:18:31.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-22T11:19:01.446+0000] {processor.py:157} INFO - Started process (PID=96784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:01.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:19:01.450+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:01.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:01.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:01.483+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:01.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:19:01.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:01.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:19:01.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T11:19:31.847+0000] {processor.py:157} INFO - Started process (PID=96794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:31.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:19:31.851+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:31.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:31.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:19:31.881+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:31.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:19:31.893+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:19:31.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:19:31.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T11:20:02.186+0000] {processor.py:157} INFO - Started process (PID=96804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:02.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:20:02.191+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:02.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:02.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:02.229+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:02.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:20:02.241+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:02.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:20:02.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-22T11:20:32.469+0000] {processor.py:157} INFO - Started process (PID=96814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:32.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:20:32.473+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:32.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:32.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:20:32.500+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:32.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:20:32.510+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:20:32.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:20:32.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T11:21:02.845+0000] {processor.py:157} INFO - Started process (PID=96824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:21:02.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:21:02.850+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:21:02.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:21:02.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:21:02.883+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:21:02.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:21:02.892+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:21:02.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:21:02.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T11:36:43.087+0000] {processor.py:157} INFO - Started process (PID=96834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:36:43.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:36:43.092+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:36:43.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:36:43.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:36:43.154+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:36:43.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:36:43.171+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:36:43.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:36:43.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T11:37:13.505+0000] {processor.py:157} INFO - Started process (PID=96844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:13.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:37:13.514+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:13.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:13.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:13.582+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:13.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:37:13.596+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:13.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:37:13.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-22T11:37:43.818+0000] {processor.py:157} INFO - Started process (PID=96854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:43.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:37:43.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:43.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:43.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:37:43.846+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:43.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:37:43.857+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:37:43.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:37:43.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T11:38:14.111+0000] {processor.py:157} INFO - Started process (PID=96864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:14.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:38:14.115+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:14.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:14.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:14.141+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:14.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:38:14.150+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:14.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:38:14.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T11:38:44.413+0000] {processor.py:157} INFO - Started process (PID=96873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:44.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:38:44.419+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:44.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:44.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:38:44.484+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:44.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:38:44.498+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:38:44.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:38:44.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T11:39:14.696+0000] {processor.py:157} INFO - Started process (PID=96884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:39:14.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:39:14.702+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:39:14.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:39:14.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:39:14.750+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:39:14.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:39:14.767+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:39:14.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:39:14.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T11:56:08.894+0000] {processor.py:157} INFO - Started process (PID=96894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:08.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:56:08.908+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:08.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:08.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:08.967+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:08.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:56:08.990+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:08.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:56:09.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-22T11:56:39.302+0000] {processor.py:157} INFO - Started process (PID=96903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:39.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:56:39.316+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:39.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:39.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:56:39.375+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:39.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:56:39.393+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:56:39.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:56:39.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T11:57:09.609+0000] {processor.py:157} INFO - Started process (PID=96914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:09.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:57:09.612+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:09.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:09.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:09.642+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:09.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:57:09.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:09.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:57:09.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T11:57:40.000+0000] {processor.py:157} INFO - Started process (PID=96924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:40.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T11:57:40.007+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:40.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:40.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T11:57:40.048+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:40.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T11:57:40.063+0000] {logging_mixin.py:151} INFO - [2024-08-22T11:57:40.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T11:57:40.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T12:13:18.081+0000] {processor.py:157} INFO - Started process (PID=96934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:18.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:13:18.091+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:18.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:18.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:18.144+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:18.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:13:18.170+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:18.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:13:18.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T12:13:48.534+0000] {processor.py:157} INFO - Started process (PID=96944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:48.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:13:48.538+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:48.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:48.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:13:48.572+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:48.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:13:48.584+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:13:48.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:13:48.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-22T12:14:18.949+0000] {processor.py:157} INFO - Started process (PID=96954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:18.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:14:18.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:18.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:18.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:18.996+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:18.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:14:19.008+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:19.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:14:19.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T12:14:49.256+0000] {processor.py:157} INFO - Started process (PID=96964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:49.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:14:49.261+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:49.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:49.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:14:49.294+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:49.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:14:49.307+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:14:49.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:14:49.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T12:15:19.541+0000] {processor.py:157} INFO - Started process (PID=96974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:19.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:15:19.544+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:19.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:19.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:19.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:19.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:15:19.617+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:19.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:15:19.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T12:15:49.976+0000] {processor.py:157} INFO - Started process (PID=96984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:49.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:15:49.982+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:49.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:49.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:15:50.015+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:50.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:15:50.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:15:50.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:15:50.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T12:32:10.965+0000] {processor.py:157} INFO - Started process (PID=96994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:10.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:32:10.969+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:10.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:10.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:11.013+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:11.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:32:11.026+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:11.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:32:11.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T12:32:41.334+0000] {processor.py:157} INFO - Started process (PID=97003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:41.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:32:41.344+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:41.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:41.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:32:41.423+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:41.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:32:41.436+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:32:41.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:32:41.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T12:33:11.816+0000] {processor.py:157} INFO - Started process (PID=97014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:11.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:33:11.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:11.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:11.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:11.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:11.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:33:11.874+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:11.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:33:11.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T12:33:42.162+0000] {processor.py:157} INFO - Started process (PID=97024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:42.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:33:42.165+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:42.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:42.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:33:42.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:42.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:33:42.202+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:33:42.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:33:42.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T12:36:20.117+0000] {processor.py:157} INFO - Started process (PID=97034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:20.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:36:20.121+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:20.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:20.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:20.164+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:20.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:36:20.180+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:20.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:36:20.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T12:36:50.415+0000] {processor.py:157} INFO - Started process (PID=97045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:50.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:36:50.419+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:50.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:50.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:36:50.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:50.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:36:50.473+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:36:50.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:36:50.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T12:37:20.752+0000] {processor.py:157} INFO - Started process (PID=97056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:20.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:37:20.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:20.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:20.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:20.782+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:20.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:37:20.794+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:20.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:37:20.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T12:37:51.101+0000] {processor.py:157} INFO - Started process (PID=97066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:51.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:37:51.104+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:51.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:51.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:37:51.132+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:51.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:37:51.143+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:37:51.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:37:51.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T12:38:21.515+0000] {processor.py:157} INFO - Started process (PID=97076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:38:21.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:38:21.518+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:38:21.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:38:21.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:38:21.547+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:38:21.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:38:21.562+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:38:21.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:38:21.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T12:40:24.318+0000] {processor.py:157} INFO - Started process (PID=97086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:24.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:40:24.323+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:24.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:24.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:24.358+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:24.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:40:24.369+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:24.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:40:24.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T12:40:54.730+0000] {processor.py:157} INFO - Started process (PID=97098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:54.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:40:54.738+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:54.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:54.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:40:54.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:54.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:40:54.785+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:40:54.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:40:54.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T12:41:25.068+0000] {processor.py:157} INFO - Started process (PID=97108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:25.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:41:25.072+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:25.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:25.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:25.102+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:25.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:41:25.115+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:25.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:41:25.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T12:41:55.503+0000] {processor.py:157} INFO - Started process (PID=97118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:55.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:41:55.507+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:55.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:55.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:41:55.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:55.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:41:55.543+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:41:55.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:41:55.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T12:42:25.928+0000] {processor.py:157} INFO - Started process (PID=97128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:42:25.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:42:25.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:42:25.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:42:25.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:42:25.973+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:42:25.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:42:25.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:42:25.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:42:25.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T12:59:00.232+0000] {processor.py:157} INFO - Started process (PID=97138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:00.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:59:00.238+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:00.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:00.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:00.302+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:00.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:59:00.320+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:00.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:59:00.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-22T12:59:30.556+0000] {processor.py:157} INFO - Started process (PID=97150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:30.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T12:59:30.565+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:30.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:30.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T12:59:30.611+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:30.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T12:59:30.627+0000] {logging_mixin.py:151} INFO - [2024-08-22T12:59:30.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T12:59:30.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T13:00:00.879+0000] {processor.py:157} INFO - Started process (PID=97160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:00.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:00:00.896+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:00.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:00.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:00.935+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:00.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:00:00.951+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:00.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:00:00.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T13:00:31.256+0000] {processor.py:157} INFO - Started process (PID=97170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:31.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:00:31.260+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:31.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:31.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:00:31.299+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:31.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:00:31.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:00:31.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:00:31.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T13:03:07.902+0000] {processor.py:157} INFO - Started process (PID=97180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:07.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:03:07.913+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:07.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:07.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:07.957+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:07.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:03:07.971+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:07.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:03:07.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T13:03:38.240+0000] {processor.py:157} INFO - Started process (PID=97192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:38.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:03:38.246+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:38.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:38.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:03:38.317+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:38.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:03:38.334+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:03:38.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:03:38.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-22T13:04:08.567+0000] {processor.py:157} INFO - Started process (PID=97202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:08.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:04:08.569+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:08.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:08.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:08.593+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:08.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:04:08.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:08.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:04:08.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-22T13:04:38.958+0000] {processor.py:157} INFO - Started process (PID=97212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:38.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:04:38.963+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:38.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:38.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:04:39.004+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:39.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:04:39.016+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:04:39.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:04:39.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T13:05:09.317+0000] {processor.py:157} INFO - Started process (PID=97222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:05:09.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:05:09.319+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:05:09.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:05:09.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:05:09.346+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:05:09.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:05:09.356+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:05:09.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:05:09.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T13:21:45.055+0000] {processor.py:157} INFO - Started process (PID=97232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:21:45.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:21:45.060+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:21:45.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:21:45.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:21:45.128+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:21:45.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:21:45.141+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:21:45.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:21:45.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T13:22:15.415+0000] {processor.py:157} INFO - Started process (PID=97244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:15.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:22:15.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:15.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:15.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:15.478+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:15.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:22:15.491+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:15.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:22:15.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T13:22:45.769+0000] {processor.py:157} INFO - Started process (PID=97254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:45.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:22:45.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:45.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:45.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:22:45.815+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:45.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:22:45.828+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:22:45.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:22:45.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T13:23:39.700+0000] {processor.py:157} INFO - Started process (PID=97266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:23:39.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:23:39.703+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:23:39.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:23:39.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:23:39.735+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:23:39.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:23:39.744+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:23:39.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:23:39.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T13:24:10.186+0000] {processor.py:157} INFO - Started process (PID=97276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:10.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:24:10.206+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:10.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:10.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:10.253+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:10.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:24:10.266+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:10.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:24:10.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T13:24:40.524+0000] {processor.py:157} INFO - Started process (PID=97286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:40.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:24:40.527+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:40.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:40.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:24:40.554+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:40.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:24:40.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:24:40.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:24:40.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T13:25:10.964+0000] {processor.py:157} INFO - Started process (PID=97295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:10.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:25:10.969+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:10.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:10.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:11.012+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:11.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:25:11.023+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:11.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:25:11.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-22T13:25:41.319+0000] {processor.py:157} INFO - Started process (PID=97306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:41.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:25:41.324+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:41.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:41.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:25:41.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:41.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:25:41.358+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:25:41.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:25:41.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T13:26:11.853+0000] {processor.py:157} INFO - Started process (PID=97316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:26:11.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:26:11.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:26:11.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:26:11.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:26:11.904+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:26:11.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:26:11.969+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:26:11.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:26:11.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-22T13:41:32.540+0000] {processor.py:157} INFO - Started process (PID=97327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:41:32.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:41:32.546+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:41:32.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:41:32.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:41:32.589+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:41:32.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:41:32.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:41:32.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:41:32.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T13:42:02.874+0000] {processor.py:157} INFO - Started process (PID=97338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:02.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:42:02.885+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:02.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:02.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:02.933+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:02.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:42:02.947+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:02.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:42:02.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T13:42:33.305+0000] {processor.py:157} INFO - Started process (PID=97348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:33.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:42:33.309+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:33.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:33.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:42:33.337+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:33.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:42:33.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:42:33.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:42:33.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T13:43:03.699+0000] {processor.py:157} INFO - Started process (PID=97357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:03.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:43:03.705+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:03.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:03.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:03.765+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:03.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:43:03.783+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:03.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:43:03.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T13:43:33.989+0000] {processor.py:157} INFO - Started process (PID=97368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:33.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:43:33.993+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:33.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:34.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:43:34.020+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:34.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:43:34.030+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:43:34.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:43:34.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T13:59:44.492+0000] {processor.py:157} INFO - Started process (PID=97378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:59:44.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T13:59:44.500+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:59:44.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:59:44.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T13:59:44.551+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:59:44.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T13:59:44.565+0000] {logging_mixin.py:151} INFO - [2024-08-22T13:59:44.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T13:59:44.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T14:00:14.868+0000] {processor.py:157} INFO - Started process (PID=97390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:14.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:00:14.880+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:14.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:14.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:14.938+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:14.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:00:14.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:14.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:00:14.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T14:00:45.175+0000] {processor.py:157} INFO - Started process (PID=97400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:45.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:00:45.179+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:45.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:45.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:00:45.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:45.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:00:45.219+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:00:45.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:00:45.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T14:01:15.562+0000] {processor.py:157} INFO - Started process (PID=97410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:15.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:01:15.567+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:15.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:15.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:15.605+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:15.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:01:15.618+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:15.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:01:15.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T14:01:45.908+0000] {processor.py:157} INFO - Started process (PID=97420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:45.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:01:45.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:45.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:45.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:01:45.935+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:45.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:01:45.946+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:01:45.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:01:45.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-22T14:02:16.318+0000] {processor.py:157} INFO - Started process (PID=97430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:16.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:02:16.323+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:16.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:16.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:16.363+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:16.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:02:16.377+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:16.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:02:16.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T14:02:46.755+0000] {processor.py:157} INFO - Started process (PID=97440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:46.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:02:46.758+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:46.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:46.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:02:46.782+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:46.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:02:46.793+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:02:46.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:02:46.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-22T14:03:17.074+0000] {processor.py:157} INFO - Started process (PID=97449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:17.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:03:17.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:17.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:17.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:17.144+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:17.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:03:17.157+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:17.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:03:17.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-22T14:03:47.393+0000] {processor.py:157} INFO - Started process (PID=97460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:47.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:03:47.396+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:47.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:47.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:03:47.421+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:47.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:03:47.432+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:03:47.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:03:47.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T14:19:34.675+0000] {processor.py:157} INFO - Started process (PID=97470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:19:34.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:19:34.693+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:19:34.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:19:34.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:19:34.754+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:19:34.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:19:34.767+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:19:34.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:19:34.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T14:20:05.052+0000] {processor.py:157} INFO - Started process (PID=97479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:05.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:20:05.064+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:05.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:05.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:05.121+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:05.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:20:05.134+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:05.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:20:05.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T14:20:35.465+0000] {processor.py:157} INFO - Started process (PID=97490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:35.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:20:35.481+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:35.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:35.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:20:35.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:35.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:20:35.557+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:20:35.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:20:35.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-22T14:21:05.852+0000] {processor.py:157} INFO - Started process (PID=97500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:05.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:21:05.856+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:05.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:05.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:05.883+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:05.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:21:05.894+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:05.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:21:05.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T14:21:36.249+0000] {processor.py:157} INFO - Started process (PID=97510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:36.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:21:36.253+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:36.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:36.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:21:36.294+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:36.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:21:36.310+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:21:36.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:21:36.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T14:37:38.372+0000] {processor.py:157} INFO - Started process (PID=97520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:37:38.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:37:38.387+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:37:38.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:37:38.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:37:38.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:37:38.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:37:38.464+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:37:38.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:37:38.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T14:38:08.837+0000] {processor.py:157} INFO - Started process (PID=97532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:08.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:38:08.850+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:08.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:08.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:08.917+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:08.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:38:08.932+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:08.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:38:08.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T14:38:39.155+0000] {processor.py:157} INFO - Started process (PID=97542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:39.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:38:39.161+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:39.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:39.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:38:39.215+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:39.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:38:39.229+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:38:39.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:38:39.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T14:39:09.549+0000] {processor.py:157} INFO - Started process (PID=97552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:09.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:39:09.552+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:09.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:09.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:09.585+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:09.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:39:09.594+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:09.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:39:09.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T14:39:40.126+0000] {processor.py:157} INFO - Started process (PID=97562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:40.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:39:40.132+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:40.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:40.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:39:40.209+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:40.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:39:40.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:39:40.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:39:40.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T14:41:32.405+0000] {processor.py:157} INFO - Started process (PID=97572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:41:32.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:41:32.409+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:41:32.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:41:32.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:41:32.434+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:41:32.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:41:32.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:41:32.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:41:32.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-22T14:42:02.780+0000] {processor.py:157} INFO - Started process (PID=97584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:02.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:42:02.798+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:02.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:02.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:02.851+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:02.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:42:02.864+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:02.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:42:02.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T14:42:33.205+0000] {processor.py:157} INFO - Started process (PID=97594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:33.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:42:33.213+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:33.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:33.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:42:33.265+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:33.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:42:33.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:42:33.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:42:33.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-22T14:43:03.560+0000] {processor.py:157} INFO - Started process (PID=97603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:43:03.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:43:03.567+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:43:03.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:43:03.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:43:03.609+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:43:03.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:43:03.624+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:43:03.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:43:03.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T14:59:29.665+0000] {processor.py:157} INFO - Started process (PID=97616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:59:29.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T14:59:29.670+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:59:29.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:59:29.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T14:59:29.741+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:59:29.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T14:59:29.766+0000] {logging_mixin.py:151} INFO - [2024-08-22T14:59:29.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T14:59:29.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T15:00:00.002+0000] {processor.py:157} INFO - Started process (PID=97626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:00.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:00:00.014+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:00.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:00.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:00.101+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:00.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:00:00.119+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:00.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:00:00.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-22T15:00:30.437+0000] {processor.py:157} INFO - Started process (PID=97635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:30.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:00:30.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:30.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:30.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:00:30.489+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:30.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:00:30.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:00:30.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:00:30.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T15:01:00.855+0000] {processor.py:157} INFO - Started process (PID=97646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:00.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:01:00.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:00.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:00.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:00.901+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:00.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:01:00.913+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:00.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:01:00.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T15:01:31.237+0000] {processor.py:157} INFO - Started process (PID=97656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:31.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:01:31.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:31.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:31.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:01:31.269+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:31.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:01:31.280+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:01:31.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:01:31.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T15:08:25.002+0000] {processor.py:157} INFO - Started process (PID=97667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:25.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:08:25.007+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:25.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:25.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:25.064+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:25.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:08:25.086+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:25.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:08:25.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-22T15:08:55.274+0000] {processor.py:157} INFO - Started process (PID=97678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:55.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:08:55.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:55.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:55.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:08:55.335+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:55.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:08:55.353+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:08:55.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:08:55.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T15:09:25.629+0000] {processor.py:157} INFO - Started process (PID=97688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:25.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:09:25.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:25.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:25.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:25.661+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:25.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:09:25.672+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:25.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:09:25.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T15:09:56.026+0000] {processor.py:157} INFO - Started process (PID=97698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:56.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:09:56.032+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:56.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:56.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:09:56.071+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:56.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:09:56.087+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:09:56.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:09:56.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T15:10:26.282+0000] {processor.py:157} INFO - Started process (PID=97708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:26.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:10:26.285+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:26.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:26.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:26.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:26.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:10:26.322+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:26.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:10:26.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T15:10:56.639+0000] {processor.py:157} INFO - Started process (PID=97718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:56.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:10:56.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:56.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:56.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:10:56.670+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:56.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:10:56.679+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:10:56.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:10:56.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-22T15:11:27.021+0000] {processor.py:157} INFO - Started process (PID=97728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:27.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:11:27.027+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:27.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:27.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:27.065+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:27.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:11:27.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:27.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:11:27.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T15:11:57.410+0000] {processor.py:157} INFO - Started process (PID=97738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:57.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:11:57.413+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:57.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:57.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:11:57.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:57.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:11:57.456+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:11:57.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:11:57.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T15:12:27.796+0000] {processor.py:157} INFO - Started process (PID=97748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:27.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:12:27.800+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:27.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:27.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:27.826+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:27.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:12:27.836+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:27.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:12:27.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T15:12:58.190+0000] {processor.py:157} INFO - Started process (PID=97758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:58.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:12:58.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:58.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:58.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:12:58.221+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:58.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:12:58.232+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:12:58.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:12:58.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T15:13:28.520+0000] {processor.py:157} INFO - Started process (PID=97767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:13:28.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:13:28.527+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:13:28.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:13:28.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:13:28.583+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:13:28.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:13:28.598+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:13:28.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:13:28.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T15:14:00.820+0000] {processor.py:157} INFO - Started process (PID=97778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:14:00.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:14:00.823+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:14:00.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:14:00.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:14:00.852+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:14:00.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:14:00.864+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:14:00.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:14:00.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T15:29:46.608+0000] {processor.py:157} INFO - Started process (PID=97788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:29:46.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:29:46.613+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:29:46.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:29:46.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:29:46.681+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:29:46.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:29:46.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:29:46.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:29:46.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-22T15:30:16.980+0000] {processor.py:157} INFO - Started process (PID=97798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:16.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:30:16.993+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:16.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:17.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:17.063+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:17.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:30:17.077+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:17.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:30:17.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T15:30:47.464+0000] {processor.py:157} INFO - Started process (PID=97808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:47.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:30:47.470+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:47.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:47.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:30:47.499+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:47.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:30:47.510+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:30:47.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:30:47.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T15:31:17.844+0000] {processor.py:157} INFO - Started process (PID=97818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:17.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:31:17.850+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:17.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:17.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:17.922+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:17.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:31:17.936+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:17.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:31:17.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T15:31:48.306+0000] {processor.py:157} INFO - Started process (PID=97828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:48.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:31:48.310+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:48.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:48.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:31:48.337+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:48.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:31:48.347+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:31:48.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:31:48.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T15:42:29.800+0000] {processor.py:157} INFO - Started process (PID=97838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:42:29.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:42:29.817+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:42:29.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:42:29.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:42:29.886+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:42:29.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:42:29.915+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:42:29.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:42:29.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-22T15:59:20.147+0000] {processor.py:157} INFO - Started process (PID=97852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:20.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:59:20.162+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:20.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:20.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:20.265+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:20.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:59:20.295+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:20.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:59:20.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-22T15:59:50.534+0000] {processor.py:157} INFO - Started process (PID=97862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:50.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T15:59:50.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:50.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:50.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T15:59:50.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:50.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T15:59:50.715+0000] {logging_mixin.py:151} INFO - [2024-08-22T15:59:50.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T15:59:50.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-08-22T16:16:58.277+0000] {processor.py:157} INFO - Started process (PID=97871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:16:58.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:16:58.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:16:58.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:16:58.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:16:58.334+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:16:58.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:16:58.353+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:16:58.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:16:58.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T16:17:28.653+0000] {processor.py:157} INFO - Started process (PID=97882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:28.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:17:28.660+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:28.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:28.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:28.702+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:28.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:17:28.728+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:28.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:17:28.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T16:17:59.067+0000] {processor.py:157} INFO - Started process (PID=97891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:59.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:17:59.070+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:59.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:59.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:17:59.092+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:59.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:17:59.104+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:17:59.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:17:59.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-22T16:18:29.415+0000] {processor.py:157} INFO - Started process (PID=97902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:29.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:18:29.418+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:29.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:29.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:29.446+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:29.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:18:29.457+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:29.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:18:29.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T16:18:59.805+0000] {processor.py:157} INFO - Started process (PID=97912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:59.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:18:59.807+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:59.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:59.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:18:59.834+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:59.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:18:59.845+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:18:59.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:18:59.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T16:19:30.111+0000] {processor.py:157} INFO - Started process (PID=97922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:19:30.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:19:30.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:19:30.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:19:30.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:19:30.136+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:19:30.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:19:30.145+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:19:30.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:19:30.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-08-22T16:20:00.561+0000] {processor.py:157} INFO - Started process (PID=97932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:20:00.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:20:00.569+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:20:00.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:20:00.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:20:00.618+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:20:00.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:20:00.635+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:20:00.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:20:00.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T16:36:40.354+0000] {processor.py:157} INFO - Started process (PID=97943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:36:40.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:36:40.358+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:36:40.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:36:40.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:36:40.393+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:36:40.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:36:40.406+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:36:40.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:36:40.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-22T16:51:32.985+0000] {processor.py:157} INFO - Started process (PID=97954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:51:32.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:51:32.994+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:51:32.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:51:33.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:51:33.054+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:51:33.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:51:33.079+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:51:33.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:51:33.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T16:52:03.466+0000] {processor.py:157} INFO - Started process (PID=97964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:03.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:52:03.475+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:03.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:03.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:03.525+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:03.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:52:03.548+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:03.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:52:03.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T16:52:36.103+0000] {processor.py:157} INFO - Started process (PID=97974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:36.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:52:36.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:36.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:36.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:52:36.133+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:36.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:52:36.146+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:52:36.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:52:36.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T16:55:21.601+0000] {processor.py:157} INFO - Started process (PID=97986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:21.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:55:21.608+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:21.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:21.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:21.722+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:21.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:55:21.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:21.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:55:21.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T16:55:52.197+0000] {processor.py:157} INFO - Started process (PID=97996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:52.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:55:52.201+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:52.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:52.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:55:52.236+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:52.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:55:52.251+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:55:52.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:55:52.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T16:59:19.775+0000] {processor.py:157} INFO - Started process (PID=98005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:59:19.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T16:59:19.786+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:59:19.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:59:19.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T16:59:19.871+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:59:19.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T16:59:19.894+0000] {logging_mixin.py:151} INFO - [2024-08-22T16:59:19.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T16:59:19.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-22T17:16:09.801+0000] {processor.py:157} INFO - Started process (PID=98016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:09.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:16:09.818+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:09.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:09.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:09.873+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:09.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:16:09.901+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:09.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:16:09.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T17:16:40.301+0000] {processor.py:157} INFO - Started process (PID=98026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:40.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:16:40.308+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:40.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:40.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:16:40.358+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:40.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:16:40.371+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:16:40.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:16:40.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T17:17:10.610+0000] {processor.py:157} INFO - Started process (PID=98036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:10.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:17:10.613+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:10.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:10.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:10.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:10.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:17:10.652+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:10.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:17:10.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T17:17:41.001+0000] {processor.py:157} INFO - Started process (PID=98046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:41.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:17:41.005+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:41.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:41.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:17:41.044+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:41.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:17:41.058+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:17:41.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:17:41.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T17:18:11.313+0000] {processor.py:157} INFO - Started process (PID=98056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:11.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:18:11.315+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:11.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:11.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:11.344+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:11.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:18:11.355+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:11.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:18:11.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T17:18:41.679+0000] {processor.py:157} INFO - Started process (PID=98066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:41.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:18:41.682+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:41.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:41.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:18:41.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:41.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:18:41.717+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:18:41.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:18:41.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T17:35:48.815+0000] {processor.py:157} INFO - Started process (PID=98078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:35:48.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:35:48.818+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:35:48.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:35:48.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:35:48.843+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:35:48.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:35:48.852+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:35:48.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:35:48.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-22T17:36:19.270+0000] {processor.py:157} INFO - Started process (PID=98088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:19.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:36:19.274+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:19.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:19.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:19.326+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:19.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:36:19.339+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:19.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:36:19.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T17:36:49.581+0000] {processor.py:157} INFO - Started process (PID=98098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:49.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:36:49.584+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:49.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:49.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:36:49.615+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:49.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:36:49.627+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:36:49.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:36:49.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T17:37:20.037+0000] {processor.py:157} INFO - Started process (PID=98108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:20.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:37:20.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:20.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:20.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:20.068+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:20.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:37:20.078+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:20.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:37:20.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T17:37:50.441+0000] {processor.py:157} INFO - Started process (PID=98118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:50.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:37:50.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:50.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:50.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:37:50.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:50.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:37:50.481+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:37:50.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:37:50.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T17:55:56.688+0000] {processor.py:157} INFO - Started process (PID=98129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:55:56.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:55:56.695+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:55:56.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:55:56.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:55:56.758+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:55:56.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:55:56.782+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:55:56.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:55:56.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T17:56:27.028+0000] {processor.py:157} INFO - Started process (PID=98139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:27.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:56:27.042+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:27.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:27.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:27.094+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:27.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:56:27.110+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:27.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:56:27.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-22T17:56:57.458+0000] {processor.py:157} INFO - Started process (PID=98150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:57.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:56:57.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:57.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:57.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:56:57.492+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:57.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:56:57.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:56:57.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:56:57.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-22T17:57:27.875+0000] {processor.py:157} INFO - Started process (PID=98159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:27.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:57:27.883+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:27.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:27.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:27.930+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:27.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:57:27.946+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:27.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:57:27.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T17:57:58.282+0000] {processor.py:157} INFO - Started process (PID=98170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:58.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:57:58.285+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:58.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:58.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:57:58.312+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:58.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:57:58.325+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:57:58.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:57:58.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T17:58:28.734+0000] {processor.py:157} INFO - Started process (PID=98180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:58:28.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T17:58:28.741+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:58:28.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:58:28.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T17:58:28.783+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:58:28.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T17:58:28.797+0000] {logging_mixin.py:151} INFO - [2024-08-22T17:58:28.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T17:58:28.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T18:14:05.252+0000] {processor.py:157} INFO - Started process (PID=98190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:05.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:14:05.260+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:05.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:05.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:05.326+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:05.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:14:05.349+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:05.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:14:05.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T18:14:35.605+0000] {processor.py:157} INFO - Started process (PID=98199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:35.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:14:35.613+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:35.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:35.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:14:35.656+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:35.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:14:35.674+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:14:35.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:14:35.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T18:15:06.056+0000] {processor.py:157} INFO - Started process (PID=98210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:06.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:15:06.060+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:06.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:06.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:06.091+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:06.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:15:06.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:06.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:15:06.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T18:15:36.438+0000] {processor.py:157} INFO - Started process (PID=98220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:36.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:15:36.447+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:36.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:36.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:15:36.484+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:36.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:15:36.497+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:15:36.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:15:36.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T18:16:06.797+0000] {processor.py:157} INFO - Started process (PID=98230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:06.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:16:06.799+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:06.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:06.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:06.827+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:06.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:16:06.841+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:06.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:16:06.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T18:16:37.236+0000] {processor.py:157} INFO - Started process (PID=98240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:37.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:16:37.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:37.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:37.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:16:37.269+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:37.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:16:37.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:16:37.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:16:37.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T18:17:07.685+0000] {processor.py:157} INFO - Started process (PID=98250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:07.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:17:07.692+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:07.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:07.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:07.737+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:07.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:17:07.754+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:07.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:17:07.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T18:17:38.136+0000] {processor.py:157} INFO - Started process (PID=98260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:38.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:17:38.140+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:38.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:38.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:17:38.168+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:38.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:17:38.178+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:17:38.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:17:38.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T18:18:08.521+0000] {processor.py:157} INFO - Started process (PID=98270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:08.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:18:08.527+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:08.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:08.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:08.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:08.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:18:08.579+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:08.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:18:08.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-22T18:18:38.861+0000] {processor.py:157} INFO - Started process (PID=98280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:38.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:18:38.864+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:38.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:38.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:18:38.891+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:38.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:18:38.903+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:18:38.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:18:38.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T18:33:22.844+0000] {processor.py:157} INFO - Started process (PID=98289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:22.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:33:22.850+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:22.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:22.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:22.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:22.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:33:22.926+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:22.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:33:22.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T18:33:53.183+0000] {processor.py:157} INFO - Started process (PID=98302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:53.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:33:53.189+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:53.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:53.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:33:53.248+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:53.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:33:53.267+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:33:53.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:33:53.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-22T18:34:23.454+0000] {processor.py:157} INFO - Started process (PID=98311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:23.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:34:23.456+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:23.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:23.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:23.484+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:23.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:34:23.495+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:23.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:34:23.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T18:34:53.848+0000] {processor.py:157} INFO - Started process (PID=98322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:53.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:34:53.853+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:53.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:53.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:34:53.880+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:53.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:34:53.890+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:34:53.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:34:53.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T18:35:24.188+0000] {processor.py:157} INFO - Started process (PID=98331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:35:24.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:35:24.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:35:24.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:35:24.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:35:24.219+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:35:24.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:35:24.228+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:35:24.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:35:24.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T18:51:25.517+0000] {processor.py:157} INFO - Started process (PID=98344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:25.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:51:25.537+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:25.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:25.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:25.591+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:25.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:51:25.612+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:25.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:51:25.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T18:51:55.824+0000] {processor.py:157} INFO - Started process (PID=98353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:55.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:51:55.828+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:55.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:55.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:51:55.866+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:55.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:51:55.878+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:51:55.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:51:55.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T18:53:31.306+0000] {processor.py:157} INFO - Started process (PID=98364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:53:31.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:53:31.312+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:53:31.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:53:31.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:53:31.362+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:53:31.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:53:31.375+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:53:31.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:53:31.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T18:54:01.636+0000] {processor.py:157} INFO - Started process (PID=98374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:54:01.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:54:01.641+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:54:01.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:54:01.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:54:01.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:54:01.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:54:01.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:54:01.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:54:01.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T18:55:37.067+0000] {processor.py:157} INFO - Started process (PID=98384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:55:37.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:55:37.084+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:55:37.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:55:37.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:55:37.156+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:55:37.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:55:37.187+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:55:37.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:55:37.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T18:56:07.494+0000] {processor.py:157} INFO - Started process (PID=98394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:56:07.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:56:07.503+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:56:07.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:56:07.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:56:07.608+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:56:07.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:56:07.625+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:56:07.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:56:07.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T18:57:01.245+0000] {processor.py:157} INFO - Started process (PID=98404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:01.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:57:01.252+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:01.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:01.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:01.300+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:01.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:57:01.316+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:01.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:57:01.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T18:57:58.448+0000] {processor.py:157} INFO - Started process (PID=98415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:58.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:57:58.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:58.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:58.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:57:58.531+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:58.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:57:58.546+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:57:58.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:57:58.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-22T18:58:28.768+0000] {processor.py:157} INFO - Started process (PID=98426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:58:28.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:58:28.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:58:28.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:58:28.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:58:28.809+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:58:28.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:58:28.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:58:28.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:58:28.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T18:59:05.386+0000] {processor.py:157} INFO - Started process (PID=98436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:59:05.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T18:59:05.389+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:59:05.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:59:05.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T18:59:05.416+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:59:05.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T18:59:05.426+0000] {logging_mixin.py:151} INFO - [2024-08-22T18:59:05.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T18:59:05.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T19:00:24.903+0000] {processor.py:157} INFO - Started process (PID=98446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:24.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:00:24.907+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:24.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:24.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:24.970+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:24.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:00:24.984+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:24.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:00:24.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T19:00:55.318+0000] {processor.py:157} INFO - Started process (PID=98456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:55.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:00:55.322+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:55.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:55.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:00:55.351+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:55.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:00:55.362+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:00:55.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:00:55.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T19:01:29.352+0000] {processor.py:157} INFO - Started process (PID=98466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:01:29.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:01:29.361+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:01:29.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:01:29.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:01:29.413+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:01:29.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:01:29.429+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:01:29.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:01:29.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T19:02:16.216+0000] {processor.py:157} INFO - Started process (PID=98475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:16.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:02:16.224+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:16.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:16.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:16.325+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:16.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:02:16.346+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:16.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:02:16.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-22T19:02:46.642+0000] {processor.py:157} INFO - Started process (PID=98487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:46.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:02:46.647+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:46.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:46.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:02:46.701+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:46.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:02:46.714+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:02:46.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:02:46.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T19:05:05.198+0000] {processor.py:157} INFO - Started process (PID=98497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:05:05.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:05:05.205+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:05:05.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:05:05.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:05:05.252+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:05:05.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:05:05.279+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:05:05.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:05:05.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-22T19:06:39.211+0000] {processor.py:157} INFO - Started process (PID=98508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:06:39.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:06:39.216+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:06:39.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:06:39.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:06:39.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:06:39.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:06:39.282+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:06:39.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:06:39.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T19:07:09.541+0000] {processor.py:157} INFO - Started process (PID=98519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:09.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:07:09.547+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:09.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:09.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:09.595+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:09.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:07:09.609+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:09.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:07:09.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T19:07:40.655+0000] {processor.py:157} INFO - Started process (PID=98529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:40.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:07:40.671+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:40.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:40.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:07:40.736+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:40.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:07:40.749+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:07:40.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:07:40.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T19:08:11.024+0000] {processor.py:157} INFO - Started process (PID=98538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:08:11.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:08:11.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:08:11.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:08:11.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:08:11.086+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:08:11.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:08:11.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:08:11.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:08:11.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T19:09:17.783+0000] {processor.py:157} INFO - Started process (PID=98550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:17.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:09:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:17.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:17.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:17.848+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:17.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:09:17.861+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:17.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:09:17.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T19:09:49.162+0000] {processor.py:157} INFO - Started process (PID=98561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:49.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:09:49.166+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:49.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:49.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:09:49.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:49.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:09:49.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:09:49.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:09:49.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T19:10:19.593+0000] {processor.py:157} INFO - Started process (PID=98571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:19.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:10:19.599+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:19.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:19.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:19.627+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:19.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:10:19.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:19.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:10:19.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T19:10:53.655+0000] {processor.py:157} INFO - Started process (PID=98580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:53.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:10:53.661+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:53.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:53.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:10:53.712+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:53.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:10:53.729+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:10:53.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:10:53.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-22T19:11:57.917+0000] {processor.py:157} INFO - Started process (PID=98590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:11:57.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:11:57.927+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:11:57.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:11:57.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:11:57.966+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:11:57.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:11:57.979+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:11:57.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:11:57.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T19:12:28.235+0000] {processor.py:157} INFO - Started process (PID=98601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:12:28.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:12:28.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:12:28.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:12:28.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:12:28.265+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:12:28.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:12:28.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:12:28.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:12:28.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T19:13:37.894+0000] {processor.py:157} INFO - Started process (PID=98611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:13:37.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:13:37.897+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:13:37.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:13:37.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:13:37.923+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:13:37.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:13:37.933+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:13:37.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:13:37.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T19:14:08.242+0000] {processor.py:157} INFO - Started process (PID=98621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:14:08.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:14:08.246+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:14:08.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:14:08.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:14:08.283+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:14:08.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:14:08.298+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:14:08.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:14:08.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T19:15:13.317+0000] {processor.py:157} INFO - Started process (PID=98631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:15:13.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:15:13.323+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:15:13.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:15:13.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:15:13.376+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:15:13.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:15:13.389+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:15:13.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:15:13.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T19:16:12.953+0000] {processor.py:157} INFO - Started process (PID=98641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:12.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:16:12.959+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:12.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:12.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:13.021+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:13.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:16:13.036+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:13.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:16:13.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T19:16:43.246+0000] {processor.py:157} INFO - Started process (PID=98651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:43.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:16:43.249+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:43.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:43.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:16:43.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:43.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:16:43.291+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:16:43.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:16:43.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T19:17:55.970+0000] {processor.py:157} INFO - Started process (PID=98663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:17:55.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:17:55.973+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:17:55.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:17:55.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:17:56.000+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:17:56.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:17:56.009+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:17:56.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:17:56.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-22T19:18:52.432+0000] {processor.py:157} INFO - Started process (PID=98673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:18:52.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:18:52.437+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:18:52.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:18:52.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:18:52.479+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:18:52.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:18:52.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:18:52.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:18:52.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T19:19:22.839+0000] {processor.py:157} INFO - Started process (PID=98683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:19:22.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:19:22.842+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:19:22.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:19:22.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:19:22.866+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:19:22.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:19:22.876+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:19:22.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:19:22.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-22T19:21:24.055+0000] {processor.py:157} INFO - Started process (PID=98693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:21:24.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:21:24.061+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:21:24.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:21:24.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:21:24.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:21:24.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:21:24.122+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:21:24.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:21:24.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-22T19:22:13.908+0000] {processor.py:157} INFO - Started process (PID=98705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:13.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:22:13.914+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:13.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:13.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:13.952+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:13.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:22:13.966+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:13.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:22:13.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T19:22:44.223+0000] {processor.py:157} INFO - Started process (PID=98715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:44.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:22:44.226+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:44.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:44.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:22:44.255+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:44.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:22:44.267+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:22:44.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:22:44.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T19:24:06.664+0000] {processor.py:157} INFO - Started process (PID=98725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:06.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:24:06.667+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:06.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:06.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:06.692+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:06.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:24:06.701+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:06.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:24:06.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-22T19:24:37.032+0000] {processor.py:157} INFO - Started process (PID=98735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:37.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:24:37.038+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:37.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:37.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:24:37.076+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:37.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:24:37.088+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:24:37.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:24:37.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T19:38:17.009+0000] {processor.py:157} INFO - Started process (PID=98744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:17.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:38:17.020+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:17.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:17.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:17.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:17.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:38:17.116+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:17.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:38:17.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T19:38:47.378+0000] {processor.py:157} INFO - Started process (PID=98755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:47.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:38:47.386+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:47.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:47.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:38:47.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:47.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:38:47.473+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:38:47.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:38:47.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-22T19:39:17.666+0000] {processor.py:157} INFO - Started process (PID=98765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:17.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:39:17.669+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:17.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:17.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:17.699+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:17.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:39:17.710+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:17.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:39:17.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T19:39:48.094+0000] {processor.py:157} INFO - Started process (PID=98775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:48.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:39:48.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:48.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:48.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:39:48.126+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:48.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:39:48.136+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:39:48.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:39:48.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T19:40:18.542+0000] {processor.py:157} INFO - Started process (PID=98785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:40:18.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:40:18.549+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:40:18.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:40:18.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:40:18.587+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:40:18.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:40:18.600+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:40:18.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:40:18.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-22T19:42:05.440+0000] {processor.py:157} INFO - Started process (PID=98796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:05.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:42:05.455+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:05.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:05.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:05.514+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:05.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:42:05.536+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:05.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:42:05.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T19:42:35.746+0000] {processor.py:157} INFO - Started process (PID=98806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:35.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:42:35.752+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:35.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:35.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:42:35.801+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:35.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:42:35.815+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:42:35.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:42:35.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T19:43:14.064+0000] {processor.py:157} INFO - Started process (PID=98817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:43:14.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:43:14.068+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:43:14.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:43:14.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:43:14.100+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:43:14.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:43:14.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:43:14.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:43:14.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T19:44:05.216+0000] {processor.py:157} INFO - Started process (PID=98827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:05.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:44:05.221+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:05.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:05.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:05.265+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:05.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:44:05.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:05.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:44:05.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T19:44:35.593+0000] {processor.py:157} INFO - Started process (PID=98837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:35.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:44:35.597+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:35.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:35.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:44:35.622+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:35.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:44:35.632+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:44:35.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:44:35.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-22T19:45:25.323+0000] {processor.py:157} INFO - Started process (PID=98847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:25.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:45:25.333+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:25.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:25.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:25.366+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:25.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:45:25.385+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:25.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:45:25.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T19:45:55.744+0000] {processor.py:157} INFO - Started process (PID=98857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:55.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:45:55.747+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:55.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:55.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:45:55.780+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:55.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:45:55.792+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:45:55.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:45:55.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-22T19:46:42.277+0000] {processor.py:157} INFO - Started process (PID=98867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:46:42.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:46:42.282+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:46:42.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:46:42.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:46:42.314+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:46:42.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:46:42.325+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:46:42.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:46:42.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T19:47:33.159+0000] {processor.py:157} INFO - Started process (PID=98876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:47:33.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:47:33.163+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:47:33.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:47:33.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:47:33.195+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:47:33.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:47:33.206+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:47:33.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:47:33.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T19:48:03.568+0000] {processor.py:157} INFO - Started process (PID=98887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:03.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:48:03.572+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:03.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:03.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:03.599+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:03.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:48:03.610+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:03.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:48:03.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-22T19:48:37.487+0000] {processor.py:157} INFO - Started process (PID=98897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:37.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:48:37.501+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:37.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:37.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:48:37.544+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:37.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:48:37.560+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:48:37.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:48:37.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T19:49:31.042+0000] {processor.py:157} INFO - Started process (PID=98909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:49:31.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:49:31.045+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:49:31.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:49:31.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:49:31.076+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:49:31.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:49:31.088+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:49:31.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:49:31.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T19:50:01.476+0000] {processor.py:157} INFO - Started process (PID=98919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:50:01.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:50:01.479+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:50:01.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:50:01.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:50:01.508+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:50:01.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:50:01.519+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:50:01.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:50:01.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-22T19:53:02.013+0000] {processor.py:157} INFO - Started process (PID=98929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:53:02.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:53:02.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:53:02.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:53:02.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:53:02.084+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:53:02.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:53:02.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:53:02.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:53:02.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T19:54:18.725+0000] {processor.py:157} INFO - Started process (PID=98938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:18.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:54:18.730+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:18.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:18.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:18.791+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:18.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:54:18.806+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:18.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:54:18.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T19:54:49.075+0000] {processor.py:157} INFO - Started process (PID=98949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:49.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T19:54:49.077+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:49.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:49.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T19:54:49.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:49.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T19:54:49.122+0000] {logging_mixin.py:151} INFO - [2024-08-22T19:54:49.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T19:54:49.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-22T20:10:44.219+0000] {processor.py:157} INFO - Started process (PID=98959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:10:44.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:10:44.224+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:10:44.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:10:44.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:10:44.258+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:10:44.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:10:44.273+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:10:44.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:10:44.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-22T20:11:14.657+0000] {processor.py:157} INFO - Started process (PID=98968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:14.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:11:14.664+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:14.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:14.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:14.729+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:14.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:11:14.745+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:14.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:11:14.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-22T20:11:44.937+0000] {processor.py:157} INFO - Started process (PID=98979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:44.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:11:44.941+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:44.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:44.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:11:44.976+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:44.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:11:44.984+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:11:44.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:11:44.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-22T20:12:15.351+0000] {processor.py:157} INFO - Started process (PID=98989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:15.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:12:15.357+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:15.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:15.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:15.386+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:15.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:12:15.398+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:15.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:12:15.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T20:12:45.705+0000] {processor.py:157} INFO - Started process (PID=98999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:45.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:12:45.709+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:45.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:45.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:12:45.732+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:45.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:12:45.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:12:45.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:12:45.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-22T20:13:16.067+0000] {processor.py:157} INFO - Started process (PID=99009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:13:16.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:13:16.071+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:13:16.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:13:16.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:13:16.324+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:13:16.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:13:16.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:13:16.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:13:16.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.371 seconds
[2024-08-22T20:29:38.154+0000] {processor.py:157} INFO - Started process (PID=99019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:29:38.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:29:38.159+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:29:38.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:29:38.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:29:38.198+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:29:38.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:29:38.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:29:38.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:29:38.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T20:40:12.674+0000] {processor.py:157} INFO - Started process (PID=99029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:12.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:40:12.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:12.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:12.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:12.719+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:12.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:40:12.736+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:12.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:40:12.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-22T20:40:43.085+0000] {processor.py:157} INFO - Started process (PID=99039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:43.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:40:43.088+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:43.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:43.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:40:43.122+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:43.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:40:43.135+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:40:43.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:40:43.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T20:42:00.527+0000] {processor.py:157} INFO - Started process (PID=99050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:00.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:42:00.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:00.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:00.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:00.581+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:00.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:42:00.595+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:00.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:42:00.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-22T20:42:56.785+0000] {processor.py:157} INFO - Started process (PID=99061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:56.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:42:56.789+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:56.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:56.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:42:56.825+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:56.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:42:56.838+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:42:56.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:42:56.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T20:43:27.149+0000] {processor.py:157} INFO - Started process (PID=99071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:43:27.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:43:27.154+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:43:27.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:43:27.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:43:27.187+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:43:27.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:43:27.199+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:43:27.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:43:27.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-22T20:54:25.833+0000] {processor.py:157} INFO - Started process (PID=99081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:54:25.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T20:54:25.841+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:54:25.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:54:25.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T20:54:25.884+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:54:25.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T20:54:25.897+0000] {logging_mixin.py:151} INFO - [2024-08-22T20:54:25.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T20:54:25.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T21:02:46.720+0000] {processor.py:157} INFO - Started process (PID=99091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:02:46.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:02:46.722+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:02:46.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:02:46.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:02:46.760+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:02:46.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:02:46.777+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:02:46.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:02:46.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T21:03:17.102+0000] {processor.py:157} INFO - Started process (PID=99101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:03:17.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:03:17.108+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:03:17.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:03:17.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:03:17.160+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:03:17.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:03:17.173+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:03:17.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:03:17.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-22T21:04:14.006+0000] {processor.py:157} INFO - Started process (PID=99111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:14.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:04:14.010+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:14.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:14.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:14.036+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:14.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:04:14.050+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:14.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:04:14.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-22T21:04:44.380+0000] {processor.py:157} INFO - Started process (PID=99121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:44.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:04:44.383+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:44.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:44.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:04:44.414+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:44.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:04:44.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:04:44.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:04:44.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-22T21:08:28.975+0000] {processor.py:157} INFO - Started process (PID=99131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:28.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:08:28.990+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:28.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:29.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:29.057+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:29.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:08:29.073+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:29.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:08:29.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T21:08:59.297+0000] {processor.py:157} INFO - Started process (PID=99142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:59.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:08:59.305+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:59.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:59.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:08:59.371+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:59.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:08:59.394+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:08:59.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:08:59.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-22T21:09:29.627+0000] {processor.py:157} INFO - Started process (PID=99151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:09:29.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:09:29.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:09:29.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:09:29.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:09:29.693+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:09:29.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:09:29.707+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:09:29.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:09:29.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-22T21:10:00.064+0000] {processor.py:157} INFO - Started process (PID=99162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:00.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:10:00.073+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:00.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:00.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:00.191+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:00.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:10:00.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:00.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:10:00.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T21:10:30.497+0000] {processor.py:157} INFO - Started process (PID=99172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:30.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:10:30.506+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:30.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:30.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:10:30.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:30.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:10:30.581+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:10:30.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:10:30.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T21:11:01.015+0000] {processor.py:157} INFO - Started process (PID=99182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:01.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:11:01.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:01.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:01.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:01.132+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:01.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:11:01.150+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:01.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:11:01.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-22T21:11:31.425+0000] {processor.py:157} INFO - Started process (PID=99192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:31.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:11:31.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:31.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:31.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:11:31.534+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:31.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:11:31.557+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:11:31.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:11:31.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-22T21:12:01.730+0000] {processor.py:157} INFO - Started process (PID=99202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:01.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:12:01.741+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:01.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:01.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:01.816+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:01.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:12:01.833+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:01.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:12:01.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-22T21:12:32.276+0000] {processor.py:157} INFO - Started process (PID=99212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:32.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:12:32.285+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:32.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:32.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:12:32.365+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:32.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:12:32.388+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:12:32.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:12:32.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-22T21:13:02.566+0000] {processor.py:157} INFO - Started process (PID=99222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:02.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:13:02.573+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:02.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:02.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:02.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:02.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:13:02.654+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:02.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:13:02.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T21:13:33.046+0000] {processor.py:157} INFO - Started process (PID=99232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:33.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:13:33.052+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:33.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:33.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:13:33.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:33.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:13:33.135+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:13:33.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:13:33.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-22T21:14:03.509+0000] {processor.py:157} INFO - Started process (PID=99241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:03.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:14:03.518+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:03.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:03.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:03.612+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:03.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:14:03.628+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:03.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:14:03.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-22T21:14:34.017+0000] {processor.py:157} INFO - Started process (PID=99252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:34.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:14:34.025+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:34.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:34.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:14:34.092+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:34.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:14:34.120+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:14:34.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:14:34.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T21:15:04.341+0000] {processor.py:157} INFO - Started process (PID=99262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:04.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:15:04.364+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:04.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:04.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:04.424+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:04.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:15:04.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:04.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:15:04.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T21:15:34.578+0000] {processor.py:157} INFO - Started process (PID=99272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:34.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:15:34.592+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:34.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:34.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:15:34.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:34.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:15:34.671+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:15:34.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:15:34.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T21:16:04.962+0000] {processor.py:157} INFO - Started process (PID=99282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:04.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:16:04.967+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:04.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:04.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:05.028+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:05.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:16:05.042+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:05.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:16:05.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T21:16:35.450+0000] {processor.py:157} INFO - Started process (PID=99292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:35.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:16:35.464+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:35.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:35.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:16:35.556+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:35.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:16:35.581+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:16:35.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:16:35.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-22T21:17:05.793+0000] {processor.py:157} INFO - Started process (PID=99301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:05.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:17:05.802+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:05.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:05.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:05.884+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:05.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:17:05.900+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:05.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:17:05.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-22T21:17:36.328+0000] {processor.py:157} INFO - Started process (PID=99312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:36.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:17:36.340+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:36.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:36.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:17:36.423+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:36.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:17:36.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:17:36.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:17:36.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T21:18:06.649+0000] {processor.py:157} INFO - Started process (PID=99322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:06.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:18:06.659+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:06.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:06.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:06.716+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:06.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:18:06.731+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:06.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:18:06.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T21:18:37.193+0000] {processor.py:157} INFO - Started process (PID=99332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:37.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:18:37.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:37.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:37.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:18:37.256+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:37.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:18:37.269+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:18:37.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:18:37.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-22T21:19:07.593+0000] {processor.py:157} INFO - Started process (PID=99341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:07.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:19:07.598+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:07.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:07.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:07.674+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:07.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:19:07.689+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:07.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:19:07.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T21:19:37.919+0000] {processor.py:157} INFO - Started process (PID=99352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:37.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:19:37.927+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:37.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:37.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:19:37.994+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:37.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:19:38.009+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:19:38.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:19:38.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-22T21:20:08.182+0000] {processor.py:157} INFO - Started process (PID=99362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:08.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:20:08.186+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:08.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:08.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:08.212+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:08.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:20:08.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:08.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:20:08.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-22T21:20:38.574+0000] {processor.py:157} INFO - Started process (PID=99372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:38.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:20:38.579+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:38.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:38.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:20:38.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:38.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:20:38.660+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:20:38.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:20:38.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-22T21:21:08.834+0000] {processor.py:157} INFO - Started process (PID=99381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:08.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:21:08.841+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:08.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:08.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:08.884+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:08.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:21:08.895+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:08.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:21:08.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T21:21:39.215+0000] {processor.py:157} INFO - Started process (PID=99392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:39.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:21:39.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:39.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:39.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:21:39.257+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:39.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:21:39.271+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:21:39.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:21:39.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T21:22:09.584+0000] {processor.py:157} INFO - Started process (PID=99401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:09.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:22:09.592+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:09.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:09.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:09.647+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:09.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:22:09.661+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:09.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:22:09.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T21:22:39.897+0000] {processor.py:157} INFO - Started process (PID=99411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:39.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:22:39.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:39.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:39.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:22:39.977+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:39.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:22:39.992+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:22:39.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:22:40.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T21:23:10.373+0000] {processor.py:157} INFO - Started process (PID=99422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:10.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:23:10.381+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:10.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:10.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:10.445+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:10.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:23:10.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:10.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:23:10.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T21:23:40.849+0000] {processor.py:157} INFO - Started process (PID=99432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:40.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:23:40.854+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:40.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:40.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:23:40.929+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:40.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:23:40.947+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:23:40.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:23:40.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T21:24:11.199+0000] {processor.py:157} INFO - Started process (PID=99441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:11.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:24:11.205+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:11.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:11.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:11.263+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:11.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:24:11.291+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:11.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:24:11.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T21:24:41.720+0000] {processor.py:157} INFO - Started process (PID=99452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:41.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:24:41.736+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:41.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:41.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:24:41.832+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:41.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:24:41.849+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:24:41.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:24:41.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T21:25:11.996+0000] {processor.py:157} INFO - Started process (PID=99462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:11.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:25:12.004+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:12.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:12.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:12.070+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:12.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:25:12.085+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:12.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:25:12.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T21:25:42.362+0000] {processor.py:157} INFO - Started process (PID=99472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:42.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:25:42.369+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:42.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:42.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:25:42.409+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:42.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:25:42.422+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:25:42.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:25:42.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T21:26:12.676+0000] {processor.py:157} INFO - Started process (PID=99482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:12.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:26:12.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:12.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:12.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:12.761+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:12.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:26:12.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:12.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:26:12.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T21:26:43.016+0000] {processor.py:157} INFO - Started process (PID=99492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:43.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:26:43.024+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:43.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:43.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:26:43.094+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:43.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:26:43.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:26:43.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:26:43.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-22T21:27:13.338+0000] {processor.py:157} INFO - Started process (PID=99502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:13.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:27:13.358+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:13.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:13.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:13.497+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:13.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:27:13.520+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:13.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:27:13.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-08-22T21:27:43.665+0000] {processor.py:157} INFO - Started process (PID=99512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:43.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:27:43.674+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:43.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:43.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:27:43.793+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:43.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:27:43.817+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:27:43.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:27:43.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T21:28:14.095+0000] {processor.py:157} INFO - Started process (PID=99522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:14.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:28:14.104+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:14.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:14.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:14.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:14.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:28:14.249+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:14.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:28:14.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-22T21:28:44.535+0000] {processor.py:157} INFO - Started process (PID=99532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:44.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:28:44.546+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:44.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:44.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:28:44.657+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:44.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:28:44.690+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:28:44.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:28:44.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T21:29:14.883+0000] {processor.py:157} INFO - Started process (PID=99542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:14.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:29:14.900+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:14.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:14.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:15.030+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:15.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:29:15.053+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:15.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:29:15.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-22T21:29:45.324+0000] {processor.py:157} INFO - Started process (PID=99551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:45.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:29:45.333+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:45.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:45.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:29:45.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:45.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:29:45.490+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:29:45.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:29:45.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-08-22T21:30:15.673+0000] {processor.py:157} INFO - Started process (PID=99562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:15.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:30:15.684+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:15.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:15.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:15.758+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:15.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:30:15.775+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:15.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:30:15.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-08-22T21:30:46.073+0000] {processor.py:157} INFO - Started process (PID=99572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:46.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:30:46.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:46.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:46.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:30:46.181+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:46.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:30:46.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:30:46.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:30:46.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-22T21:31:16.394+0000] {processor.py:157} INFO - Started process (PID=99582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:16.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:31:16.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:16.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:16.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:16.502+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:16.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:31:16.525+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:16.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:31:16.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-22T21:31:46.902+0000] {processor.py:157} INFO - Started process (PID=99591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:46.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:31:46.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:46.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:46.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:31:47.010+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:47.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:31:47.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:31:47.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:31:47.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-22T21:32:17.190+0000] {processor.py:157} INFO - Started process (PID=99602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:17.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:32:17.201+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:17.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:17.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:17.318+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:17.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:32:17.343+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:17.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:32:17.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-22T21:32:47.654+0000] {processor.py:157} INFO - Started process (PID=99612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:47.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:32:47.670+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:47.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:47.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:32:47.782+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:47.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:32:47.801+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:32:47.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:32:47.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-22T21:33:18.036+0000] {processor.py:157} INFO - Started process (PID=99621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:18.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:33:18.049+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:18.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:18.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:18.152+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:18.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:33:18.177+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:18.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:33:18.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-22T21:33:48.371+0000] {processor.py:157} INFO - Started process (PID=99632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:48.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:33:48.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:48.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:48.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:33:48.559+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:48.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:33:48.593+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:33:48.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:33:48.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-08-22T21:34:18.863+0000] {processor.py:157} INFO - Started process (PID=99642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:18.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:34:18.876+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:18.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:18.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:18.983+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:18.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:34:19.006+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:19.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:34:19.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-22T21:34:49.226+0000] {processor.py:157} INFO - Started process (PID=99652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:49.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:34:49.238+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:49.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:49.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:34:49.357+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:49.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:34:49.380+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:34:49.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:34:49.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-22T21:35:19.522+0000] {processor.py:157} INFO - Started process (PID=99661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:19.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:35:19.536+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:19.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:19.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:19.656+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:19.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:35:19.679+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:19.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:35:19.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-22T21:35:49.957+0000] {processor.py:157} INFO - Started process (PID=99671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:49.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:35:49.992+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:49.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:50.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:35:50.094+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:50.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:35:50.114+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:35:50.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:35:50.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T21:36:20.335+0000] {processor.py:157} INFO - Started process (PID=99682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:20.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:36:20.345+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:20.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:20.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:20.449+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:20.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:36:20.467+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:20.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:36:20.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T21:36:50.706+0000] {processor.py:157} INFO - Started process (PID=99692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:50.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:36:50.718+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:50.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:50.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:36:50.815+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:50.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:36:50.840+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:36:50.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:36:50.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T21:37:21.015+0000] {processor.py:157} INFO - Started process (PID=99701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:21.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:37:21.036+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:21.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:21.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:21.145+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:21.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:37:21.173+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:21.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:37:21.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T21:37:51.387+0000] {processor.py:157} INFO - Started process (PID=99711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:51.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:37:51.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:51.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:51.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:37:51.492+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:51.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:37:51.518+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:37:51.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:37:51.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-22T21:38:21.716+0000] {processor.py:157} INFO - Started process (PID=99722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:21.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:38:21.732+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:21.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:21.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:21.834+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:21.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:38:21.857+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:21.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:38:21.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-22T21:38:52.105+0000] {processor.py:157} INFO - Started process (PID=99731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:52.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:38:52.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:52.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:52.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:38:52.195+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:52.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:38:52.220+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:38:52.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:38:52.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-22T21:39:22.440+0000] {processor.py:157} INFO - Started process (PID=99741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:22.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:39:22.458+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:22.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:22.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:22.556+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:22.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:39:22.575+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:22.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:39:22.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-22T21:39:52.770+0000] {processor.py:157} INFO - Started process (PID=99752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:52.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:39:52.779+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:52.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:52.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:39:52.861+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:52.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:39:52.882+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:39:52.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:39:52.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-22T21:40:23.055+0000] {processor.py:157} INFO - Started process (PID=99762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:23.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:40:23.064+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:23.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:23.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:23.098+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:23.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:40:23.112+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:23.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:40:23.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-22T21:40:53.468+0000] {processor.py:157} INFO - Started process (PID=99772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:53.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:40:53.477+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:53.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:53.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:40:53.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:53.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:40:53.597+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:40:53.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:40:53.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-22T21:41:23.900+0000] {processor.py:157} INFO - Started process (PID=99782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:23.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:41:23.908+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:23.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:23.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:23.990+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:23.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:41:24.009+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:24.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:41:24.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-22T21:41:54.229+0000] {processor.py:157} INFO - Started process (PID=99792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:54.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:41:54.239+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:54.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:54.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:41:54.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:54.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:41:54.397+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:41:54.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:41:54.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-08-22T21:42:24.532+0000] {processor.py:157} INFO - Started process (PID=99801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:24.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:42:24.543+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:24.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:24.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:24.660+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:24.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:42:24.683+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:24.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:42:24.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-22T21:42:54.940+0000] {processor.py:157} INFO - Started process (PID=99812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:54.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:42:54.950+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:54.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:55.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:42:55.070+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:55.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:42:55.091+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:42:55.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:42:55.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-22T21:43:25.276+0000] {processor.py:157} INFO - Started process (PID=99822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:25.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:43:25.291+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:25.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:25.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:25.413+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:25.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:43:25.435+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:25.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:43:25.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-08-22T21:43:55.631+0000] {processor.py:157} INFO - Started process (PID=99832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:55.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:43:55.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:55.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:55.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:43:55.698+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:55.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:43:55.723+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:43:55.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:43:55.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T21:44:25.906+0000] {processor.py:157} INFO - Started process (PID=99842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:25.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:44:25.915+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:25.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:25.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:25.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:25.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:44:26.006+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:26.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:44:26.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T21:44:56.258+0000] {processor.py:157} INFO - Started process (PID=99852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:56.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:44:56.280+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:56.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:56.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:44:56.342+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:56.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:44:56.364+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:44:56.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:44:56.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-22T21:45:26.579+0000] {processor.py:157} INFO - Started process (PID=99862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:26.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:45:26.589+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:26.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:26.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:26.645+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:26.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:45:26.676+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:26.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:45:26.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T21:45:56.951+0000] {processor.py:157} INFO - Started process (PID=99872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:56.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:45:56.962+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:56.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:57.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:45:57.085+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:45:57.103+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:45:57.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:45:57.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T21:46:27.275+0000] {processor.py:157} INFO - Started process (PID=99882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:27.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:46:27.285+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:27.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:27.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:27.400+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:27.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:46:27.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:27.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:46:27.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T21:46:57.657+0000] {processor.py:157} INFO - Started process (PID=99892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:57.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:46:57.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:57.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:57.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:46:57.776+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:57.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:46:57.798+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:46:57.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:46:57.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-08-22T21:47:28.153+0000] {processor.py:157} INFO - Started process (PID=99902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:28.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:47:28.165+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:28.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:28.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:28.262+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:28.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:47:28.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:28.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:47:28.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T21:47:58.448+0000] {processor.py:157} INFO - Started process (PID=99912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:58.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:47:58.464+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:58.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:58.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:47:58.568+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:58.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:47:58.590+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:47:58.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:47:58.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T21:48:28.883+0000] {processor.py:157} INFO - Started process (PID=99922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:28.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:48:28.896+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:28.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:28.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:29.033+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:29.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:48:29.075+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:29.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:48:29.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-08-22T21:48:59.252+0000] {processor.py:157} INFO - Started process (PID=99932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:59.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:48:59.262+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:59.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:59.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:48:59.381+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:59.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:48:59.401+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:48:59.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:48:59.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-22T21:49:29.707+0000] {processor.py:157} INFO - Started process (PID=99941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:49:29.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:49:29.722+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:49:29.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:49:29.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:49:29.857+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:49:29.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:49:29.878+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:49:29.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:49:29.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-08-22T21:50:00.023+0000] {processor.py:157} INFO - Started process (PID=99952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:00.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:50:00.053+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:00.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:00.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:00.152+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:00.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:50:00.172+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:00.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:50:00.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-22T21:50:30.495+0000] {processor.py:157} INFO - Started process (PID=99962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:30.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:50:30.500+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:30.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:30.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:50:30.556+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:30.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:50:30.576+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:50:30.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:50:30.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T21:51:00.833+0000] {processor.py:157} INFO - Started process (PID=99972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:00.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:51:00.838+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:00.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:00.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:00.911+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:00.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:51:00.950+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:00.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:51:00.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-22T21:51:31.119+0000] {processor.py:157} INFO - Started process (PID=99982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:31.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:51:31.128+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:31.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:31.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:51:31.252+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:31.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:51:31.282+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:51:31.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:51:31.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-22T21:52:01.542+0000] {processor.py:157} INFO - Started process (PID=99992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:01.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:52:01.551+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:01.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:01.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:01.635+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:01.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:52:01.659+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:01.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:52:01.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T21:52:32.047+0000] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:32.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:52:32.072+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:32.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:32.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:52:32.160+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:32.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:52:32.177+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:52:32.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:52:32.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-22T21:53:02.461+0000] {processor.py:157} INFO - Started process (PID=313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:02.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:53:02.472+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:02.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:02.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:02.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:02.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:53:02.603+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:02.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:53:02.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-22T21:53:32.915+0000] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:32.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:53:32.926+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:32.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:32.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:53:33.037+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:33.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:53:33.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:53:33.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:53:33.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-22T21:54:03.288+0000] {processor.py:157} INFO - Started process (PID=332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:03.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:54:03.303+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:03.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:03.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:03.413+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:03.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:54:03.441+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:03.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:54:03.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T21:54:33.690+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:33.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:54:33.700+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:33.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:33.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:54:33.797+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:33.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:54:33.820+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:54:33.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:54:33.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-22T21:55:04.149+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:04.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:55:04.159+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:04.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:04.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:04.263+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:04.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:55:04.284+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:04.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:55:04.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-22T21:55:34.684+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:34.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:55:34.692+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:34.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:34.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:55:34.811+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:34.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:55:34.835+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:55:34.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:55:34.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-22T21:56:05.084+0000] {processor.py:157} INFO - Started process (PID=373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:05.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:56:05.097+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:05.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:05.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:05.214+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:05.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:56:05.242+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:05.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:56:05.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-22T21:56:35.483+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:35.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:56:35.490+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:35.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:35.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:56:35.591+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:35.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:56:35.614+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:56:35.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:56:35.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-22T21:57:05.903+0000] {processor.py:157} INFO - Started process (PID=391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:05.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:57:05.915+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:05.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:05.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:06.030+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:06.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:57:06.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:06.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:57:06.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T21:57:36.403+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:36.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:57:36.421+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:36.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:36.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:57:36.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:36.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:57:36.523+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:57:36.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:57:36.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-22T21:58:06.767+0000] {processor.py:157} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:06.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:58:06.779+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:06.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:06.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:06.885+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:06.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:58:06.916+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:06.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:58:06.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-22T21:58:37.172+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:37.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:58:37.181+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:37.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:37.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:58:37.274+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:37.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:58:37.297+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:58:37.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:58:37.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-22T21:59:07.476+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:07.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:59:07.511+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:07.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:07.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:07.591+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:07.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:59:07.615+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:07.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:59:07.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-22T21:59:37.769+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:37.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T21:59:37.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:37.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:37.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T21:59:37.853+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:37.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T21:59:37.875+0000] {logging_mixin.py:151} INFO - [2024-08-22T21:59:37.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T21:59:37.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T22:00:08.198+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:08.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:00:08.225+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:08.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:08.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:08.435+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:08.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:00:08.456+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:08.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:00:08.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.279 seconds
[2024-08-22T22:00:38.793+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:38.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:00:38.802+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:38.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:38.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:00:38.925+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:38.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:00:38.950+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:00:38.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:00:38.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T22:01:09.122+0000] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:09.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:01:09.142+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:09.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:09.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:09.240+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:09.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:01:09.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:09.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:01:09.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T22:01:39.485+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:39.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:01:39.494+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:39.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:39.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:01:39.555+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:39.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:01:39.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:01:39.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:01:39.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-22T22:02:09.783+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:09.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:02:09.791+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:09.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:09.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:09.839+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:09.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:02:09.856+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:09.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:02:09.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T22:02:40.093+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:40.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:02:40.101+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:40.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:40.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:02:40.186+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:40.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:02:40.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:02:40.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:02:40.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T22:03:10.416+0000] {processor.py:157} INFO - Started process (PID=513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:10.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:03:10.430+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:10.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:10.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:10.506+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:10.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:03:10.550+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:10.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:03:10.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-08-22T22:03:40.780+0000] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:40.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:03:40.795+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:40.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:40.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:03:40.871+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:40.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:03:40.892+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:03:40.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:03:40.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-08-22T22:04:11.092+0000] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:11.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:04:11.103+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:11.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:11.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:11.184+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:11.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:04:11.207+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:11.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:04:11.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T22:04:41.479+0000] {processor.py:157} INFO - Started process (PID=543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:41.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:04:41.496+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:41.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:41.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:04:41.603+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:41.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:04:41.629+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:04:41.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:04:41.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T22:05:11.797+0000] {processor.py:157} INFO - Started process (PID=553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:11.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:05:11.811+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:11.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:11.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:11.902+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:11.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:05:11.940+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:11.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:05:11.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T22:05:42.197+0000] {processor.py:157} INFO - Started process (PID=563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:42.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:05:42.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:42.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:42.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:05:42.304+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:42.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:05:42.335+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:05:42.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:05:42.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-22T22:06:12.541+0000] {processor.py:157} INFO - Started process (PID=573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:12.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:06:12.578+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:12.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:12.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:12.691+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:12.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:06:12.721+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:12.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:06:12.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-08-22T22:06:43.051+0000] {processor.py:157} INFO - Started process (PID=583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:43.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:06:43.058+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:43.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:43.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:06:43.114+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:43.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:06:43.135+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:06:43.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:06:43.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T22:07:13.355+0000] {processor.py:157} INFO - Started process (PID=593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:13.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:07:13.360+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:13.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:13.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:13.410+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:13.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:07:13.429+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:13.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:07:13.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-22T22:07:43.642+0000] {processor.py:157} INFO - Started process (PID=603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:43.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:07:43.665+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:43.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:43.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:07:43.727+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:43.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:07:43.746+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:07:43.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:07:43.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-22T22:08:14.085+0000] {processor.py:157} INFO - Started process (PID=613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:14.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:08:14.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:14.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:14.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:14.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:14.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:08:14.219+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:14.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:08:14.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T22:08:44.415+0000] {processor.py:157} INFO - Started process (PID=623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:44.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:08:44.422+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:44.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:44.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:08:44.501+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:44.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:08:44.519+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:08:44.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:08:44.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-22T22:09:14.802+0000] {processor.py:157} INFO - Started process (PID=633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:14.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:09:14.813+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:14.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:14.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:14.924+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:14.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:09:14.942+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:14.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:09:14.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T22:09:45.115+0000] {processor.py:157} INFO - Started process (PID=643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:45.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:09:45.127+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:45.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:45.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:09:45.223+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:45.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:09:45.261+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:09:45.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:09:45.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T22:10:15.515+0000] {processor.py:157} INFO - Started process (PID=653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:15.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:10:15.525+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:15.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:15.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:15.634+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:15.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:10:15.653+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:15.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:10:15.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T22:10:45.845+0000] {processor.py:157} INFO - Started process (PID=663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:45.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:10:45.860+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:45.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:45.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:10:45.969+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:45.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:10:45.989+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:10:45.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:10:46.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-22T22:11:16.429+0000] {processor.py:157} INFO - Started process (PID=673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:16.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:11:16.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:16.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:16.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:16.538+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:16.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:11:16.561+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:16.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:11:16.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T22:11:46.692+0000] {processor.py:157} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:46.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:11:46.702+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:46.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:46.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:11:46.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:46.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:11:46.757+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:11:46.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:11:46.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-22T22:12:17.087+0000] {processor.py:157} INFO - Started process (PID=693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:17.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:12:17.099+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:17.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:17.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:17.188+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:17.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:12:17.210+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:17.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:12:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T22:12:47.439+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:47.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:12:47.450+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:47.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:47.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:12:47.558+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:47.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:12:47.578+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:12:47.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:12:47.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-22T22:13:17.832+0000] {processor.py:157} INFO - Started process (PID=713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:17.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:13:17.848+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:17.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:17.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:17.986+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:17.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:13:18.006+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:18.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:13:18.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-08-22T22:13:48.174+0000] {processor.py:157} INFO - Started process (PID=723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:48.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:13:48.185+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:48.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:48.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:13:48.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:48.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:13:48.303+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:13:48.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:13:48.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-22T22:14:18.687+0000] {processor.py:157} INFO - Started process (PID=733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:18.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:14:18.699+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:18.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:18.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:18.796+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:18.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:14:18.846+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:18.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:14:18.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-22T22:14:49.028+0000] {processor.py:157} INFO - Started process (PID=743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:49.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:14:49.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:49.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:49.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:14:49.136+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:49.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:14:49.167+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:14:49.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:14:49.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T22:15:19.530+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:19.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:15:19.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:19.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:19.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:19.646+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:19.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:15:19.683+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:19.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:15:19.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-22T22:15:49.819+0000] {processor.py:157} INFO - Started process (PID=763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:49.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:15:49.823+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:49.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:49.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:15:49.872+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:49.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:15:49.889+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:15:49.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:15:49.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T22:16:20.149+0000] {processor.py:157} INFO - Started process (PID=773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:20.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:16:20.153+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:20.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:20.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:20.190+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:20.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:16:20.204+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:20.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:16:20.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T22:16:50.445+0000] {processor.py:157} INFO - Started process (PID=783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:50.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:16:50.454+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:50.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:50.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:16:50.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:50.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:16:50.579+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:16:50.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:16:50.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-22T22:17:20.746+0000] {processor.py:157} INFO - Started process (PID=793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:20.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:17:20.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:20.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:20.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:20.814+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:20.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:17:20.832+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:20.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:17:20.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-22T22:17:51.103+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:51.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:17:51.113+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:51.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:51.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:17:51.233+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:51.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:17:51.261+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:17:51.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:17:51.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-22T22:18:21.363+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:21.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:18:21.369+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:21.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:21.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:21.423+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:21.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:18:21.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:21.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:18:21.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T22:18:51.714+0000] {processor.py:157} INFO - Started process (PID=823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:51.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:18:51.725+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:51.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:51.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:18:51.842+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:51.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:18:51.864+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:18:51.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:18:51.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-08-22T22:19:22.073+0000] {processor.py:157} INFO - Started process (PID=833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:22.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:19:22.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:22.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:22.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:22.182+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:22.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:19:22.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:22.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:19:22.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-22T22:19:52.433+0000] {processor.py:157} INFO - Started process (PID=843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:52.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:19:52.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:52.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:52.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:19:52.535+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:52.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:19:52.552+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:19:52.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:19:52.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T22:20:22.827+0000] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:22.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:20:22.836+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:22.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:22.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:22.949+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:22.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:20:22.996+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:22.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:20:23.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-22T22:20:53.184+0000] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:53.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:20:53.192+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:53.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:53.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:20:53.319+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:53.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:20:53.338+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:20:53.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:20:53.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-22T22:21:23.545+0000] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:23.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:21:23.568+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:23.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:23.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:23.657+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:23.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:21:23.680+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:23.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:21:23.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-22T22:21:53.883+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:53.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:21:53.890+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:53.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:53.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:21:53.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:53.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:21:53.974+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:21:53.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:21:53.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T22:22:24.185+0000] {processor.py:157} INFO - Started process (PID=893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:24.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:22:24.192+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:24.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:24.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:24.249+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:24.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:22:24.271+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:24.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:22:24.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T22:22:54.529+0000] {processor.py:157} INFO - Started process (PID=903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:54.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:22:54.540+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:54.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:54.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:22:54.666+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:54.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:22:54.703+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:22:54.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:22:54.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-08-22T22:23:24.829+0000] {processor.py:157} INFO - Started process (PID=913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:24.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:23:24.854+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:24.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:24.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:24.971+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:24.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:23:25.001+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:25.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:23:25.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-08-22T22:23:55.327+0000] {processor.py:157} INFO - Started process (PID=923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:55.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:23:55.341+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:55.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:55.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:23:55.483+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:55.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:23:55.499+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:23:55.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:23:55.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-22T22:24:25.633+0000] {processor.py:157} INFO - Started process (PID=933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:25.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:24:25.674+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:25.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:25.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:25.784+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:25.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:24:25.806+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:25.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:24:25.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-22T22:24:56.118+0000] {processor.py:157} INFO - Started process (PID=943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:56.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:24:56.133+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:56.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:56.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:24:56.250+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:56.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:24:56.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:24:56.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:24:56.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T22:25:26.472+0000] {processor.py:157} INFO - Started process (PID=953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:26.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:25:26.485+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:26.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:26.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:26.599+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:26.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:25:26.621+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:26.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:25:26.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T22:25:56.893+0000] {processor.py:157} INFO - Started process (PID=963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:56.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:25:56.902+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:56.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:56.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:25:57.011+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:57.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:25:57.035+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:25:57.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:25:57.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-22T22:26:27.245+0000] {processor.py:157} INFO - Started process (PID=973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:26:27.281+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:27.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:27.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:27.392+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:27.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:26:27.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:27.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:26:27.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-08-22T22:26:57.610+0000] {processor.py:157} INFO - Started process (PID=983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:57.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:26:57.621+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:57.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:57.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:26:57.727+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:57.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:26:57.747+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:26:57.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:26:57.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-22T22:27:27.963+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:27.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:27:27.977+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:27.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:28.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:28.087+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:27:28.109+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:28.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:27:28.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-08-22T22:27:58.270+0000] {processor.py:157} INFO - Started process (PID=1003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:58.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:27:58.307+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:58.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:58.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:27:58.432+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:58.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:27:58.455+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:27:58.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:27:58.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.219 seconds
[2024-08-22T22:28:28.629+0000] {processor.py:157} INFO - Started process (PID=1013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:28.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:28:28.644+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:28.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:28.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:28.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:28.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:28:28.776+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:28.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:28:28.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-22T22:28:59.007+0000] {processor.py:157} INFO - Started process (PID=1023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:59.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:28:59.027+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:59.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:59.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:28:59.096+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:59.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:28:59.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:28:59.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:28:59.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T22:29:29.344+0000] {processor.py:157} INFO - Started process (PID=1033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:29.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:29:29.352+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:29.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:29.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:29.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:29.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:29:29.471+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:29.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:29:29.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-22T22:29:59.655+0000] {processor.py:157} INFO - Started process (PID=1043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:59.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:29:59.670+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:59.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:59.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:29:59.780+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:59.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:29:59.812+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:29:59.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:29:59.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-22T22:30:30.071+0000] {processor.py:157} INFO - Started process (PID=1053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:30:30.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:30:30.081+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:30:30.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:30:30.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:30:30.177+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:30:30.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:30:30.199+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:30:30.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:30:30.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-22T22:31:00.417+0000] {processor.py:157} INFO - Started process (PID=1063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:00.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:31:00.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:00.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:00.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:00.540+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:00.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:31:00.570+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:00.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:31:00.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-08-22T22:31:30.795+0000] {processor.py:157} INFO - Started process (PID=1073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:30.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:31:30.805+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:30.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:30.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:31:30.908+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:30.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:31:30.933+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:31:30.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:31:30.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T22:32:01.128+0000] {processor.py:157} INFO - Started process (PID=1081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:01.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:32:01.168+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:01.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:01.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:01.253+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:01.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:32:01.276+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:01.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:32:01.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-22T22:32:31.531+0000] {processor.py:157} INFO - Started process (PID=1093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:31.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:32:31.540+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:31.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:31.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:32:31.652+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:31.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:32:31.685+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:32:31.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:32:31.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T22:33:01.886+0000] {processor.py:157} INFO - Started process (PID=1103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:01.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:33:01.921+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:01.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:01.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:02.021+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:02.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:33:02.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:02.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:33:02.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T22:33:32.299+0000] {processor.py:157} INFO - Started process (PID=1113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:32.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:33:32.309+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:32.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:32.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:33:32.403+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:32.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:33:32.425+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:33:32.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:33:32.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-22T22:34:02.651+0000] {processor.py:157} INFO - Started process (PID=1123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:02.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:34:02.663+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:02.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:02.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:02.748+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:02.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:34:02.772+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:02.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:34:02.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T22:34:33.029+0000] {processor.py:157} INFO - Started process (PID=1133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:33.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:34:33.041+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:33.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:33.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:34:33.137+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:33.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:34:33.158+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:34:33.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:34:33.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T22:35:03.408+0000] {processor.py:157} INFO - Started process (PID=1143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:03.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:35:03.421+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:03.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:03.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:03.654+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:03.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:35:03.687+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:03.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:35:03.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-08-22T22:35:33.972+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:33.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:35:33.981+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:33.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:34.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:35:34.042+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:34.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:35:34.063+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:35:34.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:35:34.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T22:36:04.384+0000] {processor.py:157} INFO - Started process (PID=1163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:04.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:36:04.388+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:04.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:04.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:04.423+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:04.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:36:04.435+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:04.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:36:04.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-22T22:36:34.689+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:34.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:36:34.700+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:34.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:34.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:36:34.826+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:34.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:36:34.846+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:36:34.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:36:34.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T22:37:05.211+0000] {processor.py:157} INFO - Started process (PID=1183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:05.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:37:05.217+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:05.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:05.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:05.263+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:05.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:37:05.277+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:05.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:37:05.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T22:37:35.506+0000] {processor.py:157} INFO - Started process (PID=1193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:35.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:37:35.512+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:35.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:35.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:37:35.565+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:35.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:37:35.586+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:37:35.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:37:35.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T22:38:05.817+0000] {processor.py:157} INFO - Started process (PID=1203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:05.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:38:05.825+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:05.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:05.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:05.882+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:05.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:38:05.904+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:05.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:38:05.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-22T22:38:36.113+0000] {processor.py:157} INFO - Started process (PID=1213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:36.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:38:36.119+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:36.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:36.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:38:36.177+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:36.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:38:36.209+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:38:36.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:38:36.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T22:39:06.392+0000] {processor.py:157} INFO - Started process (PID=1223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:06.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:39:06.401+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:06.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:06.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:06.450+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:06.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:39:06.466+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:06.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:39:06.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-22T22:39:36.766+0000] {processor.py:157} INFO - Started process (PID=1233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:36.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:39:36.772+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:36.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:36.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:39:36.856+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:36.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:39:36.882+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:39:36.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:39:36.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-22T22:40:07.036+0000] {processor.py:157} INFO - Started process (PID=1243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:07.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:40:07.045+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:07.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:07.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:07.094+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:07.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:40:07.111+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:07.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:40:07.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-22T22:40:37.351+0000] {processor.py:157} INFO - Started process (PID=1253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:37.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:40:37.357+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:37.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:37.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:40:37.442+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:37.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:40:37.467+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:40:37.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:40:37.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-08-22T22:41:07.671+0000] {processor.py:157} INFO - Started process (PID=1261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:07.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:41:07.681+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:07.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:07.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:07.770+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:07.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:41:07.789+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:07.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:41:07.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-22T22:41:38.032+0000] {processor.py:157} INFO - Started process (PID=1273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:38.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:41:38.038+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:38.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:38.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:41:38.087+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:38.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:41:38.107+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:41:38.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:41:38.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T22:42:08.302+0000] {processor.py:157} INFO - Started process (PID=1283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:08.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:42:08.313+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:08.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:08.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:08.387+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:08.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:42:08.411+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:08.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:42:08.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-22T22:42:38.675+0000] {processor.py:157} INFO - Started process (PID=1293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:38.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:42:38.688+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:38.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:38.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:42:38.770+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:38.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:42:38.788+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:42:38.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:42:38.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-08-22T22:43:09.022+0000] {processor.py:157} INFO - Started process (PID=1303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:09.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:43:09.054+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:09.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:09.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:09.116+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:09.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:43:09.138+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:09.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:43:09.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-22T22:43:39.327+0000] {processor.py:157} INFO - Started process (PID=1313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:39.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:43:39.332+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:39.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:39.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:43:39.375+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:39.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:43:39.387+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:43:39.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:43:39.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-22T22:44:09.738+0000] {processor.py:157} INFO - Started process (PID=1323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:09.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:44:09.764+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:09.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:09.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:09.838+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:09.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:44:09.878+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:09.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:44:09.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T22:44:40.028+0000] {processor.py:157} INFO - Started process (PID=1333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:40.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:44:40.031+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:40.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:40.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:44:40.068+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:40.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:44:40.083+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:44:40.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:44:40.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T22:45:10.369+0000] {processor.py:157} INFO - Started process (PID=1343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:10.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:45:10.388+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:10.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:10.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:10.482+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:10.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:45:10.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:10.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:45:10.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T22:45:40.708+0000] {processor.py:157} INFO - Started process (PID=1353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:40.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:45:40.720+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:40.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:40.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:45:40.823+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:40.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:45:40.845+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:45:40.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:45:40.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-08-22T22:46:11.116+0000] {processor.py:157} INFO - Started process (PID=1363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:11.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:46:11.139+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:11.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:11.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:11.242+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:11.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:46:11.268+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:11.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:46:11.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-08-22T22:46:41.429+0000] {processor.py:157} INFO - Started process (PID=1373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:41.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:46:41.454+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:41.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:41.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:46:41.551+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:41.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:46:41.580+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:46:41.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:46:41.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-22T22:47:11.841+0000] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:11.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:47:11.854+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:11.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:11.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:11.959+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:11.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:47:11.982+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:11.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:47:11.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-22T22:47:42.200+0000] {processor.py:157} INFO - Started process (PID=1393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:42.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:47:42.212+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:42.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:42.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:47:42.288+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:42.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:47:42.313+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:47:42.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:47:42.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-22T22:48:12.485+0000] {processor.py:157} INFO - Started process (PID=1403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:12.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:48:12.494+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:12.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:12.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:12.567+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:12.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:48:12.585+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:12.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:48:12.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T22:48:42.843+0000] {processor.py:157} INFO - Started process (PID=1413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:42.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:48:42.849+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:42.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:42.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:48:42.902+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:42.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:48:42.920+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:48:42.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:48:42.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T22:49:13.123+0000] {processor.py:157} INFO - Started process (PID=1423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:13.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:49:13.128+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:13.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:13.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:13.209+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:13.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:49:13.235+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:13.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:49:13.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-22T22:49:43.529+0000] {processor.py:157} INFO - Started process (PID=1433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:43.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:49:43.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:43.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:43.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:49:43.620+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:43.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:49:43.642+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:49:43.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:49:43.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-22T22:50:13.810+0000] {processor.py:157} INFO - Started process (PID=1443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:13.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:50:13.822+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:13.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:13.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:13.888+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:13.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:50:13.906+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:13.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:50:13.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T22:50:44.139+0000] {processor.py:157} INFO - Started process (PID=1453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:44.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:50:44.145+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:44.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:44.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:50:44.200+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:44.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:50:44.242+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:50:44.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:50:44.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-22T22:51:14.451+0000] {processor.py:157} INFO - Started process (PID=1463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:14.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:51:14.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:14.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:14.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:14.519+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:14.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:51:14.542+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:14.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:51:14.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-22T22:51:44.756+0000] {processor.py:157} INFO - Started process (PID=1473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:44.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:51:44.767+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:44.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:44.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:51:44.903+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:44.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:51:44.925+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:51:44.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:51:44.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-22T22:52:15.104+0000] {processor.py:157} INFO - Started process (PID=1483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:15.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:52:15.130+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:15.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:15.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:15.237+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:15.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:52:15.258+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:15.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:52:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T22:52:45.565+0000] {processor.py:157} INFO - Started process (PID=1493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:45.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:52:45.582+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:45.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:45.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:52:45.673+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:45.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:52:45.699+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:52:45.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:52:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-22T22:53:15.890+0000] {processor.py:157} INFO - Started process (PID=1503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:15.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:53:15.900+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:15.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:15.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:15.970+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:15.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:53:15.994+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:15.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:53:16.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-22T22:53:46.280+0000] {processor.py:157} INFO - Started process (PID=1513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:46.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:53:46.311+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:46.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:46.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:53:46.422+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:46.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:53:46.444+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:53:46.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:53:46.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-22T22:54:16.615+0000] {processor.py:157} INFO - Started process (PID=1522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:16.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:54:16.626+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:16.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:16.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:16.695+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:16.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:54:16.709+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:16.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:54:16.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T22:54:46.950+0000] {processor.py:157} INFO - Started process (PID=1533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:46.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:54:46.956+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:46.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:46.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:54:46.991+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:46.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:54:47.008+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:54:47.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:54:47.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-22T22:55:17.364+0000] {processor.py:157} INFO - Started process (PID=1543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:17.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:55:17.374+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:17.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:17.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:17.468+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:17.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:55:17.492+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:17.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:55:17.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-22T22:55:47.662+0000] {processor.py:157} INFO - Started process (PID=1553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:47.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:55:47.667+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:47.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:47.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:55:47.724+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:47.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:55:47.742+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:55:47.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:55:47.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-22T22:56:18.048+0000] {processor.py:157} INFO - Started process (PID=1563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:18.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:56:18.077+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:18.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:18.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:18.172+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:18.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:56:18.195+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:18.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:56:18.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-08-22T22:56:48.373+0000] {processor.py:157} INFO - Started process (PID=1573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:48.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:56:48.390+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:48.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:48.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:56:48.504+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:48.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:56:48.525+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:56:48.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:56:48.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-08-22T22:57:18.793+0000] {processor.py:157} INFO - Started process (PID=1583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:18.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:57:18.803+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:18.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:18.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:18.926+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:18.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:57:18.948+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:18.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:57:18.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T22:57:49.073+0000] {processor.py:157} INFO - Started process (PID=1593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:49.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:57:49.080+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:49.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:49.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:57:49.123+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:49.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:57:49.139+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:57:49.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:57:49.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-22T22:58:19.445+0000] {processor.py:157} INFO - Started process (PID=1603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:19.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:58:19.450+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:19.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:19.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:19.519+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:19.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:58:19.570+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:19.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:58:19.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T22:58:49.796+0000] {processor.py:157} INFO - Started process (PID=1613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:49.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:58:49.804+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:49.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:49.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:58:49.875+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:49.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:58:49.903+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:58:49.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:58:49.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-22T22:59:20.111+0000] {processor.py:157} INFO - Started process (PID=1623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:20.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:59:20.117+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:20.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:20.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:20.189+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:20.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:59:20.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:20.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:59:20.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T22:59:50.544+0000] {processor.py:157} INFO - Started process (PID=1633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:50.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T22:59:50.558+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:50.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:50.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T22:59:50.604+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:50.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T22:59:50.622+0000] {logging_mixin.py:151} INFO - [2024-08-22T22:59:50.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T22:59:50.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T23:00:20.842+0000] {processor.py:157} INFO - Started process (PID=1643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:20.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:00:20.847+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:20.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:20.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:20.936+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:20.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:00:20.959+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:20.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:00:20.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-22T23:00:51.298+0000] {processor.py:157} INFO - Started process (PID=1652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:51.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:00:51.319+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:51.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:51.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:00:51.431+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:51.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:00:51.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:00:51.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:00:51.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-22T23:01:21.626+0000] {processor.py:157} INFO - Started process (PID=1663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:21.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:01:21.639+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:21.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:21.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:21.719+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:21.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:01:21.743+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:21.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:01:21.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-22T23:01:52.050+0000] {processor.py:157} INFO - Started process (PID=1672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:52.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:01:52.060+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:52.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:52.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:01:52.149+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:52.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:01:52.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:01:52.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:01:52.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T23:02:22.343+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:22.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:02:22.360+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:22.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:22.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:22.465+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:22.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:02:22.490+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:22.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:02:22.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-22T23:02:52.765+0000] {processor.py:157} INFO - Started process (PID=1693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:52.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:02:52.800+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:52.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:52.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:02:52.901+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:52.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:02:52.921+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:02:52.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:02:52.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-08-22T23:03:23.083+0000] {processor.py:157} INFO - Started process (PID=1703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:23.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:03:23.096+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:23.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:23.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:23.218+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:23.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:03:23.248+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:23.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:03:23.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-22T23:03:53.524+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:53.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:03:53.541+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:53.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:53.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:03:53.638+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:53.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:03:53.660+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:03:53.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:03:53.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-22T23:04:23.907+0000] {processor.py:157} INFO - Started process (PID=1722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:23.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:04:23.922+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:23.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:23.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:24.018+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:24.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:04:24.040+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:24.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:04:24.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-22T23:04:54.430+0000] {processor.py:157} INFO - Started process (PID=1733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:54.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:04:54.443+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:54.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:54.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:04:54.544+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:54.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:04:54.574+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:04:54.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:04:54.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T23:05:24.748+0000] {processor.py:157} INFO - Started process (PID=1743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:24.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:05:24.764+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:24.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:24.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:24.862+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:24.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:05:24.891+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:24.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:05:24.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-08-22T23:05:55.136+0000] {processor.py:157} INFO - Started process (PID=1753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:55.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:05:55.142+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:55.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:55.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:05:55.194+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:55.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:05:55.214+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:05:55.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:05:55.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-22T23:06:25.419+0000] {processor.py:157} INFO - Started process (PID=1763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:25.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:06:25.427+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:25.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:25.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:25.472+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:25.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:06:25.487+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:25.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:06:25.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T23:06:55.720+0000] {processor.py:157} INFO - Started process (PID=1773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:55.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:06:55.724+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:55.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:55.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:06:55.777+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:55.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:06:55.798+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:06:55.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:06:55.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T23:07:26.043+0000] {processor.py:157} INFO - Started process (PID=1783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:26.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:07:26.051+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:26.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:26.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:26.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:26.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:07:26.146+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:26.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:07:26.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T23:07:56.349+0000] {processor.py:157} INFO - Started process (PID=1793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:56.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:07:56.354+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:56.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:56.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:07:56.391+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:56.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:07:56.405+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:07:56.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:07:56.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-22T23:08:26.685+0000] {processor.py:157} INFO - Started process (PID=1803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:26.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:08:26.696+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:26.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:26.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:26.787+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:26.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:08:26.815+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:26.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:08:26.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-22T23:08:56.993+0000] {processor.py:157} INFO - Started process (PID=1813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:56.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:08:56.997+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:56.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:57.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:08:57.034+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:57.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:08:57.048+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:08:57.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:08:57.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-22T23:09:27.351+0000] {processor.py:157} INFO - Started process (PID=1823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:27.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:09:27.359+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:27.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:27.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:27.479+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:27.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:09:27.506+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:27.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:09:27.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T23:09:57.626+0000] {processor.py:157} INFO - Started process (PID=1833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:57.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:09:57.630+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:57.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:57.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:09:57.687+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:57.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:09:57.706+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:09:57.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:09:57.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T23:10:28.023+0000] {processor.py:157} INFO - Started process (PID=1843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:28.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:10:28.025+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:28.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:28.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:28.062+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:28.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:10:28.076+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:28.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:10:28.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-22T23:10:58.374+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:58.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:10:58.407+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:58.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:58.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:10:58.488+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:58.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:10:58.510+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:10:58.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:10:58.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-22T23:11:28.653+0000] {processor.py:157} INFO - Started process (PID=1863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:28.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:11:28.660+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:28.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:28.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:28.725+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:28.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:11:28.750+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:28.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:11:28.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T23:11:59.016+0000] {processor.py:157} INFO - Started process (PID=1873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:59.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:11:59.030+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:59.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:59.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:11:59.069+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:59.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:11:59.087+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:11:59.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:11:59.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-22T23:12:29.419+0000] {processor.py:157} INFO - Started process (PID=1883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:29.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:12:29.457+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:29.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:29.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:29.523+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:29.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:12:29.555+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:29.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:12:29.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-22T23:12:59.763+0000] {processor.py:157} INFO - Started process (PID=1893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:59.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:12:59.769+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:59.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:59.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:12:59.826+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:59.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:12:59.845+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:12:59.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:12:59.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-22T23:13:30.062+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:13:30.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:13:30.071+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:13:30.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:13:30.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:13:30.132+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:13:30.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:13:30.156+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:13:30.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:13:30.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-22T23:14:00.421+0000] {processor.py:157} INFO - Started process (PID=1913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:00.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:14:00.426+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:00.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:00.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:00.465+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:00.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:14:00.482+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:00.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:14:00.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-22T23:14:30.737+0000] {processor.py:157} INFO - Started process (PID=1923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:30.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:14:30.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:30.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:30.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:14:30.842+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:30.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:14:30.887+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:14:30.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:14:30.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-08-22T23:15:01.217+0000] {processor.py:157} INFO - Started process (PID=1933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:01.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:15:01.224+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:01.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:01.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:01.280+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:01.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:15:01.296+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:01.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:15:01.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-22T23:15:31.694+0000] {processor.py:157} INFO - Started process (PID=1943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:31.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:15:31.705+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:31.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:31.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:15:31.815+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:31.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:15:31.839+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:15:31.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:15:31.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-22T23:16:02.161+0000] {processor.py:157} INFO - Started process (PID=1953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:02.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:16:02.170+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:02.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:02.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:02.221+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:02.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:16:02.240+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:02.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:16:02.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-22T23:16:32.483+0000] {processor.py:157} INFO - Started process (PID=1963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:32.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:16:32.488+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:32.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:32.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:16:32.528+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:32.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:16:32.545+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:16:32.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:16:32.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-22T23:17:02.829+0000] {processor.py:157} INFO - Started process (PID=1973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:02.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:17:02.840+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:02.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:02.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:02.914+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:02.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:17:02.954+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:02.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:17:02.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-22T23:17:33.095+0000] {processor.py:157} INFO - Started process (PID=1983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:33.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:17:33.107+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:33.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:33.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:17:33.166+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:33.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:17:33.186+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:17:33.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:17:33.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-22T23:18:03.519+0000] {processor.py:157} INFO - Started process (PID=1993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:03.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:18:03.529+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:03.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:03.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:03.572+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:03.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:18:03.589+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:03.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:18:03.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T23:18:33.820+0000] {processor.py:157} INFO - Started process (PID=2003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:33.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:18:33.827+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:33.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:33.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:18:33.879+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:33.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:18:33.903+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:18:33.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:18:33.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T23:19:04.109+0000] {processor.py:157} INFO - Started process (PID=2013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:04.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:19:04.120+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:04.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:04.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:04.197+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:04.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:19:04.214+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:04.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:19:04.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-22T23:19:34.452+0000] {processor.py:157} INFO - Started process (PID=2023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:34.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:19:34.457+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:34.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:34.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:19:34.536+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:34.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:19:34.560+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:19:34.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:19:34.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-22T23:20:04.800+0000] {processor.py:157} INFO - Started process (PID=2033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:04.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:20:04.837+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:04.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:04.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:04.904+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:04.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:20:04.923+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:04.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:20:04.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-22T23:20:35.089+0000] {processor.py:157} INFO - Started process (PID=2043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:35.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:20:35.095+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:35.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:35.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:20:35.142+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:35.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:20:35.158+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:20:35.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:20:35.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-22T23:21:05.497+0000] {processor.py:157} INFO - Started process (PID=2053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:05.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:21:05.502+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:05.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:05.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:05.583+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:05.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:21:05.611+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:05.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:21:05.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-22T23:21:35.793+0000] {processor.py:157} INFO - Started process (PID=2063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:35.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:21:35.800+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:35.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:35.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:21:35.876+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:35.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:21:35.912+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:21:35.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:21:35.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-22T23:22:06.149+0000] {processor.py:157} INFO - Started process (PID=2073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:06.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:22:06.160+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:06.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:06.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:06.238+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:06.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:22:06.258+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:06.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:22:06.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-22T23:22:36.426+0000] {processor.py:157} INFO - Started process (PID=2083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:36.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:22:36.432+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:36.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:36.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:22:36.486+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:36.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:22:36.505+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:22:36.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:22:36.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-22T23:23:06.755+0000] {processor.py:157} INFO - Started process (PID=2093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:06.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:23:06.760+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:06.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:06.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:06.837+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:06.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:23:06.857+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:06.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:23:06.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T23:23:37.048+0000] {processor.py:157} INFO - Started process (PID=2103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:37.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:23:37.056+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:37.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:37.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:23:37.130+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:37.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:23:37.150+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:23:37.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:23:37.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T23:24:07.375+0000] {processor.py:157} INFO - Started process (PID=2113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:07.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:24:07.383+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:07.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:07.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:07.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:07.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:24:07.463+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:07.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:24:07.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T23:24:37.655+0000] {processor.py:157} INFO - Started process (PID=2123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:37.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:24:37.659+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:37.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:37.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:24:37.734+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:37.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:24:37.758+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:24:37.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:24:37.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-22T23:25:07.995+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:07.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:25:08.001+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:08.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:08.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:08.059+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:08.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:25:08.092+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:08.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:25:08.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-22T23:25:38.279+0000] {processor.py:157} INFO - Started process (PID=2143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:38.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:25:38.322+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:38.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:38.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:25:38.413+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:38.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:25:38.446+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:25:38.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:25:38.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-08-22T23:26:08.707+0000] {processor.py:157} INFO - Started process (PID=2153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:08.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:26:08.716+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:08.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:08.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:08.821+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:08.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:26:08.856+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:08.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:26:08.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-08-22T23:26:39.035+0000] {processor.py:157} INFO - Started process (PID=2163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:39.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:26:39.045+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:39.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:39.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:26:39.146+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:39.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:26:39.173+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:26:39.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:26:39.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T23:27:09.537+0000] {processor.py:157} INFO - Started process (PID=2173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:09.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:27:09.556+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:09.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:09.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:09.647+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:09.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:27:09.709+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:09.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:27:09.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-08-22T23:27:39.879+0000] {processor.py:157} INFO - Started process (PID=2183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:39.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:27:39.888+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:39.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:39.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:27:39.997+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:39.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:27:40.018+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:27:40.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:27:40.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-22T23:28:10.362+0000] {processor.py:157} INFO - Started process (PID=2193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:10.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:28:10.374+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:10.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:10.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:10.488+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:10.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:28:10.509+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:10.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:28:10.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-08-22T23:28:40.634+0000] {processor.py:157} INFO - Started process (PID=2203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:40.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:28:40.648+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:40.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:40.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:28:40.757+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:40.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:28:40.776+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:28:40.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:28:40.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T23:29:11.049+0000] {processor.py:157} INFO - Started process (PID=2213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:11.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:29:11.057+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:11.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:11.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:11.130+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:11.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:29:11.151+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:11.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:29:11.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-22T23:29:41.358+0000] {processor.py:157} INFO - Started process (PID=2222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:41.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:29:41.393+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:41.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:41.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:29:41.487+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:41.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:29:41.512+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:29:41.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:29:41.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-08-22T23:30:11.846+0000] {processor.py:157} INFO - Started process (PID=2233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:11.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:30:11.858+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:11.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:11.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:11.928+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:11.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:30:11.966+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:11.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:30:11.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T23:30:42.190+0000] {processor.py:157} INFO - Started process (PID=2243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:42.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:30:42.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:42.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:42.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:30:42.299+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:42.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:30:42.339+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:30:42.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:30:42.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-22T23:31:12.542+0000] {processor.py:157} INFO - Started process (PID=2253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:12.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:31:12.549+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:12.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:12.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:12.601+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:12.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:31:12.625+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:12.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:31:12.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T23:31:42.958+0000] {processor.py:157} INFO - Started process (PID=2263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:42.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:31:42.967+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:42.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:42.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:31:43.021+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:31:43.036+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:31:43.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:31:43.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-22T23:32:13.253+0000] {processor.py:157} INFO - Started process (PID=2273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:13.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:32:13.259+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:13.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:13.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:13.305+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:13.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:32:13.324+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:13.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:32:13.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-22T23:32:43.564+0000] {processor.py:157} INFO - Started process (PID=2283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:43.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:32:43.588+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:43.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:43.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:32:43.652+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:43.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:32:43.676+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:32:43.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:32:43.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-22T23:33:13.868+0000] {processor.py:157} INFO - Started process (PID=2293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:13.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:33:13.895+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:13.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:13.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:14.035+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:14.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:33:14.118+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:14.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:33:14.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.297 seconds
[2024-08-22T23:33:44.309+0000] {processor.py:157} INFO - Started process (PID=2303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:44.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:33:44.327+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:44.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:44.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:33:44.396+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:44.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:33:44.448+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:33:44.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:33:44.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-08-22T23:34:14.720+0000] {processor.py:157} INFO - Started process (PID=2312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:14.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:34:14.731+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:14.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:14.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:14.846+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:14.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:34:14.875+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:14.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:34:14.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-22T23:34:45.037+0000] {processor.py:157} INFO - Started process (PID=2323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:45.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:34:45.055+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:45.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:45.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:34:45.169+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:45.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:34:45.193+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:34:45.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:34:45.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-22T23:35:15.503+0000] {processor.py:157} INFO - Started process (PID=2333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:15.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:35:15.512+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:15.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:15.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:15.610+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:35:15.642+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:15.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:35:15.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T23:35:45.792+0000] {processor.py:157} INFO - Started process (PID=2343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:45.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:35:45.797+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:45.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:45.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:35:45.831+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:45.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:35:45.845+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:35:45.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:35:45.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-22T23:36:16.235+0000] {processor.py:157} INFO - Started process (PID=2353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:16.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:36:16.249+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:16.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:16.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:16.347+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:16.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:36:16.374+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:16.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:36:16.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-22T23:36:46.540+0000] {processor.py:157} INFO - Started process (PID=2363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:46.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:36:46.561+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:46.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:46.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:36:46.650+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:46.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:36:46.674+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:36:46.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:36:46.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-08-22T23:37:16.878+0000] {processor.py:157} INFO - Started process (PID=2373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:16.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:37:16.883+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:16.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:16.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:16.920+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:16.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:37:16.935+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:16.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:37:16.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-22T23:37:47.205+0000] {processor.py:157} INFO - Started process (PID=2383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:47.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:37:47.213+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:47.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:47.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:37:47.307+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:47.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:37:47.330+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:37:47.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:37:47.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-22T23:38:17.546+0000] {processor.py:157} INFO - Started process (PID=2392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:17.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:38:17.558+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:17.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:17.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:17.614+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:17.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:38:17.633+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:17.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:38:17.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-22T23:38:47.859+0000] {processor.py:157} INFO - Started process (PID=2403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:47.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:38:47.864+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:47.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:47.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:38:47.908+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:47.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:38:47.926+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:38:47.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:38:47.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-22T23:39:18.133+0000] {processor.py:157} INFO - Started process (PID=2413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:18.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:39:18.167+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:18.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:18.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:18.233+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:18.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:39:18.260+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:18.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:39:18.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-08-22T23:39:48.456+0000] {processor.py:157} INFO - Started process (PID=2423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:48.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:39:48.467+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:48.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:48.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:39:48.537+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:48.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:39:48.571+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:39:48.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:39:48.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-22T23:40:18.890+0000] {processor.py:157} INFO - Started process (PID=2433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:18.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:40:18.900+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:18.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:18.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:18.950+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:18.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:40:18.967+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:18.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:40:18.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-22T23:40:49.334+0000] {processor.py:157} INFO - Started process (PID=2443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:49.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:40:49.348+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:49.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:49.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:40:49.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:49.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:40:49.461+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:40:49.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:40:49.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-22T23:41:19.643+0000] {processor.py:157} INFO - Started process (PID=2453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:19.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:41:19.670+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:19.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:19.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:19.751+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:19.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:41:19.773+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:19.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:41:19.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T23:41:50.074+0000] {processor.py:157} INFO - Started process (PID=2463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:50.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:41:50.087+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:50.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:50.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:41:50.156+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:50.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:41:50.189+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:41:50.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:41:50.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T23:42:20.519+0000] {processor.py:157} INFO - Started process (PID=2473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:20.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:42:20.533+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:20.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:20.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:20.619+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:20.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:42:20.640+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:20.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:42:20.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-08-22T23:42:51.022+0000] {processor.py:157} INFO - Started process (PID=2483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:51.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:42:51.032+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:51.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:51.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:42:51.134+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:51.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:42:51.157+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:42:51.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:42:51.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-08-22T23:43:21.315+0000] {processor.py:157} INFO - Started process (PID=2493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:21.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:43:21.328+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:21.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:21.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:21.426+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:21.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:43:21.459+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:21.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:43:21.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-08-22T23:43:51.744+0000] {processor.py:157} INFO - Started process (PID=2503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:51.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:43:51.755+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:51.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:51.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:43:51.812+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:51.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:43:51.831+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:43:51.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:43:51.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-22T23:44:22.069+0000] {processor.py:157} INFO - Started process (PID=2513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:22.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:44:22.079+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:22.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:22.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:22.150+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:22.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:44:22.170+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:22.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:44:22.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-08-22T23:44:52.387+0000] {processor.py:157} INFO - Started process (PID=2523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:52.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:44:52.399+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:52.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:52.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:44:52.493+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:52.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:44:52.517+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:44:52.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:44:52.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T23:45:22.760+0000] {processor.py:157} INFO - Started process (PID=2533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:22.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:45:22.781+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:22.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:22.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:22.897+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:22.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:45:22.918+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:22.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:45:22.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-22T23:45:53.127+0000] {processor.py:157} INFO - Started process (PID=2543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:53.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:45:53.160+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:53.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:53.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:45:53.263+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:53.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:45:53.291+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:45:53.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:45:53.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-22T23:46:23.515+0000] {processor.py:157} INFO - Started process (PID=2553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:23.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:46:23.525+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:23.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:23.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:23.606+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:23.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:46:23.630+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:23.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:46:23.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-22T23:46:53.814+0000] {processor.py:157} INFO - Started process (PID=2563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:53.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:46:53.820+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:53.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:53.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:46:53.871+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:53.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:46:53.893+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:46:53.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:46:53.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-22T23:47:24.144+0000] {processor.py:157} INFO - Started process (PID=2573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:24.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:47:24.153+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:24.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:24.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:24.208+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:24.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:47:24.227+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:24.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:47:24.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-22T23:47:54.481+0000] {processor.py:157} INFO - Started process (PID=2583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:54.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:47:54.490+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:54.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:54.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:47:54.564+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:54.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:47:54.586+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:47:54.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:47:54.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-22T23:48:24.853+0000] {processor.py:157} INFO - Started process (PID=2593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:24.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:48:24.865+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:24.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:24.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:24.934+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:24.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:48:24.952+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:24.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:48:24.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-22T23:48:55.175+0000] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:55.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:48:55.185+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:55.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:55.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:48:55.246+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:55.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:48:55.264+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:48:55.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:48:55.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-22T23:49:25.492+0000] {processor.py:157} INFO - Started process (PID=2613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:25.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:49:25.494+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:25.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:25.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:25.522+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:25.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:49:25.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:25.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:49:25.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-22T23:49:55.798+0000] {processor.py:157} INFO - Started process (PID=2623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:55.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:49:55.824+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:55.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:55.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:49:55.872+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:55.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:49:55.890+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:49:55.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:49:55.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-22T23:50:26.229+0000] {processor.py:157} INFO - Started process (PID=2633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:26.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:50:26.246+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:26.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:26.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:26.333+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:26.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:50:26.377+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:26.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:50:26.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.177 seconds
[2024-08-22T23:50:56.508+0000] {processor.py:157} INFO - Started process (PID=2641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:56.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:50:56.532+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:56.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:56.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:50:56.602+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:56.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:50:56.615+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:50:56.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:50:56.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-22T23:51:27.002+0000] {processor.py:157} INFO - Started process (PID=2653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:27.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:51:27.010+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:27.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:27.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:27.069+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:27.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:51:27.090+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:27.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:51:27.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-22T23:51:57.353+0000] {processor.py:157} INFO - Started process (PID=2663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:57.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:51:57.362+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:57.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:57.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:51:57.440+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:57.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:51:57.483+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:51:57.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:51:57.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-22T23:52:27.910+0000] {processor.py:157} INFO - Started process (PID=2673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:27.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:52:27.922+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:27.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:27.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:28.007+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:28.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:52:28.025+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:28.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:52:28.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-22T23:52:58.288+0000] {processor.py:157} INFO - Started process (PID=2683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:58.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:52:58.296+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:58.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:58.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:52:58.363+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:58.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:52:58.381+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:52:58.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:52:58.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-22T23:53:28.637+0000] {processor.py:157} INFO - Started process (PID=2693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:53:28.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-22T23:53:28.645+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:53:28.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:53:28.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-22T23:53:28.691+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:53:28.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-22T23:53:28.705+0000] {logging_mixin.py:151} INFO - [2024-08-22T23:53:28.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-21T01:00:00+00:00, run_after=2024-08-22T01:00:00+00:00
[2024-08-22T23:53:28.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
