[2024-07-27T00:03:28.393+0000] {processor.py:157} INFO - Started process (PID=31770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:28.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:03:28.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:28.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:28.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:28.432+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:28.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:03:28.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:28.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:03:28.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T00:03:58.945+0000] {processor.py:157} INFO - Started process (PID=31795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:58.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:03:58.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:58.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:58.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:03:59.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:59.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:03:59.013+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:03:59.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:03:59.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T00:04:29.467+0000] {processor.py:157} INFO - Started process (PID=31820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:29.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:04:29.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:29.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:29.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:29.497+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:29.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:04:29.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:29.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:04:29.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T00:04:59.876+0000] {processor.py:157} INFO - Started process (PID=31845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:59.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:04:59.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:59.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:59.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:04:59.908+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:59.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:04:59.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:04:59.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:04:59.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T00:05:30.297+0000] {processor.py:157} INFO - Started process (PID=31870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:05:30.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:05:30.300+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:05:30.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:05:30.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:05:30.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:05:30.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:05:30.345+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:05:30.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:05:30.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:06:00.814+0000] {processor.py:157} INFO - Started process (PID=31895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:06:00.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:06:00.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:06:00.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:06:00.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:06:00.848+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:06:00.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:06:00.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:06:00.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:06:00.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:16:01.376+0000] {processor.py:157} INFO - Started process (PID=31920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:16:01.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:16:01.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:16:01.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:16:01.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:16:01.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:16:01.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:16:01.435+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:16:01.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:16:01.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T00:31:55.423+0000] {processor.py:157} INFO - Started process (PID=31945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:31:55.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:31:55.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:31:55.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:31:55.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:31:55.503+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:31:55.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:31:55.525+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:31:55.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:31:55.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-27T00:32:25.884+0000] {processor.py:157} INFO - Started process (PID=32373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:25.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:32:25.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:25.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:25.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:25.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:25.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:32:25.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:25.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:32:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T00:32:56.350+0000] {processor.py:157} INFO - Started process (PID=32398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:56.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:32:56.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:56.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:56.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:32:56.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:56.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:32:56.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:32:56.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:32:56.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:33:26.831+0000] {processor.py:157} INFO - Started process (PID=32423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:26.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:33:26.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:26.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:26.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:26.868+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:26.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:33:26.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:26.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:33:26.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T00:33:57.346+0000] {processor.py:157} INFO - Started process (PID=32448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:57.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:33:57.350+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:57.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:57.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:33:57.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:57.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:33:57.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:33:57.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:33:57.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T00:34:27.817+0000] {processor.py:157} INFO - Started process (PID=32476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:27.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:34:27.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:27.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:27.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:27.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:27.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:34:27.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:27.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:34:27.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T00:34:58.313+0000] {processor.py:157} INFO - Started process (PID=32501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:58.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:34:58.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:58.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:58.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:34:58.350+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:58.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:34:58.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:34:58.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:34:58.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:35:28.807+0000] {processor.py:157} INFO - Started process (PID=32526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:28.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:35:28.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:28.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:28.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:28.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:28.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:35:28.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:28.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:35:28.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T00:35:59.291+0000] {processor.py:157} INFO - Started process (PID=32551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:59.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:35:59.294+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:59.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:59.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:35:59.323+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:59.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:35:59.333+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:35:59.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:35:59.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T00:36:29.724+0000] {processor.py:157} INFO - Started process (PID=32576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:36:29.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:36:29.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:36:29.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:36:29.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:36:29.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:36:29.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:36:29.778+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:36:29.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:36:29.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T00:37:00.239+0000] {processor.py:157} INFO - Started process (PID=32601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:00.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:37:00.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:00.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:00.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:00.272+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:00.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:37:00.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:00.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:37:00.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:37:30.638+0000] {processor.py:157} INFO - Started process (PID=32626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:30.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:37:30.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:30.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:30.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:37:30.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:30.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:37:30.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:37:30.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:37:30.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T00:38:01.162+0000] {processor.py:157} INFO - Started process (PID=32651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:01.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:38:01.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:01.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:01.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:01.195+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:01.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:38:01.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:01.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:38:01.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T00:38:31.658+0000] {processor.py:157} INFO - Started process (PID=32676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:31.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:38:31.660+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:31.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:31.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:38:31.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:31.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:38:31.693+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:38:31.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:38:31.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T00:39:02.072+0000] {processor.py:157} INFO - Started process (PID=32701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:02.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:39:02.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:02.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:02.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:02.113+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:02.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:39:02.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:02.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:39:02.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T00:39:32.498+0000] {processor.py:157} INFO - Started process (PID=32726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:32.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:39:32.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:32.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:32.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:39:32.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:32.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:39:32.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:39:32.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:39:32.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T00:40:02.910+0000] {processor.py:157} INFO - Started process (PID=32751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:02.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:40:02.913+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:02.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:02.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:02.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:02.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:40:02.954+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:02.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:40:02.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:40:33.360+0000] {processor.py:157} INFO - Started process (PID=32776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:33.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:40:33.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:33.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:33.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:40:33.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:33.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:40:33.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:40:33.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:40:33.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T00:41:03.784+0000] {processor.py:157} INFO - Started process (PID=32801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:03.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:41:03.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:03.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:03.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:03.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:03.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:41:03.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:03.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:41:03.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T00:41:34.190+0000] {processor.py:157} INFO - Started process (PID=32826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:34.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:41:34.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:34.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:34.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:41:34.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:34.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:41:34.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:41:34.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:41:34.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T00:42:04.679+0000] {processor.py:157} INFO - Started process (PID=32851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:04.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:42:04.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:04.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:04.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:04.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:04.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:42:04.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:04.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:42:04.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T00:42:35.086+0000] {processor.py:157} INFO - Started process (PID=32876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:35.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:42:35.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:35.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:35.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:42:35.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:35.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:42:35.127+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:42:35.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:42:35.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:43:05.575+0000] {processor.py:157} INFO - Started process (PID=32901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:05.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:43:05.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:05.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:05.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:05.605+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:05.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:43:05.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:05.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:43:05.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:43:36.055+0000] {processor.py:157} INFO - Started process (PID=32926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:36.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:43:36.058+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:36.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:36.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:43:36.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:36.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:43:36.097+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:43:36.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:43:36.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:44:06.573+0000] {processor.py:157} INFO - Started process (PID=32951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:06.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:44:06.576+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:06.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:06.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:06.607+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:06.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:44:06.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:06.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:44:06.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T00:44:37.041+0000] {processor.py:157} INFO - Started process (PID=32976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:37.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:44:37.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:37.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:37.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:44:37.097+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:37.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:44:37.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:44:37.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:44:37.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T00:45:07.570+0000] {processor.py:157} INFO - Started process (PID=33001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:07.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:45:07.573+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:07.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:07.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:07.604+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:07.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:45:07.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:07.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:45:07.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T00:45:38.037+0000] {processor.py:157} INFO - Started process (PID=33026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:38.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:45:38.038+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:38.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:38.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:45:38.061+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:38.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:45:38.071+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:45:38.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:45:38.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T00:46:08.521+0000] {processor.py:157} INFO - Started process (PID=33051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:08.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:46:08.524+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:08.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:08.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:08.551+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:08.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:46:08.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:08.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:46:08.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:46:39.005+0000] {processor.py:157} INFO - Started process (PID=33076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:39.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:46:39.008+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:39.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:39.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:46:39.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:39.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:46:39.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:46:39.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:46:39.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:47:09.545+0000] {processor.py:157} INFO - Started process (PID=33101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:09.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:47:09.550+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:09.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:09.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:09.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:47:09.606+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:09.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:47:09.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T00:47:40.084+0000] {processor.py:157} INFO - Started process (PID=33126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:40.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:47:40.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:40.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:40.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:47:40.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:40.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:47:40.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:47:40.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:47:40.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:48:10.528+0000] {processor.py:157} INFO - Started process (PID=33151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:10.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:48:10.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:10.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:10.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:10.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:10.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:48:10.576+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:10.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:48:10.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T00:48:41.001+0000] {processor.py:157} INFO - Started process (PID=33176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:41.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:48:41.005+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:41.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:41.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:48:41.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:41.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:48:41.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:48:41.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:48:41.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T00:49:11.471+0000] {processor.py:157} INFO - Started process (PID=33201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:11.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:49:11.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:11.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:11.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:11.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:11.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:49:11.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:11.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:49:11.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:49:41.940+0000] {processor.py:157} INFO - Started process (PID=33226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:41.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:49:41.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:41.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:41.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:49:41.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:41.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:49:41.993+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:49:41.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:49:42.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T00:50:12.374+0000] {processor.py:157} INFO - Started process (PID=33251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:12.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:50:12.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:12.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:12.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:12.403+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:12.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:50:12.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:12.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:50:12.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T00:50:42.841+0000] {processor.py:157} INFO - Started process (PID=33276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:42.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:50:42.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:42.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:42.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:50:42.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:42.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:50:42.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:50:42.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:50:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:51:13.325+0000] {processor.py:157} INFO - Started process (PID=33301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:13.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:51:13.328+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:13.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:13.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:13.355+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:13.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:51:13.368+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:13.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:51:13.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T00:51:43.824+0000] {processor.py:157} INFO - Started process (PID=33326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:43.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:51:43.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:43.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:43.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:51:43.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:43.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:51:43.869+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:51:43.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:51:43.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T00:52:14.335+0000] {processor.py:157} INFO - Started process (PID=33351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:14.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:52:14.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:14.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:14.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:14.368+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:14.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:52:14.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:14.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:52:14.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T00:52:44.841+0000] {processor.py:157} INFO - Started process (PID=33376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:44.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:52:44.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:44.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:44.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:52:44.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:44.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:52:44.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:52:44.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:52:44.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:53:15.311+0000] {processor.py:157} INFO - Started process (PID=33401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:15.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:53:15.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:15.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:15.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:15.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:53:15.366+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:15.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:53:15.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T00:53:45.766+0000] {processor.py:157} INFO - Started process (PID=33426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:45.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:53:45.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:45.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:45.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:53:45.803+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:45.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:53:45.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:53:45.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:53:45.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T00:54:16.296+0000] {processor.py:157} INFO - Started process (PID=33451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:16.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:54:16.300+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:16.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:16.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:16.329+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:16.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:54:16.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:16.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:54:16.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T00:54:46.769+0000] {processor.py:157} INFO - Started process (PID=33476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:46.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:54:46.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:46.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:46.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:54:46.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:46.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:54:46.812+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:54:46.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:54:46.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:55:17.227+0000] {processor.py:157} INFO - Started process (PID=33501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:17.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:55:17.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:17.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:17.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:17.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:17.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:55:17.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:17.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:55:17.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:55:47.654+0000] {processor.py:157} INFO - Started process (PID=33526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:47.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:55:47.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:47.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:47.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:55:47.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:47.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:55:47.687+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:55:47.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:55:47.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-27T00:56:18.143+0000] {processor.py:157} INFO - Started process (PID=33551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:18.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:56:18.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:18.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:18.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:18.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:18.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:56:18.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:18.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:56:18.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T00:56:48.661+0000] {processor.py:157} INFO - Started process (PID=33576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:48.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:56:48.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:48.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:48.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:56:48.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:48.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:56:48.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:56:48.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:56:48.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:57:19.201+0000] {processor.py:157} INFO - Started process (PID=33601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:19.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:57:19.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:19.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:19.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:19.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:19.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:57:19.248+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:19.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:57:19.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T00:57:49.600+0000] {processor.py:157} INFO - Started process (PID=33626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:49.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:57:49.604+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:49.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:49.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:57:49.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:49.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:57:49.642+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:57:49.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:57:49.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T00:58:20.007+0000] {processor.py:157} INFO - Started process (PID=33651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:20.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:58:20.010+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:20.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:20.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:20.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:20.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:58:20.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:20.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:58:20.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T00:58:50.467+0000] {processor.py:157} INFO - Started process (PID=33676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:50.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:58:50.473+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:50.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:50.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:58:50.510+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:50.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:58:50.521+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:58:50.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:58:50.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T00:59:20.857+0000] {processor.py:157} INFO - Started process (PID=33701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:20.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:59:20.860+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:20.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:20.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:20.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:20.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:59:20.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:20.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:59:20.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T00:59:51.343+0000] {processor.py:157} INFO - Started process (PID=33726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:51.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T00:59:51.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:51.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:51.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T00:59:51.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:51.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T00:59:51.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T00:59:51.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-26T01:00:00+00:00, run_after=2024-07-27T01:00:00+00:00
[2024-07-27T00:59:51.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T01:00:21.789+0000] {processor.py:157} INFO - Started process (PID=34142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:21.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:00:21.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:21.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:21.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:21.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:21.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:00:21.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:21.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:00:21.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-27T01:00:52.324+0000] {processor.py:157} INFO - Started process (PID=34167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:52.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:00:52.329+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:52.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:52.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:00:52.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:52.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:00:52.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:00:52.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:00:52.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T01:01:22.860+0000] {processor.py:157} INFO - Started process (PID=34192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:22.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:01:22.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:22.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:22.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:22.900+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:22.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:01:22.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:22.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:01:22.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T01:01:53.311+0000] {processor.py:157} INFO - Started process (PID=34217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:53.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:01:53.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:53.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:53.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:01:53.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:53.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:01:53.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:01:53.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:01:53.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:02:23.810+0000] {processor.py:157} INFO - Started process (PID=34242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:23.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:02:23.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:23.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:23.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:23.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:23.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:02:23.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:23.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:02:23.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T01:02:54.274+0000] {processor.py:157} INFO - Started process (PID=34267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:54.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:02:54.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:54.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:54.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:02:54.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:54.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:02:54.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:02:54.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:02:54.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:03:24.780+0000] {processor.py:157} INFO - Started process (PID=34292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:24.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:03:24.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:24.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:24.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:24.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:24.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:03:24.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:24.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:03:24.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T01:03:55.200+0000] {processor.py:157} INFO - Started process (PID=34317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:55.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:03:55.207+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:55.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:55.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:03:55.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:55.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:03:55.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:03:55.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:03:55.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T01:04:25.701+0000] {processor.py:157} INFO - Started process (PID=34342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:25.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:04:25.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:25.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:25.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:25.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:25.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:04:25.746+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:25.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:04:25.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:04:56.120+0000] {processor.py:157} INFO - Started process (PID=34367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:56.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:04:56.127+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:56.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:56.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:04:56.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:56.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:04:56.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:04:56.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:04:56.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T01:05:26.625+0000] {processor.py:157} INFO - Started process (PID=34392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:26.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:05:26.638+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:26.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:26.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:26.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:26.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:05:26.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:26.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:05:26.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-27T01:05:57.139+0000] {processor.py:157} INFO - Started process (PID=34417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:57.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:05:57.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:57.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:57.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:05:57.171+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:57.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:05:57.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:05:57.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:05:57.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:06:27.603+0000] {processor.py:157} INFO - Started process (PID=34442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:27.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:06:27.606+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:27.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:27.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:27.640+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:27.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:06:27.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:27.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:06:27.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:06:58.142+0000] {processor.py:157} INFO - Started process (PID=34467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:58.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:06:58.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:58.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:58.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:06:58.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:58.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:06:58.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:06:58.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:06:58.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T01:07:28.629+0000] {processor.py:157} INFO - Started process (PID=34492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:28.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:07:28.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:28.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:28.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:28.661+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:28.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:07:28.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:28.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:07:28.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T01:07:59.083+0000] {processor.py:157} INFO - Started process (PID=34517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:59.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:07:59.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:59.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:59.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:07:59.116+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:59.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:07:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:07:59.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:07:59.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:08:29.515+0000] {processor.py:157} INFO - Started process (PID=34542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:08:29.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:08:29.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:08:29.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:08:29.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:08:29.550+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:08:29.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:08:29.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:08:29.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:08:29.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:09:00.086+0000] {processor.py:157} INFO - Started process (PID=34567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:00.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:09:00.091+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:00.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:00.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:00.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:00.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:09:00.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:00.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:09:00.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T01:09:30.546+0000] {processor.py:157} INFO - Started process (PID=34592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:30.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:09:30.551+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:30.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:30.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:09:30.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:30.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:09:30.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:09:30.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:09:30.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T01:10:01.023+0000] {processor.py:157} INFO - Started process (PID=34617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:01.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:10:01.026+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:01.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:01.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:01.052+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:01.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:10:01.063+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:01.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:10:01.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T01:10:31.406+0000] {processor.py:157} INFO - Started process (PID=34642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:31.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:10:31.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:31.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:31.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:10:31.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:31.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:10:31.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:10:31.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:10:31.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:11:01.872+0000] {processor.py:157} INFO - Started process (PID=34667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:01.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:11:01.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:01.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:01.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:01.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:01.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:11:01.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:01.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:11:01.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:11:32.341+0000] {processor.py:157} INFO - Started process (PID=34692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:32.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:11:32.345+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:32.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:32.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:11:32.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:32.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:11:32.386+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:11:32.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:11:32.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T01:12:02.878+0000] {processor.py:157} INFO - Started process (PID=34717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:02.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:12:02.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:02.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:02.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:02.923+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:02.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:12:02.936+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:02.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:12:02.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T01:12:33.368+0000] {processor.py:157} INFO - Started process (PID=34742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:33.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:12:33.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:33.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:33.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:12:33.395+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:33.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:12:33.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:12:33.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:12:33.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T01:13:03.849+0000] {processor.py:157} INFO - Started process (PID=34767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:03.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:13:03.852+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:03.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:03.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:03.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:03.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:13:03.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:03.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:13:03.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:13:34.339+0000] {processor.py:157} INFO - Started process (PID=34792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:34.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:13:34.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:34.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:34.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:13:34.373+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:34.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:13:34.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:13:34.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:13:34.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:14:04.841+0000] {processor.py:157} INFO - Started process (PID=34817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:04.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:14:04.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:04.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:04.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:04.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:04.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:14:04.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:04.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:14:04.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:14:35.331+0000] {processor.py:157} INFO - Started process (PID=34842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:35.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:14:35.336+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:35.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:35.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:14:35.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:35.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:14:35.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:14:35.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:14:35.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T01:15:05.817+0000] {processor.py:157} INFO - Started process (PID=34867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:05.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:15:05.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:05.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:05.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:05.852+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:15:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:05.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:15:05.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T01:15:36.279+0000] {processor.py:157} INFO - Started process (PID=34892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:36.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:15:36.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:36.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:36.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:15:36.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:36.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:15:36.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:15:36.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:15:36.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:16:06.672+0000] {processor.py:157} INFO - Started process (PID=34917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:06.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:16:06.674+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:06.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:06.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:06.702+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:06.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:16:06.713+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:06.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:16:06.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:16:37.094+0000] {processor.py:157} INFO - Started process (PID=34942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:37.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:16:37.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:37.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:37.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:16:37.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:37.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:16:37.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:16:37.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:16:37.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T01:17:07.586+0000] {processor.py:157} INFO - Started process (PID=34967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:07.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:17:07.591+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:07.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:07.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:07.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:07.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:17:07.627+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:07.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:17:07.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:17:38.133+0000] {processor.py:157} INFO - Started process (PID=34992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:38.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:17:38.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:38.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:38.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:17:38.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:38.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:17:38.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:17:38.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:17:38.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T01:18:08.649+0000] {processor.py:157} INFO - Started process (PID=35017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:08.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:18:08.654+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:08.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:08.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:08.687+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:08.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:18:08.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:08.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:18:08.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T01:18:39.068+0000] {processor.py:157} INFO - Started process (PID=35042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:39.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:18:39.072+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:39.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:39.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:18:39.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:39.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:18:39.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:18:39.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:18:39.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:19:09.591+0000] {processor.py:157} INFO - Started process (PID=35067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:09.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:19:09.595+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:09.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:09.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:09.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:09.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:19:09.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:09.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:19:09.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:19:40.032+0000] {processor.py:157} INFO - Started process (PID=35092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:40.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:19:40.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:40.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:40.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:19:40.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:40.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:19:40.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:19:40.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:19:40.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T01:20:10.572+0000] {processor.py:157} INFO - Started process (PID=35117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:10.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:20:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:10.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:10.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:10.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:10.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:20:10.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:10.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:20:10.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:20:41.060+0000] {processor.py:157} INFO - Started process (PID=35142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:41.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:20:41.064+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:41.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:41.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:20:41.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:41.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:20:41.110+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:20:41.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:20:41.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T01:21:11.535+0000] {processor.py:157} INFO - Started process (PID=35167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:11.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:21:11.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:11.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:11.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:11.570+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:11.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:21:11.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:11.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:21:11.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:21:41.959+0000] {processor.py:157} INFO - Started process (PID=35192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:41.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:21:41.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:41.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:41.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:21:41.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:41.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:21:42.011+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:21:42.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:21:42.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T01:22:12.487+0000] {processor.py:157} INFO - Started process (PID=35217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:12.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:22:12.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:12.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:12.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:12.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:12.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:22:12.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:12.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:22:12.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:22:42.969+0000] {processor.py:157} INFO - Started process (PID=35242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:42.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:22:42.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:42.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:42.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:22:43.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:43.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:22:43.013+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:22:43.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:22:43.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:23:13.499+0000] {processor.py:157} INFO - Started process (PID=35267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:13.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:23:13.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:13.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:13.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:13.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:13.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:23:13.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:13.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:23:13.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T01:23:43.986+0000] {processor.py:157} INFO - Started process (PID=35292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:43.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:23:43.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:43.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:44.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:23:44.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:44.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:23:44.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:23:44.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:23:44.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:24:14.376+0000] {processor.py:157} INFO - Started process (PID=35317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:14.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:24:14.378+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:14.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:14.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:14.403+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:14.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:24:14.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:14.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:24:14.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T01:24:44.885+0000] {processor.py:157} INFO - Started process (PID=35342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:44.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:24:44.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:44.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:44.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:24:44.921+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:44.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:24:44.936+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:24:44.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:24:44.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T01:25:15.337+0000] {processor.py:157} INFO - Started process (PID=35367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:15.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:25:15.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:15.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:15.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:15.368+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:15.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:25:15.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:15.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:25:15.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:25:45.840+0000] {processor.py:157} INFO - Started process (PID=35392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:45.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:25:45.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:45.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:45.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:25:45.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:45.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:25:45.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:25:45.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:25:45.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:26:16.250+0000] {processor.py:157} INFO - Started process (PID=35417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:16.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:26:16.254+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:16.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:16.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:16.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:16.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:26:16.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:16.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:26:16.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T01:26:46.720+0000] {processor.py:157} INFO - Started process (PID=35442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:46.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:26:46.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:46.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:46.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:26:46.753+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:46.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:26:46.764+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:26:46.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:26:46.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T01:27:17.181+0000] {processor.py:157} INFO - Started process (PID=35467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:17.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:27:17.184+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:17.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:17.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:17.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:17.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:27:17.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:17.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:27:17.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T01:27:47.617+0000] {processor.py:157} INFO - Started process (PID=35492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:47.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:27:47.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:47.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:47.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:27:47.654+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:47.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:27:47.667+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:27:47.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:27:47.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T01:28:18.144+0000] {processor.py:157} INFO - Started process (PID=35517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:18.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:28:18.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:18.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:18.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:18.174+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:18.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:28:18.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:18.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:28:18.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:28:48.613+0000] {processor.py:157} INFO - Started process (PID=35542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:48.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:28:48.621+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:48.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:48.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:28:48.666+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:48.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:28:48.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:28:48.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:28:48.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T01:29:19.112+0000] {processor.py:157} INFO - Started process (PID=35567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:19.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:29:19.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:19.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:19.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:19.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:19.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:29:19.158+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:19.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:29:19.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:29:49.584+0000] {processor.py:157} INFO - Started process (PID=35592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:49.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:29:49.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:49.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:49.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:29:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:49.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:29:49.631+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:29:49.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:29:49.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:30:20.064+0000] {processor.py:157} INFO - Started process (PID=35617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:20.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:30:20.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:20.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:20.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:20.094+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:20.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:30:20.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:20.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:30:20.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T01:30:50.479+0000] {processor.py:157} INFO - Started process (PID=35642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:50.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:30:50.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:50.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:50.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:30:50.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:50.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:30:50.522+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:30:50.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:30:50.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:31:20.982+0000] {processor.py:157} INFO - Started process (PID=35667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:20.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:31:20.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:20.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:21.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:21.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:21.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:31:21.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:21.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:31:21.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T01:31:51.465+0000] {processor.py:157} INFO - Started process (PID=35692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:51.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:31:51.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:51.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:51.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:31:51.504+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:51.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:31:51.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:31:51.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:31:51.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T01:32:22.002+0000] {processor.py:157} INFO - Started process (PID=35717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:22.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:32:22.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:22.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:22.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:22.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:22.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:32:22.049+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:22.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:32:22.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:32:52.412+0000] {processor.py:157} INFO - Started process (PID=35742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:52.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:32:52.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:52.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:52.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:32:52.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:52.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:32:52.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:32:52.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:32:52.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T01:33:22.931+0000] {processor.py:157} INFO - Started process (PID=35767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:22.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:33:22.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:22.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:22.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:23.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:23.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:33:23.056+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:23.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:33:23.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-27T01:33:53.573+0000] {processor.py:157} INFO - Started process (PID=35792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:53.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:33:53.577+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:53.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:53.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:33:53.628+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:53.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:33:53.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:33:53.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:33:53.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T01:34:24.093+0000] {processor.py:157} INFO - Started process (PID=35817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:24.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:34:24.095+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:24.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:24.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:24.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:24.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:34:24.134+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:24.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:34:24.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:34:54.536+0000] {processor.py:157} INFO - Started process (PID=35841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:54.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:34:54.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:54.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:54.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:34:54.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:54.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:34:54.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:34:54.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:34:54.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-27T01:35:25.113+0000] {processor.py:157} INFO - Started process (PID=35867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:25.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:35:25.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:25.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:25.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:25.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:25.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:35:25.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:25.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:35:25.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-27T01:35:55.637+0000] {processor.py:157} INFO - Started process (PID=35892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:55.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:35:55.642+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:55.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:55.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:35:55.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:55.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:35:55.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:35:55.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:35:55.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:36:26.110+0000] {processor.py:157} INFO - Started process (PID=35917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:26.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:36:26.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:26.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:26.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:26.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:26.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:36:26.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:26.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:36:26.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T01:36:56.518+0000] {processor.py:157} INFO - Started process (PID=35942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:56.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:36:56.521+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:56.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:56.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:36:56.549+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:56.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:36:56.559+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:36:56.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:36:56.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:37:26.929+0000] {processor.py:157} INFO - Started process (PID=35967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:26.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:37:26.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:26.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:26.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:26.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:26.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:37:26.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:26.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:37:26.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T01:37:57.387+0000] {processor.py:157} INFO - Started process (PID=35992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:57.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:37:57.390+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:57.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:57.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:37:57.430+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:57.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:37:57.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:37:57.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:37:57.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T01:38:27.846+0000] {processor.py:157} INFO - Started process (PID=36017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:27.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:38:27.850+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:27.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:27.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:27.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:27.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:38:27.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:27.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:38:27.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:38:58.281+0000] {processor.py:157} INFO - Started process (PID=36042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:58.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:38:58.286+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:58.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:58.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:38:58.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:58.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:38:58.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:38:58.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:38:58.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:39:28.684+0000] {processor.py:157} INFO - Started process (PID=36067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:28.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:39:28.689+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:28.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:28.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:28.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:28.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:39:28.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:28.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:39:28.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T01:39:59.168+0000] {processor.py:157} INFO - Started process (PID=36092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:59.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:39:59.173+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:59.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:59.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:39:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:59.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:39:59.211+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:39:59.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:39:59.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:40:29.680+0000] {processor.py:157} INFO - Started process (PID=36117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:40:29.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:40:29.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:40:29.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:40:29.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:40:29.710+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:40:29.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:40:29.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:40:29.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:40:29.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:41:00.170+0000] {processor.py:157} INFO - Started process (PID=36142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:00.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:41:00.175+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:00.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:00.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:00.214+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:00.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:41:00.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:00.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:41:00.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T01:41:30.701+0000] {processor.py:157} INFO - Started process (PID=36167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:30.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:41:30.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:30.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:30.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:41:30.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:30.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:41:30.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:41:30.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:41:30.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:42:01.156+0000] {processor.py:157} INFO - Started process (PID=36192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:01.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:42:01.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:01.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:01.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:01.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:01.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:42:01.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:01.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:42:01.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:42:31.666+0000] {processor.py:157} INFO - Started process (PID=36217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:31.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:42:31.670+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:31.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:31.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:42:31.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:31.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:42:31.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:42:31.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:42:31.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T01:43:02.143+0000] {processor.py:157} INFO - Started process (PID=36242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:02.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:43:02.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:02.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:02.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:02.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:02.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:43:02.186+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:02.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:43:02.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:43:32.560+0000] {processor.py:157} INFO - Started process (PID=36267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:32.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:43:32.565+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:32.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:32.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:43:32.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:32.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:43:32.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:43:32.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:43:32.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T01:44:03.019+0000] {processor.py:157} INFO - Started process (PID=36292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:03.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:44:03.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:03.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:03.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:03.049+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:03.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:44:03.061+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:03.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:44:03.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:44:33.531+0000] {processor.py:157} INFO - Started process (PID=36317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:33.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:44:33.534+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:33.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:33.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:44:33.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:33.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:44:33.574+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:44:33.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:44:33.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:45:04.043+0000] {processor.py:157} INFO - Started process (PID=36342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:04.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:45:04.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:04.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:04.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:04.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:45:04.088+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:04.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:45:04.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T01:45:34.593+0000] {processor.py:157} INFO - Started process (PID=36367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:34.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:45:34.597+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:34.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:34.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:45:34.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:34.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:45:34.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:45:34.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:45:34.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T01:46:05.069+0000] {processor.py:157} INFO - Started process (PID=36392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:05.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:46:05.071+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:05.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:05.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:05.098+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:05.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:46:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:05.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:46:05.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T01:46:35.500+0000] {processor.py:157} INFO - Started process (PID=36417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:35.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:46:35.503+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:35.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:35.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:46:35.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:35.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:46:35.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:46:35.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:46:35.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:47:05.974+0000] {processor.py:157} INFO - Started process (PID=36442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:05.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:47:05.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:05.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:05.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:06.001+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:06.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:47:06.014+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:06.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:47:06.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T01:47:36.408+0000] {processor.py:157} INFO - Started process (PID=36467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:36.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:47:36.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:36.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:36.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:47:36.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:36.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:47:36.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:47:36.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:47:36.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T01:48:06.900+0000] {processor.py:157} INFO - Started process (PID=36492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:06.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:48:06.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:06.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:06.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:06.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:06.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:48:06.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:06.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:48:06.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T01:48:37.390+0000] {processor.py:157} INFO - Started process (PID=36517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:37.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:48:37.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:37.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:37.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:48:37.425+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:37.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:48:37.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:48:37.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:48:37.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:49:07.859+0000] {processor.py:157} INFO - Started process (PID=36542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:07.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:49:07.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:07.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:07.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:07.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:07.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:49:07.900+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:07.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:49:07.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T01:49:38.260+0000] {processor.py:157} INFO - Started process (PID=36567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:38.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:49:38.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:38.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:38.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:49:38.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:38.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:49:38.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:49:38.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:49:38.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T01:50:08.782+0000] {processor.py:157} INFO - Started process (PID=36592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:08.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:50:08.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:08.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:08.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:08.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:08.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:50:08.872+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:08.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:50:08.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-27T01:50:39.335+0000] {processor.py:157} INFO - Started process (PID=36617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:39.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:50:39.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:39.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:39.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:50:39.378+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:39.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:50:39.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:50:39.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:50:39.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T01:51:09.834+0000] {processor.py:157} INFO - Started process (PID=36642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:09.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:51:09.837+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:09.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:09.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:09.872+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:09.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:51:09.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:09.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:51:09.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T01:51:40.332+0000] {processor.py:157} INFO - Started process (PID=36667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:40.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:51:40.335+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:40.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:40.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:51:40.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:40.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:51:40.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:51:40.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:51:40.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T01:52:10.893+0000] {processor.py:157} INFO - Started process (PID=36692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:10.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:52:10.896+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:10.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:10.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:10.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:10.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:52:10.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:10.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:52:10.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T01:52:41.344+0000] {processor.py:157} INFO - Started process (PID=36717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:41.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:52:41.349+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:41.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:41.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:52:41.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:41.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:52:41.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:52:41.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:52:41.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T01:53:11.758+0000] {processor.py:157} INFO - Started process (PID=36742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:11.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:53:11.761+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:11.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:11.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:11.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:11.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:53:11.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:11.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:53:11.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T01:53:42.231+0000] {processor.py:157} INFO - Started process (PID=36767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:42.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:53:42.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:42.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:42.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:53:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:42.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:53:42.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:53:42.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:53:42.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:54:12.691+0000] {processor.py:157} INFO - Started process (PID=36792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:12.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:54:12.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:12.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:12.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:12.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:12.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:54:12.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:12.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:54:12.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T01:54:43.169+0000] {processor.py:157} INFO - Started process (PID=36817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:43.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:54:43.173+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:43.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:43.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:54:43.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:43.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:54:43.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:54:43.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:54:43.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T01:55:13.648+0000] {processor.py:157} INFO - Started process (PID=36842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:13.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:55:13.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:13.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:13.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:13.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:13.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:55:13.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:13.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:55:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T01:55:44.119+0000] {processor.py:157} INFO - Started process (PID=36867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:44.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:55:44.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:44.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:44.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:55:44.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:44.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:55:44.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:55:44.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:55:44.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T01:56:14.513+0000] {processor.py:157} INFO - Started process (PID=36892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:14.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:56:14.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:14.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:14.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:14.542+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:14.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:56:14.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:14.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:56:14.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T01:56:45.006+0000] {processor.py:157} INFO - Started process (PID=36917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:45.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:56:45.011+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:45.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:45.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:56:45.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:45.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:56:45.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:56:45.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:56:45.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T01:57:15.537+0000] {processor.py:157} INFO - Started process (PID=36942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:15.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:57:15.540+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:15.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:15.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:15.568+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:15.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:57:15.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:15.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:57:15.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T01:57:45.959+0000] {processor.py:157} INFO - Started process (PID=36967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:45.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:57:45.962+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:45.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:45.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:57:45.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:45.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:57:46.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:57:46.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:57:46.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T01:58:16.415+0000] {processor.py:157} INFO - Started process (PID=36992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:16.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:58:16.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:16.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:16.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:16.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:16.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:58:16.469+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:16.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:58:16.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T01:58:46.814+0000] {processor.py:157} INFO - Started process (PID=37017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:46.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:58:46.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:46.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:46.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:58:46.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:46.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:58:46.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:58:46.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:58:46.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-27T01:59:17.329+0000] {processor.py:157} INFO - Started process (PID=37042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:17.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:59:17.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:17.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:17.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:17.358+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:17.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:59:17.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:17.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:59:17.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T01:59:47.833+0000] {processor.py:157} INFO - Started process (PID=37067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:47.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T01:59:47.835+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:47.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:47.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T01:59:47.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:47.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T01:59:47.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T01:59:47.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T01:59:47.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T02:00:18.299+0000] {processor.py:157} INFO - Started process (PID=37092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:18.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:00:18.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:18.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:18.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:18.344+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:18.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:00:18.358+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:18.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:00:18.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T02:00:48.761+0000] {processor.py:157} INFO - Started process (PID=37117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:48.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:00:48.764+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:48.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:48.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:00:48.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:48.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:00:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:00:48.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:00:48.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T02:01:19.239+0000] {processor.py:157} INFO - Started process (PID=37141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:19.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:01:19.245+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:19.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:19.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:19.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:19.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:01:19.297+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:19.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:01:19.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T02:01:49.740+0000] {processor.py:157} INFO - Started process (PID=37167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:49.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:01:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:49.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:49.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:01:49.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:49.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:01:49.777+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:01:49.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:01:49.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T02:02:20.232+0000] {processor.py:157} INFO - Started process (PID=37192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:20.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:02:20.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:20.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:20.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:20.266+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:20.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:02:20.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:20.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:02:20.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T02:02:50.787+0000] {processor.py:157} INFO - Started process (PID=37217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:50.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:02:50.791+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:50.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:50.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:02:50.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:50.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:02:50.839+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:02:50.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:02:50.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T02:03:21.291+0000] {processor.py:157} INFO - Started process (PID=37242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:21.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:03:21.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:21.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:21.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:21.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:21.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:03:21.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:21.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:03:21.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T02:03:51.832+0000] {processor.py:157} INFO - Started process (PID=37267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:51.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:03:51.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:51.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:51.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:03:51.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:51.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:03:51.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:03:51.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:03:51.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T02:04:22.375+0000] {processor.py:157} INFO - Started process (PID=37292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:22.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:04:22.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:22.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:22.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:22.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:22.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:04:22.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:22.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:04:22.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T02:04:52.872+0000] {processor.py:157} INFO - Started process (PID=37317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:52.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:04:52.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:52.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:52.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:04:52.920+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:52.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:04:52.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:04:52.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:04:52.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T02:05:23.449+0000] {processor.py:157} INFO - Started process (PID=37341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:23.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:05:23.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:23.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:23.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:23.509+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:23.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:05:23.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:23.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:05:23.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T02:05:53.993+0000] {processor.py:157} INFO - Started process (PID=37367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:53.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:05:53.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:53.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:54.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:05:54.027+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:54.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:05:54.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:05:54.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:05:54.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T02:06:24.437+0000] {processor.py:157} INFO - Started process (PID=37392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:24.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:06:24.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:24.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:24.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:24.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:24.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:06:24.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:24.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:06:24.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T02:06:54.966+0000] {processor.py:157} INFO - Started process (PID=37417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:54.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:06:54.969+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:54.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:54.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:06:54.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:54.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:06:55.005+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:06:55.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:06:55.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T02:07:25.469+0000] {processor.py:157} INFO - Started process (PID=37442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:25.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:07:25.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:25.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:25.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:25.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:25.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:07:25.517+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:25.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:07:25.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T02:07:55.960+0000] {processor.py:157} INFO - Started process (PID=37466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:55.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:07:55.965+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:55.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:55.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:07:56.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:56.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:07:56.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:07:56.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:07:56.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T02:08:26.472+0000] {processor.py:157} INFO - Started process (PID=37492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:26.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:08:26.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:26.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:26.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:26.509+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:26.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:08:26.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:26.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:08:26.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T02:08:56.913+0000] {processor.py:157} INFO - Started process (PID=37517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:56.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:08:56.916+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:56.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:56.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:08:56.947+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:56.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:08:56.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:08:56.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:08:56.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T02:09:27.372+0000] {processor.py:157} INFO - Started process (PID=37542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:27.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:09:27.374+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:27.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:27.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:27.405+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:27.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:09:27.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:27.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:09:27.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T02:09:57.819+0000] {processor.py:157} INFO - Started process (PID=37567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:57.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:09:57.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:57.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:57.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:09:57.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:57.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:09:57.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:09:57.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:09:57.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T02:10:28.256+0000] {processor.py:157} INFO - Started process (PID=37592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:28.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:10:28.262+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:28.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:28.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:28.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:28.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:10:28.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:28.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:10:28.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T02:10:58.743+0000] {processor.py:157} INFO - Started process (PID=37617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:58.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:10:58.749+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:58.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:58.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:10:58.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:58.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:10:58.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:10:58.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:10:58.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T02:11:29.172+0000] {processor.py:157} INFO - Started process (PID=37642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:29.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:11:29.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:29.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:29.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:29.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:29.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:11:29.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:29.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:11:29.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T02:11:59.697+0000] {processor.py:157} INFO - Started process (PID=37667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:59.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:11:59.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:59.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:59.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:11:59.726+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:59.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:11:59.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:11:59.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:11:59.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T02:12:30.216+0000] {processor.py:157} INFO - Started process (PID=37692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:12:30.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:12:30.218+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:12:30.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:12:30.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:12:30.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:12:30.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:12:30.256+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:12:30.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:12:30.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T02:13:00.698+0000] {processor.py:157} INFO - Started process (PID=37717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:00.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:13:00.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:00.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:00.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:00.731+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:00.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:13:00.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:00.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:13:00.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:13:31.164+0000] {processor.py:157} INFO - Started process (PID=37742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:31.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:13:31.170+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:31.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:31.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:13:31.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:31.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:13:31.218+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:13:31.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:13:31.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T02:14:01.610+0000] {processor.py:157} INFO - Started process (PID=37767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:01.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:14:01.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:01.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:01.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:01.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:01.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:14:01.655+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:01.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:14:01.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T02:14:32.114+0000] {processor.py:157} INFO - Started process (PID=37792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:32.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:14:32.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:32.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:32.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:14:32.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:32.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:14:32.163+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:14:32.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:14:32.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T02:15:02.638+0000] {processor.py:157} INFO - Started process (PID=37817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:02.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:15:02.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:02.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:02.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:02.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:02.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:15:02.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:02.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:15:02.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T02:15:33.136+0000] {processor.py:157} INFO - Started process (PID=37842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:33.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:15:33.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:33.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:33.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:15:33.182+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:33.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:15:33.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:15:33.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:15:33.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T02:16:03.630+0000] {processor.py:157} INFO - Started process (PID=37867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:03.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:16:03.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:03.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:03.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:03.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:03.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:16:03.667+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:03.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:16:03.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T02:16:34.110+0000] {processor.py:157} INFO - Started process (PID=37892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:34.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:16:34.113+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:34.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:34.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:16:34.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:34.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:16:34.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:16:34.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:16:34.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:17:04.557+0000] {processor.py:157} INFO - Started process (PID=37917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:04.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:17:04.560+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:04.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:04.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:04.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:04.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:17:04.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:04.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:17:04.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:17:35.072+0000] {processor.py:157} INFO - Started process (PID=37942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:35.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:17:35.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:35.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:35.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:17:35.103+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:35.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:17:35.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:17:35.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:17:35.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T02:18:05.537+0000] {processor.py:157} INFO - Started process (PID=37966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:05.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:18:05.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:05.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:05.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:05.612+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:05.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:18:05.623+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:05.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:18:05.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-27T02:18:36.042+0000] {processor.py:157} INFO - Started process (PID=37992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:36.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:18:36.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:36.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:36.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:18:36.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:36.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:18:36.085+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:18:36.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:18:36.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:19:06.500+0000] {processor.py:157} INFO - Started process (PID=38017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:06.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:19:06.504+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:06.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:06.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:06.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:06.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:19:06.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:06.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:19:06.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T02:19:36.978+0000] {processor.py:157} INFO - Started process (PID=38042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:36.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:19:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:36.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:37.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:19:37.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:37.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:19:37.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:19:37.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:19:37.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T02:20:07.512+0000] {processor.py:157} INFO - Started process (PID=38067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:07.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:20:07.515+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:07.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:07.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:07.542+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:07.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:20:07.552+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:07.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:20:07.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T02:20:37.965+0000] {processor.py:157} INFO - Started process (PID=38092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:37.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:20:37.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:37.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:37.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:20:38.004+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:38.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:20:38.015+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:20:38.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:20:38.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T02:21:08.425+0000] {processor.py:157} INFO - Started process (PID=38117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:08.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:21:08.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:08.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:08.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:08.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:08.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:21:08.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:08.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:21:08.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:21:38.844+0000] {processor.py:157} INFO - Started process (PID=38142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:38.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:21:38.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:38.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:38.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:21:38.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:38.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:21:38.902+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:21:38.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:21:38.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T02:22:09.351+0000] {processor.py:157} INFO - Started process (PID=38167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:09.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:22:09.356+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:09.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:09.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:09.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:09.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:22:09.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:09.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:22:09.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T02:22:39.811+0000] {processor.py:157} INFO - Started process (PID=38192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:39.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:22:39.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:39.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:39.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:22:39.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:39.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:22:39.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:22:39.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:22:39.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T02:23:10.225+0000] {processor.py:157} INFO - Started process (PID=38217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:10.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:23:10.229+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:10.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:10.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:10.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:10.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:23:10.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:10.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:23:10.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T02:23:40.678+0000] {processor.py:157} INFO - Started process (PID=38242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:40.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:23:40.681+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:40.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:40.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:23:40.710+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:40.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:23:40.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:23:40.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:23:40.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T02:24:11.124+0000] {processor.py:157} INFO - Started process (PID=38267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:11.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:24:11.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:11.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:11.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:11.169+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:11.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:24:11.181+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:11.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:24:11.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T02:24:41.645+0000] {processor.py:157} INFO - Started process (PID=38292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:41.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:24:41.648+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:41.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:41.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:24:41.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:41.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:24:41.691+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:24:41.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:24:41.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T02:25:12.098+0000] {processor.py:157} INFO - Started process (PID=38317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:12.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:25:12.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:12.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:12.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:12.132+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:12.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:25:12.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:12.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:25:12.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T02:25:42.560+0000] {processor.py:157} INFO - Started process (PID=38342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:42.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:25:42.567+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:42.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:42.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:25:42.606+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:42.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:25:42.619+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:25:42.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:25:42.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T02:26:13.049+0000] {processor.py:157} INFO - Started process (PID=38367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:13.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:26:13.051+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:13.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:13.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:13.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:13.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:26:13.085+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:13.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:26:13.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T02:26:43.474+0000] {processor.py:157} INFO - Started process (PID=38392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:43.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:26:43.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:43.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:43.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:26:43.510+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:43.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:26:43.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:26:43.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:26:43.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T02:27:13.932+0000] {processor.py:157} INFO - Started process (PID=38417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:13.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:27:13.936+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:13.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:13.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:13.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:13.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:27:13.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:13.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:27:13.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T02:27:44.379+0000] {processor.py:157} INFO - Started process (PID=38442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:44.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:27:44.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:44.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:44.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:27:44.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:44.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:27:44.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:27:44.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:27:44.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T02:28:14.828+0000] {processor.py:157} INFO - Started process (PID=38467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:14.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:28:14.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:14.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:14.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:14.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:14.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:28:14.873+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:14.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:28:14.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T02:28:45.249+0000] {processor.py:157} INFO - Started process (PID=38492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:45.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:28:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:45.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:45.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:28:45.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:45.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:28:45.297+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:28:45.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:28:45.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T02:29:15.773+0000] {processor.py:157} INFO - Started process (PID=38517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:15.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:29:15.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:15.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:15.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:15.817+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:15.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:29:15.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:15.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:29:15.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T02:29:46.240+0000] {processor.py:157} INFO - Started process (PID=38542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:46.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:29:46.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:46.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:46.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:29:46.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:46.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:29:46.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:29:46.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:29:46.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T02:30:16.748+0000] {processor.py:157} INFO - Started process (PID=38567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:16.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:30:16.751+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:16.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:16.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:16.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:16.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:30:16.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:16.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:30:16.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T02:30:47.270+0000] {processor.py:157} INFO - Started process (PID=38592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:47.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:30:47.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:47.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:47.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:30:47.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:47.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:30:47.323+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:30:47.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:30:47.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T02:31:17.784+0000] {processor.py:157} INFO - Started process (PID=38617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:17.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:31:17.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:17.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:17.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:17.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:17.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:31:17.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:17.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:31:17.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T02:31:48.300+0000] {processor.py:157} INFO - Started process (PID=38642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:48.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:31:48.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:48.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:48.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:31:48.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:48.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:31:48.350+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:31:48.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:31:48.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T02:32:18.782+0000] {processor.py:157} INFO - Started process (PID=38667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:18.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:32:18.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:18.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:18.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:18.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:18.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:32:18.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:18.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:32:18.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T02:32:49.189+0000] {processor.py:157} INFO - Started process (PID=38692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:49.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:32:49.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:49.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:49.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:32:49.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:49.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:32:49.237+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:32:49.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:32:49.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T02:33:19.439+0000] {processor.py:157} INFO - Started process (PID=38717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:33:19.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:33:19.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:33:19.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:33:19.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:33:19.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:33:19.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:33:19.524+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:33:19.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:33:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T02:50:06.763+0000] {processor.py:157} INFO - Started process (PID=38744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:06.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:50:06.775+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:06.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:06.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:06.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:06.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:50:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:06.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:50:06.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T02:50:37.416+0000] {processor.py:157} INFO - Started process (PID=38769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:37.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:50:37.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:37.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:37.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:50:37.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:37.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:50:37.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:50:37.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:50:37.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-27T02:51:07.970+0000] {processor.py:157} INFO - Started process (PID=38794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:07.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:51:07.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:07.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:07.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:08.003+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:08.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:51:08.016+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:08.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:51:08.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T02:51:38.382+0000] {processor.py:157} INFO - Started process (PID=38819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:38.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:51:38.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:38.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:38.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:51:38.426+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:38.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:51:38.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:51:38.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:51:38.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T02:52:08.856+0000] {processor.py:157} INFO - Started process (PID=38844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:52:08.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T02:52:08.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:52:08.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:52:08.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T02:52:08.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:52:08.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T02:52:08.907+0000] {logging_mixin.py:151} INFO - [2024-07-27T02:52:08.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T02:52:08.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T03:08:22.961+0000] {processor.py:157} INFO - Started process (PID=38870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:22.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:08:22.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:22.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:22.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:23.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:23.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:08:23.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:23.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:08:23.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-27T03:08:53.520+0000] {processor.py:157} INFO - Started process (PID=38896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:53.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:08:53.526+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:53.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:53.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:08:53.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:53.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:08:53.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:08:53.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:08:53.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T03:09:24.035+0000] {processor.py:157} INFO - Started process (PID=38921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:24.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:09:24.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:24.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:24.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:24.068+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:24.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:09:24.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:24.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:09:24.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T03:09:54.414+0000] {processor.py:157} INFO - Started process (PID=38946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:54.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:09:54.418+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:54.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:54.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:09:54.446+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:54.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:09:54.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:09:54.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:09:54.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:10:24.830+0000] {processor.py:157} INFO - Started process (PID=38971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:24.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:10:24.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:24.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:24.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:24.861+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:24.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:10:24.872+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:24.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:10:24.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:10:55.297+0000] {processor.py:157} INFO - Started process (PID=38996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:55.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:10:55.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:55.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:55.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:10:55.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:55.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:10:55.336+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:10:55.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:10:55.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T03:11:25.762+0000] {processor.py:157} INFO - Started process (PID=39021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:25.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:11:25.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:25.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:25.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:25.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:25.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:11:25.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:25.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:11:25.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:11:56.229+0000] {processor.py:157} INFO - Started process (PID=39046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:56.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:11:56.232+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:56.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:56.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:11:56.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:56.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:11:56.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:11:56.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:11:56.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T03:12:26.622+0000] {processor.py:157} INFO - Started process (PID=39071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:26.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:12:26.627+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:26.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:26.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:26.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:26.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:12:26.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:26.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:12:26.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T03:12:57.159+0000] {processor.py:157} INFO - Started process (PID=39096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:57.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:12:57.162+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:57.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:57.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:12:57.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:57.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:12:57.207+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:12:57.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:12:57.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T03:13:27.649+0000] {processor.py:157} INFO - Started process (PID=39121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:27.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:13:27.653+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:27.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:27.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:27.685+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:27.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:13:27.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:27.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:13:27.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T03:13:58.204+0000] {processor.py:157} INFO - Started process (PID=39146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:58.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:13:58.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:58.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:58.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:13:58.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:58.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:13:58.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:13:58.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:13:58.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:14:28.667+0000] {processor.py:157} INFO - Started process (PID=39171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:28.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:14:28.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:28.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:28.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:28.693+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:28.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:14:28.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:28.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:14:28.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:14:59.094+0000] {processor.py:157} INFO - Started process (PID=39196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:59.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:14:59.098+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:59.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:59.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:14:59.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:59.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:14:59.137+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:14:59.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:14:59.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:15:29.602+0000] {processor.py:157} INFO - Started process (PID=39221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:15:29.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:15:29.605+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:15:29.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:15:29.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:15:29.634+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:15:29.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:15:29.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:15:29.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:15:29.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:16:00.094+0000] {processor.py:157} INFO - Started process (PID=39246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:16:00.098+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:00.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:00.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:00.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:00.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:16:00.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:00.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:16:00.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:16:30.536+0000] {processor.py:157} INFO - Started process (PID=39271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:30.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:16:30.539+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:30.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:30.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:16:30.567+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:30.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:16:30.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:16:30.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:16:30.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:17:00.942+0000] {processor.py:157} INFO - Started process (PID=39296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:00.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:17:00.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:00.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:00.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:00.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:00.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:17:00.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:00.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:17:00.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:17:31.386+0000] {processor.py:157} INFO - Started process (PID=39321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:31.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:17:31.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:31.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:31.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:17:31.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:31.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:17:31.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:17:31.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:17:31.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T03:18:01.770+0000] {processor.py:157} INFO - Started process (PID=39346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:01.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:18:01.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:01.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:01.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:01.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:01.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:18:01.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:01.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:18:01.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T03:18:32.280+0000] {processor.py:157} INFO - Started process (PID=39371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:32.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:18:32.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:32.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:32.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:18:32.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:32.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:18:32.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:18:32.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:18:32.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T03:19:02.763+0000] {processor.py:157} INFO - Started process (PID=39396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:02.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:19:02.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:02.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:02.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:02.798+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:02.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:19:02.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:02.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:19:02.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:19:33.189+0000] {processor.py:157} INFO - Started process (PID=39421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:33.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:19:33.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:33.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:33.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:19:33.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:33.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:19:33.238+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:19:33.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:19:33.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T03:20:03.646+0000] {processor.py:157} INFO - Started process (PID=39446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:03.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:20:03.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:03.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:03.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:03.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:03.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:20:03.690+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:03.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:20:03.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T03:20:34.086+0000] {processor.py:157} INFO - Started process (PID=39471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:34.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:20:34.090+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:34.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:34.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:20:34.118+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:34.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:20:34.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:20:34.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:20:34.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:21:04.554+0000] {processor.py:157} INFO - Started process (PID=39496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:04.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:21:04.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:04.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:04.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:04.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:04.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:21:04.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:04.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:21:04.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T03:21:34.982+0000] {processor.py:157} INFO - Started process (PID=39521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:34.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:21:34.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:34.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:34.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:21:35.008+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:35.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:21:35.016+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:21:35.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:21:35.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T03:22:05.429+0000] {processor.py:157} INFO - Started process (PID=39546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:05.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:22:05.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:05.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:05.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:05.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:05.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:22:05.469+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:05.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:22:05.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T03:22:35.867+0000] {processor.py:157} INFO - Started process (PID=39571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:35.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:22:35.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:35.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:35.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:22:35.897+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:35.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:22:35.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:22:35.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:22:35.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:23:06.312+0000] {processor.py:157} INFO - Started process (PID=39596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:06.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:23:06.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:06.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:06.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:06.343+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:06.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:23:06.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:06.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:23:06.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:23:36.863+0000] {processor.py:157} INFO - Started process (PID=39621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:36.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:23:36.868+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:36.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:36.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:23:36.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:36.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:23:36.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:23:36.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:23:36.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T03:24:07.320+0000] {processor.py:157} INFO - Started process (PID=39646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:07.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:24:07.324+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:07.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:07.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:07.354+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:07.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:24:07.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:07.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:24:07.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:24:37.824+0000] {processor.py:157} INFO - Started process (PID=39671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:37.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:24:37.828+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:37.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:37.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:24:37.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:37.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:24:37.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:24:37.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:24:37.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T03:25:08.241+0000] {processor.py:157} INFO - Started process (PID=39696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:08.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:25:08.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:08.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:08.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:08.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:08.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:25:08.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:08.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:25:08.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T03:25:38.723+0000] {processor.py:157} INFO - Started process (PID=39721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:38.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:25:38.725+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:38.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:38.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:25:38.753+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:38.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:25:38.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:25:38.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:25:38.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:26:09.140+0000] {processor.py:157} INFO - Started process (PID=39746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:09.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:26:09.143+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:09.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:09.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:09.170+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:09.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:26:09.180+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:09.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:26:09.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:26:39.643+0000] {processor.py:157} INFO - Started process (PID=39771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:39.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:26:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:39.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:39.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:26:39.674+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:39.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:26:39.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:26:39.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:26:39.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:27:10.085+0000] {processor.py:157} INFO - Started process (PID=39796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:10.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:27:10.088+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:10.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:10.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:10.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:10.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:27:10.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:10.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:27:10.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T03:27:40.438+0000] {processor.py:157} INFO - Started process (PID=39821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:40.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:27:40.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:40.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:40.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:27:40.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:40.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:27:40.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:27:40.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:27:40.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T03:28:10.938+0000] {processor.py:157} INFO - Started process (PID=39846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:10.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:28:10.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:10.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:10.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:10.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:10.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:28:10.986+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:10.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:28:10.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T03:28:41.396+0000] {processor.py:157} INFO - Started process (PID=39871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:41.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:28:41.401+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:41.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:41.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:28:41.432+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:41.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:28:41.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:28:41.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:28:41.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:29:11.894+0000] {processor.py:157} INFO - Started process (PID=39896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:11.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:29:11.897+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:11.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:11.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:11.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:11.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:29:11.942+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:11.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:29:11.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T03:29:42.335+0000] {processor.py:157} INFO - Started process (PID=39921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:42.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:29:42.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:42.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:42.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:29:42.373+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:42.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:29:42.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:29:42.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:29:42.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T03:30:12.760+0000] {processor.py:157} INFO - Started process (PID=39946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:12.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:30:12.764+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:12.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:12.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:12.796+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:12.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:30:12.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:12.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:30:12.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T03:30:43.215+0000] {processor.py:157} INFO - Started process (PID=39971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:43.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:30:43.219+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:43.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:43.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:30:43.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:43.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:30:43.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:30:43.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:30:43.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T03:31:13.670+0000] {processor.py:157} INFO - Started process (PID=39996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:13.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:31:13.674+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:13.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:13.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:13.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:13.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:31:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:13.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:31:13.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T03:31:44.110+0000] {processor.py:157} INFO - Started process (PID=40021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:44.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:31:44.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:44.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:44.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:31:44.231+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:44.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:31:44.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:31:44.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:31:44.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-27T03:32:14.572+0000] {processor.py:157} INFO - Started process (PID=40046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:14.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:32:14.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:14.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:14.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:14.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:14.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:32:14.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:14.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:32:14.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:32:45.089+0000] {processor.py:157} INFO - Started process (PID=40071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:45.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:32:45.095+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:45.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:45.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:32:45.123+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:45.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:32:45.132+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:32:45.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:32:45.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:33:15.576+0000] {processor.py:157} INFO - Started process (PID=40096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:15.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:33:15.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:15.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:15.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:15.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:15.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:33:15.619+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:15.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:33:15.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:33:46.126+0000] {processor.py:157} INFO - Started process (PID=40121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:46.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:33:46.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:46.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:46.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:33:46.195+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:46.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:33:46.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:33:46.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:33:46.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T03:34:16.676+0000] {processor.py:157} INFO - Started process (PID=40146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:16.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:34:16.681+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:16.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:16.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:16.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:16.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:34:16.727+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:16.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:34:16.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T03:34:47.127+0000] {processor.py:157} INFO - Started process (PID=40171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:47.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:34:47.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:47.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:47.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:34:47.168+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:47.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:34:47.178+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:34:47.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:34:47.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T03:35:17.598+0000] {processor.py:157} INFO - Started process (PID=40196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:17.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:35:17.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:17.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:17.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:17.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:17.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:35:17.649+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:17.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:35:17.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T03:35:48.110+0000] {processor.py:157} INFO - Started process (PID=40221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:48.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:35:48.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:48.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:48.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:35:48.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:48.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:35:48.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:35:48.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:35:48.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:36:18.614+0000] {processor.py:157} INFO - Started process (PID=40246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:18.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:36:18.616+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:18.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:18.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:18.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:18.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:36:18.653+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:18.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:36:18.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:36:49.088+0000] {processor.py:157} INFO - Started process (PID=40271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:49.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:36:49.092+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:49.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:49.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:36:49.122+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:49.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:36:49.133+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:36:49.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:36:49.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:37:19.576+0000] {processor.py:157} INFO - Started process (PID=40296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:19.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:37:19.582+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:19.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:19.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:19.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:19.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:37:19.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:19.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:37:19.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T03:37:50.040+0000] {processor.py:157} INFO - Started process (PID=40321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:50.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:37:50.043+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:50.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:50.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:37:50.073+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:50.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:37:50.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:37:50.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:37:50.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:38:20.581+0000] {processor.py:157} INFO - Started process (PID=40346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:20.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:38:20.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:20.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:20.634+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:20.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:38:20.647+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:20.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:38:20.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T03:38:51.112+0000] {processor.py:157} INFO - Started process (PID=40371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:51.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:38:51.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:51.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:51.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:38:51.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:51.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:38:51.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:38:51.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:38:51.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:39:21.607+0000] {processor.py:157} INFO - Started process (PID=40396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:21.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:39:21.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:21.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:21.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:21.637+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:21.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:39:21.648+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:21.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:39:21.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:39:52.046+0000] {processor.py:157} INFO - Started process (PID=40421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:52.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:39:52.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:52.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:52.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:39:52.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:52.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:39:52.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:39:52.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:39:52.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:40:22.508+0000] {processor.py:157} INFO - Started process (PID=40446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:22.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:40:22.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:22.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:22.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:22.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:22.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:40:22.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:22.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:40:22.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:40:52.929+0000] {processor.py:157} INFO - Started process (PID=40471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:52.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:40:52.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:52.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:52.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:40:52.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:52.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:40:52.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:40:52.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:40:52.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T03:41:23.373+0000] {processor.py:157} INFO - Started process (PID=40496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:23.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:41:23.378+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:23.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:23.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:23.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:23.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:41:23.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:23.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:41:23.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T03:41:53.838+0000] {processor.py:157} INFO - Started process (PID=40521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:53.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:41:53.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:53.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:53.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:41:53.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:53.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:41:53.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:41:53.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:41:53.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T03:42:24.343+0000] {processor.py:157} INFO - Started process (PID=40546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:24.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:42:24.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:24.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:24.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:24.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:24.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:42:24.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:24.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:42:24.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T03:42:54.834+0000] {processor.py:157} INFO - Started process (PID=40571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:54.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:42:54.839+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:54.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:54.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:42:54.869+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:54.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:42:54.881+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:42:54.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:42:54.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T03:43:25.281+0000] {processor.py:157} INFO - Started process (PID=40596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:25.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:43:25.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:25.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:25.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:25.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:25.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:43:25.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:25.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:43:25.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T03:43:55.782+0000] {processor.py:157} INFO - Started process (PID=40621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:55.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:43:55.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:55.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:55.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:43:55.812+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:55.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:43:55.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:43:55.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:43:55.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:44:26.187+0000] {processor.py:157} INFO - Started process (PID=40646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:26.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:44:26.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:26.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:26.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:26.214+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:26.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:44:26.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:26.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:44:26.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T03:44:56.630+0000] {processor.py:157} INFO - Started process (PID=40671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:56.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:44:56.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:56.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:56.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:44:56.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:56.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:44:56.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:44:56.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:44:56.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T03:45:27.077+0000] {processor.py:157} INFO - Started process (PID=40696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:27.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:45:27.079+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:27.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:27.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:27.110+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:27.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:45:27.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:27.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:45:27.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:45:57.511+0000] {processor.py:157} INFO - Started process (PID=40721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:57.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:45:57.515+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:57.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:57.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:45:57.544+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:57.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:45:57.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:45:57.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:45:57.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:46:28.013+0000] {processor.py:157} INFO - Started process (PID=40746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:28.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:46:28.016+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:28.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:28.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:28.044+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:28.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:46:28.053+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:28.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:46:28.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:46:58.402+0000] {processor.py:157} INFO - Started process (PID=40771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:58.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:46:58.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:58.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:46:58.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:58.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:46:58.456+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:46:58.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:46:58.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T03:47:28.896+0000] {processor.py:157} INFO - Started process (PID=40796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:28.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:47:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:28.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:28.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:28.924+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:28.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:47:28.933+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:28.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:47:28.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T03:47:59.314+0000] {processor.py:157} INFO - Started process (PID=40821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:59.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:47:59.317+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:59.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:59.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:47:59.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:59.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:47:59.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:47:59.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:47:59.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:48:29.809+0000] {processor.py:157} INFO - Started process (PID=40846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:48:29.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:48:29.811+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:48:29.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:48:29.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:48:29.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:48:29.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:48:29.848+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:48:29.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:48:29.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:49:00.237+0000] {processor.py:157} INFO - Started process (PID=40871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:00.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:49:00.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:00.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:00.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:00.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:00.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:49:00.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:00.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:49:00.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:49:30.692+0000] {processor.py:157} INFO - Started process (PID=40896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:30.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:49:30.695+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:30.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:30.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:49:30.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:30.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:49:30.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:49:30.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:49:30.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:50:01.116+0000] {processor.py:157} INFO - Started process (PID=40921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:01.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:50:01.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:01.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:01.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:01.162+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:01.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:50:01.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:01.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:50:01.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T03:50:31.584+0000] {processor.py:157} INFO - Started process (PID=40946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:31.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:50:31.594+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:31.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:31.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:50:31.616+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:31.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:50:31.625+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:50:31.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:50:31.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:51:02.027+0000] {processor.py:157} INFO - Started process (PID=40971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:02.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:51:02.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:02.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:02.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:02.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:51:02.070+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:02.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:51:02.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:51:32.489+0000] {processor.py:157} INFO - Started process (PID=40996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:32.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:51:32.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:32.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:32.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:51:32.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:32.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:51:32.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:51:32.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:51:32.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:52:02.988+0000] {processor.py:157} INFO - Started process (PID=41021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:02.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:52:02.993+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:02.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:03.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:03.024+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:03.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:52:03.034+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:03.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:52:03.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T03:52:33.450+0000] {processor.py:157} INFO - Started process (PID=41046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:33.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:52:33.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:33.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:33.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:52:33.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:33.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:52:33.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:52:33.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:52:33.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T03:53:03.898+0000] {processor.py:157} INFO - Started process (PID=41071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:03.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:53:03.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:03.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:03.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:03.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:03.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:53:03.939+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:03.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:53:03.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T03:53:34.343+0000] {processor.py:157} INFO - Started process (PID=41096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:34.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:53:34.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:34.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:34.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:53:34.370+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:34.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:53:34.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:53:34.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:53:34.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T03:54:04.777+0000] {processor.py:157} INFO - Started process (PID=41121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:04.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:54:04.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:04.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:04.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:04.804+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:04.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:54:04.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:04.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:54:04.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T03:54:35.251+0000] {processor.py:157} INFO - Started process (PID=41146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:35.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:54:35.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:35.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:35.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:54:35.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:35.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:54:35.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:54:35.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:54:35.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T03:55:05.720+0000] {processor.py:157} INFO - Started process (PID=41171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:05.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:55:05.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:05.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:05.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:05.750+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:05.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:55:05.760+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:05.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:55:05.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T03:55:36.186+0000] {processor.py:157} INFO - Started process (PID=41196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:36.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:55:36.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:36.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:36.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:55:36.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:36.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:55:36.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:55:36.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:55:36.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T03:56:06.663+0000] {processor.py:157} INFO - Started process (PID=41221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:06.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:56:06.666+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:06.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:06.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:06.685+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:06.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:56:06.693+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:06.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:56:06.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-27T03:56:37.054+0000] {processor.py:157} INFO - Started process (PID=41246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:37.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:56:37.057+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:37.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:37.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:56:37.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:37.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:56:37.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:56:37.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:56:37.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:57:07.570+0000] {processor.py:157} INFO - Started process (PID=41271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:07.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:57:07.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:07.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:07.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:07.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:07.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:57:07.621+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:07.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:57:07.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T03:57:38.048+0000] {processor.py:157} INFO - Started process (PID=41296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:38.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:57:38.051+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:38.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:38.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:57:38.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:38.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:57:38.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:57:38.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:57:38.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T03:58:08.494+0000] {processor.py:157} INFO - Started process (PID=41321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:08.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:58:08.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:08.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:08.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:08.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:08.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:58:08.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:08.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:58:08.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T03:58:38.924+0000] {processor.py:157} INFO - Started process (PID=41346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:38.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:58:38.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:38.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:38.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:58:38.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:38.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:58:38.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:58:38.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:58:38.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T03:59:09.424+0000] {processor.py:157} INFO - Started process (PID=41371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:09.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:59:09.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:09.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:09.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:09.457+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:09.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:59:09.466+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:09.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:59:09.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T03:59:39.875+0000] {processor.py:157} INFO - Started process (PID=41396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:39.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T03:59:39.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:39.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:39.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T03:59:39.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:39.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T03:59:39.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T03:59:39.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T03:59:39.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T04:00:10.274+0000] {processor.py:157} INFO - Started process (PID=41421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:10.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:00:10.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:10.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:10.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:10.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:10.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:00:10.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:10.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:00:10.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T04:00:40.743+0000] {processor.py:157} INFO - Started process (PID=41446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:40.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:00:40.746+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:40.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:40.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:00:40.774+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:40.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:00:40.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:00:40.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:00:40.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T04:01:11.156+0000] {processor.py:157} INFO - Started process (PID=41471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:11.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:01:11.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:11.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:11.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:11.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:11.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:01:11.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:11.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:01:11.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T04:01:41.660+0000] {processor.py:157} INFO - Started process (PID=41496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:41.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:01:41.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:41.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:41.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:01:41.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:41.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:01:41.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:01:41.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:01:41.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T04:02:12.113+0000] {processor.py:157} INFO - Started process (PID=41521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:12.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:02:12.116+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:12.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:12.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:12.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:12.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:02:12.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:12.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:02:12.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T04:02:42.581+0000] {processor.py:157} INFO - Started process (PID=41546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:42.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:02:42.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:42.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:42.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:02:42.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:42.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:02:42.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:02:42.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:02:42.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T04:03:13.020+0000] {processor.py:157} INFO - Started process (PID=41571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:13.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:03:13.022+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:13.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:13.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:13.044+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:13.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:03:13.055+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:13.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:03:13.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-27T04:03:43.475+0000] {processor.py:157} INFO - Started process (PID=41596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:43.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:03:43.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:43.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:43.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:03:43.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:43.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:03:43.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:03:43.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:03:43.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T04:04:13.931+0000] {processor.py:157} INFO - Started process (PID=41621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:13.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:04:13.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:13.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:13.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:13.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:13.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:04:13.969+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:13.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:04:13.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T04:04:44.367+0000] {processor.py:157} INFO - Started process (PID=41646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:44.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:04:44.370+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:44.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:44.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:04:44.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:44.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:04:44.404+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:04:44.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:04:44.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T04:05:14.825+0000] {processor.py:157} INFO - Started process (PID=41671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:14.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:05:14.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:14.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:14.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:14.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:14.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:05:14.872+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:14.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:05:14.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T04:05:45.247+0000] {processor.py:157} INFO - Started process (PID=41696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:45.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:05:45.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:45.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:45.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:05:45.280+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:45.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:05:45.293+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:05:45.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:05:45.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T04:06:15.730+0000] {processor.py:157} INFO - Started process (PID=41721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:15.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:06:15.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:15.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:15.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:15.769+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:15.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:06:15.780+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:15.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:06:15.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T04:06:46.158+0000] {processor.py:157} INFO - Started process (PID=41746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:46.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:06:46.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:46.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:46.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:06:46.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:46.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:06:46.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:06:46.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:06:46.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T04:07:16.565+0000] {processor.py:157} INFO - Started process (PID=41771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:16.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:07:16.569+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:16.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:16.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:16.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:16.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:07:16.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:16.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:07:16.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T04:07:46.983+0000] {processor.py:157} INFO - Started process (PID=41796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:46.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:07:46.988+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:46.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:47.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:07:47.022+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:47.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:07:47.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:07:47.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:07:47.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T04:08:17.422+0000] {processor.py:157} INFO - Started process (PID=41821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:08:17.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:08:17.425+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:08:17.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:08:17.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:08:17.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:08:17.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:08:17.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:08:17.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:08:17.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T04:16:34.584+0000] {processor.py:157} INFO - Started process (PID=41846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:16:34.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:16:34.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:16:34.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:16:34.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:16:34.616+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:16:34.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:16:34.627+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:16:34.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:16:34.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T04:17:05.215+0000] {processor.py:157} INFO - Started process (PID=41873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:17:05.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:17:05.222+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:17:05.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:17:05.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:17:05.257+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:17:05.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:17:05.269+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:17:05.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:17:05.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T04:24:47.552+0000] {processor.py:157} INFO - Started process (PID=41898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:24:47.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:24:47.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:24:47.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:24:47.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:24:47.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:24:47.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:24:47.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:24:47.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:24:47.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T04:27:27.245+0000] {processor.py:157} INFO - Started process (PID=41923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:27.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:27:27.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:27.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:27.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:27.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:27.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:27:27.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:27.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:27:27.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-27T04:27:57.712+0000] {processor.py:157} INFO - Started process (PID=41948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:57.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:27:57.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:57.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:57.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:27:57.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:57.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:27:57.755+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:27:57.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:27:57.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T04:28:35.056+0000] {processor.py:157} INFO - Started process (PID=41973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:28:35.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:28:35.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:28:35.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:28:35.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:28:35.091+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:28:35.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:28:35.105+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:28:35.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:28:35.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T04:29:05.560+0000] {processor.py:157} INFO - Started process (PID=41998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:29:05.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:29:05.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:29:05.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:29:05.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:29:05.598+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:29:05.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:29:05.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:29:05.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:29:05.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T04:44:41.634+0000] {processor.py:157} INFO - Started process (PID=42025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:44:41.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:44:41.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:44:41.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:44:41.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:44:41.718+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:44:41.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:44:41.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:44:41.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:44:41.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-27T04:45:12.217+0000] {processor.py:157} INFO - Started process (PID=42050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:45:12.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T04:45:12.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:45:12.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:45:12.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T04:45:12.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:45:12.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T04:45:12.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T04:45:12.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T04:45:12.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T05:02:38.328+0000] {processor.py:157} INFO - Started process (PID=42075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:02:38.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:02:38.333+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:02:38.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:02:38.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:02:38.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:02:38.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:02:38.388+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:02:38.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:02:38.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T05:03:08.883+0000] {processor.py:157} INFO - Started process (PID=42100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:08.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:03:08.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:08.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:08.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:08.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:08.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:03:08.939+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:08.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:03:08.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T05:03:39.392+0000] {processor.py:157} INFO - Started process (PID=42125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:39.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:03:39.395+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:39.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:39.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:03:39.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:39.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:03:39.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:03:39.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:03:39.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:09:07.097+0000] {processor.py:157} INFO - Started process (PID=42151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:09:07.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:09:07.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:09:07.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:09:07.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:09:07.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:09:07.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:09:07.154+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:09:07.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:09:07.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T05:10:32.085+0000] {processor.py:157} INFO - Started process (PID=42177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:10:32.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:10:32.100+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:10:32.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:10:32.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:10:32.173+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:10:32.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:10:32.187+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:10:32.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:10:32.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-27T05:11:02.682+0000] {processor.py:157} INFO - Started process (PID=42202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:02.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:11:02.690+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:02.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:02.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:02.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:02.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:11:02.741+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:02.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:11:02.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T05:11:59.606+0000] {processor.py:157} INFO - Started process (PID=42227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:59.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:11:59.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:59.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:59.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:11:59.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:59.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:11:59.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:11:59.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:11:59.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T05:12:30.125+0000] {processor.py:157} INFO - Started process (PID=42252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:12:30.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:12:30.136+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:12:30.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:12:30.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:12:30.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:12:30.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:12:30.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:12:30.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:12:30.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-27T05:13:00.645+0000] {processor.py:157} INFO - Started process (PID=42277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:00.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:13:00.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:00.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:00.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:00.674+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:00.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:13:00.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:00.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:13:00.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:13:31.111+0000] {processor.py:157} INFO - Started process (PID=42302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:31.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:13:31.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:31.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:31.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:13:31.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:31.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:13:31.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:13:31.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:13:31.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T05:14:01.534+0000] {processor.py:157} INFO - Started process (PID=42327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:01.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:14:01.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:01.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:01.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:01.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:01.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:14:01.572+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:01.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:14:01.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:14:31.931+0000] {processor.py:157} INFO - Started process (PID=42352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:31.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:14:31.936+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:31.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:31.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:14:31.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:31.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:14:31.987+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:14:31.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:14:31.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T05:15:02.372+0000] {processor.py:157} INFO - Started process (PID=42377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:02.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:15:02.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:02.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:02.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:02.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:02.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:15:02.416+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:02.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:15:02.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:15:32.823+0000] {processor.py:157} INFO - Started process (PID=42402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:32.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:15:32.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:32.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:32.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:15:32.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:32.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:15:32.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:15:32.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:15:32.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:16:03.280+0000] {processor.py:157} INFO - Started process (PID=42427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:03.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:16:03.283+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:03.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:03.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:03.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:03.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:16:03.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:03.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:16:03.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:16:33.707+0000] {processor.py:157} INFO - Started process (PID=42452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:33.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:16:33.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:33.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:33.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:16:33.738+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:33.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:16:33.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:16:33.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:16:33.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:17:04.115+0000] {processor.py:157} INFO - Started process (PID=42477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:04.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:17:04.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:04.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:04.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:04.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:17:04.158+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:04.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:17:04.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:17:34.570+0000] {processor.py:157} INFO - Started process (PID=42502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:34.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:17:34.572+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:34.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:34.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:17:34.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:34.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:17:34.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:17:34.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:17:34.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:18:04.973+0000] {processor.py:157} INFO - Started process (PID=42527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:04.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:18:04.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:04.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:04.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:05.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:05.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:18:05.011+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:05.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:18:05.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:18:35.429+0000] {processor.py:157} INFO - Started process (PID=42552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:35.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:18:35.432+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:35.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:35.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:18:35.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:35.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:18:35.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:18:35.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:18:35.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:19:05.883+0000] {processor.py:157} INFO - Started process (PID=42577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:05.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:19:05.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:05.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:05.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:05.914+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:05.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:19:05.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:05.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:19:05.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:19:36.360+0000] {processor.py:157} INFO - Started process (PID=42602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:36.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:19:36.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:36.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:36.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:19:36.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:36.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:19:36.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:19:36.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:19:36.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T05:20:06.858+0000] {processor.py:157} INFO - Started process (PID=42627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:06.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:20:06.860+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:06.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:06.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:06.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:06.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:20:06.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:06.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:20:06.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T05:20:37.274+0000] {processor.py:157} INFO - Started process (PID=42652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:37.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:20:37.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:37.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:37.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:20:37.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:37.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:20:37.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:20:37.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:20:37.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:21:07.802+0000] {processor.py:157} INFO - Started process (PID=42677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:07.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:21:07.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:07.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:07.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:07.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:07.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:21:07.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:07.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:21:07.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:21:38.226+0000] {processor.py:157} INFO - Started process (PID=42702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:38.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:21:38.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:38.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:38.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:21:38.257+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:38.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:21:38.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:21:38.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:21:38.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:22:08.676+0000] {processor.py:157} INFO - Started process (PID=42727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:08.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:22:08.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:08.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:08.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:08.719+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:08.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:22:08.731+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:08.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:22:08.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T05:22:39.089+0000] {processor.py:157} INFO - Started process (PID=42752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:39.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:22:39.092+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:39.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:39.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:22:39.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:39.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:22:39.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:22:39.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:22:39.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:23:09.547+0000] {processor.py:157} INFO - Started process (PID=42777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:09.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:23:09.551+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:09.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:09.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:09.582+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:09.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:23:09.591+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:09.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:23:09.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:23:39.946+0000] {processor.py:157} INFO - Started process (PID=42802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:39.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:23:39.948+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:39.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:39.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:23:39.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:39.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:23:39.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:23:39.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:23:39.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:24:10.363+0000] {processor.py:157} INFO - Started process (PID=42827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:10.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:24:10.368+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:10.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:10.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:10.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:10.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:24:10.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:10.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:24:10.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:24:40.780+0000] {processor.py:157} INFO - Started process (PID=42852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:40.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:24:40.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:40.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:40.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:24:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:40.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:24:40.820+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:24:40.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:24:40.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:25:11.087+0000] {processor.py:157} INFO - Started process (PID=42877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:11.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:25:11.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:11.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:11.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:11.113+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:11.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:25:11.122+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:11.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:25:11.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T05:25:41.487+0000] {processor.py:157} INFO - Started process (PID=42902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:41.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:25:41.490+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:41.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:41.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:25:41.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:41.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:25:41.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:25:41.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:25:41.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:26:11.931+0000] {processor.py:157} INFO - Started process (PID=42927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:11.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:26:11.933+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:11.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:11.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:11.962+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:11.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:26:11.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:11.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:26:11.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:26:42.303+0000] {processor.py:157} INFO - Started process (PID=42952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:42.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:26:42.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:42.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:42.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:26:42.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:42.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:26:42.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:26:42.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:26:42.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:27:12.785+0000] {processor.py:157} INFO - Started process (PID=42977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:12.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:27:12.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:12.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:12.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:12.820+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:12.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:27:12.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:12.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:27:12.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:27:43.197+0000] {processor.py:157} INFO - Started process (PID=43002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:43.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:27:43.200+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:43.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:43.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:27:43.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:43.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:27:43.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:27:43.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:27:43.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:28:13.671+0000] {processor.py:157} INFO - Started process (PID=43027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:13.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:28:13.676+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:13.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:13.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:13.702+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:13.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:28:13.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:13.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:28:13.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:28:44.094+0000] {processor.py:157} INFO - Started process (PID=43052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:44.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:28:44.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:44.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:44.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:28:44.123+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:44.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:28:44.133+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:28:44.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:28:44.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:29:14.550+0000] {processor.py:157} INFO - Started process (PID=43077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:14.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:29:14.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:14.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:14.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:14.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:14.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:29:14.590+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:14.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:29:14.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T05:29:45.030+0000] {processor.py:157} INFO - Started process (PID=43102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:45.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:29:45.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:45.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:45.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:29:45.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:45.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:29:45.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:29:45.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:29:45.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T05:30:15.501+0000] {processor.py:157} INFO - Started process (PID=43127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:15.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:30:15.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:15.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:15.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:15.535+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:15.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:30:15.545+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:15.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:30:15.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:30:45.944+0000] {processor.py:157} INFO - Started process (PID=43152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:45.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:30:45.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:45.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:45.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:30:45.978+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:45.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:30:45.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:30:45.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:30:46.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T05:31:16.343+0000] {processor.py:157} INFO - Started process (PID=43177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:16.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:31:16.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:16.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:16.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:16.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:16.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:31:16.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:16.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:31:16.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:31:46.807+0000] {processor.py:157} INFO - Started process (PID=43202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:46.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:31:46.809+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:46.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:46.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:31:46.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:46.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:31:46.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:31:46.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:31:46.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:32:17.268+0000] {processor.py:157} INFO - Started process (PID=43227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:17.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:32:17.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:17.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:17.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:17.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:17.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:32:17.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:17.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:32:17.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T05:32:47.740+0000] {processor.py:157} INFO - Started process (PID=43252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:47.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:32:47.744+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:47.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:47.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:32:47.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:47.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:32:47.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:32:47.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:32:47.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:33:18.230+0000] {processor.py:157} INFO - Started process (PID=43277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:18.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:33:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:18.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:18.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:18.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:18.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:33:18.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:18.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:33:18.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T05:33:48.663+0000] {processor.py:157} INFO - Started process (PID=43302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:48.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:33:48.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:48.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:48.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:33:48.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:48.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:33:48.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:33:48.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:33:48.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T05:34:19.171+0000] {processor.py:157} INFO - Started process (PID=43327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:19.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:34:19.180+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:19.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:19.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:19.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:19.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:34:19.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:19.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:34:19.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:34:49.576+0000] {processor.py:157} INFO - Started process (PID=43352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:49.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:34:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:49.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:49.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:34:49.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:49.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:34:49.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:34:49.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:34:49.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:35:19.979+0000] {processor.py:157} INFO - Started process (PID=43377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:19.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:35:19.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:19.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:19.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:20.011+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:20.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:35:20.022+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:20.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:35:20.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:35:50.391+0000] {processor.py:157} INFO - Started process (PID=43402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:50.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:35:50.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:50.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:50.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:35:50.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:50.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:35:50.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:35:50.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:35:50.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-27T05:36:20.817+0000] {processor.py:157} INFO - Started process (PID=43427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:20.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:36:20.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:20.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:20.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:20.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:20.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:36:20.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:20.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:36:20.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:36:51.290+0000] {processor.py:157} INFO - Started process (PID=43452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:51.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:36:51.294+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:51.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:51.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:36:51.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:51.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:36:51.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:36:51.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:36:51.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T05:37:21.719+0000] {processor.py:157} INFO - Started process (PID=43477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:21.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:37:21.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:21.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:21.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:21.749+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:21.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:37:21.759+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:21.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:37:21.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:37:52.136+0000] {processor.py:157} INFO - Started process (PID=43502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:52.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:37:52.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:52.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:52.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:37:52.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:52.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:37:52.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:37:52.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:37:52.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:38:22.534+0000] {processor.py:157} INFO - Started process (PID=43527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:22.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:38:22.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:22.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:22.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:22.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:22.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:38:22.573+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:22.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:38:22.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:38:52.883+0000] {processor.py:157} INFO - Started process (PID=43552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:52.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:38:52.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:52.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:52.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:38:52.924+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:52.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:38:52.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:38:52.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:38:52.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T05:39:23.596+0000] {processor.py:157} INFO - Started process (PID=43577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:23.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:39:23.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:23.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:23.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:23.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:23.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:39:23.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:23.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:39:23.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-07-27T05:39:54.300+0000] {processor.py:157} INFO - Started process (PID=43601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:54.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:39:54.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:54.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:54.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:39:54.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:54.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:39:54.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:39:54.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:39:54.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-27T05:40:24.808+0000] {processor.py:157} INFO - Started process (PID=43627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:24.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:40:24.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:24.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:24.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:24.873+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:24.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:40:24.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:24.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:40:24.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-27T05:40:55.329+0000] {processor.py:157} INFO - Started process (PID=43652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:55.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:40:55.336+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:55.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:55.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:40:55.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:55.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:40:55.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:40:55.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:40:55.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T05:41:25.855+0000] {processor.py:157} INFO - Started process (PID=43677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:25.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:41:25.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:25.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:25.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:25.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:25.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:41:25.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:25.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:41:25.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T05:41:56.412+0000] {processor.py:157} INFO - Started process (PID=43702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:56.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:41:56.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:56.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:56.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:41:56.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:56.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:41:56.485+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:41:56.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:41:56.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T05:42:26.888+0000] {processor.py:157} INFO - Started process (PID=43727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:26.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:42:26.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:26.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:26.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:26.918+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:26.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:42:26.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:26.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:42:26.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:42:57.307+0000] {processor.py:157} INFO - Started process (PID=43752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:57.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:42:57.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:57.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:57.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:42:57.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:57.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:42:57.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:42:57.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:42:57.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T05:43:27.714+0000] {processor.py:157} INFO - Started process (PID=43777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:27.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:43:27.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:27.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:27.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:27.759+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:27.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:43:27.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:27.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:43:27.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T05:43:58.141+0000] {processor.py:157} INFO - Started process (PID=43802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:58.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:43:58.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:58.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:58.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:43:58.172+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:58.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:43:58.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:43:58.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:43:58.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:44:28.580+0000] {processor.py:157} INFO - Started process (PID=43827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:28.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:44:28.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:28.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:28.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:28.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:28.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:44:28.621+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:28.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:44:28.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:44:58.988+0000] {processor.py:157} INFO - Started process (PID=43852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:58.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:44:58.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:58.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:59.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:44:59.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:59.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:44:59.031+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:44:59.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:44:59.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T05:45:29.401+0000] {processor.py:157} INFO - Started process (PID=43877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:29.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:45:29.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:29.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:29.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:29.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:29.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:45:29.446+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:29.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:45:29.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:45:59.784+0000] {processor.py:157} INFO - Started process (PID=43902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:59.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:45:59.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:59.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:59.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:45:59.804+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:59.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:45:59.811+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:45:59.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:45:59.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.036 seconds
[2024-07-27T05:46:30.165+0000] {processor.py:157} INFO - Started process (PID=43927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:46:30.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:46:30.167+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:46:30.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:46:30.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:46:30.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:46:30.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:46:30.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:46:30.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:46:30.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:47:00.589+0000] {processor.py:157} INFO - Started process (PID=43951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:00.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:47:00.597+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:00.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:00.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:00.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:00.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:47:00.664+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:00.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:47:00.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T05:47:31.036+0000] {processor.py:157} INFO - Started process (PID=43977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:31.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:47:31.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:31.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:31.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:47:31.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:31.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:47:31.079+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:47:31.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:47:31.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T05:48:01.424+0000] {processor.py:157} INFO - Started process (PID=44002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:01.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:48:01.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:01.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:01.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:01.497+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:01.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:48:01.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:01.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:48:01.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T05:48:31.890+0000] {processor.py:157} INFO - Started process (PID=44027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:31.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:48:31.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:31.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:31.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:48:31.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:31.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:48:31.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:48:31.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:48:31.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T05:49:02.339+0000] {processor.py:157} INFO - Started process (PID=44052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:02.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:49:02.343+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:02.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:02.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:02.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:02.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:49:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:02.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:49:02.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:49:32.815+0000] {processor.py:157} INFO - Started process (PID=44077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:32.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:49:32.819+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:32.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:32.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:49:32.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:32.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:49:32.852+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:49:32.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:49:32.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T05:50:03.189+0000] {processor.py:157} INFO - Started process (PID=44102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:03.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:50:03.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:03.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:03.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:03.220+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:03.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:50:03.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:03.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:50:03.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:50:33.639+0000] {processor.py:157} INFO - Started process (PID=44127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:33.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:50:33.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:33.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:33.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:50:33.677+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:33.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:50:33.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:50:33.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:50:33.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T05:51:04.042+0000] {processor.py:157} INFO - Started process (PID=44152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:04.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:51:04.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:04.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:04.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:04.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:04.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:51:04.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:04.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:51:04.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T05:51:34.485+0000] {processor.py:157} INFO - Started process (PID=44177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:34.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:51:34.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:34.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:34.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:51:34.534+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:34.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:51:34.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:51:34.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:51:34.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T05:52:04.931+0000] {processor.py:157} INFO - Started process (PID=44202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:04.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:52:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:04.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:04.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:04.964+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:04.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:52:04.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:04.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:52:04.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T05:52:35.316+0000] {processor.py:157} INFO - Started process (PID=44227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:35.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:52:35.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:35.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:35.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:52:35.349+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:35.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:52:35.361+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:52:35.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:52:35.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:53:05.715+0000] {processor.py:157} INFO - Started process (PID=44252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:05.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:53:05.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:05.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:05.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:05.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:05.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:53:05.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:05.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:53:05.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T05:53:36.100+0000] {processor.py:157} INFO - Started process (PID=44277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:36.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:53:36.103+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:36.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:36.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:53:36.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:36.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:53:36.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:53:36.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:53:36.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T05:54:06.558+0000] {processor.py:157} INFO - Started process (PID=44302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:06.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:54:06.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:06.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:06.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:06.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:06.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:54:06.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:06.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:54:06.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T05:54:36.989+0000] {processor.py:157} INFO - Started process (PID=44327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:36.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:54:36.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:36.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:37.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:54:37.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:37.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:54:37.031+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:54:37.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:54:37.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:55:07.442+0000] {processor.py:157} INFO - Started process (PID=44352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:07.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:55:07.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:07.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:07.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:07.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:07.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:55:07.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:07.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:55:07.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T05:55:37.867+0000] {processor.py:157} INFO - Started process (PID=44377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:37.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:55:37.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:37.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:37.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:55:37.902+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:37.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:55:37.913+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:55:37.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:55:37.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T05:56:08.264+0000] {processor.py:157} INFO - Started process (PID=44402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:08.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:56:08.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:08.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:08.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:08.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:08.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:56:08.313+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:08.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:56:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T05:56:38.745+0000] {processor.py:157} INFO - Started process (PID=44427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:38.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:56:38.749+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:38.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:38.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:56:38.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:38.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:56:38.789+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:56:38.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:56:38.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T05:57:09.157+0000] {processor.py:157} INFO - Started process (PID=44452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:09.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:57:09.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:09.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:09.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:09.186+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:09.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:57:09.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:09.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:57:09.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T05:57:39.641+0000] {processor.py:157} INFO - Started process (PID=44477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:39.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:57:39.648+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:39.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:39.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:57:39.689+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:39.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:57:39.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:57:39.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:57:39.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T05:58:10.117+0000] {processor.py:157} INFO - Started process (PID=44502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:10.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:58:10.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:10.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:10.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:10.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:10.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:58:10.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:10.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:58:10.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T05:58:40.489+0000] {processor.py:157} INFO - Started process (PID=44527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:40.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:58:40.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:40.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:40.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:58:40.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:40.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:58:40.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:58:40.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:58:40.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T05:59:10.929+0000] {processor.py:157} INFO - Started process (PID=44552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:10.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:59:10.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:10.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:10.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:10.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:10.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:59:10.969+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:10.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:59:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T05:59:41.342+0000] {processor.py:157} INFO - Started process (PID=44577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:41.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T05:59:41.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:41.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:41.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T05:59:41.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:41.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T05:59:41.386+0000] {logging_mixin.py:151} INFO - [2024-07-27T05:59:41.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T05:59:41.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:00:11.758+0000] {processor.py:157} INFO - Started process (PID=44602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:11.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:00:11.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:11.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:11.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:11.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:11.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:00:11.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:11.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:00:11.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:00:42.138+0000] {processor.py:157} INFO - Started process (PID=44627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:42.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:00:42.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:42.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:42.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:00:42.165+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:42.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:00:42.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:00:42.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:00:42.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T06:01:12.502+0000] {processor.py:157} INFO - Started process (PID=44652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:12.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:01:12.504+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:12.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:12.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:12.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:12.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:01:12.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:12.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:01:12.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:01:42.882+0000] {processor.py:157} INFO - Started process (PID=44677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:42.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:01:42.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:42.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:42.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:01:42.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:42.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:01:42.923+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:01:42.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:01:42.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:02:13.336+0000] {processor.py:157} INFO - Started process (PID=44702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:13.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:02:13.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:13.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:13.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:13.367+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:13.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:02:13.378+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:13.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:02:13.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:02:43.804+0000] {processor.py:157} INFO - Started process (PID=44727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:43.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:02:43.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:43.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:43.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:02:43.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:43.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:02:43.850+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:02:43.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:02:43.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T06:03:14.303+0000] {processor.py:157} INFO - Started process (PID=44752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:14.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:03:14.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:14.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:14.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:14.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:14.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:03:14.359+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:14.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:03:14.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T06:03:44.828+0000] {processor.py:157} INFO - Started process (PID=44777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:44.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:03:44.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:44.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:44.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:03:44.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:44.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:03:44.869+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:03:44.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:03:44.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:04:15.253+0000] {processor.py:157} INFO - Started process (PID=44802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:15.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:04:15.255+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:15.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:15.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:15.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:15.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:04:15.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:15.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:04:15.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T06:04:45.685+0000] {processor.py:157} INFO - Started process (PID=44827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:45.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:04:45.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:45.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:45.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:04:45.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:45.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:04:45.725+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:04:45.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:04:45.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:05:16.172+0000] {processor.py:157} INFO - Started process (PID=44852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:16.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:05:16.175+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:16.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:16.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:16.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:16.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:05:16.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:16.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:05:16.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:05:46.564+0000] {processor.py:157} INFO - Started process (PID=44877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:46.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:05:46.568+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:46.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:46.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:05:46.594+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:46.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:05:46.605+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:05:46.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:05:46.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:06:17.053+0000] {processor.py:157} INFO - Started process (PID=44902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:17.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:06:17.057+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:17.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:17.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:17.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:17.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:06:17.094+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:17.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:06:17.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:06:47.521+0000] {processor.py:157} INFO - Started process (PID=44927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:47.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:06:47.526+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:47.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:47.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:06:47.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:47.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:06:47.568+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:06:47.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:06:47.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T06:07:18.027+0000] {processor.py:157} INFO - Started process (PID=44952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:18.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:07:18.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:18.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:18.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:18.058+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:18.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:07:18.068+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:18.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:07:18.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:07:48.456+0000] {processor.py:157} INFO - Started process (PID=44977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:48.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:07:48.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:48.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:48.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:07:48.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:48.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:07:48.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:07:48.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:07:48.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T06:08:18.938+0000] {processor.py:157} INFO - Started process (PID=45002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:18.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:08:18.942+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:18.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:18.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:18.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:18.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:08:18.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:18.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:08:18.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:08:49.377+0000] {processor.py:157} INFO - Started process (PID=45027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:49.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:08:49.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:49.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:49.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:08:49.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:49.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:08:49.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:08:49.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:08:49.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:09:19.757+0000] {processor.py:157} INFO - Started process (PID=45052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:19.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:09:19.760+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:19.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:19.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:19.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:19.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:09:19.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:19.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:09:19.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T06:09:50.174+0000] {processor.py:157} INFO - Started process (PID=45077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:50.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:09:50.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:50.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:50.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:09:50.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:50.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:09:50.215+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:09:50.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:09:50.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:10:20.653+0000] {processor.py:157} INFO - Started process (PID=45102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:20.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:10:20.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:20.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:20.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:20.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:20.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:10:20.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:20.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:10:20.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T06:10:51.117+0000] {processor.py:157} INFO - Started process (PID=45127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:51.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:10:51.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:51.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:51.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:10:51.163+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:51.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:10:51.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:10:51.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:10:51.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T06:11:21.642+0000] {processor.py:157} INFO - Started process (PID=45152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:21.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:11:21.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:21.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:21.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:21.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:21.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:11:21.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:21.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:11:21.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:11:52.002+0000] {processor.py:157} INFO - Started process (PID=45176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:52.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:11:52.006+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:52.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:52.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:11:52.065+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:52.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:11:52.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:11:52.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:11:52.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T06:12:22.447+0000] {processor.py:157} INFO - Started process (PID=45202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:22.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:12:22.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:22.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:22.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:22.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:22.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:12:22.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:22.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:12:22.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T06:12:52.908+0000] {processor.py:157} INFO - Started process (PID=45227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:52.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:12:52.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:52.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:52.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:12:52.947+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:52.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:12:52.960+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:12:52.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:12:52.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T06:13:23.446+0000] {processor.py:157} INFO - Started process (PID=45252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:23.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:13:23.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:23.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:23.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:23.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:23.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:13:23.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:23.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:13:23.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T06:13:53.925+0000] {processor.py:157} INFO - Started process (PID=45277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:53.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:13:53.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:53.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:53.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:13:53.962+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:53.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:13:53.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:13:53.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:13:53.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T06:14:24.360+0000] {processor.py:157} INFO - Started process (PID=45302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:24.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:14:24.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:24.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:24.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:24.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:24.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:14:24.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:24.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:14:24.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T06:14:54.790+0000] {processor.py:157} INFO - Started process (PID=45327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:54.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:14:54.796+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:54.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:54.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:14:54.832+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:54.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:14:54.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:14:54.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:14:54.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T06:15:25.247+0000] {processor.py:157} INFO - Started process (PID=45352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:25.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:15:25.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:25.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:25.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:25.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:25.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:15:25.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:25.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:15:25.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:15:55.741+0000] {processor.py:157} INFO - Started process (PID=45377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:55.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:15:55.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:55.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:55.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:15:55.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:55.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:15:55.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:15:55.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:15:55.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:16:26.240+0000] {processor.py:157} INFO - Started process (PID=45402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:26.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:16:26.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:26.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:26.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:26.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:26.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:16:26.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:26.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:16:26.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T06:16:56.644+0000] {processor.py:157} INFO - Started process (PID=45427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:56.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:16:56.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:56.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:56.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:16:56.675+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:56.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:16:56.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:16:56.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:16:56.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T06:17:27.110+0000] {processor.py:157} INFO - Started process (PID=45452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:27.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:17:27.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:27.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:27.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:27.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:27.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:17:27.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:27.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:17:27.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T06:17:57.575+0000] {processor.py:157} INFO - Started process (PID=45477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:57.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:17:57.579+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:57.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:57.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:17:57.609+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:57.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:17:57.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:17:57.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:17:57.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T06:18:28.004+0000] {processor.py:157} INFO - Started process (PID=45502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:28.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:18:28.009+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:28.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:28.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:28.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:28.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:18:28.059+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:28.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:18:28.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T06:18:58.490+0000] {processor.py:157} INFO - Started process (PID=45527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:58.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:18:58.495+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:58.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:58.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:18:58.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:58.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:18:58.534+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:18:58.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:18:58.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:19:28.961+0000] {processor.py:157} INFO - Started process (PID=45552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:28.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:19:28.964+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:28.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:28.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:28.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:28.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:19:29.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:29.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:19:29.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:19:59.376+0000] {processor.py:157} INFO - Started process (PID=45577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:59.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:19:59.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:59.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:59.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:19:59.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:59.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:19:59.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:19:59.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:19:59.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:20:29.853+0000] {processor.py:157} INFO - Started process (PID=45602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:20:29.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:20:29.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:20:29.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:20:29.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:20:29.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:20:29.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:20:29.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:20:29.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:20:29.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T06:21:00.284+0000] {processor.py:157} INFO - Started process (PID=45627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:00.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:21:00.288+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:00.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:00.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:00.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:00.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:21:00.328+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:00.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:21:00.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:21:30.722+0000] {processor.py:157} INFO - Started process (PID=45652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:30.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:21:30.727+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:30.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:30.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:21:30.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:30.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:21:30.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:21:30.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:21:30.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T06:22:01.187+0000] {processor.py:157} INFO - Started process (PID=45677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:01.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:22:01.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:01.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:01.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:01.215+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:01.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:22:01.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:01.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:22:01.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:22:31.630+0000] {processor.py:157} INFO - Started process (PID=45702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:31.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:22:31.638+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:31.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:31.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:22:31.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:31.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:22:31.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:22:31.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:22:31.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T06:23:02.135+0000] {processor.py:157} INFO - Started process (PID=45727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:02.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:23:02.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:02.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:02.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:02.180+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:02.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:23:02.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:02.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:23:02.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T06:23:32.638+0000] {processor.py:157} INFO - Started process (PID=45752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:32.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:23:32.641+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:32.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:32.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:23:32.668+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:32.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:23:32.679+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:23:32.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:23:32.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:24:03.144+0000] {processor.py:157} INFO - Started process (PID=45777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:03.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:24:03.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:03.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:03.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:03.175+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:03.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:24:03.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:03.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:24:03.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:24:33.619+0000] {processor.py:157} INFO - Started process (PID=45802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:33.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:24:33.624+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:33.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:33.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:24:33.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:33.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:24:33.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:24:33.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:24:33.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T06:25:04.115+0000] {processor.py:157} INFO - Started process (PID=45827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:04.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:25:04.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:04.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:04.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:04.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:04.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:25:04.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:04.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:25:04.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:25:34.512+0000] {processor.py:157} INFO - Started process (PID=45852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:34.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:25:34.519+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:34.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:34.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:25:34.548+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:34.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:25:34.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:25:34.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:25:34.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T06:26:05.020+0000] {processor.py:157} INFO - Started process (PID=45877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:05.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:26:05.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:05.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:05.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:05.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:05.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:26:05.059+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:05.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:26:05.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:26:35.447+0000] {processor.py:157} INFO - Started process (PID=45902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:35.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:26:35.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:35.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:35.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:26:35.480+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:35.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:26:35.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:26:35.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:26:35.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:27:05.852+0000] {processor.py:157} INFO - Started process (PID=45927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:05.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:27:05.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:05.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:05.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:05.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:05.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:27:05.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:05.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:27:05.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:27:36.348+0000] {processor.py:157} INFO - Started process (PID=45952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:36.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:27:36.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:36.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:36.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:27:36.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:36.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:27:36.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:27:36.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:27:36.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T06:28:06.767+0000] {processor.py:157} INFO - Started process (PID=45977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:06.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:28:06.773+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:06.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:06.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:06.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:06.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:28:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:06.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:28:06.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T06:28:37.274+0000] {processor.py:157} INFO - Started process (PID=46002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:37.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:28:37.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:37.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:37.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:28:37.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:37.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:28:37.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:28:37.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:28:37.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:29:07.636+0000] {processor.py:157} INFO - Started process (PID=46027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:07.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:29:07.639+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:07.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:07.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:07.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:07.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:29:07.679+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:07.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:29:07.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:29:38.059+0000] {processor.py:157} INFO - Started process (PID=46052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:38.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:29:38.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:38.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:38.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:29:38.085+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:38.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:29:38.095+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:29:38.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:29:38.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T06:30:08.477+0000] {processor.py:157} INFO - Started process (PID=46077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:08.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:30:08.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:08.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:08.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:08.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:08.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:30:08.519+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:08.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:30:08.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:30:38.966+0000] {processor.py:157} INFO - Started process (PID=46102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:38.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:30:38.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:38.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:38.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:30:38.998+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:38.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:30:39.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:30:39.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:30:39.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:31:09.386+0000] {processor.py:157} INFO - Started process (PID=46127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:09.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:31:09.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:09.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:09.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:09.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:09.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:31:09.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:09.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:31:09.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T06:31:39.848+0000] {processor.py:157} INFO - Started process (PID=46152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:39.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:31:39.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:39.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:39.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:31:39.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:39.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:31:39.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:31:39.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:31:39.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:32:10.323+0000] {processor.py:157} INFO - Started process (PID=46177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:10.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:32:10.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:10.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:10.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:10.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:10.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:32:10.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:10.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:32:10.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T06:32:40.788+0000] {processor.py:157} INFO - Started process (PID=46201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:40.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:32:40.796+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:40.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:40.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:32:40.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:40.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:32:40.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:32:40.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:32:40.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T06:33:11.615+0000] {processor.py:157} INFO - Started process (PID=46227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:11.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:33:11.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:11.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:11.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:11.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:11.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:33:11.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:11.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:33:11.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T06:33:42.052+0000] {processor.py:157} INFO - Started process (PID=46252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:42.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:33:42.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:42.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:42.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:33:42.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:42.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:33:42.092+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:33:42.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:33:42.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:34:12.516+0000] {processor.py:157} INFO - Started process (PID=46277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:12.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:34:12.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:12.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:12.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:12.548+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:12.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:34:12.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:12.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:34:12.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:34:42.927+0000] {processor.py:157} INFO - Started process (PID=46302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:42.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:34:42.930+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:42.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:42.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:34:42.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:42.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:34:42.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:34:42.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:34:42.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:35:13.392+0000] {processor.py:157} INFO - Started process (PID=46327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:13.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:35:13.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:13.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:13.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:13.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:13.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:35:13.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:13.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:35:13.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T06:35:43.841+0000] {processor.py:157} INFO - Started process (PID=46352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:43.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:35:43.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:43.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:43.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:35:43.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:43.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:35:43.881+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:35:43.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:35:43.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:36:14.262+0000] {processor.py:157} INFO - Started process (PID=46377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:14.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:36:14.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:14.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:14.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:14.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:14.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:36:14.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:14.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:36:14.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T06:36:44.917+0000] {processor.py:157} INFO - Started process (PID=46402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:44.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:36:44.933+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:44.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:44.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:36:45.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:45.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:36:45.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:36:45.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:36:45.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.225 seconds
[2024-07-27T06:37:15.730+0000] {processor.py:157} INFO - Started process (PID=46427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:15.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:37:15.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:15.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:15.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:15.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:15.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:37:15.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:15.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:37:15.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-27T06:37:46.385+0000] {processor.py:157} INFO - Started process (PID=46452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:46.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:37:46.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:46.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:46.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:37:46.456+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:46.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:37:46.471+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:37:46.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:37:46.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-27T06:38:16.929+0000] {processor.py:157} INFO - Started process (PID=46477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:16.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:38:16.936+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:16.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:16.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:16.994+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:16.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:38:17.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:17.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:38:17.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-27T06:38:47.525+0000] {processor.py:157} INFO - Started process (PID=46502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:47.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:38:47.534+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:47.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:47.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:38:47.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:47.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:38:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:38:47.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:38:47.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-27T06:39:18.387+0000] {processor.py:157} INFO - Started process (PID=46527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:18.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:39:18.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:18.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:18.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:18.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:18.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:39:18.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:18.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:39:18.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T06:39:48.986+0000] {processor.py:157} INFO - Started process (PID=46552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:48.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:39:49.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:49.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:49.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:39:49.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:49.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:39:49.108+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:39:49.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:39:49.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T06:40:19.556+0000] {processor.py:157} INFO - Started process (PID=46577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:19.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:40:19.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:19.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:19.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:19.616+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:19.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:40:19.631+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:19.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:40:19.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T06:40:50.013+0000] {processor.py:157} INFO - Started process (PID=46602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:50.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:40:50.016+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:50.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:50.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:40:50.042+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:50.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:40:50.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:40:50.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:40:50.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T06:41:20.402+0000] {processor.py:157} INFO - Started process (PID=46627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:20.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:41:20.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:20.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:20.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:20.443+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:20.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:41:20.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:20.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:41:20.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T06:41:50.970+0000] {processor.py:157} INFO - Started process (PID=46652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:50.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:41:50.976+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:50.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:50.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:41:51.018+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:51.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:41:51.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:41:51.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:41:51.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T06:42:21.400+0000] {processor.py:157} INFO - Started process (PID=46677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:21.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:42:21.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:21.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:21.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:21.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:21.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:42:21.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:21.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:42:21.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T06:42:51.912+0000] {processor.py:157} INFO - Started process (PID=46702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:51.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:42:51.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:51.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:51.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:42:51.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:51.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:42:51.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:42:51.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:42:51.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T06:43:22.391+0000] {processor.py:157} INFO - Started process (PID=46727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:22.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:43:22.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:22.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:22.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:22.453+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:22.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:43:22.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:22.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:43:22.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-27T06:43:52.916+0000] {processor.py:157} INFO - Started process (PID=46752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:52.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:43:52.923+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:52.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:52.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:43:52.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:52.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:43:52.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:43:52.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:43:52.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T06:44:23.394+0000] {processor.py:157} INFO - Started process (PID=46777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:23.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:44:23.400+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:23.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:23.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:23.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:23.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:44:23.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:23.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:44:23.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T06:44:53.850+0000] {processor.py:157} INFO - Started process (PID=46802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:53.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:44:53.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:53.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:53.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:44:53.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:53.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:44:53.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:44:53.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:44:54.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-07-27T06:45:24.444+0000] {processor.py:157} INFO - Started process (PID=46827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:24.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:45:24.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:24.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:24.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:24.493+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:24.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:45:24.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:24.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:45:24.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T06:45:55.110+0000] {processor.py:157} INFO - Started process (PID=46852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:55.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:45:55.116+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:55.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:55.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:45:55.170+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:55.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:45:55.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:45:55.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:45:55.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-27T06:46:25.908+0000] {processor.py:157} INFO - Started process (PID=46877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:25.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:46:25.914+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:25.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:25.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:25.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:25.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:46:25.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:25.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:46:25.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T06:46:56.423+0000] {processor.py:157} INFO - Started process (PID=46902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:56.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:46:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:56.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:56.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:46:56.524+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:56.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:46:56.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:46:56.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:46:56.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-27T06:47:26.996+0000] {processor.py:157} INFO - Started process (PID=46927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:27.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:47:27.006+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:27.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:27.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:27.071+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:27.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:47:27.094+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:27.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:47:27.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-27T06:47:57.587+0000] {processor.py:157} INFO - Started process (PID=46952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:57.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:47:57.595+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:57.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:57.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:47:57.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:57.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:47:57.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:47:57.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:47:57.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-27T06:48:28.196+0000] {processor.py:157} INFO - Started process (PID=46977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:28.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:48:28.203+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:28.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:28.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:28.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:28.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:48:28.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:28.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:48:28.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T06:48:58.700+0000] {processor.py:157} INFO - Started process (PID=47002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:58.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:48:58.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:58.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:58.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:48:58.773+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:58.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:48:58.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:48:58.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:48:58.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T06:49:29.336+0000] {processor.py:157} INFO - Started process (PID=47027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:29.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:49:29.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:29.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:29.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:29.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:29.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:49:29.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:29.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:49:29.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T06:49:59.791+0000] {processor.py:157} INFO - Started process (PID=47052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:59.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:49:59.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:59.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:59.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:49:59.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:59.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:49:59.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:49:59.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:49:59.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T06:50:30.328+0000] {processor.py:157} INFO - Started process (PID=47077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:50:30.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:50:30.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:50:30.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:50:30.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:50:30.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:50:30.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:50:30.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:50:30.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:50:30.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-27T06:51:00.832+0000] {processor.py:157} INFO - Started process (PID=47102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:00.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:51:00.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:00.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:00.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:00.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:00.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:51:00.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:00.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:51:00.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T06:51:31.448+0000] {processor.py:157} INFO - Started process (PID=47127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:31.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:51:31.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:31.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:31.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:51:31.534+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:31.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:51:31.555+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:51:31.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:51:31.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-27T06:52:01.992+0000] {processor.py:157} INFO - Started process (PID=47152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:01.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:52:02.013+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:02.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:02.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:02.088+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:02.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:52:02.108+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:02.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:52:02.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-27T06:52:32.581+0000] {processor.py:157} INFO - Started process (PID=47175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:32.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:52:32.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:32.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:32.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:52:32.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:32.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:52:32.660+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:52:32.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:52:32.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T06:53:03.137+0000] {processor.py:157} INFO - Started process (PID=47201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:03.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:53:03.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:03.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:03.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:03.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:03.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:53:03.241+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:03.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:53:03.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-27T06:53:33.708+0000] {processor.py:157} INFO - Started process (PID=47227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:33.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:53:33.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:33.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:33.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:53:33.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:33.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:53:33.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:53:33.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:53:33.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T06:54:04.351+0000] {processor.py:157} INFO - Started process (PID=47252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:04.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:54:04.356+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:04.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:04.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:04.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:04.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:54:04.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:04.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:54:04.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T06:54:34.846+0000] {processor.py:157} INFO - Started process (PID=47277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:34.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:54:34.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:34.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:34.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:54:34.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:34.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:54:34.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:54:34.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:54:34.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:55:05.306+0000] {processor.py:157} INFO - Started process (PID=47301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:05.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:55:05.312+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:05.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:05.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:05.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:05.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:55:05.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:05.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:55:05.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T06:55:35.769+0000] {processor.py:157} INFO - Started process (PID=47327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:35.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:55:35.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:35.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:35.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:55:35.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:35.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:55:35.804+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:55:35.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:55:35.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T06:56:06.161+0000] {processor.py:157} INFO - Started process (PID=47352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:06.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:56:06.164+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:06.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:06.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:06.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:06.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:56:06.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:06.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:56:06.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T06:56:36.574+0000] {processor.py:157} INFO - Started process (PID=47377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:36.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:56:36.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:36.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:36.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:56:36.615+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:36.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:56:36.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:56:36.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:56:36.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T06:57:06.979+0000] {processor.py:157} INFO - Started process (PID=47402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:06.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:57:06.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:06.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:06.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:07.009+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:07.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:57:07.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:07.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:57:07.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T06:57:37.459+0000] {processor.py:157} INFO - Started process (PID=47427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:37.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:57:37.462+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:37.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:37.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:57:37.493+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:37.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:57:37.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:57:37.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:57:37.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T06:58:07.935+0000] {processor.py:157} INFO - Started process (PID=47452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:07.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:58:07.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:07.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:07.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:07.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:07.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:58:07.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:07.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:58:08.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T06:58:38.422+0000] {processor.py:157} INFO - Started process (PID=47477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:38.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:58:38.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:38.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:38.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:58:38.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:38.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:58:38.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:58:38.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:58:38.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T06:59:08.835+0000] {processor.py:157} INFO - Started process (PID=47502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:08.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:59:08.839+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:08.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:08.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:08.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:08.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:59:08.887+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:08.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:59:08.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T06:59:39.354+0000] {processor.py:157} INFO - Started process (PID=47527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:39.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T06:59:39.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:39.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:39.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T06:59:39.388+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:39.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T06:59:39.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T06:59:39.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T06:59:39.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:00:09.826+0000] {processor.py:157} INFO - Started process (PID=47552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:09.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:00:09.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:09.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:09.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:09.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:09.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:00:09.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:09.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:00:09.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T07:00:40.300+0000] {processor.py:157} INFO - Started process (PID=47577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:40.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:00:40.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:40.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:40.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:00:40.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:40.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:00:40.340+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:00:40.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:00:40.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:01:10.744+0000] {processor.py:157} INFO - Started process (PID=47602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:10.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:01:10.749+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:10.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:10.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:10.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:10.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:01:10.799+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:10.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:01:10.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T07:01:41.158+0000] {processor.py:157} INFO - Started process (PID=47627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:41.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:01:41.162+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:41.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:41.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:01:41.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:41.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:01:41.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:01:41.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:01:41.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:02:11.701+0000] {processor.py:157} INFO - Started process (PID=47652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:11.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:02:11.730+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:11.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:11.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:11.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:11.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:02:11.792+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:11.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:02:11.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-27T07:02:42.195+0000] {processor.py:157} INFO - Started process (PID=47677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:42.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:02:42.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:42.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:42.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:02:42.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:42.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:02:42.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:02:42.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:02:42.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T07:03:12.691+0000] {processor.py:157} INFO - Started process (PID=47701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:12.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:03:12.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:12.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:12.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:12.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:12.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:03:12.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:12.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:03:12.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T07:03:43.129+0000] {processor.py:157} INFO - Started process (PID=47727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:43.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:03:43.137+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:43.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:43.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:03:43.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:43.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:03:43.170+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:03:43.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:03:43.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:04:13.517+0000] {processor.py:157} INFO - Started process (PID=47752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:13.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:04:13.522+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:13.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:13.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:13.559+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:13.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:04:13.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:13.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:04:13.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T07:04:44.025+0000] {processor.py:157} INFO - Started process (PID=47777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:44.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:04:44.028+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:44.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:44.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:04:44.058+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:44.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:04:44.068+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:04:44.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:04:44.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T07:05:14.481+0000] {processor.py:157} INFO - Started process (PID=47802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:14.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:05:14.486+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:14.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:14.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:14.521+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:14.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:05:14.533+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:14.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:05:14.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T07:05:44.995+0000] {processor.py:157} INFO - Started process (PID=47827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:44.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:05:45.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:44.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:45.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:05:45.028+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:45.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:05:45.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:05:45.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:05:45.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T07:06:15.388+0000] {processor.py:157} INFO - Started process (PID=47852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:15.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:06:15.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:15.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:15.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:15.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:15.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:06:15.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:15.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:06:15.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T07:06:45.863+0000] {processor.py:157} INFO - Started process (PID=47877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:45.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:06:45.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:45.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:45.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:06:45.893+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:45.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:06:45.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:06:45.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:06:45.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:07:16.283+0000] {processor.py:157} INFO - Started process (PID=47902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:16.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:07:16.289+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:16.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:16.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:16.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:16.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:07:16.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:16.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:07:16.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T07:07:46.772+0000] {processor.py:157} INFO - Started process (PID=47927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:46.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:07:46.775+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:46.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:46.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:07:46.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:46.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:07:46.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:07:46.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:07:46.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T07:08:17.321+0000] {processor.py:157} INFO - Started process (PID=47951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:17.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:08:17.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:17.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:17.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:17.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:17.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:08:17.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:17.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:08:17.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T07:08:47.796+0000] {processor.py:157} INFO - Started process (PID=47977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:47.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:08:47.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:47.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:47.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:08:47.839+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:47.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:08:47.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:08:47.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:08:47.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T07:09:18.226+0000] {processor.py:157} INFO - Started process (PID=48002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:18.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:09:18.232+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:18.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:18.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:18.286+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:18.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:09:18.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:18.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:09:18.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T07:09:48.785+0000] {processor.py:157} INFO - Started process (PID=48027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:48.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:09:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:48.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:48.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:09:48.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:48.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:09:48.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:09:48.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:09:48.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-27T07:10:19.289+0000] {processor.py:157} INFO - Started process (PID=48052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:19.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:10:19.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:19.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:19.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:19.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:19.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:10:19.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:19.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:10:19.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T07:10:49.782+0000] {processor.py:157} INFO - Started process (PID=48077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:49.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:10:49.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:49.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:49.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:10:49.832+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:49.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:10:49.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:10:49.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:10:49.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T07:11:20.265+0000] {processor.py:157} INFO - Started process (PID=48102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:20.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:11:20.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:20.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:20.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:20.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:20.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:11:20.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:20.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:11:20.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:11:50.670+0000] {processor.py:157} INFO - Started process (PID=48127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:50.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:11:50.675+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:50.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:50.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:11:50.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:50.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:11:50.713+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:11:50.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:11:50.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:12:21.099+0000] {processor.py:157} INFO - Started process (PID=48152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:21.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:12:21.103+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:21.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:21.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:21.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:21.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:12:21.163+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:21.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:12:21.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T07:12:51.620+0000] {processor.py:157} INFO - Started process (PID=48177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:51.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:12:51.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:51.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:51.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:12:51.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:51.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:12:51.652+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:12:51.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:12:51.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-27T07:13:22.116+0000] {processor.py:157} INFO - Started process (PID=48202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:22.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:13:22.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:22.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:22.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:22.158+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:22.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:13:22.170+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:22.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:13:22.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:13:52.552+0000] {processor.py:157} INFO - Started process (PID=48227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:52.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:13:52.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:52.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:52.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:13:52.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:52.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:13:52.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:13:52.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:13:52.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:14:22.967+0000] {processor.py:157} INFO - Started process (PID=48252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:22.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:14:22.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:22.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:22.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:23.019+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:23.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:14:23.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:23.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:14:23.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T07:14:53.492+0000] {processor.py:157} INFO - Started process (PID=48277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:53.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:14:53.494+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:53.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:53.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:14:53.522+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:53.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:14:53.535+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:14:53.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:14:53.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T07:15:23.951+0000] {processor.py:157} INFO - Started process (PID=48302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:23.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:15:23.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:23.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:23.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:23.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:23.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:15:24.014+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:24.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:15:24.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T07:15:54.482+0000] {processor.py:157} INFO - Started process (PID=48327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:54.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:15:54.485+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:54.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:54.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:15:54.513+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:54.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:15:54.524+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:15:54.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:15:54.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:16:24.881+0000] {processor.py:157} INFO - Started process (PID=48352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:24.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:16:24.887+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:24.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:24.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:24.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:24.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:16:24.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:24.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:16:24.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T07:16:55.454+0000] {processor.py:157} INFO - Started process (PID=48377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:55.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:16:55.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:55.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:55.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:16:55.487+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:55.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:16:55.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:16:55.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:16:55.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T07:17:25.935+0000] {processor.py:157} INFO - Started process (PID=48402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:25.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:17:25.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:25.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:25.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:25.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:25.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:17:25.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:25.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:17:25.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T07:17:56.413+0000] {processor.py:157} INFO - Started process (PID=48427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:56.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:17:56.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:56.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:56.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:17:56.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:56.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:17:56.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:17:56.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:17:56.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T07:18:26.908+0000] {processor.py:157} INFO - Started process (PID=48452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:26.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:18:26.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:26.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:26.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:26.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:26.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:18:26.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:26.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:18:26.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T07:18:57.376+0000] {processor.py:157} INFO - Started process (PID=48477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:57.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:18:57.380+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:57.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:57.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:18:57.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:57.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:18:57.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:18:57.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:18:57.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T07:19:27.917+0000] {processor.py:157} INFO - Started process (PID=48502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:27.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:19:27.922+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:27.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:27.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:27.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:27.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:19:27.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:27.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:19:27.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T07:19:58.354+0000] {processor.py:157} INFO - Started process (PID=48527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:58.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:19:58.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:58.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:58.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:19:58.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:58.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:19:58.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:19:58.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:19:58.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T07:20:28.871+0000] {processor.py:157} INFO - Started process (PID=48552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:28.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:20:28.876+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:28.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:28.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:28.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:28.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:20:28.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:28.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:20:28.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T07:20:59.359+0000] {processor.py:157} INFO - Started process (PID=48577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:59.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:20:59.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:59.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:59.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:20:59.401+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:59.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:20:59.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:20:59.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:20:59.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T07:21:29.896+0000] {processor.py:157} INFO - Started process (PID=48602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:21:29.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:21:29.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:21:29.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:21:29.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:21:29.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:21:29.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:21:29.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:21:29.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:21:29.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:22:00.327+0000] {processor.py:157} INFO - Started process (PID=48627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:00.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:22:00.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:00.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:00.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:00.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:00.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:22:00.398+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:00.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:22:00.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T07:22:30.804+0000] {processor.py:157} INFO - Started process (PID=48652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:30.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:22:30.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:30.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:30.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:22:30.837+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:30.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:22:30.847+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:22:30.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:22:30.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T07:23:01.288+0000] {processor.py:157} INFO - Started process (PID=48677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:01.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:23:01.294+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:01.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:01.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:01.330+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:01.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:23:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:01.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:23:01.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T07:23:31.722+0000] {processor.py:157} INFO - Started process (PID=48702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:31.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:23:31.725+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:31.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:31.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:23:31.755+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:31.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:23:31.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:23:31.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:23:31.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:24:02.190+0000] {processor.py:157} INFO - Started process (PID=48727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:02.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:24:02.195+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:02.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:02.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:02.221+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:02.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:24:02.231+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:02.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:24:02.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:24:32.550+0000] {processor.py:157} INFO - Started process (PID=48751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:32.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:24:32.555+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:32.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:32.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:24:32.596+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:32.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:24:32.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:24:32.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:24:32.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T07:25:03.036+0000] {processor.py:157} INFO - Started process (PID=48777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:03.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:25:03.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:03.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:03.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:03.069+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:03.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:25:03.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:03.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:25:03.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T07:25:33.438+0000] {processor.py:157} INFO - Started process (PID=48802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:33.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:25:33.443+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:33.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:33.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:25:33.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:33.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:25:33.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:25:33.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:25:33.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:26:03.963+0000] {processor.py:157} INFO - Started process (PID=48827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:03.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:26:03.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:03.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:03.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:03.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:03.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:26:04.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:04.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:26:04.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:26:34.451+0000] {processor.py:157} INFO - Started process (PID=48852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:34.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:26:34.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:34.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:34.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:26:34.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:34.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:26:34.504+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:26:34.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:26:34.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:27:04.912+0000] {processor.py:157} INFO - Started process (PID=48877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:04.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:27:04.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:04.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:04.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:04.978+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:04.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:27:04.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:04.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:27:05.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-27T07:27:35.373+0000] {processor.py:157} INFO - Started process (PID=48902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:35.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:27:35.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:35.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:35.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:27:35.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:35.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:27:35.418+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:27:35.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:27:35.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T07:28:05.879+0000] {processor.py:157} INFO - Started process (PID=48927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:05.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:28:05.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:05.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:05.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:05.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:05.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:28:05.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:05.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:28:05.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T07:28:36.284+0000] {processor.py:157} INFO - Started process (PID=48952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:36.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:28:36.288+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:36.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:36.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:28:36.317+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:36.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:28:36.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:28:36.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:28:36.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:29:06.726+0000] {processor.py:157} INFO - Started process (PID=48977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:06.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:29:06.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:06.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:06.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:06.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:06.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:29:06.766+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:06.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:29:06.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:29:37.257+0000] {processor.py:157} INFO - Started process (PID=49002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:37.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:29:37.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:37.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:37.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:29:37.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:37.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:29:37.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:29:37.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:29:37.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T07:30:07.765+0000] {processor.py:157} INFO - Started process (PID=49027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:07.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:30:07.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:07.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:07.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:07.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:07.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:30:07.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:07.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:30:07.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T07:30:38.268+0000] {processor.py:157} INFO - Started process (PID=49052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:38.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:30:38.272+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:38.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:38.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:30:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:38.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:30:38.312+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:30:38.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:30:38.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T07:31:08.682+0000] {processor.py:157} INFO - Started process (PID=49077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:08.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:31:08.687+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:08.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:08.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:08.725+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:08.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:31:08.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:08.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:31:08.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T07:31:39.117+0000] {processor.py:157} INFO - Started process (PID=49102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:39.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:31:39.122+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:39.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:39.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:31:39.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:39.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:31:39.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:31:39.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:31:39.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:32:09.542+0000] {processor.py:157} INFO - Started process (PID=49127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:09.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:32:09.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:09.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:09.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:09.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:32:09.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:09.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:32:09.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T07:32:40.061+0000] {processor.py:157} INFO - Started process (PID=49151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:40.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:32:40.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:40.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:40.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:32:40.107+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:40.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:32:40.132+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:32:40.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:32:40.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T07:33:10.520+0000] {processor.py:157} INFO - Started process (PID=49177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:10.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:33:10.522+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:10.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:10.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:10.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:10.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:33:10.555+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:10.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:33:10.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T07:33:40.929+0000] {processor.py:157} INFO - Started process (PID=49202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:40.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:33:40.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:40.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:40.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:33:40.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:40.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:33:41.012+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:33:41.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:33:41.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T07:34:11.459+0000] {processor.py:157} INFO - Started process (PID=49227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:11.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:34:11.464+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:11.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:11.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:11.493+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:11.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:34:11.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:11.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:34:11.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T07:34:41.930+0000] {processor.py:157} INFO - Started process (PID=49252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:41.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:34:41.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:41.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:41.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:34:41.978+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:41.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:34:41.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:34:41.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:34:41.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T07:35:12.462+0000] {processor.py:157} INFO - Started process (PID=49277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:12.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:35:12.469+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:12.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:12.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:12.495+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:12.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:35:12.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:12.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:35:12.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:35:42.814+0000] {processor.py:157} INFO - Started process (PID=49302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:42.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:35:42.817+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:42.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:42.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:35:42.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:42.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:35:42.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:35:42.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:35:42.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:36:13.294+0000] {processor.py:157} INFO - Started process (PID=49327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:13.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:36:13.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:13.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:13.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:13.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:13.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:36:13.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:13.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:36:13.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T07:36:43.760+0000] {processor.py:157} INFO - Started process (PID=49352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:43.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:36:43.763+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:43.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:43.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:36:43.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:43.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:36:43.791+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:36:43.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:36:43.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T07:37:14.313+0000] {processor.py:157} INFO - Started process (PID=49377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:14.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:37:14.321+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:14.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:14.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:14.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:14.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:37:14.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:14.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:37:14.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-27T07:37:44.819+0000] {processor.py:157} INFO - Started process (PID=49402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:44.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:37:44.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:44.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:44.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:37:44.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:44.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:37:44.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:37:44.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:37:44.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T07:38:15.206+0000] {processor.py:157} INFO - Started process (PID=49426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:15.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:38:15.212+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:15.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:15.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:15.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:15.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:38:15.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:15.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:38:15.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T07:38:45.747+0000] {processor.py:157} INFO - Started process (PID=49452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:45.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:38:45.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:45.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:45.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:38:45.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:45.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:38:45.801+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:38:45.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:38:45.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:39:16.259+0000] {processor.py:157} INFO - Started process (PID=49477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:16.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:39:16.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:16.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:16.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:16.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:16.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:39:16.319+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:16.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:39:16.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T07:39:46.887+0000] {processor.py:157} INFO - Started process (PID=49502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:46.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:39:46.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:46.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:46.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:39:46.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:46.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:39:46.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:39:46.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:39:46.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T07:40:17.370+0000] {processor.py:157} INFO - Started process (PID=49527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:17.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:40:17.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:17.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:17.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:17.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:17.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:40:17.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:17.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:40:17.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T07:40:47.871+0000] {processor.py:157} INFO - Started process (PID=49552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:47.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:40:47.873+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:47.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:47.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:40:47.897+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:47.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:40:47.914+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:40:47.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:40:47.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T07:41:18.263+0000] {processor.py:157} INFO - Started process (PID=49577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:18.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:41:18.269+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:18.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:18.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:18.300+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:18.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:41:18.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:18.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:41:18.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T07:41:48.795+0000] {processor.py:157} INFO - Started process (PID=49602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:48.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:41:48.800+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:48.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:48.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:41:48.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:48.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:41:48.852+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:41:48.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:41:48.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T07:42:19.236+0000] {processor.py:157} INFO - Started process (PID=49627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:19.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:42:19.242+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:19.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:19.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:19.269+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:19.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:42:19.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:19.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:42:19.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:42:49.715+0000] {processor.py:157} INFO - Started process (PID=49652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:49.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:42:49.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:49.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:49.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:42:49.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:49.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:42:49.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:42:49.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:42:49.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T07:43:20.182+0000] {processor.py:157} INFO - Started process (PID=49677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:20.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:43:20.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:20.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:20.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:20.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:20.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:43:20.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:20.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:43:20.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T07:43:50.710+0000] {processor.py:157} INFO - Started process (PID=49702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:50.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:43:50.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:50.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:50.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:43:50.753+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:50.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:43:50.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:43:50.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:43:50.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:44:21.179+0000] {processor.py:157} INFO - Started process (PID=49727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:21.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:44:21.181+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:21.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:21.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:21.212+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:21.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:44:21.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:21.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:44:21.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:44:51.775+0000] {processor.py:157} INFO - Started process (PID=49752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:51.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:44:51.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:51.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:51.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:44:51.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:51.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:44:51.897+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:44:51.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:44:51.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-27T07:45:22.374+0000] {processor.py:157} INFO - Started process (PID=49777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:22.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:45:22.386+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:22.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:22.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:22.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:22.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:45:22.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:22.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:45:22.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-27T07:45:52.977+0000] {processor.py:157} INFO - Started process (PID=49802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:52.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:45:52.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:52.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:53.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:45:53.028+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:53.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:45:53.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:45:53.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:45:53.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T07:46:23.456+0000] {processor.py:157} INFO - Started process (PID=49827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:23.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:46:23.462+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:23.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:23.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:23.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:23.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:46:23.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:23.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:46:23.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T07:46:53.943+0000] {processor.py:157} INFO - Started process (PID=49852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:53.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:46:53.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:53.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:53.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:46:54.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:54.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:46:54.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:46:54.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:46:54.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T07:47:24.420+0000] {processor.py:157} INFO - Started process (PID=49877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:24.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:47:24.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:24.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:24.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:24.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:47:24.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:24.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:47:24.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T07:47:54.852+0000] {processor.py:157} INFO - Started process (PID=49902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:54.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:47:54.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:54.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:54.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:47:54.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:54.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:47:54.924+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:47:54.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:47:54.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T07:48:25.375+0000] {processor.py:157} INFO - Started process (PID=49927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:25.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:48:25.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:25.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:25.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:25.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:25.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:48:25.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:25.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:48:25.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T07:48:55.827+0000] {processor.py:157} INFO - Started process (PID=49952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:55.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:48:55.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:55.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:55.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:48:55.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:55.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:48:55.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:48:55.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:48:55.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T07:49:26.334+0000] {processor.py:157} INFO - Started process (PID=49977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:26.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:49:26.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:26.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:26.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:26.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:26.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:49:26.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:26.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:49:26.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T07:49:56.766+0000] {processor.py:157} INFO - Started process (PID=50002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:56.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:49:56.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:56.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:56.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:49:56.799+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:56.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:49:56.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:49:56.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:49:56.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T07:50:27.245+0000] {processor.py:157} INFO - Started process (PID=50026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:27.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:50:27.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:27.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:27.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:27.311+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:27.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:50:27.324+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:27.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:50:27.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T07:50:57.673+0000] {processor.py:157} INFO - Started process (PID=50052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:57.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:50:57.676+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:57.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:57.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:50:57.706+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:57.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:50:57.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:50:57.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:50:57.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T07:51:28.115+0000] {processor.py:157} INFO - Started process (PID=50077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:28.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:51:28.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:28.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:28.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:28.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:28.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:51:28.172+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:28.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:51:28.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T07:51:58.575+0000] {processor.py:157} INFO - Started process (PID=50102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:58.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:51:58.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:58.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:58.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:51:58.615+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:58.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:51:58.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:51:58.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:51:58.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T07:52:29.083+0000] {processor.py:157} INFO - Started process (PID=50127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:29.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:52:29.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:29.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:29.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:29.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:29.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:52:29.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:29.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:52:29.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T07:52:59.573+0000] {processor.py:157} INFO - Started process (PID=50152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:59.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:52:59.577+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:59.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:59.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:52:59.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:59.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:52:59.630+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:52:59.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:52:59.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T07:53:30.024+0000] {processor.py:157} INFO - Started process (PID=50177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:53:30.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:53:30.038+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:53:30.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:53:30.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:53:30.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:53:30.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:53:30.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:53:30.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:53:30.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T07:54:00.544+0000] {processor.py:157} INFO - Started process (PID=50202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:00.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:54:00.551+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:00.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:00.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:00.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:00.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:54:00.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:00.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:54:00.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T07:54:31.143+0000] {processor.py:157} INFO - Started process (PID=50227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:31.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:54:31.152+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:31.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:31.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:54:31.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:31.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:54:31.212+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:54:31.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:54:31.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T07:55:01.657+0000] {processor.py:157} INFO - Started process (PID=50252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:01.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:55:01.663+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:01.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:01.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:01.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:01.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:55:01.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:01.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:55:01.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T07:55:32.166+0000] {processor.py:157} INFO - Started process (PID=50277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:32.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:55:32.169+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:32.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:32.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:55:32.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:32.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:55:32.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:55:32.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:55:32.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T07:56:02.605+0000] {processor.py:157} INFO - Started process (PID=50302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:02.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:56:02.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:02.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:02.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:02.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:02.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:56:02.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:02.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:56:02.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T07:56:33.092+0000] {processor.py:157} INFO - Started process (PID=50327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:33.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:56:33.097+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:33.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:33.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:56:33.138+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:33.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:56:33.152+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:56:33.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:56:33.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T07:57:03.613+0000] {processor.py:157} INFO - Started process (PID=50352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:03.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:57:03.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:03.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:03.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:03.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:03.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:57:03.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:03.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:57:03.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T07:57:34.000+0000] {processor.py:157} INFO - Started process (PID=50376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:34.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:57:34.004+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:34.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:34.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:57:34.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:34.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:57:34.051+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:57:34.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:57:34.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T07:58:04.645+0000] {processor.py:157} INFO - Started process (PID=50401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:04.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:58:04.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:04.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:04.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:04.727+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:04.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:58:04.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:04.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:58:04.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-27T07:58:35.250+0000] {processor.py:157} INFO - Started process (PID=50427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:35.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:58:35.262+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:35.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:35.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:58:35.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:35.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:58:35.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:58:35.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:58:35.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-27T07:59:06.105+0000] {processor.py:157} INFO - Started process (PID=50451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:06.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:59:06.112+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:06.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:06.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:06.178+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:06.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:59:06.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:06.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:59:06.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-27T07:59:36.956+0000] {processor.py:157} INFO - Started process (PID=50477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:36.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T07:59:36.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:36.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:36.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T07:59:37.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:37.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T07:59:37.055+0000] {logging_mixin.py:151} INFO - [2024-07-27T07:59:37.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T07:59:37.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-27T08:00:07.321+0000] {processor.py:157} INFO - Started process (PID=50502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:07.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:00:07.328+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:07.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:07.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:07.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:07.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:00:07.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:07.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:00:07.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-27T08:00:37.806+0000] {processor.py:157} INFO - Started process (PID=50527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:37.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:00:37.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:37.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:37.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:00:37.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:37.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:00:37.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:00:37.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:00:37.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-27T08:01:08.340+0000] {processor.py:157} INFO - Started process (PID=50552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:08.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:01:08.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:08.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:08.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:08.421+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:08.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:01:08.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:08.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:01:08.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-27T08:01:38.961+0000] {processor.py:157} INFO - Started process (PID=50577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:38.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:01:38.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:38.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:39.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:01:39.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:39.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:01:39.072+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:01:39.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:01:39.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-07-27T08:02:09.582+0000] {processor.py:157} INFO - Started process (PID=50602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:09.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:02:09.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:09.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:09.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:09.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:09.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:02:09.648+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:09.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:02:09.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T08:02:40.063+0000] {processor.py:157} INFO - Started process (PID=50627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:40.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:02:40.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:40.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:40.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:02:40.098+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:40.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:02:40.108+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:02:40.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:02:40.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T08:03:10.482+0000] {processor.py:157} INFO - Started process (PID=50652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:10.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:03:10.487+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:10.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:10.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:10.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:10.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:03:10.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:10.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:03:10.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-27T08:03:41.297+0000] {processor.py:157} INFO - Started process (PID=50677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:41.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:03:41.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:41.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:03:41.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:41.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:03:41.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:03:41.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:03:41.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T08:04:11.759+0000] {processor.py:157} INFO - Started process (PID=50702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:11.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:04:11.774+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:11.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:11.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:11.893+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:11.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:04:11.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:11.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:04:11.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-07-27T08:04:42.152+0000] {processor.py:157} INFO - Started process (PID=50727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:42.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:04:42.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:42.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:42.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:04:42.203+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:42.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:04:42.219+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:04:42.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:04:42.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T08:05:12.627+0000] {processor.py:157} INFO - Started process (PID=50752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:12.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:05:12.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:12.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:12.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:12.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:12.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:05:12.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:12.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:05:12.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T08:05:43.069+0000] {processor.py:157} INFO - Started process (PID=50777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:43.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:05:43.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:43.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:43.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:05:43.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:43.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:05:43.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:05:43.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:05:43.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T08:06:13.476+0000] {processor.py:157} INFO - Started process (PID=50802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:13.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:06:13.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:13.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:13.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:13.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:13.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:06:13.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:13.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:06:13.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T08:06:43.907+0000] {processor.py:157} INFO - Started process (PID=50827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:43.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:06:43.916+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:43.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:43.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:06:44.010+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:44.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:06:44.031+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:06:44.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:06:44.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-27T08:07:14.368+0000] {processor.py:157} INFO - Started process (PID=50852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:14.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:07:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:14.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:14.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:14.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:14.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:07:14.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:14.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:07:14.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T08:07:44.864+0000] {processor.py:157} INFO - Started process (PID=50877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:44.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:07:44.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:44.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:44.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:07:44.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:44.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:07:44.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:07:44.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:07:44.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-27T08:08:15.345+0000] {processor.py:157} INFO - Started process (PID=50902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:15.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:08:15.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:15.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:15.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:15.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:15.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:08:15.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:15.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:08:15.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-07-27T08:08:45.812+0000] {processor.py:157} INFO - Started process (PID=50927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:45.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:08:45.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:45.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:45.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:08:45.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:45.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:08:45.939+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:08:45.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:08:45.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-27T08:09:16.326+0000] {processor.py:157} INFO - Started process (PID=50952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:16.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:09:16.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:16.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:16.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:16.432+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:16.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:09:16.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:16.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:09:16.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-27T08:09:46.764+0000] {processor.py:157} INFO - Started process (PID=50977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:46.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:09:46.778+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:46.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:46.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:09:46.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:46.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:09:46.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:09:46.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:09:46.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-27T08:10:17.225+0000] {processor.py:157} INFO - Started process (PID=51002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:17.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:10:17.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:17.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:17.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:17.280+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:17.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:10:17.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:17.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:10:17.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T08:10:47.609+0000] {processor.py:157} INFO - Started process (PID=51027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:47.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:10:47.615+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:47.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:47.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:10:47.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:47.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:10:47.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:10:47.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:10:47.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-27T08:11:17.984+0000] {processor.py:157} INFO - Started process (PID=51052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:17.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:11:17.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:17.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:18.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:18.052+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:18.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:11:18.065+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:18.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:11:18.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T08:11:48.422+0000] {processor.py:157} INFO - Started process (PID=51077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:48.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:11:48.426+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:48.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:48.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:11:48.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:48.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:11:48.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:11:48.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:11:48.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T08:12:18.897+0000] {processor.py:157} INFO - Started process (PID=51102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:18.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:12:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:18.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:18.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:18.965+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:18.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:12:18.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:18.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:12:19.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-27T08:12:49.302+0000] {processor.py:157} INFO - Started process (PID=51127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:49.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:12:49.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:49.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:49.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:12:49.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:49.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:12:49.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:12:49.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:12:49.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T08:13:19.617+0000] {processor.py:157} INFO - Started process (PID=51151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:19.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:13:19.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:19.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:19.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:19.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:19.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:13:19.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:19.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:13:19.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T08:13:50.031+0000] {processor.py:157} INFO - Started process (PID=51177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:50.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:13:50.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:50.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:50.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:13:50.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:50.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:13:50.090+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:13:50.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:13:50.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T08:14:20.445+0000] {processor.py:157} INFO - Started process (PID=51202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:20.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:14:20.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:20.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:20.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:20.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:20.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:14:20.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:20.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:14:20.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T08:14:50.900+0000] {processor.py:157} INFO - Started process (PID=51227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:50.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:14:50.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:50.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:50.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:14:50.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:50.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:14:50.980+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:14:50.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:14:50.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-27T08:15:21.272+0000] {processor.py:157} INFO - Started process (PID=51252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:21.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:15:21.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:21.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:21.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:21.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:21.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:15:21.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:21.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:15:21.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T08:15:51.642+0000] {processor.py:157} INFO - Started process (PID=51277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:51.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:15:51.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:51.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:51.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:15:51.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:51.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:15:51.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:15:51.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:15:51.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T08:16:22.109+0000] {processor.py:157} INFO - Started process (PID=51302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:22.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:16:22.113+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:22.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:22.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:22.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:22.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:16:22.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:22.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:16:22.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:16:52.541+0000] {processor.py:157} INFO - Started process (PID=51327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:52.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:16:52.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:52.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:52.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:16:52.612+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:52.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:16:52.627+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:16:52.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:16:52.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-27T08:17:23.024+0000] {processor.py:157} INFO - Started process (PID=51351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:23.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:17:23.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:23.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:23.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:23.057+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:23.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:17:23.068+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:23.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:17:23.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T08:17:53.436+0000] {processor.py:157} INFO - Started process (PID=51377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:53.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:17:53.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:53.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:53.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:17:53.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:53.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:17:53.510+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:17:53.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:17:53.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T08:18:23.769+0000] {processor.py:157} INFO - Started process (PID=51402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:23.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:18:23.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:23.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:23.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:23.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:23.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:18:23.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:23.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:18:23.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T08:18:54.186+0000] {processor.py:157} INFO - Started process (PID=51427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:54.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:18:54.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:54.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:54.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:18:54.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:54.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:18:54.271+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:18:54.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:18:54.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T08:19:24.570+0000] {processor.py:157} INFO - Started process (PID=51452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:24.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:19:24.582+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:24.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:24.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:24.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:24.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:19:24.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:24.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:19:24.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T08:19:55.467+0000] {processor.py:157} INFO - Started process (PID=51477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:55.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:19:55.487+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:55.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:55.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:19:55.574+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:55.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:19:55.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:19:55.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:19:55.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-27T08:20:25.810+0000] {processor.py:157} INFO - Started process (PID=51501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:25.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:20:25.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:25.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:25.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:25.853+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:25.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:20:25.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:25.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:20:25.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T08:20:56.240+0000] {processor.py:157} INFO - Started process (PID=51527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:56.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:20:56.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:56.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:56.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:20:56.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:56.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:20:56.335+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:20:56.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:20:57.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.959 seconds
[2024-07-27T08:21:27.742+0000] {processor.py:157} INFO - Started process (PID=51552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:27.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:21:27.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:27.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:27.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:27.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:27.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:21:27.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:27.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:21:27.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-27T08:21:58.277+0000] {processor.py:157} INFO - Started process (PID=51577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:58.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:21:58.283+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:58.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:58.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:21:58.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:58.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:21:58.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:21:58.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:21:58.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T08:22:28.772+0000] {processor.py:157} INFO - Started process (PID=51602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:28.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:22:28.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:28.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:28.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:28.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:28.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:22:28.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:28.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:22:28.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T08:22:59.316+0000] {processor.py:157} INFO - Started process (PID=51627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:59.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:22:59.328+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:59.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:59.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:22:59.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:59.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:22:59.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:22:59.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:22:59.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-27T08:23:30.130+0000] {processor.py:157} INFO - Started process (PID=51651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:23:30.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:23:30.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:23:30.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:23:30.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:23:30.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:23:30.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:23:30.257+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:23:30.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:23:30.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-27T08:24:00.674+0000] {processor.py:157} INFO - Started process (PID=51677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:00.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:24:00.681+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:00.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:00.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:00.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:00.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:24:00.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:00.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:24:00.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T08:24:31.174+0000] {processor.py:157} INFO - Started process (PID=51702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:31.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:24:31.178+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:31.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:31.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:24:31.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:31.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:24:31.254+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:24:31.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:24:31.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T08:25:01.709+0000] {processor.py:157} INFO - Started process (PID=51727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:01.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:25:01.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:01.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:01.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:01.755+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:01.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:25:01.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:01.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:25:01.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T08:25:32.146+0000] {processor.py:157} INFO - Started process (PID=51752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:32.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:25:32.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:32.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:32.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:25:32.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:32.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:25:32.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:25:32.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:25:32.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-27T08:26:02.816+0000] {processor.py:157} INFO - Started process (PID=51777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:02.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:26:02.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:02.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:02.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:02.872+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:02.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:26:02.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:02.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:26:02.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T08:26:33.195+0000] {processor.py:157} INFO - Started process (PID=51802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:33.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:26:33.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:33.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:33.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:26:33.241+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:33.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:26:33.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:26:33.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:26:33.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T08:27:04.242+0000] {processor.py:157} INFO - Started process (PID=51827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:04.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:27:04.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:04.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:04.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:04.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:04.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:27:04.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:04.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:27:04.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-27T08:27:34.829+0000] {processor.py:157} INFO - Started process (PID=51852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:34.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:27:34.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:34.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:34.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:27:34.902+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:34.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:27:34.921+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:27:34.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:27:34.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-27T08:28:05.402+0000] {processor.py:157} INFO - Started process (PID=51877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:05.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:28:05.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:05.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:05.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:05.456+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:05.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:28:05.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:05.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:28:05.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T08:28:35.860+0000] {processor.py:157} INFO - Started process (PID=51902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:35.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:28:35.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:35.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:35.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:28:35.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:35.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:28:35.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:28:35.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:28:35.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T08:29:06.252+0000] {processor.py:157} INFO - Started process (PID=51926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:06.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:29:06.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:06.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:06.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:06.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:06.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:29:06.319+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:06.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:29:06.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T08:29:36.722+0000] {processor.py:157} INFO - Started process (PID=51951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:36.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:29:36.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:36.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:36.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:29:36.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:36.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:29:36.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:29:36.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:29:37.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.297 seconds
[2024-07-27T08:30:07.573+0000] {processor.py:157} INFO - Started process (PID=51977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:07.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:30:07.577+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:07.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:07.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:07.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:07.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:30:07.628+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:07.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:30:07.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T08:30:37.948+0000] {processor.py:157} INFO - Started process (PID=52002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:37.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:30:37.950+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:37.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:37.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:30:37.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:37.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:30:37.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:30:37.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:30:38.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T08:31:08.376+0000] {processor.py:157} INFO - Started process (PID=52027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:08.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:31:08.395+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:08.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:08.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:08.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:08.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:31:08.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:08.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:31:08.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T08:31:38.867+0000] {processor.py:157} INFO - Started process (PID=52052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:38.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:31:38.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:38.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:38.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:31:38.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:38.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:31:38.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:31:38.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:31:38.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:32:09.294+0000] {processor.py:157} INFO - Started process (PID=52077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:09.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:32:09.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:09.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:09.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:09.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:09.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:32:09.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:09.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:32:09.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T08:32:39.777+0000] {processor.py:157} INFO - Started process (PID=52102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:39.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:32:39.780+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:39.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:39.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:32:39.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:39.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:32:39.817+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:32:39.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:32:39.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T08:33:10.319+0000] {processor.py:157} INFO - Started process (PID=52127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:10.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:33:10.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:10.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:10.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:10.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:10.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:33:10.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:10.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:33:10.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T08:33:40.795+0000] {processor.py:157} INFO - Started process (PID=52152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:40.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:33:40.803+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:40.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:40.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:33:40.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:40.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:33:40.853+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:33:40.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:33:40.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T08:34:11.262+0000] {processor.py:157} INFO - Started process (PID=52177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:11.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:34:11.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:11.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:11.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:11.293+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:11.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:34:11.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:11.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:34:11.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T08:34:41.888+0000] {processor.py:157} INFO - Started process (PID=52202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:41.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:34:41.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:41.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:41.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:34:41.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:41.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:34:41.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:34:41.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:34:41.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T08:35:12.316+0000] {processor.py:157} INFO - Started process (PID=52227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:12.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:35:12.319+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:12.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:12.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:12.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:12.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:35:12.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:12.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:35:12.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-27T08:35:42.918+0000] {processor.py:157} INFO - Started process (PID=52252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:42.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:35:42.922+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:42.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:42.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:35:42.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:42.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:35:42.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:35:42.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:35:42.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T08:36:13.333+0000] {processor.py:157} INFO - Started process (PID=52277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:13.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:36:13.336+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:13.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:13.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:13.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:13.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:36:13.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:13.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:36:13.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T08:36:43.785+0000] {processor.py:157} INFO - Started process (PID=52302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:43.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:36:43.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:43.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:43.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:36:43.817+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:43.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:36:43.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:36:43.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:36:43.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:37:14.231+0000] {processor.py:157} INFO - Started process (PID=52327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:14.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:37:14.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:14.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:14.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:14.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:14.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:37:14.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:14.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:37:14.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T08:37:44.679+0000] {processor.py:157} INFO - Started process (PID=52352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:44.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:37:44.681+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:44.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:44.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:37:44.719+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:44.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:37:44.730+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:37:44.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:37:44.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T08:38:15.145+0000] {processor.py:157} INFO - Started process (PID=52377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:15.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:38:15.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:15.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:15.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:15.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:15.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:38:15.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:15.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:38:15.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-07-27T08:38:45.859+0000] {processor.py:157} INFO - Started process (PID=52402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:45.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:38:45.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:45.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:45.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:38:45.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:45.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:38:45.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:38:45.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:38:45.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T08:39:16.279+0000] {processor.py:157} INFO - Started process (PID=52426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:16.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:39:16.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:16.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:16.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:16.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:16.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:39:16.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:16.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:39:16.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-27T08:39:46.712+0000] {processor.py:157} INFO - Started process (PID=52452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:46.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:39:46.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:46.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:46.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:39:46.744+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:46.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:39:46.758+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:39:46.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:39:46.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T08:40:17.143+0000] {processor.py:157} INFO - Started process (PID=52477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:17.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:40:17.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:17.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:17.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:17.172+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:17.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:40:17.181+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:17.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:40:17.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T08:40:47.526+0000] {processor.py:157} INFO - Started process (PID=52502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:47.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:40:47.530+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:47.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:47.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:40:47.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:47.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:40:47.566+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:40:47.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:40:47.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T08:41:18.007+0000] {processor.py:157} INFO - Started process (PID=52527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:18.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:41:18.010+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:18.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:18.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:18.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:18.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:41:18.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:18.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:41:18.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T08:41:48.506+0000] {processor.py:157} INFO - Started process (PID=52552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:48.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:41:48.509+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:48.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:48.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:41:48.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:48.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:41:48.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:41:48.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:41:48.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T08:42:18.902+0000] {processor.py:157} INFO - Started process (PID=52577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:42:18.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:18.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:18.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:18.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:18.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:42:18.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:18.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:42:18.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:42:49.328+0000] {processor.py:157} INFO - Started process (PID=52602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:49.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:42:49.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:49.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:49.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:42:49.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:49.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:42:49.386+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:42:49.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:42:49.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T08:43:19.822+0000] {processor.py:157} INFO - Started process (PID=52627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:19.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:43:19.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:19.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:19.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:19.853+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:19.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:43:19.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:19.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:43:19.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T08:43:50.243+0000] {processor.py:157} INFO - Started process (PID=52652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:50.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:43:50.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:50.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:50.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:43:50.272+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:50.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:43:50.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:43:50.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:43:50.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-07-27T08:44:20.853+0000] {processor.py:157} INFO - Started process (PID=52677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:20.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:44:20.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:20.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:20.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:20.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:20.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:44:20.960+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:20.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:44:20.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-27T08:44:51.361+0000] {processor.py:157} INFO - Started process (PID=52702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:51.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:44:51.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:51.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:51.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:44:51.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:51.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:44:51.404+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:44:51.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:44:51.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:45:21.799+0000] {processor.py:157} INFO - Started process (PID=52727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:21.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:45:21.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:21.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:21.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:21.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:21.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:45:21.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:21.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:45:21.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T08:45:52.267+0000] {processor.py:157} INFO - Started process (PID=52752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:52.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:45:52.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:52.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:52.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:45:52.298+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:52.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:45:52.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:45:52.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:45:52.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T08:46:22.641+0000] {processor.py:157} INFO - Started process (PID=52777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:22.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:46:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:22.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:22.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:22.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:22.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:46:22.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:22.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:46:22.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-27T08:46:53.048+0000] {processor.py:157} INFO - Started process (PID=52802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:53.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:46:53.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:53.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:53.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:46:53.093+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:53.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:46:53.109+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:46:53.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:46:53.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-27T08:47:23.715+0000] {processor.py:157} INFO - Started process (PID=52827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:23.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:47:23.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:23.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:23.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:23.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:23.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:47:23.753+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:23.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:47:23.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T08:47:54.200+0000] {processor.py:157} INFO - Started process (PID=52852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:54.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:47:54.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:54.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:54.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:47:54.279+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:54.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:47:54.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:47:54.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:47:54.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-27T08:48:24.790+0000] {processor.py:157} INFO - Started process (PID=52877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:24.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:48:24.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:24.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:24.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:24.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:24.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:48:24.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:24.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:48:24.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T08:48:55.265+0000] {processor.py:157} INFO - Started process (PID=52902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:55.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:48:55.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:55.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:55.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:48:55.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:55.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:48:55.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:48:55.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:48:55.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T08:49:25.675+0000] {processor.py:157} INFO - Started process (PID=52927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:25.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:49:25.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:25.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:25.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:25.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:25.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:49:25.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:25.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:49:25.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-27T08:49:56.370+0000] {processor.py:157} INFO - Started process (PID=52952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:56.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:49:56.373+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:56.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:56.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:49:56.405+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:56.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:49:56.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:49:56.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:49:56.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-27T08:50:26.987+0000] {processor.py:157} INFO - Started process (PID=52977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:26.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:50:26.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:26.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:27.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:27.017+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:27.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:50:27.026+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:27.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:50:27.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T08:50:57.406+0000] {processor.py:157} INFO - Started process (PID=53002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:57.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:50:57.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:57.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:57.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:50:57.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:57.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:50:57.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:50:57.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:50:57.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T08:51:27.849+0000] {processor.py:157} INFO - Started process (PID=53027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:27.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:51:27.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:27.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:27.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:27.881+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:27.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:51:27.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:27.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:51:27.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T08:51:58.278+0000] {processor.py:157} INFO - Started process (PID=53052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:58.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:51:58.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:58.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:58.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:51:58.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:58.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:51:58.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:51:58.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:51:58.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T08:52:28.707+0000] {processor.py:157} INFO - Started process (PID=53077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:28.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:52:28.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:28.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:28.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:28.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:28.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:52:28.754+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:28.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:52:28.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-27T08:52:59.274+0000] {processor.py:157} INFO - Started process (PID=53102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:59.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:52:59.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:59.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:59.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:52:59.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:59.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:52:59.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:52:59.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:52:59.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-27T08:53:29.867+0000] {processor.py:157} INFO - Started process (PID=53127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:53:29.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:53:29.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:53:29.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:53:29.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:53:29.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:53:29.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:53:29.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:53:29.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:53:29.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T08:54:00.243+0000] {processor.py:157} INFO - Started process (PID=53152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:00.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:54:00.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:00.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:00.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:00.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:00.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:54:00.289+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:00.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:54:00.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T08:54:30.756+0000] {processor.py:157} INFO - Started process (PID=53177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:30.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:54:30.764+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:30.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:30.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:54:30.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:30.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:54:30.820+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:54:30.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:54:30.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T08:55:01.155+0000] {processor.py:157} INFO - Started process (PID=53202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:01.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:55:01.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:01.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:01.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:01.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:01.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:55:01.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:01.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:55:01.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T08:55:31.627+0000] {processor.py:157} INFO - Started process (PID=53227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:31.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:55:31.631+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:31.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:31.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:55:31.658+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:31.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:55:31.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:55:31.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:55:31.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-07-27T08:56:02.354+0000] {processor.py:157} INFO - Started process (PID=53252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:02.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:56:02.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:02.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:02.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:02.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:02.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:56:02.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:02.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:56:02.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T08:56:32.753+0000] {processor.py:157} INFO - Started process (PID=53277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:32.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:56:32.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:32.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:32.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:56:32.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:32.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:56:32.806+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:56:32.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:56:32.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T08:57:03.192+0000] {processor.py:157} INFO - Started process (PID=53302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:03.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:57:03.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:03.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:03.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:03.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:03.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:57:03.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:03.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:57:03.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T08:57:33.616+0000] {processor.py:157} INFO - Started process (PID=53327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:33.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:57:33.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:33.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:33.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:57:33.647+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:33.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:57:33.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:57:33.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:57:33.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T08:58:04.076+0000] {processor.py:157} INFO - Started process (PID=53352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:04.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:58:04.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:04.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:04.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:04.106+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:04.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:58:04.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:04.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:58:04.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-27T08:58:34.589+0000] {processor.py:157} INFO - Started process (PID=53377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:34.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:58:34.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:34.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:34.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:58:34.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:34.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:58:34.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:58:34.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:58:34.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-27T08:59:05.214+0000] {processor.py:157} INFO - Started process (PID=53402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:05.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:59:05.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:05.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:05.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:05.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:05.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:59:05.252+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:05.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:59:05.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T08:59:35.625+0000] {processor.py:157} INFO - Started process (PID=53427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:35.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T08:59:35.628+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:35.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:35.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T08:59:35.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:35.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T08:59:35.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T08:59:35.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T08:59:35.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T09:00:06.094+0000] {processor.py:157} INFO - Started process (PID=53452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:06.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:00:06.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:06.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:06.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:06.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:06.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:00:06.135+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:06.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:00:06.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:00:36.487+0000] {processor.py:157} INFO - Started process (PID=53477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:36.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:00:36.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:36.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:36.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:00:36.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:36.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:00:36.540+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:00:36.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:00:36.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T09:01:06.927+0000] {processor.py:157} INFO - Started process (PID=53502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:06.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:01:06.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:06.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:06.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:06.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:06.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:01:06.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:06.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:01:07.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-27T09:01:37.494+0000] {processor.py:157} INFO - Started process (PID=53527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:37.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:01:37.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:37.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:37.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:01:37.526+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:37.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:01:37.637+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:01:37.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:01:37.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-27T09:02:08.104+0000] {processor.py:157} INFO - Started process (PID=53552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:08.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:02:08.107+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:08.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:08.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:08.135+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:08.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:02:08.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:08.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:02:08.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:02:38.449+0000] {processor.py:157} INFO - Started process (PID=53577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:38.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:02:38.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:38.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:38.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:02:38.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:38.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:02:38.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:02:38.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:02:38.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T09:03:08.915+0000] {processor.py:157} INFO - Started process (PID=53602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:08.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:03:08.922+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:08.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:08.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:08.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:08.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:03:08.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:08.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:03:08.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T09:03:39.410+0000] {processor.py:157} INFO - Started process (PID=53627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:39.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:03:39.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:39.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:39.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:03:39.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:39.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:03:39.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:03:39.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:03:39.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:04:09.904+0000] {processor.py:157} INFO - Started process (PID=53652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:09.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:04:09.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:09.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:09.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:09.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:09.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:04:10.043+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:10.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:04:10.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-27T09:04:40.491+0000] {processor.py:157} INFO - Started process (PID=53677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:40.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:04:40.494+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:40.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:40.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:04:40.521+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:40.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:04:40.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:04:40.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:04:40.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T09:05:10.926+0000] {processor.py:157} INFO - Started process (PID=53702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:10.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:05:10.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:10.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:10.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:10.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:05:10.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:10.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:05:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T09:05:41.329+0000] {processor.py:157} INFO - Started process (PID=53727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:41.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:05:41.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:41.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:41.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:05:41.359+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:41.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:05:41.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:05:41.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:05:41.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T09:06:11.757+0000] {processor.py:157} INFO - Started process (PID=53752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:11.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:06:11.760+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:11.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:11.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:11.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:11.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:06:11.798+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:11.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:06:11.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T09:06:42.222+0000] {processor.py:157} INFO - Started process (PID=53777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:42.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:06:42.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:42.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:42.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:06:42.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:42.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:06:42.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:06:42.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:06:42.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-27T09:07:12.751+0000] {processor.py:157} INFO - Started process (PID=53802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:12.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:07:12.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:12.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:12.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:12.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:12.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:07:12.861+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:12.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:07:12.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T09:07:43.373+0000] {processor.py:157} INFO - Started process (PID=53827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:43.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:07:43.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:43.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:43.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:07:43.403+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:43.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:07:43.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:07:43.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:07:43.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T09:08:13.799+0000] {processor.py:157} INFO - Started process (PID=53852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:13.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:08:13.804+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:13.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:13.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:13.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:13.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:08:13.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:13.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:08:13.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T09:08:44.260+0000] {processor.py:157} INFO - Started process (PID=53877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:44.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:08:44.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:44.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:44.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:08:44.300+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:44.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:08:44.313+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:08:44.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:08:44.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T09:09:14.703+0000] {processor.py:157} INFO - Started process (PID=53902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:14.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:09:14.707+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:14.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:14.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:14.726+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:14.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:09:14.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:14.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:09:14.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T09:09:45.206+0000] {processor.py:157} INFO - Started process (PID=53927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:45.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:09:45.211+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:45.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:45.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:09:45.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:45.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:09:45.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:09:45.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:09:45.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-27T09:10:15.852+0000] {processor.py:157} INFO - Started process (PID=53952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:15.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:10:15.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:15.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:15.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:15.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:15.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:10:15.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:15.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:10:15.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-27T09:10:46.501+0000] {processor.py:157} INFO - Started process (PID=53977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:46.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:10:46.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:46.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:46.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:10:46.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:46.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:10:46.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:10:46.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:10:46.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T09:11:16.897+0000] {processor.py:157} INFO - Started process (PID=54002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:16.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:11:16.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:16.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:16.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:16.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:16.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:11:16.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:16.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:11:16.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:11:47.346+0000] {processor.py:157} INFO - Started process (PID=54027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:47.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:11:47.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:47.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:47.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:11:47.374+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:47.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:11:47.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:11:47.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:11:47.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T09:12:17.758+0000] {processor.py:157} INFO - Started process (PID=54052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:17.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:12:17.760+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:17.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:17.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:17.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:17.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:12:17.790+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:17.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:12:17.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-27T09:12:48.355+0000] {processor.py:157} INFO - Started process (PID=54077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:48.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:12:48.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:48.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:48.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:12:48.398+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:48.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:12:48.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:12:48.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:12:48.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-27T09:13:19.031+0000] {processor.py:157} INFO - Started process (PID=54102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:19.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:13:19.034+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:19.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:19.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:19.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:19.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:13:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:13:19.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-27T09:13:49.737+0000] {processor.py:157} INFO - Started process (PID=54127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:49.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:13:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:49.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:49.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:13:49.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:49.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:13:49.778+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:13:49.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:13:49.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T09:14:20.188+0000] {processor.py:157} INFO - Started process (PID=54152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:20.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:14:20.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:20.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:20.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:20.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:20.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:14:20.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:20.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:14:20.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T09:14:50.669+0000] {processor.py:157} INFO - Started process (PID=54177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:50.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:14:50.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:50.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:50.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:14:50.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:50.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:14:50.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:14:50.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:14:50.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T09:15:21.030+0000] {processor.py:157} INFO - Started process (PID=54202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:21.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:15:21.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:21.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:21.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:21.053+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:21.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:15:21.063+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:21.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:15:21.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T09:15:51.828+0000] {processor.py:157} INFO - Started process (PID=54227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:51.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:15:51.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:51.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:51.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:15:51.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:51.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:15:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:15:52.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:15:52.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-27T09:16:22.465+0000] {processor.py:157} INFO - Started process (PID=54252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:22.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:16:22.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:22.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:22.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:22.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:22.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:16:22.513+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:22.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:16:22.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T09:16:52.935+0000] {processor.py:157} INFO - Started process (PID=54277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:52.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:16:52.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:52.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:52.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:16:52.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:52.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:16:52.976+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:16:52.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:16:52.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:17:23.322+0000] {processor.py:157} INFO - Started process (PID=54302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:23.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:17:23.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:23.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:23.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:23.354+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:23.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:17:23.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:23.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:17:23.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T09:17:53.773+0000] {processor.py:157} INFO - Started process (PID=54327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:53.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:17:53.780+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:53.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:53.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:17:53.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:53.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:17:53.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:17:53.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:17:53.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T09:18:24.189+0000] {processor.py:157} INFO - Started process (PID=54352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:24.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:18:24.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:24.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:24.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:24.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:24.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:18:24.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:24.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:18:24.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-27T09:18:54.768+0000] {processor.py:157} INFO - Started process (PID=54377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:54.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:18:54.775+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:54.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:54.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:18:54.811+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:54.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:18:54.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:18:54.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:18:54.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-27T09:19:25.350+0000] {processor.py:157} INFO - Started process (PID=54402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:25.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:19:25.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:25.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:25.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:25.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:25.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:19:25.390+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:25.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:19:25.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:19:55.806+0000] {processor.py:157} INFO - Started process (PID=54427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:55.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:19:55.809+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:55.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:55.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:19:55.835+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:55.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:19:55.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:19:55.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:19:55.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T09:20:26.201+0000] {processor.py:157} INFO - Started process (PID=54452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:26.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:20:26.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:26.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:26.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:26.233+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:26.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:20:26.243+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:26.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:20:26.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T09:20:56.652+0000] {processor.py:157} INFO - Started process (PID=54477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:56.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:20:56.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:56.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:56.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:20:56.685+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:56.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:20:56.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:20:56.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:20:56.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-27T09:21:27.205+0000] {processor.py:157} INFO - Started process (PID=54502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:27.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:21:27.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:27.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:27.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:27.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:27.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:21:27.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:27.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:21:27.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-27T09:21:57.854+0000] {processor.py:157} INFO - Started process (PID=54527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:57.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:21:57.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:57.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:57.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:21:57.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:57.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:21:57.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:21:57.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:21:57.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-27T09:22:28.354+0000] {processor.py:157} INFO - Started process (PID=54552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:28.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:22:28.361+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:28.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:28.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:28.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:28.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:22:28.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:28.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:22:28.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T09:22:58.797+0000] {processor.py:157} INFO - Started process (PID=54577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:58.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:22:58.801+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:58.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:58.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:22:58.825+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:58.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:22:58.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:22:58.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:22:58.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T09:23:29.260+0000] {processor.py:157} INFO - Started process (PID=54602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:29.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:23:29.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:29.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:29.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:29.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:29.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:23:29.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:29.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:23:29.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T09:23:59.698+0000] {processor.py:157} INFO - Started process (PID=54627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:59.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:23:59.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:59.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:59.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:23:59.727+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:59.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:23:59.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:23:59.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:23:59.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-07-27T09:24:30.310+0000] {processor.py:157} INFO - Started process (PID=54652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:24:30.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:24:30.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:24:30.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:24:30.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:24:30.345+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:24:30.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:24:30.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:24:30.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:24:30.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T09:25:00.870+0000] {processor.py:157} INFO - Started process (PID=54677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:00.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:25:00.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:00.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:00.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:00.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:00.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:25:00.979+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:00.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:25:00.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T09:25:31.484+0000] {processor.py:157} INFO - Started process (PID=54702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:31.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:25:31.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:31.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:31.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:25:31.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:31.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:25:31.525+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:25:31.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:25:31.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T09:26:01.929+0000] {processor.py:157} INFO - Started process (PID=54727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:01.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:26:01.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:01.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:01.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:01.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:01.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:26:01.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:01.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:26:01.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T09:26:32.333+0000] {processor.py:157} INFO - Started process (PID=54752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:32.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:26:32.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:32.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:32.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:26:32.367+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:32.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:26:32.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:26:32.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:26:32.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T09:27:02.777+0000] {processor.py:157} INFO - Started process (PID=54777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:02.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:27:02.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:02.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:02.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:02.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:02.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:27:02.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:02.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:27:02.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-27T09:27:33.394+0000] {processor.py:157} INFO - Started process (PID=54802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:33.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:27:33.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:33.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:33.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:27:33.428+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:33.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:27:33.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:27:33.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:27:33.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-27T09:28:04.029+0000] {processor.py:157} INFO - Started process (PID=54827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:04.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:28:04.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:04.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:04.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:04.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:04.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:28:04.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:04.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:28:04.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-27T09:28:34.614+0000] {processor.py:157} INFO - Started process (PID=54852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:34.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:28:34.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:34.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:34.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:28:34.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:34.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:28:34.654+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:28:34.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:28:34.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T09:29:05.087+0000] {processor.py:157} INFO - Started process (PID=54877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:05.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:29:05.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:05.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:05.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:05.118+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:05.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:29:05.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:05.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:29:05.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T09:29:35.471+0000] {processor.py:157} INFO - Started process (PID=54902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:35.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:29:35.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:35.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:35.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:29:35.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:35.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:29:35.514+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:29:35.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:29:35.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-27T09:30:06.030+0000] {processor.py:157} INFO - Started process (PID=54927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:06.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:30:06.034+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:06.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:06.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:06.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:06.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:30:06.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:06.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:30:06.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T09:30:36.701+0000] {processor.py:157} INFO - Started process (PID=54952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:36.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:30:36.706+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:36.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:30:36.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:36.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:30:36.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:30:36.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:30:36.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-27T09:31:07.238+0000] {processor.py:157} INFO - Started process (PID=54977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:07.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:31:07.243+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:07.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:07.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:07.271+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:07.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:31:07.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:07.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:31:07.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T09:31:37.694+0000] {processor.py:157} INFO - Started process (PID=55002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:37.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:31:37.697+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:37.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:37.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:31:37.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:37.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:31:37.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:31:37.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:31:37.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:32:08.168+0000] {processor.py:157} INFO - Started process (PID=55027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:08.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:32:08.171+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:08.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:08.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:08.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:08.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:32:08.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:08.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:32:08.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T09:32:38.606+0000] {processor.py:157} INFO - Started process (PID=55052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:38.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:32:38.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:38.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:38.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:32:38.652+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:38.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:32:38.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:32:38.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:32:38.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-07-27T09:33:09.398+0000] {processor.py:157} INFO - Started process (PID=55077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:09.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:33:09.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:09.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:09.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:09.466+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:09.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:33:09.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:09.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:33:09.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-27T09:33:39.908+0000] {processor.py:157} INFO - Started process (PID=55102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:39.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:33:39.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:39.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:39.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:33:40.025+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:40.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:33:40.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:33:40.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:33:40.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-27T09:34:10.585+0000] {processor.py:157} INFO - Started process (PID=55127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:10.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:34:10.590+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:10.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:10.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:10.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:10.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:34:10.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:10.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:34:10.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T09:34:40.956+0000] {processor.py:157} INFO - Started process (PID=55152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:40.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:34:40.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:40.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:40.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:34:41.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:41.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:34:41.015+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:34:41.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:34:41.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T09:35:11.383+0000] {processor.py:157} INFO - Started process (PID=55177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:11.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:35:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:11.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:11.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:11.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:11.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:35:11.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:11.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:35:11.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-07-27T09:35:42.000+0000] {processor.py:157} INFO - Started process (PID=55202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:42.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:35:42.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:42.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:42.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:35:42.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:42.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:35:42.113+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:35:42.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:35:42.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-27T09:36:12.554+0000] {processor.py:157} INFO - Started process (PID=55227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:12.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:36:12.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:12.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:12.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:12.591+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:12.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:36:12.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:12.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:36:12.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-27T09:36:43.248+0000] {processor.py:157} INFO - Started process (PID=55252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:43.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:36:43.252+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:43.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:43.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:36:43.418+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:43.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:36:43.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:36:43.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:36:43.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-07-27T09:37:13.883+0000] {processor.py:157} INFO - Started process (PID=55277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:13.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:37:13.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:13.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:13.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:13.942+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:13.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:37:13.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:13.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:37:13.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T09:37:44.318+0000] {processor.py:157} INFO - Started process (PID=55302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:44.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:37:44.322+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:44.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:44.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:37:44.355+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:44.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:37:44.370+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:37:44.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:37:44.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T09:38:14.748+0000] {processor.py:157} INFO - Started process (PID=55327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:14.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:38:14.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:14.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:14.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:14.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:14.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:38:14.792+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:14.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:38:14.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-07-27T09:38:45.349+0000] {processor.py:157} INFO - Started process (PID=55352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:45.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:38:45.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:45.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:45.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:38:45.383+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:45.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:38:45.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:38:45.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:38:45.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-27T09:39:15.966+0000] {processor.py:157} INFO - Started process (PID=55377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:15.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:39:15.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:15.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:15.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:15.998+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:15.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:39:16.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:16.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:39:16.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T09:39:46.642+0000] {processor.py:157} INFO - Started process (PID=55402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:46.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:39:46.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:46.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:46.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:39:46.675+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:46.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:39:46.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:39:46.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:39:46.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T09:40:17.116+0000] {processor.py:157} INFO - Started process (PID=55427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:17.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:40:17.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:17.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:17.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:17.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:17.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:40:17.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:17.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:40:17.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:40:47.589+0000] {processor.py:157} INFO - Started process (PID=55452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:47.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:40:47.594+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:47.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:47.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:40:47.634+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:47.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:40:47.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:40:47.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:40:47.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T09:41:18.090+0000] {processor.py:157} INFO - Started process (PID=55477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:18.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:41:18.094+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:18.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:18.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:18.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:18.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:41:18.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:18.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:41:18.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-07-27T09:41:48.826+0000] {processor.py:157} INFO - Started process (PID=55502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:48.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:41:48.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:48.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:48.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:41:48.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:48.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:41:48.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:41:48.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:41:48.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T09:42:19.358+0000] {processor.py:157} INFO - Started process (PID=55527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:19.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:42:19.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:19.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:19.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:19.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:19.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:42:19.515+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:19.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:42:19.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-27T09:42:49.962+0000] {processor.py:157} INFO - Started process (PID=55552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:49.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:42:49.965+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:49.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:49.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:42:49.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:49.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:42:50.006+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:42:50.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:42:50.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:43:20.402+0000] {processor.py:157} INFO - Started process (PID=55577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:20.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:43:20.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:20.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:20.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:20.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:20.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:43:20.464+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:20.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:43:20.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T09:43:50.914+0000] {processor.py:157} INFO - Started process (PID=55602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:50.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:43:50.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:50.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:50.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:43:50.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:50.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:43:50.955+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:43:50.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:43:51.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-27T09:44:21.550+0000] {processor.py:157} INFO - Started process (PID=55627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:21.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:44:21.552+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:21.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:21.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:21.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:21.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:44:21.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:21.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:44:21.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-27T09:44:52.120+0000] {processor.py:157} INFO - Started process (PID=55652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:52.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:44:52.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:52.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:52.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:44:52.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:52.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:44:52.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:44:52.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:44:52.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T09:45:22.802+0000] {processor.py:157} INFO - Started process (PID=55677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:22.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:45:22.806+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:22.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:22.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:22.939+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:22.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:45:22.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:22.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:45:22.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-07-27T09:45:53.348+0000] {processor.py:157} INFO - Started process (PID=55702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:53.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:45:53.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:53.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:53.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:45:53.380+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:53.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:45:53.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:45:53.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:45:53.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T09:46:23.813+0000] {processor.py:157} INFO - Started process (PID=55727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:23.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:46:23.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:23.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:23.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:23.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:23.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:46:23.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:23.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:46:23.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T09:46:54.226+0000] {processor.py:157} INFO - Started process (PID=55752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:54.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:46:54.229+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:54.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:54.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:46:54.260+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:54.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:46:54.271+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:46:54.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:46:54.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-27T09:47:24.810+0000] {processor.py:157} INFO - Started process (PID=55777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:24.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:47:24.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:24.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:24.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:24.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:24.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:47:24.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:24.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:47:24.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-07-27T09:47:55.383+0000] {processor.py:157} INFO - Started process (PID=55802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:55.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:47:55.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:55.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:55.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:47:55.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:55.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:47:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:47:55.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:47:55.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-27T09:48:25.877+0000] {processor.py:157} INFO - Started process (PID=55827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:25.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:48:25.883+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:25.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:25.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:25.987+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:25.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:48:25.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:25.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:48:26.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-27T09:48:56.526+0000] {processor.py:157} INFO - Started process (PID=55852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:56.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:48:56.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:56.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:56.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:48:56.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:56.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:48:56.577+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:48:56.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:48:56.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T09:49:27.013+0000] {processor.py:157} INFO - Started process (PID=55877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:27.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:49:27.016+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:27.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:27.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:27.043+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:27.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:49:27.053+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:27.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:49:27.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T09:49:57.499+0000] {processor.py:157} INFO - Started process (PID=55902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:57.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:49:57.503+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:57.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:57.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:49:57.530+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:57.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:49:57.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:49:57.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:49:57.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-07-27T09:50:28.234+0000] {processor.py:157} INFO - Started process (PID=55927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:28.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:50:28.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:28.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:28.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:28.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:28.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:50:28.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:28.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:50:28.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-27T09:50:58.792+0000] {processor.py:157} INFO - Started process (PID=55952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:58.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:50:58.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:58.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:58.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:50:58.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:58.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:50:58.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:50:58.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:50:58.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-27T09:51:29.348+0000] {processor.py:157} INFO - Started process (PID=55977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:29.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:51:29.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:29.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:29.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:29.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:29.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:51:29.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:29.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:51:29.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T09:51:59.781+0000] {processor.py:157} INFO - Started process (PID=56002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:59.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:51:59.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:59.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:59.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:51:59.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:59.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:51:59.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:51:59.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:51:59.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T09:52:30.272+0000] {processor.py:157} INFO - Started process (PID=56027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:52:30.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:52:30.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:52:30.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:52:30.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:52:30.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:52:30.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:52:30.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:52:30.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:52:30.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-07-27T09:53:00.904+0000] {processor.py:157} INFO - Started process (PID=56052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:00.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:53:00.908+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:00.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:00.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:00.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:00.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:53:01.014+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:01.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:53:01.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T09:53:31.421+0000] {processor.py:157} INFO - Started process (PID=56077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:31.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:53:31.425+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:31.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:31.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:53:31.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:31.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:53:31.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:53:31.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:53:31.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-27T09:54:02.128+0000] {processor.py:157} INFO - Started process (PID=56102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:02.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:54:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:02.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:02.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:02.288+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:02.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:54:02.298+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:02.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:54:02.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-07-27T09:54:32.742+0000] {processor.py:157} INFO - Started process (PID=56127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:32.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:54:32.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:32.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:32.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:54:32.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:32.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:54:32.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:54:32.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:54:32.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:55:03.144+0000] {processor.py:157} INFO - Started process (PID=56152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:03.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:55:03.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:03.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:03.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:03.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:03.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:55:03.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:03.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:55:03.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T09:55:33.518+0000] {processor.py:157} INFO - Started process (PID=56177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:33.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:55:33.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:33.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:33.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:55:33.551+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:33.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:55:33.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:55:33.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:55:33.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T09:56:04.223+0000] {processor.py:157} INFO - Started process (PID=56202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:04.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:56:04.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:04.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:04.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:04.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:04.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:56:04.367+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:04.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:56:04.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-27T09:56:34.802+0000] {processor.py:157} INFO - Started process (PID=56227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:34.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:56:34.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:34.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:34.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:56:34.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:34.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:56:34.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:56:34.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:56:34.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T09:57:05.484+0000] {processor.py:157} INFO - Started process (PID=56252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:05.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:57:05.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:05.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:05.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:05.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:05.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:57:05.619+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:05.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:57:05.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-27T09:57:36.162+0000] {processor.py:157} INFO - Started process (PID=56277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:36.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:57:36.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:36.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:36.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:57:36.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:57:36.211+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:57:36.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:57:36.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T09:58:06.636+0000] {processor.py:157} INFO - Started process (PID=56302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:06.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:58:06.639+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:06.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:06.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:06.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:06.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:58:06.677+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:06.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:58:06.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-27T09:58:37.171+0000] {processor.py:157} INFO - Started process (PID=56327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:37.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:58:37.174+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:37.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:37.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:58:37.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:37.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:58:37.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:58:37.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:58:37.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-27T09:59:07.773+0000] {processor.py:157} INFO - Started process (PID=56352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:07.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:59:07.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:07.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:07.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:07.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:07.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:59:07.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:07.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:59:07.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T09:59:38.446+0000] {processor.py:157} INFO - Started process (PID=56377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:38.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T09:59:38.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:38.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:38.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T09:59:38.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:38.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T09:59:38.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T09:59:38.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T09:59:38.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-27T10:00:08.988+0000] {processor.py:157} INFO - Started process (PID=56402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:08.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:00:08.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:08.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:09.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:09.108+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:09.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:00:09.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:09.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:00:09.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T10:00:39.522+0000] {processor.py:157} INFO - Started process (PID=56427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:39.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:00:39.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:39.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:39.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:00:39.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:39.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:00:39.572+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:00:39.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:00:39.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T10:01:10.033+0000] {processor.py:157} INFO - Started process (PID=56452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:10.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:01:10.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:10.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:10.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:10.069+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:10.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:01:10.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:10.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:01:10.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-27T10:01:40.634+0000] {processor.py:157} INFO - Started process (PID=56477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:40.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:01:40.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:40.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:40.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:01:40.663+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:40.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:01:40.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:01:40.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:01:40.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T10:02:11.137+0000] {processor.py:157} INFO - Started process (PID=56502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:11.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:02:11.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:11.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:11.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:11.168+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:11.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:02:11.252+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:11.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:02:11.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-27T10:02:41.701+0000] {processor.py:157} INFO - Started process (PID=56527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:41.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:02:41.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:41.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:41.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:02:41.848+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:41.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:02:41.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:02:41.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:02:41.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-27T10:03:12.395+0000] {processor.py:157} INFO - Started process (PID=56552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:12.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:03:12.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:12.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:12.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:12.425+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:12.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:03:12.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:12.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:03:12.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T10:03:42.879+0000] {processor.py:157} INFO - Started process (PID=56577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:42.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:03:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:42.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:42.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:03:42.908+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:42.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:03:42.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:03:42.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:03:42.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:04:13.326+0000] {processor.py:157} INFO - Started process (PID=56602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:13.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:04:13.333+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:13.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:13.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:13.366+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:13.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:04:13.480+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:13.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:04:13.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-07-27T10:04:44.072+0000] {processor.py:157} INFO - Started process (PID=56627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:44.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:04:44.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:44.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:44.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:04:44.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:44.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:04:44.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:04:44.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:04:44.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-27T10:05:14.856+0000] {processor.py:157} INFO - Started process (PID=56652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:14.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:05:14.860+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:14.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:14.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:15.004+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:15.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:05:15.012+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:15.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:05:15.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-27T10:05:45.530+0000] {processor.py:157} INFO - Started process (PID=56677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:45.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:05:45.533+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:45.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:45.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:05:45.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:45.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:05:45.652+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:05:45.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:05:45.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-27T10:06:16.154+0000] {processor.py:157} INFO - Started process (PID=56702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:16.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:06:16.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:16.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:16.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:16.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:16.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:06:16.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:16.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:06:16.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T10:06:46.585+0000] {processor.py:157} INFO - Started process (PID=56727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:46.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:06:46.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:46.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:46.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:06:46.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:46.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:06:46.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:06:46.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:06:46.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:07:17.091+0000] {processor.py:157} INFO - Started process (PID=56752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:17.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:07:17.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:17.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:17.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:17.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:17.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:07:17.143+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:17.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:07:17.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T10:07:47.539+0000] {processor.py:157} INFO - Started process (PID=56777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:47.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:07:47.542+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:47.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:47.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:07:47.570+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:47.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:07:47.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:07:47.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:07:47.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T10:08:17.981+0000] {processor.py:157} INFO - Started process (PID=56802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:17.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:08:17.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:17.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:18.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:18.015+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:18.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:08:18.025+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:18.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:08:18.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T10:08:48.437+0000] {processor.py:157} INFO - Started process (PID=56827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:48.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:08:48.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:48.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:48.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:08:48.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:48.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:08:48.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:08:48.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:08:48.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:09:18.831+0000] {processor.py:157} INFO - Started process (PID=56852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:18.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:09:18.835+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:18.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:18.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:18.861+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:18.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:09:18.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:18.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:09:18.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:09:49.341+0000] {processor.py:157} INFO - Started process (PID=56877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:49.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:09:49.343+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:49.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:49.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:09:49.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:49.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:09:49.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:09:49.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:09:49.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T10:10:19.748+0000] {processor.py:157} INFO - Started process (PID=56902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:19.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:10:19.751+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:19.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:19.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:19.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:19.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:10:19.796+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:19.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:10:19.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T10:10:50.189+0000] {processor.py:157} INFO - Started process (PID=56927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:50.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:10:50.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:50.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:50.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:10:50.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:50.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:10:50.227+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:10:50.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:10:50.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T10:11:20.559+0000] {processor.py:157} INFO - Started process (PID=56952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:20.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:11:20.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:20.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:20.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:20.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:20.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:11:20.594+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:20.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:11:20.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T10:11:51.022+0000] {processor.py:157} INFO - Started process (PID=56977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:51.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:11:51.027+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:51.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:51.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:11:51.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:51.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:11:51.075+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:11:51.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:11:51.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T10:12:21.498+0000] {processor.py:157} INFO - Started process (PID=57002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:21.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:12:21.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:21.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:21.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:21.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:21.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:12:21.538+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:21.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:12:21.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T10:12:51.917+0000] {processor.py:157} INFO - Started process (PID=57027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:51.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:12:51.921+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:51.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:51.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:12:51.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:51.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:12:51.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:12:51.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:12:51.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:13:22.383+0000] {processor.py:157} INFO - Started process (PID=57052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:22.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:13:22.388+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:22.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:22.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:22.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:22.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:13:22.435+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:22.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:13:22.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T10:13:52.822+0000] {processor.py:157} INFO - Started process (PID=57077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:52.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:13:52.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:52.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:52.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:13:52.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:52.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:13:52.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:13:52.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:13:52.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T10:14:23.298+0000] {processor.py:157} INFO - Started process (PID=57102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:23.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:14:23.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:23.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:23.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:23.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:23.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:14:23.349+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:23.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:14:23.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T10:14:53.769+0000] {processor.py:157} INFO - Started process (PID=57127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:53.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:14:53.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:53.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:53.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:14:53.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:53.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:14:53.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:14:53.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:14:53.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T10:15:24.193+0000] {processor.py:157} INFO - Started process (PID=57152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:24.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:15:24.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:24.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:24.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:24.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:24.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:15:24.237+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:24.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:15:24.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T10:15:54.660+0000] {processor.py:157} INFO - Started process (PID=57177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:54.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:15:54.666+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:54.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:54.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:15:54.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:54.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:15:54.714+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:15:54.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:15:54.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T10:16:25.037+0000] {processor.py:157} INFO - Started process (PID=57202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:25.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:16:25.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:25.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:25.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:25.070+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:25.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:16:25.081+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:25.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:16:25.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T10:16:55.467+0000] {processor.py:157} INFO - Started process (PID=57227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:55.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:16:55.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:55.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:55.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:16:55.503+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:55.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:16:55.513+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:16:55.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:16:55.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:17:25.922+0000] {processor.py:157} INFO - Started process (PID=57252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:25.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:17:25.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:25.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:25.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:25.954+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:25.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:17:25.964+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:25.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:17:25.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T10:17:56.336+0000] {processor.py:157} INFO - Started process (PID=57277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:56.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:17:56.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:56.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:56.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:17:56.367+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:56.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:17:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:17:56.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:17:56.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T10:18:26.818+0000] {processor.py:157} INFO - Started process (PID=57302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:26.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:18:26.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:26.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:26.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:26.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:26.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:18:26.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:26.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:18:26.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T10:18:57.236+0000] {processor.py:157} INFO - Started process (PID=57327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:57.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:18:57.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:57.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:57.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:18:57.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:57.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:18:57.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:18:57.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:18:57.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T10:19:27.733+0000] {processor.py:157} INFO - Started process (PID=57352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:27.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:19:27.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:27.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:27.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:27.770+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:27.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:19:27.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:27.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:19:27.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T10:19:58.179+0000] {processor.py:157} INFO - Started process (PID=57377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:58.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:19:58.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:58.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:58.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:19:58.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:58.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:19:58.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:19:58.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:19:58.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T10:20:28.677+0000] {processor.py:157} INFO - Started process (PID=57402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:28.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:20:28.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:28.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:28.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:28.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:28.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:20:28.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:28.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:20:28.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T10:20:59.112+0000] {processor.py:157} INFO - Started process (PID=57427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:59.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:20:59.116+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:59.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:59.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:20:59.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:59.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:20:59.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:20:59.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:20:59.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T10:21:29.578+0000] {processor.py:157} INFO - Started process (PID=57452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:21:29.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:21:29.582+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:21:29.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:21:29.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:21:29.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:21:29.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:21:29.625+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:21:29.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:21:29.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T10:22:00.003+0000] {processor.py:157} INFO - Started process (PID=57477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:00.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:22:00.005+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:00.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:00.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:00.038+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:00.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:22:00.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:00.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:22:00.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T10:22:30.378+0000] {processor.py:157} INFO - Started process (PID=57502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:30.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:22:30.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:30.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:30.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:22:30.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:30.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:22:30.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:22:30.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:22:30.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T10:23:00.820+0000] {processor.py:157} INFO - Started process (PID=57527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:00.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:23:00.825+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:00.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:00.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:00.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:00.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:23:00.881+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:00.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:23:00.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T10:23:31.285+0000] {processor.py:157} INFO - Started process (PID=57552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:31.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:23:31.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:31.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:31.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:23:31.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:31.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:23:31.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:23:31.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:23:31.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T10:24:01.754+0000] {processor.py:157} INFO - Started process (PID=57577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:01.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:24:01.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:01.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:01.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:01.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:01.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:24:01.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:01.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:24:01.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T10:24:32.162+0000] {processor.py:157} INFO - Started process (PID=57602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:32.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:24:32.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:32.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:32.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:24:32.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:32.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:24:32.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:24:32.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:24:32.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:25:02.556+0000] {processor.py:157} INFO - Started process (PID=57627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:02.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:25:02.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:02.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:02.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:02.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:02.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:25:02.599+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:02.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:25:02.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T10:25:33.042+0000] {processor.py:157} INFO - Started process (PID=57652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:33.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:25:33.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:33.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:33.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:25:33.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:33.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:25:33.091+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:25:33.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:25:33.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T10:26:03.440+0000] {processor.py:157} INFO - Started process (PID=57677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:03.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:26:03.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:03.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:03.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:03.471+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:03.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:26:03.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:03.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:26:03.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T10:26:33.852+0000] {processor.py:157} INFO - Started process (PID=57702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:33.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:26:33.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:33.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:33.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:26:33.881+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:33.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:26:33.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:26:33.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:26:33.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:27:04.295+0000] {processor.py:157} INFO - Started process (PID=57727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:04.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:27:04.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:04.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:04.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:04.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:04.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:27:04.335+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:04.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:27:04.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T10:27:34.694+0000] {processor.py:157} INFO - Started process (PID=57752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:34.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:27:34.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:34.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:34.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:27:34.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:34.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:27:34.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:27:34.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:27:34.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T10:28:05.152+0000] {processor.py:157} INFO - Started process (PID=57777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:05.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:28:05.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:05.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:05.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:05.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:05.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:28:05.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:05.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:28:05.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:28:35.587+0000] {processor.py:157} INFO - Started process (PID=57802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:35.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:28:35.590+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:35.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:35.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:28:35.621+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:35.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:28:35.630+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:28:35.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:28:35.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T10:29:06.075+0000] {processor.py:157} INFO - Started process (PID=57827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:06.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:29:06.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:06.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:06.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:06.106+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:06.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:29:06.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:06.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:29:06.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T10:29:36.512+0000] {processor.py:157} INFO - Started process (PID=57852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:36.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:29:36.514+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:36.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:36.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:29:36.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:36.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:29:36.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:29:36.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:29:36.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T10:30:06.940+0000] {processor.py:157} INFO - Started process (PID=57877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:06.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:30:06.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:06.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:06.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:06.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:06.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:30:06.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:06.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:30:06.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T10:30:37.365+0000] {processor.py:157} INFO - Started process (PID=57902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:37.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:30:37.370+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:37.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:37.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:30:37.403+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:37.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:30:37.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:30:37.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:30:37.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T10:31:07.818+0000] {processor.py:157} INFO - Started process (PID=57927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:07.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:31:07.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:07.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:07.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:07.848+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:07.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:31:07.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:07.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:31:07.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T10:31:38.206+0000] {processor.py:157} INFO - Started process (PID=57952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:38.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:31:38.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:38.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:38.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:31:38.237+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:38.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:31:38.248+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:31:38.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:31:38.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:32:08.626+0000] {processor.py:157} INFO - Started process (PID=57977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:08.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:32:08.628+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:08.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:08.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:08.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:08.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:32:08.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:08.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:32:08.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T10:32:39.096+0000] {processor.py:157} INFO - Started process (PID=58002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:39.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:32:39.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:39.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:39.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:32:39.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:39.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:32:39.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:32:39.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:32:39.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T10:33:09.472+0000] {processor.py:157} INFO - Started process (PID=58027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:09.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:33:09.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:09.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:09.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:09.504+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:09.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:33:09.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:09.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:33:09.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T10:33:39.821+0000] {processor.py:157} INFO - Started process (PID=58052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:39.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:33:39.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:39.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:39.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:33:39.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:39.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:33:39.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:33:39.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:33:39.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T10:34:10.294+0000] {processor.py:157} INFO - Started process (PID=58076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:10.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:34:10.298+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:10.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:10.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:10.330+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:10.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:34:10.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:10.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:34:10.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T10:34:40.738+0000] {processor.py:157} INFO - Started process (PID=58102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:40.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:34:40.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:40.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:40.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:34:40.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:40.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:34:40.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:34:40.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:34:40.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T10:35:11.157+0000] {processor.py:157} INFO - Started process (PID=58127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:11.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:35:11.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:11.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:11.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:11.187+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:11.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:35:11.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:11.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:35:11.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T10:35:41.656+0000] {processor.py:157} INFO - Started process (PID=58152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:41.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:35:41.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:41.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:41.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:35:41.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:41.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:35:41.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:35:41.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:35:41.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T10:36:12.100+0000] {processor.py:157} INFO - Started process (PID=58177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:12.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:36:12.107+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:12.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:12.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:12.168+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:12.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:36:12.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:12.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:36:12.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-27T10:36:42.601+0000] {processor.py:157} INFO - Started process (PID=58201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:42.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:36:42.604+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:42.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:42.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:36:42.630+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:42.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:36:42.640+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:36:42.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:36:42.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T10:37:12.998+0000] {processor.py:157} INFO - Started process (PID=58226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:12.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:37:13.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:13.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:13.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:13.055+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:13.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:37:13.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:13.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:37:13.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T10:37:43.532+0000] {processor.py:157} INFO - Started process (PID=58252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:43.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:37:43.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:43.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:43.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:37:43.565+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:43.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:37:43.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:37:43.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:37:43.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T10:38:13.959+0000] {processor.py:157} INFO - Started process (PID=58277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:13.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:38:13.964+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:13.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:13.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:13.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:13.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:38:14.015+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:14.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:38:14.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T10:38:44.481+0000] {processor.py:157} INFO - Started process (PID=58302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:44.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:38:44.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:44.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:44.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:38:44.524+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:44.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:38:44.540+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:38:44.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:38:44.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T10:39:14.948+0000] {processor.py:157} INFO - Started process (PID=58327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:14.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:39:14.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:14.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:14.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:14.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:14.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:39:14.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:14.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:39:14.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T10:39:45.406+0000] {processor.py:157} INFO - Started process (PID=58352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:45.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:39:45.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:45.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:45.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:39:45.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:45.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:39:45.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:39:45.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:39:45.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T10:40:15.889+0000] {processor.py:157} INFO - Started process (PID=58377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:15.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:40:15.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:15.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:15.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:15.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:15.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:40:15.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:15.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:40:15.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T10:40:46.264+0000] {processor.py:157} INFO - Started process (PID=58402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:46.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:40:46.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:46.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:46.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:40:46.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:46.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:40:46.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:40:46.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:40:46.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T10:41:16.698+0000] {processor.py:157} INFO - Started process (PID=58427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:16.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:41:16.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:16.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:16.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:16.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:16.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:41:16.734+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:16.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:41:16.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T10:41:47.079+0000] {processor.py:157} INFO - Started process (PID=58452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:47.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:41:47.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:47.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:47.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:41:47.118+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:47.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:41:47.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:41:47.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:41:47.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T10:42:17.681+0000] {processor.py:157} INFO - Started process (PID=58477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:42:17.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:42:17.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:42:17.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:42:17.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:42:17.734+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:42:17.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:42:17.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:42:17.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:42:17.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T10:50:01.207+0000] {processor.py:157} INFO - Started process (PID=58502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:50:01.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:50:01.216+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:50:01.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:50:01.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:50:01.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:50:01.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:50:01.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:50:01.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:50:01.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-27T10:52:23.801+0000] {processor.py:157} INFO - Started process (PID=58529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:23.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:52:23.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:23.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:23.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:23.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:23.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:52:23.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:23.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:52:23.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T10:52:54.255+0000] {processor.py:157} INFO - Started process (PID=58554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:54.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T10:52:54.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:54.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:54.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T10:52:54.293+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:54.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T10:52:54.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T10:52:54.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T10:52:54.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T11:06:53.037+0000] {processor.py:157} INFO - Started process (PID=58581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:06:53.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:06:53.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:06:53.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:06:53.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:06:53.088+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:06:53.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:06:53.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:06:53.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:06:53.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-27T11:07:23.502+0000] {processor.py:157} INFO - Started process (PID=58606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:07:23.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:07:23.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:07:23.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:07:23.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:07:24.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:07:24.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:07:24.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:07:24.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:07:24.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 1.005 seconds
[2024-07-27T11:10:50.287+0000] {processor.py:157} INFO - Started process (PID=58631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:10:50.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:10:50.294+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:10:50.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:10:50.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:10:50.361+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:10:50.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:10:50.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:10:50.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:10:50.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-27T11:11:20.824+0000] {processor.py:157} INFO - Started process (PID=58656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:20.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:11:20.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:20.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:20.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:20.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:20.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:11:20.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:20.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:11:20.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T11:11:51.282+0000] {processor.py:157} INFO - Started process (PID=58681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:51.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:11:51.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:51.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:51.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:11:51.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:51.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:11:51.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:11:51.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:11:51.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T11:12:21.669+0000] {processor.py:157} INFO - Started process (PID=58706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:21.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:12:21.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:21.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:21.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:21.693+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:21.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:12:21.702+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:21.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:12:21.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-27T11:12:52.138+0000] {processor.py:157} INFO - Started process (PID=58731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:52.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:12:52.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:52.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:52.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:12:52.168+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:52.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:12:52.180+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:12:52.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:12:52.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:13:22.592+0000] {processor.py:157} INFO - Started process (PID=58756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:22.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:13:22.595+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:22.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:22.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:22.623+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:22.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:13:22.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:22.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:13:22.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:13:52.949+0000] {processor.py:157} INFO - Started process (PID=58781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:52.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:13:52.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:52.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:52.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:13:52.978+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:52.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:13:52.987+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:13:52.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:13:52.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:14:23.404+0000] {processor.py:157} INFO - Started process (PID=58806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:23.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:14:23.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:23.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:23.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:23.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:23.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:14:23.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:23.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:14:23.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T11:14:53.790+0000] {processor.py:157} INFO - Started process (PID=58831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:53.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:14:53.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:53.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:53.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:14:53.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:53.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:14:53.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:14:53.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:14:53.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:15:24.280+0000] {processor.py:157} INFO - Started process (PID=58856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:24.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:15:24.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:24.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:24.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:24.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:24.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:15:24.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:24.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:15:24.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:15:54.734+0000] {processor.py:157} INFO - Started process (PID=58880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:54.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:15:54.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:54.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:54.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:15:54.759+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:54.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:15:54.770+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:15:54.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:15:54.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T11:16:25.195+0000] {processor.py:157} INFO - Started process (PID=58906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:25.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:16:25.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:25.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:25.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:25.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:25.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:16:25.237+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:25.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:16:25.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:16:55.728+0000] {processor.py:157} INFO - Started process (PID=58931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:55.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:16:55.731+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:55.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:55.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:16:55.761+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:55.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:16:55.769+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:16:55.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:16:55.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:17:25.995+0000] {processor.py:157} INFO - Started process (PID=58956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:25.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:17:25.998+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:25.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:26.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:26.027+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:26.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:17:26.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:26.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:17:26.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:17:56.412+0000] {processor.py:157} INFO - Started process (PID=58981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:56.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:17:56.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:56.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:56.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:17:56.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:56.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:17:56.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:17:56.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:17:56.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:18:26.922+0000] {processor.py:157} INFO - Started process (PID=59006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:26.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:18:26.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:26.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:26.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:26.950+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:26.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:18:26.960+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:26.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:18:26.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:18:57.412+0000] {processor.py:157} INFO - Started process (PID=59031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:57.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:18:57.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:57.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:57.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:18:57.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:57.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:18:57.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:18:57.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:18:57.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:19:27.810+0000] {processor.py:157} INFO - Started process (PID=59056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:27.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:19:27.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:27.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:27.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:27.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:27.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:19:27.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:27.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:19:27.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:19:58.277+0000] {processor.py:157} INFO - Started process (PID=59081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:58.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:19:58.280+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:58.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:58.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:19:58.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:58.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:19:58.317+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:19:58.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:19:58.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:20:28.721+0000] {processor.py:157} INFO - Started process (PID=59105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:28.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:20:28.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:28.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:28.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:28.746+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:28.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:20:28.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:28.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:20:28.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T11:20:59.146+0000] {processor.py:157} INFO - Started process (PID=59131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:59.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:20:59.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:59.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:59.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:20:59.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:59.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:20:59.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:20:59.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:20:59.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T11:21:29.621+0000] {processor.py:157} INFO - Started process (PID=59156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:21:29.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:21:29.625+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:21:29.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:21:29.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:21:29.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:21:29.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:21:29.668+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:21:29.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:21:29.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T11:22:00.055+0000] {processor.py:157} INFO - Started process (PID=59181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:00.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:22:00.059+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:00.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:00.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:00.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:00.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:22:00.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:00.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:22:00.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T11:22:30.462+0000] {processor.py:157} INFO - Started process (PID=59206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:30.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:22:30.464+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:30.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:30.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:22:30.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:30.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:22:30.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:22:30.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:22:30.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:23:00.904+0000] {processor.py:157} INFO - Started process (PID=59231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:00.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:23:00.907+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:00.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:00.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:00.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:00.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:23:00.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:00.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:23:00.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:23:31.291+0000] {processor.py:157} INFO - Started process (PID=59256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:31.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:23:31.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:31.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:31.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:23:31.322+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:31.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:23:31.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:23:31.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:23:31.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:24:01.781+0000] {processor.py:157} INFO - Started process (PID=59281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:01.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:24:01.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:01.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:01.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:01.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:01.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:24:01.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:01.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:24:01.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:24:32.223+0000] {processor.py:157} INFO - Started process (PID=59306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:32.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:24:32.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:32.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:32.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:24:32.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:32.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:24:32.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:24:32.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:24:32.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:25:02.645+0000] {processor.py:157} INFO - Started process (PID=59331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:02.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:25:02.647+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:02.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:02.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:02.675+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:02.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:25:02.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:02.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:25:02.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:25:33.080+0000] {processor.py:157} INFO - Started process (PID=59356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:33.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:25:33.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:33.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:33.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:25:33.109+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:33.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:25:33.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:25:33.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:25:33.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:26:03.513+0000] {processor.py:157} INFO - Started process (PID=59381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:03.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:26:03.517+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:03.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:03.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:03.544+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:03.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:26:03.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:03.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:26:03.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T11:26:33.957+0000] {processor.py:157} INFO - Started process (PID=59406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:33.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:26:33.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:33.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:33.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:26:33.986+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:33.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:26:33.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:26:33.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:26:34.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:27:04.371+0000] {processor.py:157} INFO - Started process (PID=59431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:04.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:27:04.373+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:04.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:04.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:04.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:04.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:27:04.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:04.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:27:04.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:27:34.821+0000] {processor.py:157} INFO - Started process (PID=59456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:34.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:27:34.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:34.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:34.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:27:34.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:34.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:27:34.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:27:34.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:27:34.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T11:28:05.277+0000] {processor.py:157} INFO - Started process (PID=59481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:05.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:28:05.280+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:05.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:05.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:05.312+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:05.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:28:05.323+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:05.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:28:05.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T11:28:35.765+0000] {processor.py:157} INFO - Started process (PID=59506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:35.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:28:35.769+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:35.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:35.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:28:35.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:35.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:28:35.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:28:35.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:28:35.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T11:29:06.198+0000] {processor.py:157} INFO - Started process (PID=59531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:06.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:29:06.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:06.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:06.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:06.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:06.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:29:06.238+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:06.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:29:06.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:29:36.696+0000] {processor.py:157} INFO - Started process (PID=59556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:36.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:29:36.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:36.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:36.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:29:36.727+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:36.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:29:36.738+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:29:36.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:29:36.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:30:07.094+0000] {processor.py:157} INFO - Started process (PID=59581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:07.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:30:07.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:07.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:07.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:07.126+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:07.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:30:07.137+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:07.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:30:07.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:30:37.474+0000] {processor.py:157} INFO - Started process (PID=59606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:37.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:30:37.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:37.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:37.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:30:37.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:37.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:30:37.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:30:37.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:30:37.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T11:31:07.868+0000] {processor.py:157} INFO - Started process (PID=59631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:07.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:31:07.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:07.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:07.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:07.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:07.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:31:07.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:07.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:31:07.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:31:38.284+0000] {processor.py:157} INFO - Started process (PID=59656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:38.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:31:38.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:38.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:38.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:31:38.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:38.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:31:38.315+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:31:38.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:31:38.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T11:32:08.784+0000] {processor.py:157} INFO - Started process (PID=59681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:08.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:32:08.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:08.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:08.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:08.812+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:08.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:32:08.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:08.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:32:08.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:32:39.187+0000] {processor.py:157} INFO - Started process (PID=59706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:39.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:32:39.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:39.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:39.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:32:39.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:39.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:32:39.227+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:32:39.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:32:39.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:33:09.597+0000] {processor.py:157} INFO - Started process (PID=59731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:09.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:33:09.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:09.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:09.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:09.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:09.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:33:09.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:09.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:33:09.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:33:40.039+0000] {processor.py:157} INFO - Started process (PID=59756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:40.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:33:40.043+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:40.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:40.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:33:40.068+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:40.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:33:40.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:33:40.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:33:40.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T11:34:10.449+0000] {processor.py:157} INFO - Started process (PID=59781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:10.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:34:10.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:10.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:10.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:10.487+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:10.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:34:10.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:10.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:34:10.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T11:34:40.925+0000] {processor.py:157} INFO - Started process (PID=59806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:40.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:34:40.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:40.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:40.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:34:40.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:40.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:34:40.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:34:40.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:34:40.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:35:11.330+0000] {processor.py:157} INFO - Started process (PID=59831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:11.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:35:11.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:11.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:11.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:11.356+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:11.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:35:11.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:11.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:35:11.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:35:41.767+0000] {processor.py:157} INFO - Started process (PID=59856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:41.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:35:41.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:41.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:41.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:35:41.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:41.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:35:41.819+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:35:41.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:35:41.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T11:36:12.235+0000] {processor.py:157} INFO - Started process (PID=59881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:12.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:36:12.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:12.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:12.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:12.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:12.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:36:12.278+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:12.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:36:12.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:36:42.740+0000] {processor.py:157} INFO - Started process (PID=59906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:42.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:36:42.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:42.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:42.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:36:42.777+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:42.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:36:42.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:36:42.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:36:42.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:37:13.174+0000] {processor.py:157} INFO - Started process (PID=59931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:13.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:37:13.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:13.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:13.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:13.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:13.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:37:13.215+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:13.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:37:13.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:37:43.548+0000] {processor.py:157} INFO - Started process (PID=59956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:43.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:37:43.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:43.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:43.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:37:43.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:43.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:37:43.590+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:37:43.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:37:43.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:38:13.998+0000] {processor.py:157} INFO - Started process (PID=59981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:14.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:38:14.006+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:14.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:14.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:14.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:14.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:38:14.049+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:14.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:38:14.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T11:38:44.451+0000] {processor.py:157} INFO - Started process (PID=60006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:44.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:38:44.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:44.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:44.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:38:44.486+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:44.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:38:44.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:38:44.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:38:44.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:39:14.836+0000] {processor.py:157} INFO - Started process (PID=60031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:14.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:39:14.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:14.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:14.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:14.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:14.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:39:14.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:14.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:39:14.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:39:45.303+0000] {processor.py:157} INFO - Started process (PID=60056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:45.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:39:45.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:45.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:45.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:39:45.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:45.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:39:45.349+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:39:45.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:39:45.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:40:15.683+0000] {processor.py:157} INFO - Started process (PID=60081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:15.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:40:15.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:15.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:15.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:15.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:15.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:40:15.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:15.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:40:15.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:40:46.161+0000] {processor.py:157} INFO - Started process (PID=60106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:46.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:40:46.163+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:46.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:46.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:40:46.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:46.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:40:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:40:46.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:40:46.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:41:16.605+0000] {processor.py:157} INFO - Started process (PID=60131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:16.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:41:16.612+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:16.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:16.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:16.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:16.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:41:16.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:16.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:41:16.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:41:47.189+0000] {processor.py:157} INFO - Started process (PID=60156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:47.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:41:47.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:47.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:47.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:41:47.220+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:47.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:41:47.230+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:41:47.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:41:47.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:42:17.663+0000] {processor.py:157} INFO - Started process (PID=60181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:17.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:42:17.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:17.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:17.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:17.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:17.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:42:17.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:17.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:42:17.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T11:42:48.071+0000] {processor.py:157} INFO - Started process (PID=60206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:48.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:42:48.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:48.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:48.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:42:48.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:48.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:42:48.112+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:42:48.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:42:48.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:43:18.597+0000] {processor.py:157} INFO - Started process (PID=60231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:18.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:43:18.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:18.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:18.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:18.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:18.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:43:18.638+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:18.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:43:18.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:43:49.045+0000] {processor.py:157} INFO - Started process (PID=60256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:49.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:43:49.049+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:49.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:49.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:43:49.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:49.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:43:49.092+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:43:49.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:43:49.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T11:44:19.520+0000] {processor.py:157} INFO - Started process (PID=60281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:19.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:44:19.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:19.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:19.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:19.550+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:19.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:44:19.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:19.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:44:19.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T11:44:50.013+0000] {processor.py:157} INFO - Started process (PID=60306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:50.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:44:50.018+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:50.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:50.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:44:50.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:50.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:44:50.056+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:44:50.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:44:50.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:45:20.525+0000] {processor.py:157} INFO - Started process (PID=60330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:20.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:45:20.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:20.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:20.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:20.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:20.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:45:20.566+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:20.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:45:20.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:45:50.935+0000] {processor.py:157} INFO - Started process (PID=60356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:50.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:45:50.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:50.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:50.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:45:50.965+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:50.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:45:50.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:45:50.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:45:50.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:46:21.355+0000] {processor.py:157} INFO - Started process (PID=60381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:21.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:46:21.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:21.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:21.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:21.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:21.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:46:21.400+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:21.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:46:21.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T11:46:51.814+0000] {processor.py:157} INFO - Started process (PID=60406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:51.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:46:51.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:51.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:51.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:46:51.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:51.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:46:51.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:46:51.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:46:51.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:47:22.314+0000] {processor.py:157} INFO - Started process (PID=60431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:22.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:47:22.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:22.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:22.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:22.344+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:22.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:47:22.354+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:22.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:47:22.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:47:52.813+0000] {processor.py:157} INFO - Started process (PID=60456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:52.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:47:52.817+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:52.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:52.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:47:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:52.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:47:52.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:47:52.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:47:52.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T11:48:23.298+0000] {processor.py:157} INFO - Started process (PID=60481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:23.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:48:23.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:23.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:23.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:23.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:23.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:48:23.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:23.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:48:23.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T11:48:53.782+0000] {processor.py:157} INFO - Started process (PID=60506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:53.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:48:53.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:53.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:53.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:48:53.811+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:53.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:48:53.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:48:53.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:48:53.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:49:24.276+0000] {processor.py:157} INFO - Started process (PID=60531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:24.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:49:24.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:24.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:24.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:24.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:24.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:49:24.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:24.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:49:24.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:49:54.801+0000] {processor.py:157} INFO - Started process (PID=60556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:54.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:49:54.806+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:54.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:54.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:49:54.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:54.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:49:54.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:49:54.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:49:54.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:50:25.265+0000] {processor.py:157} INFO - Started process (PID=60581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:25.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:50:25.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:25.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:25.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:25.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:25.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:50:25.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:25.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:50:25.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T11:50:55.739+0000] {processor.py:157} INFO - Started process (PID=60606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:55.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:50:55.741+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:55.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:55.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:50:55.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:55.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:50:55.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:50:55.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:50:55.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:51:26.121+0000] {processor.py:157} INFO - Started process (PID=60631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:26.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:51:26.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:26.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:26.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:26.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:26.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:51:26.158+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:26.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:51:26.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T11:51:56.619+0000] {processor.py:157} INFO - Started process (PID=60656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:56.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:51:56.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:56.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:56.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:51:56.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:56.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:51:56.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:51:56.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:51:56.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T11:52:27.042+0000] {processor.py:157} INFO - Started process (PID=60681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:27.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:52:27.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:27.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:27.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:27.071+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:27.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:52:27.082+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:27.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:52:27.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:52:57.484+0000] {processor.py:157} INFO - Started process (PID=60706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:57.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:52:57.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:57.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:57.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:52:57.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:57.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:52:57.526+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:52:57.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:52:57.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:53:27.998+0000] {processor.py:157} INFO - Started process (PID=60731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:27.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:53:28.001+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:28.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:28.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:28.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:28.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:53:28.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:28.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:53:28.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T11:53:58.396+0000] {processor.py:157} INFO - Started process (PID=60756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:58.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:53:58.400+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:58.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:58.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:53:58.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:58.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:53:58.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:53:58.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:53:58.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T11:54:28.847+0000] {processor.py:157} INFO - Started process (PID=60781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:28.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:54:28.850+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:28.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:28.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:28.876+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:28.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:54:28.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:28.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:54:28.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T11:54:59.247+0000] {processor.py:157} INFO - Started process (PID=60806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:59.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:54:59.250+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:59.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:59.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:54:59.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:59.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:54:59.294+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:54:59.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:54:59.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T11:55:29.718+0000] {processor.py:157} INFO - Started process (PID=60831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:55:29.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:55:29.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:55:29.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:55:29.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:55:29.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:55:29.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:55:29.758+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:55:29.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:55:29.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T11:56:00.191+0000] {processor.py:157} INFO - Started process (PID=60856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:00.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:56:00.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:00.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:00.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:00.221+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:00.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:56:00.232+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:00.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:56:00.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:56:30.601+0000] {processor.py:157} INFO - Started process (PID=60881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:30.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:56:30.605+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:30.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:30.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:56:30.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:30.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:56:30.642+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:56:30.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:56:30.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:57:01.151+0000] {processor.py:157} INFO - Started process (PID=60906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:01.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:57:01.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:01.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:01.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:01.184+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:01.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:57:01.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:01.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:57:01.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T11:57:31.537+0000] {processor.py:157} INFO - Started process (PID=60931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:31.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:57:31.540+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:31.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:31.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:57:31.569+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:31.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:57:31.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:57:31.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:57:31.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:58:01.980+0000] {processor.py:157} INFO - Started process (PID=60956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:01.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:58:01.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:01.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:01.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:02.012+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:02.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:58:02.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:02.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:58:02.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T11:58:32.485+0000] {processor.py:157} INFO - Started process (PID=60981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:32.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:58:32.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:32.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:32.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:58:32.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:32.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:58:32.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:58:32.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:58:32.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T11:59:02.906+0000] {processor.py:157} INFO - Started process (PID=61006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:02.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:59:02.911+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:02.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:02.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:02.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:02.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:59:02.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:02.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:59:02.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T11:59:33.375+0000] {processor.py:157} INFO - Started process (PID=61031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:33.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T11:59:33.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:33.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:33.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T11:59:33.406+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:33.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T11:59:33.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T11:59:33.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T11:59:33.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:00:03.766+0000] {processor.py:157} INFO - Started process (PID=61056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:03.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:00:03.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:03.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:03.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:03.792+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:03.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:00:03.801+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:03.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:00:03.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T12:00:34.205+0000] {processor.py:157} INFO - Started process (PID=61081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:34.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:00:34.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:34.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:34.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:00:34.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:34.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:00:34.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:00:34.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:00:34.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T12:01:04.665+0000] {processor.py:157} INFO - Started process (PID=61106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:04.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:01:04.668+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:04.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:04.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:04.695+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:04.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:01:04.706+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:04.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:01:04.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T12:01:35.135+0000] {processor.py:157} INFO - Started process (PID=61131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:35.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:01:35.138+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:35.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:35.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:01:35.164+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:35.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:01:35.174+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:01:35.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:01:35.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:02:05.626+0000] {processor.py:157} INFO - Started process (PID=61156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:05.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:02:05.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:05.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:05.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:05.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:05.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:02:05.666+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:05.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:02:05.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T12:02:36.117+0000] {processor.py:157} INFO - Started process (PID=61181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:36.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:02:36.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:36.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:36.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:02:36.148+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:36.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:02:36.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:02:36.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:02:36.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T12:03:06.739+0000] {processor.py:157} INFO - Started process (PID=61206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:06.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:03:06.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:06.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:06.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:06.773+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:06.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:03:06.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:06.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:03:06.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T12:03:37.248+0000] {processor.py:157} INFO - Started process (PID=61231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:37.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:03:37.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:37.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:37.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:03:37.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:37.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:03:37.297+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:03:37.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:03:37.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T12:04:07.731+0000] {processor.py:157} INFO - Started process (PID=61256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:07.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:04:07.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:07.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:07.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:07.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:07.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:04:07.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:07.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:04:07.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T12:04:38.127+0000] {processor.py:157} INFO - Started process (PID=61281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:38.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:04:38.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:38.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:38.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:04:38.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:38.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:04:38.167+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:04:38.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:04:38.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:05:08.574+0000] {processor.py:157} INFO - Started process (PID=61306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:08.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:05:08.579+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:08.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:08.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:08.604+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:08.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:05:08.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:08.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:05:08.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:05:39.007+0000] {processor.py:157} INFO - Started process (PID=61331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:39.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:05:39.009+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:39.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:39.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:05:39.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:39.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:05:39.042+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:05:39.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:05:39.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-27T12:06:09.525+0000] {processor.py:157} INFO - Started process (PID=61356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:09.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:06:09.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:09.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:09.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:09.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:09.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:06:09.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:09.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:06:09.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T12:06:39.937+0000] {processor.py:157} INFO - Started process (PID=61381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:39.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:06:39.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:39.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:39.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:06:39.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:39.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:06:39.980+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:06:39.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:06:39.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:07:10.432+0000] {processor.py:157} INFO - Started process (PID=61406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:10.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:07:10.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:10.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:10.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:10.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:10.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:07:10.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:10.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:07:10.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:07:40.948+0000] {processor.py:157} INFO - Started process (PID=61431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:40.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:07:40.953+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:40.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:40.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:07:40.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:40.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:07:40.994+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:07:40.994+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:07:41.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:08:11.465+0000] {processor.py:157} INFO - Started process (PID=61456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:11.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:08:11.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:11.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:11.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:11.493+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:11.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:08:11.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:11.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:08:11.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T12:08:41.979+0000] {processor.py:157} INFO - Started process (PID=61481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:41.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:08:41.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:41.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:41.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:08:42.009+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:42.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:08:42.019+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:08:42.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:08:42.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T12:09:12.401+0000] {processor.py:157} INFO - Started process (PID=61506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:12.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:09:12.404+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:12.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:12.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:12.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:12.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:09:12.450+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:12.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:09:12.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T12:09:42.917+0000] {processor.py:157} INFO - Started process (PID=61531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:42.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:09:42.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:42.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:42.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:09:42.947+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:42.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:09:42.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:09:42.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:09:42.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:10:13.274+0000] {processor.py:157} INFO - Started process (PID=61556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:13.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:10:13.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:13.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:13.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:13.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:13.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:10:13.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:13.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:10:13.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T12:10:43.774+0000] {processor.py:157} INFO - Started process (PID=61581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:43.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:10:43.777+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:43.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:43.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:10:43.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:43.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:10:43.819+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:10:43.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:10:43.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T12:11:14.281+0000] {processor.py:157} INFO - Started process (PID=61606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:14.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:11:14.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:14.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:14.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:14.307+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:14.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:11:14.319+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:14.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:11:14.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T12:11:44.653+0000] {processor.py:157} INFO - Started process (PID=61631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:44.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:11:44.656+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:44.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:44.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:11:44.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:44.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:11:44.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:11:44.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:11:44.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:12:15.139+0000] {processor.py:157} INFO - Started process (PID=61656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:15.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:12:15.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:15.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:15.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:15.167+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:15.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:12:15.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:15.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:12:15.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:12:45.606+0000] {processor.py:157} INFO - Started process (PID=61681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:45.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:12:45.609+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:45.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:45.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:12:45.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:45.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:12:45.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:12:45.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:12:45.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:13:16.148+0000] {processor.py:157} INFO - Started process (PID=61706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:16.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:13:16.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:16.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:16.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:16.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:16.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:13:16.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:16.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:13:16.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:13:46.531+0000] {processor.py:157} INFO - Started process (PID=61731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:46.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:13:46.535+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:46.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:46.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:13:46.568+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:46.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:13:46.579+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:13:46.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:13:46.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T12:14:17.010+0000] {processor.py:157} INFO - Started process (PID=61756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:17.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:14:17.015+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:17.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:17.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:17.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:17.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:14:17.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:17.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:14:17.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T12:14:47.483+0000] {processor.py:157} INFO - Started process (PID=61781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:47.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:14:47.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:47.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:47.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:14:47.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:47.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:14:47.522+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:14:47.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:14:47.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:15:17.934+0000] {processor.py:157} INFO - Started process (PID=61806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:17.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:15:17.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:17.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:17.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:17.966+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:17.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:15:17.976+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:17.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:15:17.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:15:48.429+0000] {processor.py:157} INFO - Started process (PID=61831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:48.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:15:48.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:48.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:48.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:15:48.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:48.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:15:48.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:15:48.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:15:48.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:16:18.908+0000] {processor.py:157} INFO - Started process (PID=61856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:18.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:16:18.911+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:18.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:18.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:18.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:18.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:16:18.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:18.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:16:18.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:16:49.364+0000] {processor.py:157} INFO - Started process (PID=61881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:49.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:16:49.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:49.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:49.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:16:49.398+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:49.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:16:49.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:16:49.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:16:49.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:17:19.760+0000] {processor.py:157} INFO - Started process (PID=61906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:19.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:17:19.763+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:19.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:19.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:19.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:19.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:17:19.807+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:19.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:17:19.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:17:50.175+0000] {processor.py:157} INFO - Started process (PID=61931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:50.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:17:50.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:50.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:50.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:17:50.202+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:50.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:17:50.212+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:17:50.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:17:50.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T12:18:20.625+0000] {processor.py:157} INFO - Started process (PID=61956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:20.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:18:20.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:20.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:20.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:20.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:20.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:18:20.668+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:20.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:18:20.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:18:51.155+0000] {processor.py:157} INFO - Started process (PID=61981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:51.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:18:51.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:51.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:51.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:18:51.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:51.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:18:51.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:18:51.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:18:51.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T12:19:21.647+0000] {processor.py:157} INFO - Started process (PID=62006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:21.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:19:21.649+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:21.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:21.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:21.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:21.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:19:21.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:21.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:19:21.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T12:19:52.104+0000] {processor.py:157} INFO - Started process (PID=62031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:52.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:19:52.109+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:52.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:52.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:19:52.135+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:52.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:19:52.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:19:52.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:19:52.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T12:20:22.578+0000] {processor.py:157} INFO - Started process (PID=62056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:22.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:20:22.581+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:22.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:22.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:22.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:22.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:20:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:22.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:20:22.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:20:53.035+0000] {processor.py:157} INFO - Started process (PID=62081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:53.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:20:53.038+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:53.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:53.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:20:53.070+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:53.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:20:53.082+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:20:53.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:20:53.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T12:21:23.450+0000] {processor.py:157} INFO - Started process (PID=62106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:23.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:21:23.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:23.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:23.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:23.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:23.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:21:23.490+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:23.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:21:23.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:21:53.930+0000] {processor.py:157} INFO - Started process (PID=62131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:53.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:21:53.933+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:53.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:53.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:21:53.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:53.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:21:53.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:21:53.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:21:53.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T12:22:24.389+0000] {processor.py:157} INFO - Started process (PID=62155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:24.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:22:24.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:24.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:24.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:24.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:24.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:22:24.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:24.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:22:24.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:22:54.813+0000] {processor.py:157} INFO - Started process (PID=62181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:54.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:22:54.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:54.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:54.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:22:54.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:54.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:22:54.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:22:54.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:22:54.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:23:25.238+0000] {processor.py:157} INFO - Started process (PID=62206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:25.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:23:25.241+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:25.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:25.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:25.266+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:25.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:23:25.276+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:25.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:23:25.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:23:55.693+0000] {processor.py:157} INFO - Started process (PID=62231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:55.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:23:55.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:55.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:55.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:23:55.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:55.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:23:55.734+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:23:55.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:23:55.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T12:24:26.097+0000] {processor.py:157} INFO - Started process (PID=62256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:26.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:24:26.100+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:26.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:26.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:26.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:26.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:24:26.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:26.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:24:26.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T12:24:56.632+0000] {processor.py:157} INFO - Started process (PID=62281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:56.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:24:56.637+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:56.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:56.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:24:56.668+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:56.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:24:56.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:24:56.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:24:56.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T12:25:26.987+0000] {processor.py:157} INFO - Started process (PID=62306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:26.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:25:26.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:26.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:27.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:27.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:27.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:25:27.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:27.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:25:27.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:25:57.394+0000] {processor.py:157} INFO - Started process (PID=62331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:57.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:25:57.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:57.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:57.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:25:57.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:57.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:25:57.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:25:57.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:25:57.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T12:26:27.853+0000] {processor.py:157} INFO - Started process (PID=62356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:27.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:26:27.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:27.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:27.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:27.876+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:27.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:26:27.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:27.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:26:27.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T12:26:58.267+0000] {processor.py:157} INFO - Started process (PID=62381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:58.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:26:58.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:58.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:58.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:26:58.331+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:58.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:26:58.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:26:58.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:26:58.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T12:27:28.783+0000] {processor.py:157} INFO - Started process (PID=62406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:28.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:27:28.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:28.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:28.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:28.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:28.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:27:28.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:28.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:27:28.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T12:27:59.188+0000] {processor.py:157} INFO - Started process (PID=62431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:59.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:27:59.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:59.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:59.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:27:59.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:59.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:27:59.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:27:59.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:27:59.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T12:28:29.756+0000] {processor.py:157} INFO - Started process (PID=62456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:28:29.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:28:29.759+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:28:29.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:28:29.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:28:29.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:28:29.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:28:29.800+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:28:29.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:28:29.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:29:00.167+0000] {processor.py:157} INFO - Started process (PID=62481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:00.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:29:00.175+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:00.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:00.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:00.227+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:00.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:29:00.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:00.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:29:00.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-27T12:29:30.839+0000] {processor.py:157} INFO - Started process (PID=62506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:30.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:29:30.847+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:30.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:30.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:29:30.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:30.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:29:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:29:30.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:29:30.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-07-27T12:30:01.643+0000] {processor.py:157} INFO - Started process (PID=62531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:01.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:30:01.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:01.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:01.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:01.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:01.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:30:01.723+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:01.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:30:01.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T12:30:32.250+0000] {processor.py:157} INFO - Started process (PID=62555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:32.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:30:32.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:32.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:32.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:30:32.329+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:32.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:30:32.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:30:32.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:30:32.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-07-27T12:31:02.817+0000] {processor.py:157} INFO - Started process (PID=62581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:02.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:31:02.835+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:02.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:02.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:02.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:02.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:31:02.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:02.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:31:02.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-27T12:31:33.396+0000] {processor.py:157} INFO - Started process (PID=62606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:33.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:31:33.406+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:33.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:33.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:31:33.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:33.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:31:33.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:31:33.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:31:33.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-07-27T12:32:04.126+0000] {processor.py:157} INFO - Started process (PID=62631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:04.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:32:04.140+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:04.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:04.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:04.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:04.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:32:04.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:04.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:32:04.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T12:32:34.645+0000] {processor.py:157} INFO - Started process (PID=62656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:34.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:32:34.648+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:34.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:34.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:32:34.676+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:34.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:32:34.687+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:32:34.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:32:34.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T12:33:05.139+0000] {processor.py:157} INFO - Started process (PID=62680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:05.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:33:05.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:05.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:05.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:05.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:05.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:33:05.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:05.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:33:05.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T12:33:35.620+0000] {processor.py:157} INFO - Started process (PID=62706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:35.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:33:35.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:35.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:35.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:33:35.666+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:35.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:33:35.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:33:35.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:33:35.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T12:34:06.192+0000] {processor.py:157} INFO - Started process (PID=62731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:06.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:34:06.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:06.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:06.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:06.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:06.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:34:06.287+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:06.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:34:06.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T12:34:36.807+0000] {processor.py:157} INFO - Started process (PID=62756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:36.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:34:36.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:36.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:36.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:34:36.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:36.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:34:36.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:34:36.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:34:36.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-27T12:35:07.337+0000] {processor.py:157} INFO - Started process (PID=62781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:07.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:35:07.344+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:07.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:07.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:07.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:07.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:35:07.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:07.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:35:07.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T12:35:37.866+0000] {processor.py:157} INFO - Started process (PID=62806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:37.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:35:37.873+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:37.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:37.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:35:37.932+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:37.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:35:37.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:35:37.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:35:37.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T12:36:08.390+0000] {processor.py:157} INFO - Started process (PID=62831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:08.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:36:08.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:08.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:08.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:08.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:08.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:36:08.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:08.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:36:08.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T12:36:38.958+0000] {processor.py:157} INFO - Started process (PID=62856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:38.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:36:38.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:38.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:39.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:36:39.053+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:39.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:36:39.090+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:36:39.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:36:39.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-27T12:37:09.467+0000] {processor.py:157} INFO - Started process (PID=62881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:09.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:37:09.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:09.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:09.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:09.515+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:09.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:37:09.528+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:09.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:37:09.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T12:37:39.949+0000] {processor.py:157} INFO - Started process (PID=62906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:39.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:37:39.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:39.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:40.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:37:40.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:40.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:37:40.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:37:40.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:37:40.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-07-27T12:38:10.581+0000] {processor.py:157} INFO - Started process (PID=62930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:10.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:38:10.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:10.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:10.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:10.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:10.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:38:10.672+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:10.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:38:10.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-27T12:38:41.171+0000] {processor.py:157} INFO - Started process (PID=62955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:41.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:38:41.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:41.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:41.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:38:41.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:41.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:38:41.257+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:38:41.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:38:41.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T12:39:11.713+0000] {processor.py:157} INFO - Started process (PID=62980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:11.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:39:11.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:11.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:11.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:11.766+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:11.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:39:11.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:11.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:39:11.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T12:39:42.275+0000] {processor.py:157} INFO - Started process (PID=63006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:42.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:39:42.283+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:42.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:42.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:39:42.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:42.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:39:42.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:39:42.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:39:42.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-27T12:40:12.714+0000] {processor.py:157} INFO - Started process (PID=63031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:12.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:40:12.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:12.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:12.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:12.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:12.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:40:12.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:12.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:40:12.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T12:40:43.228+0000] {processor.py:157} INFO - Started process (PID=63056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:43.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:40:43.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:43.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:43.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:40:43.287+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:43.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:40:43.304+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:40:43.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:40:43.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T12:41:13.829+0000] {processor.py:157} INFO - Started process (PID=63081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:13.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:41:13.837+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:13.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:13.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:13.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:13.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:41:13.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:13.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:41:13.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T12:41:44.297+0000] {processor.py:157} INFO - Started process (PID=63106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:44.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:41:44.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:44.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:44.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:41:44.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:44.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:41:44.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:41:44.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:41:44.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:42:14.726+0000] {processor.py:157} INFO - Started process (PID=63131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:14.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:42:14.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:14.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:14.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:14.767+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:14.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:42:14.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:14.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:42:14.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T12:42:45.201+0000] {processor.py:157} INFO - Started process (PID=63156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:45.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:42:45.203+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:45.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:45.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:42:45.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:45.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:42:45.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:42:45.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:42:45.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T12:43:15.690+0000] {processor.py:157} INFO - Started process (PID=63181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:15.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:43:15.698+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:15.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:15.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:15.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:15.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:43:15.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:15.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:43:15.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-27T12:43:46.253+0000] {processor.py:157} INFO - Started process (PID=63206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:46.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:43:46.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:46.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:46.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:43:46.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:46.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:43:46.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:43:46.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:43:46.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T12:44:16.710+0000] {processor.py:157} INFO - Started process (PID=63231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:16.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:44:16.713+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:16.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:16.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:16.748+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:16.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:44:16.774+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:16.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:44:16.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T12:44:47.316+0000] {processor.py:157} INFO - Started process (PID=63256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:47.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:44:47.324+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:47.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:47.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:44:47.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:47.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:44:47.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:44:47.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:44:47.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T12:45:17.858+0000] {processor.py:157} INFO - Started process (PID=63281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:17.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:45:17.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:17.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:17.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:17.903+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:17.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:45:17.916+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:17.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:45:17.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T12:45:48.357+0000] {processor.py:157} INFO - Started process (PID=63306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:48.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:45:48.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:48.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:48.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:45:48.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:48.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:45:48.401+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:45:48.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:45:48.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T12:46:18.831+0000] {processor.py:157} INFO - Started process (PID=63330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:18.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:46:18.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:18.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:18.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:18.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:18.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:46:18.893+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:18.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:46:18.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T12:46:49.429+0000] {processor.py:157} INFO - Started process (PID=63356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:49.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:46:49.434+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:49.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:49.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:46:49.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:49.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:46:49.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:46:49.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:46:49.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T12:47:19.916+0000] {processor.py:157} INFO - Started process (PID=63381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:19.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:47:19.920+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:19.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:19.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:19.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:19.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:47:19.969+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:19.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:47:19.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T12:47:50.454+0000] {processor.py:157} INFO - Started process (PID=63405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:50.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:47:50.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:50.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:50.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:47:50.517+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:50.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:47:50.530+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:47:50.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:47:50.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T12:48:21.010+0000] {processor.py:157} INFO - Started process (PID=63431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:21.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:48:21.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:21.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:21.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:21.064+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:21.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:48:21.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:21.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:48:21.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T12:48:51.569+0000] {processor.py:157} INFO - Started process (PID=63456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:51.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:48:51.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:51.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:51.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:48:51.643+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:51.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:48:51.664+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:48:51.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:48:51.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-27T12:49:22.137+0000] {processor.py:157} INFO - Started process (PID=63481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:22.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:49:22.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:22.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:22.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:22.188+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:22.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:49:22.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:22.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:49:22.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T12:49:52.671+0000] {processor.py:157} INFO - Started process (PID=63506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:52.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:49:52.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:52.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:52.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:49:52.736+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:52.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:49:52.751+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:49:52.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:49:52.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-27T12:50:23.284+0000] {processor.py:157} INFO - Started process (PID=63531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:23.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:50:23.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:23.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:23.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:23.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:23.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:50:23.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:23.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:50:23.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T12:50:53.805+0000] {processor.py:157} INFO - Started process (PID=63556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:53.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:50:53.825+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:53.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:53.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:50:53.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:53.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:50:53.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:50:53.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:50:53.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-07-27T12:51:24.404+0000] {processor.py:157} INFO - Started process (PID=63581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:24.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:51:24.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:24.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:24.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:24.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:24.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:51:24.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:24.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:51:24.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-27T12:51:54.938+0000] {processor.py:157} INFO - Started process (PID=63606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:54.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:51:54.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:54.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:54.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:51:54.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:54.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:51:54.996+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:51:54.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:51:55.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T12:52:25.434+0000] {processor.py:157} INFO - Started process (PID=63631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:25.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:52:25.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:25.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:25.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:25.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:25.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:52:25.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:25.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:52:25.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T12:52:55.895+0000] {processor.py:157} INFO - Started process (PID=63656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:55.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:52:55.897+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:55.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:55.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:52:55.923+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:55.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:52:55.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:52:55.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:52:55.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T12:53:26.317+0000] {processor.py:157} INFO - Started process (PID=63681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:26.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:53:26.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:26.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:26.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:26.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:26.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:53:26.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:26.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:53:26.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:53:56.806+0000] {processor.py:157} INFO - Started process (PID=63706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:56.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:53:56.812+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:56.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:56.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:53:56.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:56.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:53:56.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:53:56.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:53:56.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-27T12:54:27.404+0000] {processor.py:157} INFO - Started process (PID=63731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:27.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:54:27.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:27.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:27.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:27.447+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:27.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:54:27.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:27.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:54:27.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T12:54:57.864+0000] {processor.py:157} INFO - Started process (PID=63756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:57.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:54:57.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:57.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:57.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:54:57.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:57.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:54:57.911+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:54:57.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:54:57.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T12:55:28.323+0000] {processor.py:157} INFO - Started process (PID=63781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:28.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:55:28.329+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:28.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:28.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:28.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:28.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:55:28.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:28.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:55:28.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T12:55:58.754+0000] {processor.py:157} INFO - Started process (PID=63806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:58.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:55:58.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:58.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:58.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:55:58.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:58.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:55:58.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:55:58.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:55:58.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T12:56:29.329+0000] {processor.py:157} INFO - Started process (PID=63831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:29.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:56:29.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:29.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:29.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:29.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:29.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:56:29.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:29.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:56:29.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T12:56:59.850+0000] {processor.py:157} INFO - Started process (PID=63856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:59.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:56:59.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:59.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:59.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:56:59.891+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:59.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:56:59.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:56:59.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:56:59.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T12:57:30.337+0000] {processor.py:157} INFO - Started process (PID=63881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:57:30.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:57:30.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:57:30.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:57:30.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:57:30.374+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:57:30.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:57:30.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:57:30.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:57:30.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T12:58:00.796+0000] {processor.py:157} INFO - Started process (PID=63906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:00.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:58:00.799+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:00.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:00.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:00.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:00.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:58:00.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:00.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:58:00.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T12:58:31.305+0000] {processor.py:157} INFO - Started process (PID=63931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:31.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:58:31.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:31.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:31.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:58:31.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:31.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:58:31.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:58:31.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:58:31.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T12:59:01.785+0000] {processor.py:157} INFO - Started process (PID=63956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:01.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:59:01.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:01.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:01.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:01.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:01.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:59:01.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:01.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:59:01.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T12:59:32.273+0000] {processor.py:157} INFO - Started process (PID=63981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:32.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T12:59:32.276+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:32.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:32.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T12:59:32.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:32.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T12:59:32.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T12:59:32.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T12:59:32.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:00:02.737+0000] {processor.py:157} INFO - Started process (PID=64006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:02.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:00:02.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:02.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:02.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:02.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:02.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:00:02.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:02.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:00:02.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T13:00:33.121+0000] {processor.py:157} INFO - Started process (PID=64031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:33.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:00:33.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:33.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:33.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:00:33.152+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:33.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:00:33.163+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:00:33.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:00:33.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:01:03.589+0000] {processor.py:157} INFO - Started process (PID=64056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:03.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:01:03.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:03.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:03.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:03.619+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:03.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:01:03.630+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:03.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:01:03.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:01:34.071+0000] {processor.py:157} INFO - Started process (PID=64081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:34.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:01:34.075+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:34.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:34.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:01:34.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:34.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:01:34.111+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:01:34.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:01:34.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:02:04.557+0000] {processor.py:157} INFO - Started process (PID=64106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:04.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:02:04.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:04.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:04.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:04.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:04.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:02:04.599+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:04.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:02:04.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:02:35.016+0000] {processor.py:157} INFO - Started process (PID=64131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:35.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:02:35.018+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:35.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:35.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:02:35.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:35.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:02:35.051+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:02:35.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:02:35.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T13:03:05.418+0000] {processor.py:157} INFO - Started process (PID=64156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:05.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:03:05.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:05.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:05.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:05.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:05.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:03:05.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:05.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:03:05.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:03:35.911+0000] {processor.py:157} INFO - Started process (PID=64181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:35.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:03:35.913+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:35.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:35.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:03:35.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:35.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:03:35.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:03:35.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:03:35.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T13:04:06.422+0000] {processor.py:157} INFO - Started process (PID=64206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:06.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:04:06.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:06.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:06.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:06.463+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:06.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:04:06.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:06.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:04:06.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T13:04:36.956+0000] {processor.py:157} INFO - Started process (PID=64231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:36.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:04:36.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:36.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:36.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:04:36.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:36.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:04:36.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:04:36.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:04:37.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:05:07.333+0000] {processor.py:157} INFO - Started process (PID=64256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:07.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:05:07.335+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:07.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:07.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:07.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:07.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:05:07.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:07.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:05:07.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T13:05:37.782+0000] {processor.py:157} INFO - Started process (PID=64281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:37.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:05:37.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:37.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:37.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:05:37.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:37.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:05:37.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:05:37.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:05:37.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:06:08.267+0000] {processor.py:157} INFO - Started process (PID=64305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:08.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:06:08.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:08.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:08.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:08.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:08.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:06:08.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:08.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:06:08.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T13:06:38.712+0000] {processor.py:157} INFO - Started process (PID=64331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:38.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:06:38.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:38.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:38.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:06:38.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:38.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:06:38.755+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:06:38.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:06:38.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:07:09.301+0000] {processor.py:157} INFO - Started process (PID=64356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:09.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:07:09.304+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:09.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:09.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:09.333+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:09.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:07:09.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:09.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:07:09.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T13:07:39.728+0000] {processor.py:157} INFO - Started process (PID=64381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:39.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:07:39.732+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:39.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:39.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:07:39.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:39.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:07:39.766+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:07:39.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:07:39.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:08:10.131+0000] {processor.py:157} INFO - Started process (PID=64406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:10.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:08:10.135+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:10.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:10.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:10.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:10.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:08:10.174+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:10.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:08:10.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:08:40.657+0000] {processor.py:157} INFO - Started process (PID=64431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:40.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:08:40.661+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:40.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:40.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:08:40.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:40.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:08:40.714+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:08:40.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:08:40.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T13:09:11.158+0000] {processor.py:157} INFO - Started process (PID=64456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:11.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:09:11.162+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:11.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:11.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:11.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:11.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:09:11.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:11.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:09:11.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T13:09:41.534+0000] {processor.py:157} INFO - Started process (PID=64481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:41.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:09:41.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:41.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:41.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:09:41.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:41.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:09:41.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:09:41.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:09:41.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T13:10:12.052+0000] {processor.py:157} INFO - Started process (PID=64506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:12.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:10:12.056+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:12.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:12.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:12.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:12.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:10:12.090+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:12.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:10:12.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T13:10:42.449+0000] {processor.py:157} INFO - Started process (PID=64531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:42.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:10:42.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:42.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:42.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:10:42.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:42.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:10:42.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:10:42.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:10:42.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:11:12.987+0000] {processor.py:157} INFO - Started process (PID=64556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:12.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:11:12.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:12.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:13.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:13.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:13.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:11:13.029+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:13.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:11:13.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:11:43.421+0000] {processor.py:157} INFO - Started process (PID=64581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:43.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:11:43.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:43.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:43.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:11:43.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:43.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:11:43.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:11:43.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:11:43.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:12:13.929+0000] {processor.py:157} INFO - Started process (PID=64606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:13.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:12:13.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:13.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:13.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:13.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:13.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:12:13.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:13.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:12:13.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:12:44.332+0000] {processor.py:157} INFO - Started process (PID=64631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:44.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:12:44.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:44.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:44.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:12:44.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:44.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:12:44.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:12:44.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:12:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:13:14.708+0000] {processor.py:157} INFO - Started process (PID=64656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:14.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:13:14.712+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:14.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:14.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:14.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:14.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:13:14.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:14.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:13:14.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T13:13:45.221+0000] {processor.py:157} INFO - Started process (PID=64681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:45.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:13:45.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:45.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:45.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:13:45.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:45.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:13:45.265+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:13:45.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:13:45.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T13:14:15.647+0000] {processor.py:157} INFO - Started process (PID=64706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:15.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:14:15.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:15.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:15.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:15.678+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:15.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:14:15.689+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:15.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:14:15.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T13:14:46.159+0000] {processor.py:157} INFO - Started process (PID=64731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:46.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:14:46.164+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:46.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:46.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:14:46.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:46.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:14:46.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:14:46.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:14:46.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:15:16.584+0000] {processor.py:157} INFO - Started process (PID=64756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:16.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:15:16.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:16.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:16.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:16.612+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:16.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:15:16.623+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:16.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:15:16.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:15:47.036+0000] {processor.py:157} INFO - Started process (PID=64781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:47.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:15:47.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:47.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:47.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:15:47.069+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:47.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:15:47.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:15:47.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:15:47.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:16:17.551+0000] {processor.py:157} INFO - Started process (PID=64806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:17.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:16:17.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:17.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:17.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:17.581+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:17.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:16:17.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:17.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:16:17.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:16:48.074+0000] {processor.py:157} INFO - Started process (PID=64831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:48.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:16:48.081+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:48.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:48.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:16:48.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:48.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:16:48.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:16:48.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:16:48.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T13:17:18.586+0000] {processor.py:157} INFO - Started process (PID=64856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:18.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:17:18.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:18.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:18.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:18.621+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:18.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:17:18.631+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:18.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:17:18.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:17:48.948+0000] {processor.py:157} INFO - Started process (PID=64881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:48.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:17:48.953+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:48.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:48.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:17:48.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:48.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:17:48.987+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:17:48.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:17:48.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:18:19.436+0000] {processor.py:157} INFO - Started process (PID=64906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:19.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:18:19.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:19.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:19.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:19.463+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:19.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:18:19.473+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:19.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:18:19.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:18:49.901+0000] {processor.py:157} INFO - Started process (PID=64931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:49.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:18:49.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:49.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:49.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:18:49.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:49.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:18:49.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:18:49.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:18:49.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:19:20.472+0000] {processor.py:157} INFO - Started process (PID=64956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:20.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:19:20.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:20.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:20.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:20.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:20.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:19:20.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:20.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:19:20.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:19:50.856+0000] {processor.py:157} INFO - Started process (PID=64981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:50.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:19:50.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:50.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:50.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:19:50.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:50.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:19:50.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:19:50.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:19:50.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-27T13:20:21.293+0000] {processor.py:157} INFO - Started process (PID=65006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:21.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:20:21.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:21.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:21.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:21.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:21.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:20:21.330+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:21.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:20:21.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:20:51.890+0000] {processor.py:157} INFO - Started process (PID=65031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:51.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:20:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:51.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:51.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:20:51.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:51.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:20:51.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:20:51.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:20:51.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T13:21:22.361+0000] {processor.py:157} INFO - Started process (PID=65056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:22.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:21:22.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:22.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:22.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:22.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:22.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:21:22.403+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:22.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:21:22.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:21:52.833+0000] {processor.py:157} INFO - Started process (PID=65081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:52.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:21:52.837+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:52.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:52.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:21:52.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:52.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:21:52.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:21:52.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:21:52.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:22:23.208+0000] {processor.py:157} INFO - Started process (PID=65106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:23.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:22:23.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:23.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:23.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:23.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:23.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:22:23.250+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:23.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:22:23.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T13:22:53.712+0000] {processor.py:157} INFO - Started process (PID=65131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:53.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:22:53.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:53.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:53.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:22:53.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:53.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:22:53.754+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:22:53.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:22:53.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:23:24.137+0000] {processor.py:157} INFO - Started process (PID=65155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:24.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:23:24.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:24.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:24.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:24.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:24.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:23:24.169+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:24.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:23:24.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T13:23:54.563+0000] {processor.py:157} INFO - Started process (PID=65181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:54.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:23:54.567+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:54.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:54.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:23:54.596+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:54.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:23:54.607+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:23:54.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:23:54.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T13:24:25.153+0000] {processor.py:157} INFO - Started process (PID=65206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:25.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:24:25.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:25.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:25.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:25.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:25.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:24:25.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:25.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:24:25.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T13:24:55.649+0000] {processor.py:157} INFO - Started process (PID=65231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:55.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:24:55.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:55.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:55.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:24:55.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:55.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:24:55.679+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:24:55.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:24:55.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-27T13:25:26.006+0000] {processor.py:157} INFO - Started process (PID=65256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:26.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:25:26.012+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:26.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:26.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:26.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:26.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:25:26.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:26.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:25:26.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:25:56.338+0000] {processor.py:157} INFO - Started process (PID=65281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:56.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:25:56.340+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:56.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:56.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:25:56.366+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:56.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:25:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:25:56.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:25:56.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:26:26.846+0000] {processor.py:157} INFO - Started process (PID=65306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:26.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:26:26.850+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:26.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:26.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:26.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:26.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:26:26.900+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:26.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:26:26.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T13:26:57.298+0000] {processor.py:157} INFO - Started process (PID=65331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:57.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:26:57.300+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:57.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:57.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:26:57.319+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:57.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:26:57.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:26:57.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:26:57.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-27T13:27:27.707+0000] {processor.py:157} INFO - Started process (PID=65356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:27.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:27:27.710+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:27.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:27.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:27.739+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:27.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:27:27.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:27.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:27:27.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:27:58.163+0000] {processor.py:157} INFO - Started process (PID=65381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:58.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:27:58.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:58.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:58.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:27:58.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:58.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:27:58.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:27:58.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:27:58.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:28:28.620+0000] {processor.py:157} INFO - Started process (PID=65404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:28.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:28:28.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:28.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:28.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:28.663+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:28.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:28:28.675+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:28.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:28:28.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T13:28:59.095+0000] {processor.py:157} INFO - Started process (PID=65431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:59.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:28:59.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:59.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:59.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:28:59.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:59.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:28:59.139+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:28:59.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:28:59.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:29:29.530+0000] {processor.py:157} INFO - Started process (PID=65456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:29:29.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:29:29.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:29:29.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:29:29.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:29:29.560+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:29:29.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:29:29.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:29:29.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:29:29.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:30:00.039+0000] {processor.py:157} INFO - Started process (PID=65481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:00.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:30:00.042+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:00.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:00.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:00.070+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:00.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:30:00.080+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:00.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:30:00.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:30:30.431+0000] {processor.py:157} INFO - Started process (PID=65506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:30.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:30:30.432+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:30.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:30.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:30:30.451+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:30.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:30:30.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:30:30.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:30:30.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-27T13:31:00.884+0000] {processor.py:157} INFO - Started process (PID=65531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:00.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:31:00.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:00.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:00.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:00.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:00.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:31:00.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:00.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:31:00.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:31:31.382+0000] {processor.py:157} INFO - Started process (PID=65556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:31.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:31:31.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:31.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:31.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:31:31.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:31.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:31:31.419+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:31:31.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:31:31.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T13:32:01.801+0000] {processor.py:157} INFO - Started process (PID=65581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:01.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:32:01.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:01.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:01.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:01.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:01.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:32:01.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:01.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:32:01.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T13:32:32.307+0000] {processor.py:157} INFO - Started process (PID=65606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:32.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:32:32.312+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:32.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:32.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:32:32.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:32.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:32:32.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:32:32.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:32:32.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:33:02.657+0000] {processor.py:157} INFO - Started process (PID=65631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:02.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:33:02.660+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:02.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:02.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:02.686+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:02.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:33:02.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:02.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:33:02.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:33:33.188+0000] {processor.py:157} INFO - Started process (PID=65656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:33.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:33:33.201+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:33.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:33.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:33:33.289+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:33.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:33:33.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:33:33.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:33:33.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-07-27T13:34:03.783+0000] {processor.py:157} INFO - Started process (PID=65681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:03.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:34:03.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:03.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:03.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:03.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:03.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:34:03.847+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:03.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:34:03.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T13:34:34.220+0000] {processor.py:157} INFO - Started process (PID=65706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:34.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:34:34.223+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:34.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:34.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:34:34.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:34.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:34:34.260+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:34:34.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:34:34.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:35:04.632+0000] {processor.py:157} INFO - Started process (PID=65731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:04.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:35:04.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:04.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:04.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:04.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:04.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:35:04.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:04.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:35:04.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T13:35:35.123+0000] {processor.py:157} INFO - Started process (PID=65756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:35.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:35:35.127+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:35.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:35.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:35:35.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:35.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:35:35.165+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:35:35.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:35:35.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T13:36:05.581+0000] {processor.py:157} INFO - Started process (PID=65781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:05.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:36:05.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:05.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:05.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:05.623+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:05.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:36:05.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:05.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:36:05.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T13:36:36.111+0000] {processor.py:157} INFO - Started process (PID=65806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:36.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:36:36.116+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:36.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:36.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:36:36.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:36.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:36:36.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:36:36.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:36:36.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:37:06.556+0000] {processor.py:157} INFO - Started process (PID=65831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:06.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:37:06.559+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:06.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:06.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:06.582+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:06.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:37:06.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:06.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:37:06.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T13:37:36.999+0000] {processor.py:157} INFO - Started process (PID=65856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:37.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:37:37.003+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:37.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:37.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:37:37.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:37.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:37:37.046+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:37:37.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:37:37.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T13:38:07.435+0000] {processor.py:157} INFO - Started process (PID=65881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:07.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:38:07.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:07.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:07.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:07.463+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:07.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:38:07.473+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:07.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:38:07.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:38:37.854+0000] {processor.py:157} INFO - Started process (PID=65906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:37.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:38:37.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:37.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:37.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:38:37.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:37.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:38:37.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:38:37.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:38:37.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:39:08.271+0000] {processor.py:157} INFO - Started process (PID=65931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:08.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:39:08.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:08.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:08.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:08.304+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:08.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:39:08.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:08.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:39:08.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:39:38.667+0000] {processor.py:157} INFO - Started process (PID=65956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:38.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:39:38.674+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:38.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:38.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:39:38.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:38.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:39:38.720+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:39:38.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:39:38.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T13:40:09.102+0000] {processor.py:157} INFO - Started process (PID=65981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:09.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:40:09.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:09.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:09.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:09.129+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:09.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:40:09.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:09.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:40:09.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:40:39.614+0000] {processor.py:157} INFO - Started process (PID=66006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:39.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:40:39.618+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:39.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:39.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:40:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:39.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:40:39.655+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:40:39.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:40:39.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:41:10.002+0000] {processor.py:157} INFO - Started process (PID=66031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:10.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:41:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:10.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:10.041+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:10.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:41:10.056+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:10.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:41:10.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T13:41:40.508+0000] {processor.py:157} INFO - Started process (PID=66056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:40.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:41:40.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:40.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:40.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:41:40.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:40.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:41:40.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:41:40.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:41:40.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:42:10.940+0000] {processor.py:157} INFO - Started process (PID=66081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:10.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:42:10.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:10.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:10.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:10.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:10.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:42:10.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:10.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:42:10.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:42:41.445+0000] {processor.py:157} INFO - Started process (PID=66106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:41.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:42:41.447+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:41.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:41.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:42:41.473+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:41.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:42:41.483+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:42:41.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:42:41.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:43:11.916+0000] {processor.py:157} INFO - Started process (PID=66131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:11.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:43:11.924+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:11.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:11.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:11.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:11.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:43:11.953+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:11.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:43:11.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T13:43:42.329+0000] {processor.py:157} INFO - Started process (PID=66156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:42.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:43:42.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:42.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:42.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:43:42.359+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:42.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:43:42.369+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:43:42.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:43:42.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T13:44:12.787+0000] {processor.py:157} INFO - Started process (PID=66181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:12.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:44:12.792+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:12.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:12.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:12.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:12.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:44:12.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:12.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:44:12.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T13:44:43.265+0000] {processor.py:157} INFO - Started process (PID=66206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:43.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:44:43.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:43.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:43.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:44:43.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:43.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:44:43.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:44:43.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:44:43.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:45:13.736+0000] {processor.py:157} INFO - Started process (PID=66231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:13.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:45:13.740+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:13.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:13.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:13.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:13.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:45:13.775+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:13.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:45:13.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:45:44.153+0000] {processor.py:157} INFO - Started process (PID=66256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:44.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:45:44.155+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:44.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:44.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:45:44.181+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:44.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:45:44.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:45:44.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:45:44.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T13:46:14.674+0000] {processor.py:157} INFO - Started process (PID=66281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:14.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:46:14.679+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:14.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:14.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:14.706+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:14.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:46:14.717+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:14.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:46:14.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:46:45.177+0000] {processor.py:157} INFO - Started process (PID=66306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:45.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:46:45.179+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:45.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:45.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:46:45.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:45.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:46:45.219+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:46:45.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:46:45.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T13:47:15.706+0000] {processor.py:157} INFO - Started process (PID=66331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:15.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:47:15.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:15.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:15.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:15.745+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:15.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:47:15.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:15.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:47:15.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T13:47:46.114+0000] {processor.py:157} INFO - Started process (PID=66356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:46.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:47:46.117+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:46.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:46.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:47:46.137+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:46.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:47:46.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:47:46.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:47:46.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T13:48:16.585+0000] {processor.py:157} INFO - Started process (PID=66381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:16.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:48:16.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:16.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:16.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:16.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:16.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:48:16.624+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:16.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:48:16.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T13:48:47.101+0000] {processor.py:157} INFO - Started process (PID=66406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:47.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:48:47.104+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:47.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:47.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:48:47.135+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:47.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:48:47.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:48:47.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:48:47.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:49:17.575+0000] {processor.py:157} INFO - Started process (PID=66431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:17.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:49:17.579+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:17.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:17.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:17.609+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:17.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:49:17.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:17.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:49:17.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:49:48.048+0000] {processor.py:157} INFO - Started process (PID=66456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:48.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:49:48.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:48.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:48.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:49:48.075+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:48.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:49:48.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:49:48.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:49:48.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T13:50:18.549+0000] {processor.py:157} INFO - Started process (PID=66481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:18.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:50:18.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:18.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:18.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:18.591+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:18.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:50:18.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:18.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:50:18.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T13:50:49.098+0000] {processor.py:157} INFO - Started process (PID=66506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:49.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:50:49.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:49.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:49.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:50:49.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:49.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:50:49.138+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:50:49.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:50:49.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:51:19.649+0000] {processor.py:157} INFO - Started process (PID=66531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:19.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:51:19.654+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:19.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:19.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:19.683+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:19.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:51:19.695+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:19.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:51:19.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T13:51:50.087+0000] {processor.py:157} INFO - Started process (PID=66556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:50.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:51:50.091+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:50.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:50.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:51:50.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:50.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:51:50.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:51:50.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:51:50.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:52:20.592+0000] {processor.py:157} INFO - Started process (PID=66581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:20.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:52:20.598+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:20.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:20.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:20.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:20.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:52:20.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:20.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:52:20.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:52:51.117+0000] {processor.py:157} INFO - Started process (PID=66606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:51.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:52:51.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:51.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:51.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:52:51.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:51.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:52:51.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:52:51.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:52:51.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T13:53:21.517+0000] {processor.py:157} INFO - Started process (PID=66631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:21.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:53:21.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:21.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:21.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:21.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:21.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:53:21.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:21.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:53:21.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T13:53:51.995+0000] {processor.py:157} INFO - Started process (PID=66655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:51.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:53:51.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:51.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:52.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:53:52.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:52.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:53:52.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:53:52.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:53:52.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T13:54:22.456+0000] {processor.py:157} INFO - Started process (PID=66681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:22.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:54:22.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:22.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:22.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:22.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:22.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:54:22.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:22.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:54:22.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T13:54:52.945+0000] {processor.py:157} INFO - Started process (PID=66706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:52.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:54:52.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:52.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:52.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:54:52.978+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:52.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:54:52.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:54:52.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:54:52.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T13:55:23.407+0000] {processor.py:157} INFO - Started process (PID=66731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:23.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:55:23.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:23.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:23.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:23.446+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:23.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:55:23.457+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:23.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:55:23.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T13:55:53.921+0000] {processor.py:157} INFO - Started process (PID=66756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:53.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:55:53.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:53.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:53.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:55:53.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:53.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:55:53.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:55:53.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:55:53.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T13:56:24.350+0000] {processor.py:157} INFO - Started process (PID=66781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:24.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:56:24.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:24.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:24.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:24.381+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:24.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:56:24.391+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:24.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:56:24.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T13:56:54.763+0000] {processor.py:157} INFO - Started process (PID=66806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:54.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:56:54.765+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:54.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:54.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:56:54.791+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:54.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:56:54.801+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:56:54.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:56:54.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T13:57:25.244+0000] {processor.py:157} INFO - Started process (PID=66831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:25.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:57:25.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:25.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:25.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:25.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:25.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:57:25.286+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:25.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:57:25.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T13:57:55.688+0000] {processor.py:157} INFO - Started process (PID=66856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:55.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:57:55.690+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:55.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:55.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:57:55.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:55.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:57:55.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:57:55.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:57:55.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T13:58:26.255+0000] {processor.py:157} INFO - Started process (PID=66881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:26.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:58:26.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:26.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:26.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:26.287+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:26.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:58:26.297+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:26.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:58:26.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T13:58:56.699+0000] {processor.py:157} INFO - Started process (PID=66906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:56.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:58:56.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:56.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:56.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:58:56.744+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:56.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:58:56.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:58:56.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:58:56.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T13:59:27.149+0000] {processor.py:157} INFO - Started process (PID=66931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:27.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:59:27.152+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:27.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:27.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:27.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:59:27.196+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:27.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:59:27.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T13:59:57.575+0000] {processor.py:157} INFO - Started process (PID=66956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:57.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T13:59:57.577+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:57.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:57.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T13:59:57.604+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:57.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T13:59:57.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T13:59:57.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T13:59:57.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:00:27.991+0000] {processor.py:157} INFO - Started process (PID=66981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:27.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:00:27.998+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:27.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:28.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:28.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:28.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:00:28.044+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:28.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:00:28.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T14:00:58.471+0000] {processor.py:157} INFO - Started process (PID=67006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:58.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:00:58.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:58.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:58.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:00:58.500+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:58.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:00:58.510+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:00:58.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:00:58.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:01:28.852+0000] {processor.py:157} INFO - Started process (PID=67031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:28.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:01:28.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:28.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:28.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:28.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:28.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:01:28.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:28.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:01:28.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:01:59.223+0000] {processor.py:157} INFO - Started process (PID=67056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:59.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:01:59.225+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:59.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:59.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:01:59.250+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:59.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:01:59.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:01:59.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:01:59.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:02:29.601+0000] {processor.py:157} INFO - Started process (PID=67081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:02:29.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:02:29.603+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:02:29.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:02:29.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:02:29.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:02:29.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:02:29.642+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:02:29.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:02:29.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:03:00.000+0000] {processor.py:157} INFO - Started process (PID=67106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:00.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:03:00.003+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:00.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:00.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:00.031+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:00.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:03:00.042+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:00.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:03:00.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:03:30.427+0000] {processor.py:157} INFO - Started process (PID=67131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:30.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:03:30.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:30.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:30.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:03:30.462+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:30.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:03:30.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:03:30.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:03:30.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:04:00.894+0000] {processor.py:157} INFO - Started process (PID=67156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:00.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:04:00.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:00.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:00.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:00.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:00.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:04:00.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:00.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:04:00.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T14:04:31.436+0000] {processor.py:157} INFO - Started process (PID=67181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:31.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:04:31.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:31.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:31.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:04:31.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:31.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:04:31.490+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:04:31.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:04:31.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T14:05:01.940+0000] {processor.py:157} INFO - Started process (PID=67206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:01.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:05:01.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:01.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:01.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:01.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:01.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:05:01.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:01.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:05:01.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:05:32.404+0000] {processor.py:157} INFO - Started process (PID=67231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:32.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:05:32.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:32.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:32.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:05:32.439+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:32.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:05:32.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:05:32.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:05:32.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T14:06:02.811+0000] {processor.py:157} INFO - Started process (PID=67256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:02.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:06:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:02.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:02.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:02.849+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:02.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:06:02.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:02.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:06:02.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T14:06:33.231+0000] {processor.py:157} INFO - Started process (PID=67281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:33.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:06:33.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:33.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:33.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:06:33.262+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:33.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:06:33.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:06:33.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:06:33.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:07:03.654+0000] {processor.py:157} INFO - Started process (PID=67306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:03.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:07:03.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:03.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:03.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:03.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:03.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:07:03.701+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:03.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:07:03.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T14:07:34.098+0000] {processor.py:157} INFO - Started process (PID=67331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:34.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:07:34.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:34.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:34.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:07:34.126+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:34.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:07:34.136+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:07:34.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:07:34.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:08:04.585+0000] {processor.py:157} INFO - Started process (PID=67356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:04.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:08:04.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:04.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:04.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:04.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:04.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:08:04.628+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:04.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:08:04.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:08:34.988+0000] {processor.py:157} INFO - Started process (PID=67381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:34.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:08:34.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:34.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:35.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:08:35.014+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:35.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:08:35.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:08:35.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:08:35.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-27T14:09:05.410+0000] {processor.py:157} INFO - Started process (PID=67405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:05.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:09:05.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:05.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:05.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:05.450+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:05.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:09:05.462+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:05.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:09:05.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T14:09:35.843+0000] {processor.py:157} INFO - Started process (PID=67431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:35.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:09:35.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:35.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:35.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:09:35.876+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:35.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:09:35.889+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:09:35.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:09:35.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T14:10:06.358+0000] {processor.py:157} INFO - Started process (PID=67456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:06.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:10:06.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:06.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:06.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:06.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:06.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:10:06.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:06.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:10:06.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T14:10:36.843+0000] {processor.py:157} INFO - Started process (PID=67481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:36.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:10:36.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:36.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:36.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:10:36.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:36.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:10:36.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:10:36.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:10:36.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:11:07.293+0000] {processor.py:157} INFO - Started process (PID=67506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:07.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:11:07.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:07.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:07.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:07.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:07.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:11:07.340+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:07.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:11:07.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T14:11:37.749+0000] {processor.py:157} INFO - Started process (PID=67531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:37.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:11:37.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:37.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:37.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:11:37.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:37.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:11:37.792+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:11:37.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:11:37.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:12:08.158+0000] {processor.py:157} INFO - Started process (PID=67556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:08.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:12:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:08.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:08.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:08.182+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:08.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:12:08.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:08.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:12:08.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T14:12:38.660+0000] {processor.py:157} INFO - Started process (PID=67581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:38.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:12:38.667+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:38.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:38.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:12:38.702+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:38.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:12:38.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:12:38.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:12:38.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T14:13:09.123+0000] {processor.py:157} INFO - Started process (PID=67606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:09.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:13:09.126+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:09.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:09.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:09.150+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:09.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:13:09.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:09.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:13:09.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T14:13:39.605+0000] {processor.py:157} INFO - Started process (PID=67631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:39.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:13:39.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:39.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:39.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:13:39.636+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:39.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:13:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:13:39.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:13:39.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:14:10.127+0000] {processor.py:157} INFO - Started process (PID=67656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:10.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:14:10.130+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:10.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:10.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:10.160+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:10.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:14:10.174+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:10.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:14:10.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T14:14:40.533+0000] {processor.py:157} INFO - Started process (PID=67681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:40.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:14:40.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:40.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:40.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:14:40.564+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:40.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:14:40.574+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:14:40.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:14:40.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:15:10.992+0000] {processor.py:157} INFO - Started process (PID=67706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:10.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:15:10.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:10.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:11.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:11.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:11.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:15:11.041+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:11.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:15:11.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T14:15:41.436+0000] {processor.py:157} INFO - Started process (PID=67731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:41.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:15:41.439+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:41.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:41.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:15:41.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:41.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:15:41.478+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:15:41.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:15:41.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:16:11.946+0000] {processor.py:157} INFO - Started process (PID=67756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:11.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:16:11.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:11.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:11.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:11.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:11.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:16:11.988+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:11.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:16:11.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:16:42.407+0000] {processor.py:157} INFO - Started process (PID=67781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:42.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:16:42.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:42.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:42.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:16:42.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:42.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:16:42.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:16:42.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:16:42.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:17:12.906+0000] {processor.py:157} INFO - Started process (PID=67806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:12.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:17:12.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:12.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:12.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:12.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:12.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:17:12.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:12.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:17:12.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T14:17:43.389+0000] {processor.py:157} INFO - Started process (PID=67831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:43.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:17:43.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:43.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:43.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:17:43.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:43.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:17:43.430+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:17:43.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:17:43.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:18:13.827+0000] {processor.py:157} INFO - Started process (PID=67856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:13.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:18:13.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:13.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:13.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:13.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:13.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:18:13.868+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:13.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:18:13.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:18:44.299+0000] {processor.py:157} INFO - Started process (PID=67881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:44.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:18:44.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:44.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:44.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:18:44.330+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:44.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:18:44.340+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:18:44.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:18:44.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:19:14.708+0000] {processor.py:157} INFO - Started process (PID=67905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:14.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:19:14.713+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:14.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:14.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:14.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:14.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:19:14.781+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:14.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:19:14.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-27T14:19:45.250+0000] {processor.py:157} INFO - Started process (PID=67931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:45.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:19:45.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:45.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:45.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:19:45.287+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:45.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:19:45.298+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:19:45.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:19:45.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T14:20:15.692+0000] {processor.py:157} INFO - Started process (PID=67956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:15.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:20:15.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:15.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:15.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:15.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:15.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:20:15.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:15.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:20:15.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:20:46.173+0000] {processor.py:157} INFO - Started process (PID=67981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:46.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:20:46.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:46.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:46.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:20:46.205+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:46.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:20:46.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:20:46.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:20:46.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:21:16.719+0000] {processor.py:157} INFO - Started process (PID=68006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:16.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:21:16.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:16.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:16.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:16.760+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:16.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:21:16.770+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:16.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:21:16.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T14:21:47.116+0000] {processor.py:157} INFO - Started process (PID=68031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:47.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:21:47.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:47.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:47.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:21:47.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:47.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:21:47.155+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:21:47.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:21:47.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:22:17.631+0000] {processor.py:157} INFO - Started process (PID=68056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:17.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:22:17.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:17.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:17.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:17.655+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:17.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:22:17.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:17.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:22:17.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T14:22:48.062+0000] {processor.py:157} INFO - Started process (PID=68081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:48.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:22:48.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:48.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:48.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:22:48.098+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:48.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:22:48.112+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:22:48.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:22:48.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T14:23:18.555+0000] {processor.py:157} INFO - Started process (PID=68106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:18.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:23:18.559+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:18.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:18.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:18.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:18.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:23:18.593+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:18.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:23:18.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T14:23:48.975+0000] {processor.py:157} INFO - Started process (PID=68131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:48.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:23:48.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:48.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:48.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:23:49.011+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:49.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:23:49.024+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:23:49.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:23:49.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T14:24:19.535+0000] {processor.py:157} INFO - Started process (PID=68156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:19.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:24:19.541+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:19.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:19.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:19.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:24:19.597+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:19.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:24:19.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T14:24:49.986+0000] {processor.py:157} INFO - Started process (PID=68181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:49.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:24:49.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:49.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:49.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:24:50.018+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:50.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:24:50.032+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:24:50.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:24:50.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:25:20.550+0000] {processor.py:157} INFO - Started process (PID=68206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:20.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:25:20.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:20.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:20.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:20.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:20.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:25:20.592+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:20.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:25:20.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:25:51.004+0000] {processor.py:157} INFO - Started process (PID=68231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:51.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:25:51.008+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:51.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:51.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:25:51.034+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:51.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:25:51.043+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:25:51.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:25:51.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T14:26:21.479+0000] {processor.py:157} INFO - Started process (PID=68256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:21.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:26:21.482+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:21.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:21.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:21.509+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:21.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:26:21.519+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:21.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:26:21.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:26:51.925+0000] {processor.py:157} INFO - Started process (PID=68281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:51.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:26:51.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:51.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:51.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:26:51.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:51.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:26:51.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:26:51.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:26:51.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:27:22.387+0000] {processor.py:157} INFO - Started process (PID=68306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:22.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:27:22.390+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:22.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:22.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:22.416+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:22.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:27:22.426+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:22.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:27:22.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T14:27:52.889+0000] {processor.py:157} INFO - Started process (PID=68331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:52.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:27:52.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:52.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:52.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:27:52.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:52.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:27:52.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:27:52.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:27:52.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T14:28:23.383+0000] {processor.py:157} INFO - Started process (PID=68356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:23.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:28:23.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:23.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:23.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:23.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:23.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:28:23.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:23.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:28:23.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:28:53.864+0000] {processor.py:157} INFO - Started process (PID=68381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:53.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:28:53.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:53.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:53.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:28:53.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:53.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:28:53.907+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:28:53.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:28:53.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:29:24.372+0000] {processor.py:157} INFO - Started process (PID=68406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:24.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:29:24.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:24.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:24.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:24.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:24.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:29:24.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:24.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:29:24.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:29:54.864+0000] {processor.py:157} INFO - Started process (PID=68431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:54.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:29:54.867+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:54.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:54.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:29:54.896+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:54.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:29:54.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:29:54.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:29:54.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:30:25.320+0000] {processor.py:157} INFO - Started process (PID=68456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:25.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:30:25.324+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:25.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:25.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:25.353+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:25.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:30:25.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:25.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:30:25.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:30:55.825+0000] {processor.py:157} INFO - Started process (PID=68481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:55.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:30:55.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:55.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:55.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:30:55.868+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:55.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:30:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:30:55.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:30:55.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T14:31:26.347+0000] {processor.py:157} INFO - Started process (PID=68506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:26.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:31:26.351+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:26.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:26.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:26.379+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:26.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:31:26.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:26.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:31:26.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T14:31:56.789+0000] {processor.py:157} INFO - Started process (PID=68531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:56.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:31:56.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:56.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:56.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:31:56.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:56.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:31:56.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:31:56.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:31:56.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:32:27.237+0000] {processor.py:157} INFO - Started process (PID=68555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:27.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:32:27.241+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:27.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:27.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:27.271+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:27.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:32:27.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:27.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:32:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T14:32:57.660+0000] {processor.py:157} INFO - Started process (PID=68581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:57.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:32:57.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:57.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:57.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:32:57.693+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:57.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:32:57.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:32:57.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:32:57.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T14:33:28.117+0000] {processor.py:157} INFO - Started process (PID=68606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:28.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:33:28.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:28.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:28.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:28.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:28.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:33:28.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:28.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:33:28.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:33:58.617+0000] {processor.py:157} INFO - Started process (PID=68631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:58.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:33:58.624+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:58.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:58.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:33:58.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:58.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:33:58.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:33:58.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:33:58.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T14:34:29.030+0000] {processor.py:157} INFO - Started process (PID=68656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:29.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:34:29.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:29.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:29.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:29.065+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:29.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:34:29.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:29.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:34:29.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T14:34:59.527+0000] {processor.py:157} INFO - Started process (PID=68681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:59.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:34:59.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:59.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:59.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:34:59.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:59.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:34:59.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:34:59.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:34:59.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T14:35:29.968+0000] {processor.py:157} INFO - Started process (PID=68706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:35:29.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:35:29.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:35:29.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:35:29.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:35:30.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:35:30.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:35:30.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:35:30.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:35:30.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-27T14:36:00.457+0000] {processor.py:157} INFO - Started process (PID=68731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:00.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:36:00.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:00.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:00.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:00.525+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:00.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:36:00.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:00.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:36:00.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T14:36:30.943+0000] {processor.py:157} INFO - Started process (PID=68756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:30.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:36:30.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:30.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:30.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:36:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:30.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:36:30.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:36:30.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:36:30.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:37:01.363+0000] {processor.py:157} INFO - Started process (PID=68781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:01.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:37:01.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:01.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:01.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:01.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:01.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:37:01.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:01.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:37:01.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:37:31.832+0000] {processor.py:157} INFO - Started process (PID=68806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:31.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:37:31.835+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:31.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:31.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:37:31.871+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:31.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:37:31.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:37:31.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:37:31.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T14:38:02.328+0000] {processor.py:157} INFO - Started process (PID=68831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:02.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:38:02.332+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:02.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:02.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:02.358+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:02.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:38:02.368+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:02.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:38:02.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:38:32.711+0000] {processor.py:157} INFO - Started process (PID=68856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:32.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:38:32.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:32.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:32.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:38:32.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:32.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:38:32.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:38:32.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:38:32.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:39:03.287+0000] {processor.py:157} INFO - Started process (PID=68881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:03.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:39:03.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:03.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:03.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:03.334+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:03.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:39:03.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:03.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:39:03.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T14:39:33.816+0000] {processor.py:157} INFO - Started process (PID=68906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:33.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:39:33.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:33.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:33.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:39:33.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:33.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:39:33.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:39:33.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:39:33.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:40:04.197+0000] {processor.py:157} INFO - Started process (PID=68931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:04.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:40:04.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:04.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:04.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:04.222+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:04.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:40:04.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:04.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:40:04.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T14:40:34.606+0000] {processor.py:157} INFO - Started process (PID=68956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:34.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:40:34.609+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:34.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:34.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:40:34.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:34.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:40:34.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:40:34.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:40:34.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:41:05.036+0000] {processor.py:157} INFO - Started process (PID=68981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:05.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:41:05.041+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:05.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:05.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:05.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:05.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:41:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:05.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:41:05.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T14:41:35.557+0000] {processor.py:157} INFO - Started process (PID=69006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:35.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:41:35.560+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:35.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:35.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:41:35.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:35.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:41:35.594+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:41:35.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:41:35.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T14:42:06.034+0000] {processor.py:157} INFO - Started process (PID=69031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:06.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:42:06.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:06.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:06.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:06.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:06.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:42:06.078+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:06.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:42:06.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:42:36.440+0000] {processor.py:157} INFO - Started process (PID=69056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:36.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:42:36.446+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:36.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:36.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:42:36.463+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:36.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:42:36.472+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:42:36.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:42:36.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T14:43:06.924+0000] {processor.py:157} INFO - Started process (PID=69081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:06.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:43:06.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:06.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:06.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:06.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:06.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:43:06.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:06.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:43:06.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T14:43:37.443+0000] {processor.py:157} INFO - Started process (PID=69106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:37.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:43:37.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:37.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:37.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:43:37.486+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:37.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:43:37.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:43:37.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:43:37.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T14:44:07.970+0000] {processor.py:157} INFO - Started process (PID=69131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:07.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:44:07.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:07.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:07.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:08.004+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:08.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:44:08.019+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:08.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:44:08.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T14:44:38.494+0000] {processor.py:157} INFO - Started process (PID=69156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:38.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:44:38.497+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:38.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:38.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:44:38.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:38.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:44:38.533+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:44:38.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:44:38.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T14:45:08.999+0000] {processor.py:157} INFO - Started process (PID=69181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:09.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:45:09.003+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:09.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:09.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:09.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:09.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:45:09.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:09.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:45:09.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T14:45:39.585+0000] {processor.py:157} INFO - Started process (PID=69206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:39.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:45:39.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:39.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:39.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:45:39.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:39.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:45:39.623+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:45:39.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:45:39.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T14:46:10.046+0000] {processor.py:157} INFO - Started process (PID=69231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:10.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:46:10.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:10.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:10.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:10.079+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:10.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:46:10.091+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:10.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:46:10.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:46:40.608+0000] {processor.py:157} INFO - Started process (PID=69256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:40.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:46:40.611+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:40.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:40.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:46:40.640+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:40.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:46:40.649+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:46:40.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:46:40.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:47:10.997+0000] {processor.py:157} INFO - Started process (PID=69281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:10.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:47:11.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:11.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:11.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:11.029+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:11.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:47:11.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:11.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:47:11.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:47:41.488+0000] {processor.py:157} INFO - Started process (PID=69306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:41.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:47:41.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:41.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:41.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:47:41.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:41.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:47:41.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:47:41.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:47:41.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:48:11.878+0000] {processor.py:157} INFO - Started process (PID=69331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:11.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:48:11.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:11.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:11.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:11.914+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:11.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:48:11.923+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:11.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:48:11.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:48:42.393+0000] {processor.py:157} INFO - Started process (PID=69356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:42.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:48:42.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:42.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:42.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:48:42.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:42.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:48:42.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:48:42.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:48:42.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T14:49:12.853+0000] {processor.py:157} INFO - Started process (PID=69381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:12.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:49:12.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:12.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:12.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:12.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:12.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:49:12.883+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:12.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:49:12.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-07-27T14:49:43.457+0000] {processor.py:157} INFO - Started process (PID=69406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:43.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:49:43.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:43.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:43.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:49:43.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:43.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:49:43.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:49:43.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:49:43.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:50:14.015+0000] {processor.py:157} INFO - Started process (PID=69431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:14.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:50:14.022+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:14.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:14.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:14.054+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:14.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:50:14.063+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:14.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:50:14.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T14:50:44.504+0000] {processor.py:157} INFO - Started process (PID=69456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:44.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:50:44.506+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:44.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:44.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:50:44.535+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:44.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:50:44.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:50:44.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:50:44.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:51:14.977+0000] {processor.py:157} INFO - Started process (PID=69481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:14.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:51:14.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:14.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:14.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:15.007+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:15.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:51:15.018+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:15.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:51:15.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:51:45.466+0000] {processor.py:157} INFO - Started process (PID=69506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:45.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:51:45.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:45.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:45.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:51:45.496+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:45.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:51:45.506+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:51:45.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:51:45.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:52:15.923+0000] {processor.py:157} INFO - Started process (PID=69531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:15.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:52:15.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:15.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:15.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:15.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:15.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:52:15.954+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:15.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:52:15.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-07-27T14:52:46.374+0000] {processor.py:157} INFO - Started process (PID=69556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:46.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:52:46.377+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:46.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:46.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:52:46.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:46.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:52:46.417+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:52:46.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:52:46.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T14:53:16.824+0000] {processor.py:157} INFO - Started process (PID=69581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:16.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:53:16.829+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:16.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:16.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:16.863+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:16.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:53:16.874+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:16.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:53:16.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T14:53:47.278+0000] {processor.py:157} INFO - Started process (PID=69606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:47.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:53:47.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:47.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:47.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:53:47.311+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:47.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:53:47.323+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:53:47.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:53:47.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T14:54:17.840+0000] {processor.py:157} INFO - Started process (PID=69631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:17.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:54:17.843+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:17.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:17.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:17.870+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:17.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:54:17.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:17.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:54:17.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T14:54:48.269+0000] {processor.py:157} INFO - Started process (PID=69656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:48.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:54:48.273+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:48.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:48.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:54:48.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:48.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:54:48.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:54:48.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:54:48.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T14:55:18.783+0000] {processor.py:157} INFO - Started process (PID=69681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:18.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:55:18.787+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:18.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:18.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:18.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:18.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:55:18.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:18.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:55:18.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:55:49.187+0000] {processor.py:157} INFO - Started process (PID=69706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:49.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:55:49.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:49.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:49.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:55:49.215+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:49.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:55:49.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:55:49.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:55:49.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T14:56:19.612+0000] {processor.py:157} INFO - Started process (PID=69731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:19.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:56:19.615+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:19.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:19.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:19.647+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:19.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:56:19.658+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:19.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:56:19.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T14:56:50.208+0000] {processor.py:157} INFO - Started process (PID=69756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:50.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:56:50.213+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:50.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:50.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:56:50.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:50.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:56:50.250+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:56:50.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:56:50.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T14:57:20.671+0000] {processor.py:157} INFO - Started process (PID=69781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:20.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:57:20.677+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:20.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:20.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:20.709+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:20.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:57:20.720+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:20.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:57:20.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T14:57:51.142+0000] {processor.py:157} INFO - Started process (PID=69806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:51.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:57:51.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:51.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:51.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:57:51.173+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:51.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:57:51.187+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:57:51.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:57:51.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:58:21.560+0000] {processor.py:157} INFO - Started process (PID=69831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:21.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:58:21.565+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:21.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:21.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:21.593+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:21.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:58:21.605+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:21.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:58:21.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T14:58:52.114+0000] {processor.py:157} INFO - Started process (PID=69856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:52.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:58:52.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:52.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:52.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:58:52.148+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:52.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:58:52.158+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:58:52.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:58:52.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T14:59:22.568+0000] {processor.py:157} INFO - Started process (PID=69881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:22.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:59:22.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:22.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:22.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:22.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:22.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:59:22.614+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:22.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:59:22.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T14:59:53.028+0000] {processor.py:157} INFO - Started process (PID=69906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:53.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T14:59:53.033+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:53.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:53.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T14:59:53.081+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:53.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T14:59:53.097+0000] {logging_mixin.py:151} INFO - [2024-07-27T14:59:53.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T14:59:53.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-27T15:00:23.495+0000] {processor.py:157} INFO - Started process (PID=69931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:23.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:00:23.500+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:23.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:23.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:23.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:23.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:00:23.536+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:23.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:00:23.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T15:00:53.967+0000] {processor.py:157} INFO - Started process (PID=69956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:53.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:00:53.969+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:53.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:53.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:00:54.000+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:54.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:00:54.013+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:00:54.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:00:54.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T15:01:24.410+0000] {processor.py:157} INFO - Started process (PID=69981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:24.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:01:24.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:24.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:24.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:24.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:24.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:01:24.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:24.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:01:24.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T15:01:54.930+0000] {processor.py:157} INFO - Started process (PID=70006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:54.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:01:54.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:54.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:54.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:01:54.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:54.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:01:54.979+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:01:54.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:01:54.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T15:02:25.428+0000] {processor.py:157} INFO - Started process (PID=70031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:25.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:02:25.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:25.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:25.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:25.456+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:25.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:02:25.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:25.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:02:25.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T15:02:55.912+0000] {processor.py:157} INFO - Started process (PID=70056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:55.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:02:55.916+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:55.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:55.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:02:55.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:55.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:02:55.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:02:55.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:02:55.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T15:03:26.359+0000] {processor.py:157} INFO - Started process (PID=70081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:26.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:03:26.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:26.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:26.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:26.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:26.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:03:26.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:26.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:03:26.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T15:03:56.764+0000] {processor.py:157} INFO - Started process (PID=70106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:56.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:03:56.769+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:56.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:56.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:03:56.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:56.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:03:56.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:03:56.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:03:56.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T15:04:27.301+0000] {processor.py:157} INFO - Started process (PID=70131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:27.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:04:27.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:27.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:27.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:27.335+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:27.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:04:27.346+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:27.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:04:27.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T15:04:57.754+0000] {processor.py:157} INFO - Started process (PID=70156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:57.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:04:57.758+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:57.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:57.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:04:57.789+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:57.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:04:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:04:57.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:04:57.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:05:28.340+0000] {processor.py:157} INFO - Started process (PID=70181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:28.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:05:28.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:28.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:28.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:28.390+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:28.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:05:28.402+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:28.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:05:28.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T15:05:58.806+0000] {processor.py:157} INFO - Started process (PID=70205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:58.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:05:58.816+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:58.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:58.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:05:58.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:58.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:05:58.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:05:58.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:05:58.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T15:06:29.306+0000] {processor.py:157} INFO - Started process (PID=70231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:29.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:06:29.311+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:29.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:29.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:29.339+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:29.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:06:29.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:29.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:06:29.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T15:06:59.745+0000] {processor.py:157} INFO - Started process (PID=70256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:59.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:06:59.748+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:59.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:59.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:06:59.780+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:59.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:06:59.793+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:06:59.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:06:59.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T15:07:30.259+0000] {processor.py:157} INFO - Started process (PID=70281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:07:30.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:07:30.262+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:07:30.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:07:30.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:07:30.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:07:30.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:07:30.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:07:30.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:07:30.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T15:08:00.796+0000] {processor.py:157} INFO - Started process (PID=70306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:00.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:08:00.799+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:00.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:00.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:00.828+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:00.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:08:00.839+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:00.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:08:00.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T15:08:31.293+0000] {processor.py:157} INFO - Started process (PID=70331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:31.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:08:31.297+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:31.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:31.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:08:31.329+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:31.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:08:31.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:08:31.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:08:31.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T15:09:01.781+0000] {processor.py:157} INFO - Started process (PID=70356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:01.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:09:01.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:01.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:01.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:01.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:01.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:09:01.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:01.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:09:01.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T15:09:32.269+0000] {processor.py:157} INFO - Started process (PID=70381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:32.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:09:32.273+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:32.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:32.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:09:32.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:32.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:09:32.313+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:09:32.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:09:32.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T15:10:02.782+0000] {processor.py:157} INFO - Started process (PID=70406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:02.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:10:02.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:02.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:02.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:02.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:10:02.827+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:02.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:10:02.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T15:10:33.333+0000] {processor.py:157} INFO - Started process (PID=70431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:33.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:10:33.338+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:33.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:10:33.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:33.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:10:33.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:10:33.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:10:33.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T15:11:03.850+0000] {processor.py:157} INFO - Started process (PID=70456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:03.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:11:03.852+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:03.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:03.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:03.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:03.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:11:03.890+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:03.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:11:03.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T15:11:34.317+0000] {processor.py:157} INFO - Started process (PID=70481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:34.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:11:34.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:34.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:34.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:11:34.347+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:34.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:11:34.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:11:34.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:11:34.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T15:12:04.852+0000] {processor.py:157} INFO - Started process (PID=70506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:04.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:12:04.855+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:04.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:04.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:04.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:04.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:12:04.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:04.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:12:04.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T15:12:35.359+0000] {processor.py:157} INFO - Started process (PID=70531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:35.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:12:35.366+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:35.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:35.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:12:35.399+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:35.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:12:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:12:35.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:12:35.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T15:13:05.810+0000] {processor.py:157} INFO - Started process (PID=70556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:05.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:13:05.814+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:05.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:05.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:05.841+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:05.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:13:05.854+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:05.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:13:05.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T15:13:36.323+0000] {processor.py:157} INFO - Started process (PID=70579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:36.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:13:36.326+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:36.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:36.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:13:36.352+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:36.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:13:36.362+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:13:36.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:13:36.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T15:14:06.849+0000] {processor.py:157} INFO - Started process (PID=70606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:06.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:14:06.853+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:06.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:06.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:06.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:06.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:14:06.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:06.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:14:06.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T15:14:37.273+0000] {processor.py:157} INFO - Started process (PID=70631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:37.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:14:37.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:37.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:37.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:14:37.311+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:37.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:14:37.322+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:14:37.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:14:37.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T15:15:07.784+0000] {processor.py:157} INFO - Started process (PID=70656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:07.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:15:07.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:07.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:07.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:07.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:07.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:15:07.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:07.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:15:07.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T15:15:38.214+0000] {processor.py:157} INFO - Started process (PID=70681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:38.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:15:38.216+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:38.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:38.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:15:38.242+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:38.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:15:38.252+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:15:38.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:15:38.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T15:16:08.590+0000] {processor.py:157} INFO - Started process (PID=70706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:08.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:16:08.593+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:08.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:08.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:08.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:08.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:16:08.631+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:08.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:16:08.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T15:16:39.036+0000] {processor.py:157} INFO - Started process (PID=70731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:39.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:16:39.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:39.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:39.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:16:39.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:39.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:16:39.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:16:39.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:16:39.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T15:17:09.497+0000] {processor.py:157} INFO - Started process (PID=70756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:09.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:17:09.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:09.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:09.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:09.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:09.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:17:09.543+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:09.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:17:09.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T15:17:39.991+0000] {processor.py:157} INFO - Started process (PID=70781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:39.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:17:39.994+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:39.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:40.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:17:40.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:40.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:17:40.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:17:40.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:17:40.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T15:18:10.440+0000] {processor.py:157} INFO - Started process (PID=70806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:10.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:18:10.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:10.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:10.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:10.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:10.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:18:10.487+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:10.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:18:10.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T15:18:40.815+0000] {processor.py:157} INFO - Started process (PID=70831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:40.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:18:40.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:40.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:40.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:18:40.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:40.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:18:40.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:18:40.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:18:40.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T15:19:11.251+0000] {processor.py:157} INFO - Started process (PID=70856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:11.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:19:11.253+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:11.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:11.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:11.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:11.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:19:11.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:11.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:19:11.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T15:19:41.712+0000] {processor.py:157} INFO - Started process (PID=70881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:41.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:19:41.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:41.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:41.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:19:41.740+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:41.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:19:41.750+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:19:41.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:19:41.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T15:20:12.198+0000] {processor.py:157} INFO - Started process (PID=70906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:12.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:20:12.202+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:12.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:12.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:12.232+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:12.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:20:12.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:12.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:20:12.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T15:20:42.723+0000] {processor.py:157} INFO - Started process (PID=70931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:42.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:20:42.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:42.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:42.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:20:42.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:42.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:20:42.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:20:42.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:20:42.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T15:21:13.242+0000] {processor.py:157} INFO - Started process (PID=70956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:13.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:21:13.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:13.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:13.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:13.275+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:13.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:21:13.289+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:13.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:21:13.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T15:21:43.676+0000] {processor.py:157} INFO - Started process (PID=70981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:43.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:21:43.682+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:43.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:43.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:21:43.706+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:43.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:21:43.714+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:21:43.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:21:43.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T15:22:14.120+0000] {processor.py:157} INFO - Started process (PID=71006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:14.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:22:14.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:14.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:14.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:14.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:14.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:22:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:14.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:22:14.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T15:22:44.524+0000] {processor.py:157} INFO - Started process (PID=71031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:44.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:22:44.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:44.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:44.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:22:44.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:44.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:22:44.573+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:22:44.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:22:44.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T15:23:15.016+0000] {processor.py:157} INFO - Started process (PID=71056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:15.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:23:15.019+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:15.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:15.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:15.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:15.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:23:15.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:15.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:23:15.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:23:45.476+0000] {processor.py:157} INFO - Started process (PID=71081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:45.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:23:45.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:45.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:45.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:23:45.506+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:45.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:23:45.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:23:45.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:23:45.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T15:24:15.995+0000] {processor.py:157} INFO - Started process (PID=71106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:15.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:24:15.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:15.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:16.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:16.026+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:16.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:24:16.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:16.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:24:16.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T15:24:46.428+0000] {processor.py:157} INFO - Started process (PID=71131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:46.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:24:46.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:46.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:46.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:24:46.464+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:46.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:24:46.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:24:46.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:24:46.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T15:25:16.921+0000] {processor.py:157} INFO - Started process (PID=71156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:16.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:25:16.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:16.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:16.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:16.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:16.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:25:16.968+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:16.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:25:16.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:25:47.445+0000] {processor.py:157} INFO - Started process (PID=71181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:47.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:25:47.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:47.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:47.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:25:47.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:47.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:25:47.485+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:25:47.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:25:47.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T15:26:17.943+0000] {processor.py:157} INFO - Started process (PID=71206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:17.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:26:17.947+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:17.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:17.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:17.974+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:17.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:26:17.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:17.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:26:17.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T15:26:48.416+0000] {processor.py:157} INFO - Started process (PID=71231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:48.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:26:48.418+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:48.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:48.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:26:48.445+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:48.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:26:48.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:26:48.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:26:48.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T15:27:18.908+0000] {processor.py:157} INFO - Started process (PID=71256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:18.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:27:18.912+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:18.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:18.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:18.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:18.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:27:18.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:18.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:27:18.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T15:27:49.411+0000] {processor.py:157} INFO - Started process (PID=71281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:49.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:27:49.414+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:49.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:49.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:27:49.439+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:49.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:27:49.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:27:49.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:27:49.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T15:28:19.793+0000] {processor.py:157} INFO - Started process (PID=71306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:19.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:28:19.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:19.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:19.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:19.832+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:19.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:28:19.841+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:19.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:28:19.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T15:28:50.271+0000] {processor.py:157} INFO - Started process (PID=71331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:50.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:28:50.273+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:50.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:50.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:28:50.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:50.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:28:50.316+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:28:50.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:28:50.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:29:20.694+0000] {processor.py:157} INFO - Started process (PID=71356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:20.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:29:20.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:20.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:20.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:20.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:20.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:29:20.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:20.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:29:20.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T15:29:51.190+0000] {processor.py:157} INFO - Started process (PID=71381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:51.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:29:51.192+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:51.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:51.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:29:51.222+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:51.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:29:51.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:29:51.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:29:51.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:30:22.175+0000] {processor.py:157} INFO - Started process (PID=71405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:22.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:30:22.186+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:22.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:22.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:22.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:22.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:30:22.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:22.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:30:22.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.425 seconds
[2024-07-27T15:30:53.168+0000] {processor.py:157} INFO - Started process (PID=71431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:53.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:30:53.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:53.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:53.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:30:53.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:53.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:30:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:30:53.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:30:53.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-27T15:31:23.753+0000] {processor.py:157} INFO - Started process (PID=71456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:23.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:31:23.789+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:23.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:23.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:23.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:23.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:31:23.877+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:23.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:31:23.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-07-27T15:31:54.319+0000] {processor.py:157} INFO - Started process (PID=71481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:54.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:31:54.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:54.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:54.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:31:54.374+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:54.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:31:54.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:31:54.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:31:54.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T15:32:24.923+0000] {processor.py:157} INFO - Started process (PID=71506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:24.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:32:24.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:24.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:24.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:24.986+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:24.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:32:25.002+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:25.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:32:25.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-27T15:32:55.491+0000] {processor.py:157} INFO - Started process (PID=71530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:55.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:32:55.501+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:55.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:55.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:32:55.579+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:55.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:32:55.624+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:32:55.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:32:55.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-07-27T15:33:26.078+0000] {processor.py:157} INFO - Started process (PID=71556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:26.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:33:26.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:26.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:26.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:26.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:26.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:33:26.171+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:26.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:33:26.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-27T15:33:56.697+0000] {processor.py:157} INFO - Started process (PID=71581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:56.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:33:56.718+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:56.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:56.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:33:56.809+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:56.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:33:56.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:33:56.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:33:56.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-07-27T15:34:27.358+0000] {processor.py:157} INFO - Started process (PID=71606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:27.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:34:27.364+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:27.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:27.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:27.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:27.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:34:27.428+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:27.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:34:27.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-27T15:34:57.878+0000] {processor.py:157} INFO - Started process (PID=71631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:57.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:34:57.886+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:57.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:57.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:34:57.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:57.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:34:57.950+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:34:57.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:34:57.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-27T15:35:28.389+0000] {processor.py:157} INFO - Started process (PID=71656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:28.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:35:28.394+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:28.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:28.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:28.430+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:28.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:35:28.444+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:28.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:35:28.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T15:35:58.953+0000] {processor.py:157} INFO - Started process (PID=71681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:58.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:35:58.960+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:58.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:58.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:35:59.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:59.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:35:59.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:35:59.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:35:59.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T15:36:29.427+0000] {processor.py:157} INFO - Started process (PID=71706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:36:29.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:36:29.434+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:36:29.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:36:29.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:36:29.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:36:29.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:36:29.499+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:36:29.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:36:29.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-27T15:36:59.991+0000] {processor.py:157} INFO - Started process (PID=71729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:36:59.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:36:59.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:36:59.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:37:00.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:37:00.045+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:37:00.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:37:00.057+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:37:00.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:37:00.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-27T15:37:30.512+0000] {processor.py:157} INFO - Started process (PID=71756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:37:30.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:37:30.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:37:30.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:37:30.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:37:30.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:37:30.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:37:30.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:37:30.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:37:30.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:38:01.034+0000] {processor.py:157} INFO - Started process (PID=71780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:01.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:38:01.041+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:01.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:01.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:01.103+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:01.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:38:01.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:01.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:38:01.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-27T15:38:31.641+0000] {processor.py:157} INFO - Started process (PID=71805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:31.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:38:31.649+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:31.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:31.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:38:31.720+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:31.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:38:31.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:38:31.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:38:31.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T15:39:02.198+0000] {processor.py:157} INFO - Started process (PID=71830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:02.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:39:02.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:02.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:02.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:02.248+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:02.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:39:02.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:02.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:39:02.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T15:39:32.723+0000] {processor.py:157} INFO - Started process (PID=71856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:32.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:39:32.733+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:32.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:32.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:39:32.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:32.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:39:32.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:39:32.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:39:32.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-27T15:40:03.257+0000] {processor.py:157} INFO - Started process (PID=71881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:03.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:40:03.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:03.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:03.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:03.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:03.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:40:03.321+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:03.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:40:03.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T15:40:33.767+0000] {processor.py:157} INFO - Started process (PID=71906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:33.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:40:33.779+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:33.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:33.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:40:33.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:33.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:40:33.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:40:33.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:40:33.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T15:41:04.271+0000] {processor.py:157} INFO - Started process (PID=71931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:04.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:41:04.279+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:04.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:04.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:04.349+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:04.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:41:04.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:04.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:41:04.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-27T15:41:34.875+0000] {processor.py:157} INFO - Started process (PID=71956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:34.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:41:34.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:34.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:34.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:41:34.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:34.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:41:34.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:41:34.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:41:34.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-27T15:42:05.302+0000] {processor.py:157} INFO - Started process (PID=71981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:05.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:42:05.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:05.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:05.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:05.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:05.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:42:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:05.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:42:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T15:42:35.929+0000] {processor.py:157} INFO - Started process (PID=72006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:35.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:42:35.954+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:35.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:35.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:42:36.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:36.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:42:36.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:42:36.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:42:36.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-27T15:43:06.625+0000] {processor.py:157} INFO - Started process (PID=72030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:06.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:43:06.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:06.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:06.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:06.692+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:06.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:43:06.708+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:06.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:43:06.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T15:43:37.184+0000] {processor.py:157} INFO - Started process (PID=72056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:37.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:43:37.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:37.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:37.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:43:37.236+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:37.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:43:37.250+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:43:37.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:43:37.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T15:44:07.837+0000] {processor.py:157} INFO - Started process (PID=72081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:07.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:44:07.846+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:07.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:07.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:07.893+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:07.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:44:07.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:07.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:44:07.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T15:44:38.428+0000] {processor.py:157} INFO - Started process (PID=72105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:38.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:44:38.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:38.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:38.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:44:38.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:38.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:44:38.495+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:44:38.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:44:38.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T15:45:08.921+0000] {processor.py:157} INFO - Started process (PID=72131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:08.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:45:08.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:08.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:08.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:08.970+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:08.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:45:08.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:08.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:45:08.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T15:45:39.393+0000] {processor.py:157} INFO - Started process (PID=72156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:39.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:45:39.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:39.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:39.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:45:39.424+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:39.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:45:39.437+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:45:39.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:45:39.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T15:46:09.830+0000] {processor.py:157} INFO - Started process (PID=72180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:09.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:46:09.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:09.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:09.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:09.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:09.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:46:09.953+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:09.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:46:09.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-27T15:46:40.498+0000] {processor.py:157} INFO - Started process (PID=72206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:40.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:46:40.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:40.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:40.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:46:40.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:40.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:46:40.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:46:40.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:46:40.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-27T15:47:11.153+0000] {processor.py:157} INFO - Started process (PID=72230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:11.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:47:11.161+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:11.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:11.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:11.219+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:11.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:47:11.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:11.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:47:11.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T15:47:41.694+0000] {processor.py:157} INFO - Started process (PID=72256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:41.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:47:41.702+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:41.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:41.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:47:41.748+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:41.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:47:41.761+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:47:41.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:47:41.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T15:48:12.187+0000] {processor.py:157} INFO - Started process (PID=72281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:12.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:48:12.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:12.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:12.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:12.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:12.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:48:12.254+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:12.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:48:12.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T15:48:42.709+0000] {processor.py:157} INFO - Started process (PID=72305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:42.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:48:42.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:42.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:42.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:48:42.774+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:42.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:48:42.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:48:42.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:48:42.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T15:49:13.279+0000] {processor.py:157} INFO - Started process (PID=72331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:13.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:49:13.286+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:13.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:13.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:13.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:13.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:49:13.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:13.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:49:13.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T15:49:43.821+0000] {processor.py:157} INFO - Started process (PID=72356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:43.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:49:43.833+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:43.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:43.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:49:43.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:43.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:49:43.937+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:49:43.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:49:43.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-27T15:50:14.432+0000] {processor.py:157} INFO - Started process (PID=72381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:14.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:50:14.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:14.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:14.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:14.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:14.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:50:14.488+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:14.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:50:14.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T15:50:44.985+0000] {processor.py:157} INFO - Started process (PID=72406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:44.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:50:44.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:44.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:45.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:50:45.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:45.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:50:45.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:50:45.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:50:45.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T15:51:15.501+0000] {processor.py:157} INFO - Started process (PID=72431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:15.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:51:15.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:15.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:15.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:15.554+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:15.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:51:15.570+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:15.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:51:15.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T15:51:45.992+0000] {processor.py:157} INFO - Started process (PID=72456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:45.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:51:45.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:45.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:46.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:51:46.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:46.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:51:46.052+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:51:46.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:51:46.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T15:52:16.538+0000] {processor.py:157} INFO - Started process (PID=72481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:16.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:52:16.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:16.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:16.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:16.610+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:16.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:52:16.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:16.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:52:16.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T15:52:47.119+0000] {processor.py:157} INFO - Started process (PID=72506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:47.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:52:47.125+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:47.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:47.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:52:47.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:47.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:52:47.198+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:52:47.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:52:47.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T15:53:17.665+0000] {processor.py:157} INFO - Started process (PID=72531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:17.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:53:17.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:17.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:17.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:17.722+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:17.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:53:17.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:17.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:53:17.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T15:53:48.185+0000] {processor.py:157} INFO - Started process (PID=72556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:48.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:53:48.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:48.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:48.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:53:48.242+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:48.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:53:48.255+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:53:48.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:53:48.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-27T15:54:18.784+0000] {processor.py:157} INFO - Started process (PID=72581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:18.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:54:18.791+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:18.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:18.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:18.837+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:18.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:54:18.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:18.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:54:18.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T15:54:49.244+0000] {processor.py:157} INFO - Started process (PID=72606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:49.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:54:49.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:49.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:49.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:54:49.311+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:49.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:54:49.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:54:49.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:54:49.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T15:55:19.779+0000] {processor.py:157} INFO - Started process (PID=72631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:19.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:55:19.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:19.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:19.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:19.844+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:19.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:55:19.858+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:19.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:55:19.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-27T15:55:50.373+0000] {processor.py:157} INFO - Started process (PID=72656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:50.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:55:50.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:50.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:50.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:55:50.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:50.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:55:50.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:55:50.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:55:50.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-27T15:56:20.898+0000] {processor.py:157} INFO - Started process (PID=72681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:20.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:56:20.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:20.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:20.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:20.959+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:20.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:56:20.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:20.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:56:20.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-27T15:56:51.409+0000] {processor.py:157} INFO - Started process (PID=72706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:51.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:56:51.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:51.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:51.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:56:51.447+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:51.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:56:51.457+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:56:51.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:56:51.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T15:57:21.853+0000] {processor.py:157} INFO - Started process (PID=72731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:21.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:57:21.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:21.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:21.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:21.898+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:21.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:57:21.911+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:21.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:57:21.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T15:57:52.363+0000] {processor.py:157} INFO - Started process (PID=72756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:52.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:57:52.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:52.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:52.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:57:52.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:52.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:57:52.446+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:57:52.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:57:52.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T15:58:22.976+0000] {processor.py:157} INFO - Started process (PID=72781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:22.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:58:22.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:22.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:23.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:23.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:23.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:58:23.108+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:23.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:58:23.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-27T15:58:53.650+0000] {processor.py:157} INFO - Started process (PID=72806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:53.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:58:53.657+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:53.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:53.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:58:53.728+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:53.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:58:53.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:58:53.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:58:53.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-27T15:59:24.289+0000] {processor.py:157} INFO - Started process (PID=72831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:24.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:59:24.321+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:24.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:24.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:24.393+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:24.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:59:24.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:24.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:59:24.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-07-27T15:59:54.821+0000] {processor.py:157} INFO - Started process (PID=72856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:54.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T15:59:54.828+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:54.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:54.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T15:59:54.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:54.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T15:59:54.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T15:59:54.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T15:59:54.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T16:00:25.295+0000] {processor.py:157} INFO - Started process (PID=72880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:25.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:00:25.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:25.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:25.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:25.357+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:25.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:00:25.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:25.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:00:25.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-27T16:00:55.882+0000] {processor.py:157} INFO - Started process (PID=72906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:55.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:00:55.888+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:55.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:55.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:00:55.933+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:55.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:00:55.947+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:00:55.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:00:55.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T16:01:26.365+0000] {processor.py:157} INFO - Started process (PID=72931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:26.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:01:26.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:26.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:26.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:26.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:26.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:01:26.447+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:26.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:01:26.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-07-27T16:01:56.933+0000] {processor.py:157} INFO - Started process (PID=72956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:56.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:01:56.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:56.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:56.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:01:56.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:56.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:01:56.990+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:01:56.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:01:57.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T16:02:27.439+0000] {processor.py:157} INFO - Started process (PID=72981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:27.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:02:27.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:27.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:27.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:27.467+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:27.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:02:27.477+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:27.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:02:27.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T16:02:57.937+0000] {processor.py:157} INFO - Started process (PID=73005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:57.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:02:57.942+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:57.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:57.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:02:57.984+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:57.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:02:58.001+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:02:58.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:02:58.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T16:03:28.339+0000] {processor.py:157} INFO - Started process (PID=73031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:28.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:03:28.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:28.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:28.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:28.363+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:28.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:03:28.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:28.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:03:28.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T16:03:58.874+0000] {processor.py:157} INFO - Started process (PID=73055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:58.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:03:58.880+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:58.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:58.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:03:58.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:58.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:03:58.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:03:58.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:03:58.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T16:04:29.393+0000] {processor.py:157} INFO - Started process (PID=73081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:29.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:04:29.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:29.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:29.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:29.425+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:29.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:04:29.436+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:29.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:04:29.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T16:04:59.861+0000] {processor.py:157} INFO - Started process (PID=73106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:59.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:04:59.869+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:59.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:59.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:04:59.910+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:59.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:04:59.924+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:04:59.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:04:59.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T16:05:30.388+0000] {processor.py:157} INFO - Started process (PID=73131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:05:30.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:05:30.392+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:05:30.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:05:30.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:05:30.443+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:05:30.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:05:30.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:05:30.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:05:30.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T16:06:00.945+0000] {processor.py:157} INFO - Started process (PID=73156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:00.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:06:00.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:00.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:00.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:00.992+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:00.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:06:01.004+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:01.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:06:01.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T16:06:31.483+0000] {processor.py:157} INFO - Started process (PID=73181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:31.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:06:31.490+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:31.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:31.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:06:31.537+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:31.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:06:31.557+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:06:31.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:06:31.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-27T16:07:02.083+0000] {processor.py:157} INFO - Started process (PID=73206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:02.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:07:02.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:02.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:02.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:02.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:02.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:07:02.128+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:02.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:07:02.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T16:07:32.548+0000] {processor.py:157} INFO - Started process (PID=73231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:32.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:07:32.553+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:32.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:32.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:07:32.596+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:32.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:07:32.609+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:07:32.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:07:32.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T16:08:03.067+0000] {processor.py:157} INFO - Started process (PID=73256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:08:03.072+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:03.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:03.102+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:03.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:08:03.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:03.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:08:03.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T16:08:33.528+0000] {processor.py:157} INFO - Started process (PID=73281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:33.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:08:33.533+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:33.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:33.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:08:33.574+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:33.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:08:33.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:08:33.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:08:33.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T16:09:04.020+0000] {processor.py:157} INFO - Started process (PID=73306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:04.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:09:04.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:04.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:04.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:04.050+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:04.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:09:04.062+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:04.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:09:04.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T16:09:34.474+0000] {processor.py:157} INFO - Started process (PID=73331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:34.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:09:34.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:34.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:34.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:09:34.532+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:34.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:09:34.545+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:09:34.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:09:34.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T16:10:05.046+0000] {processor.py:157} INFO - Started process (PID=73356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:05.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:10:05.049+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:05.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:05.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:05.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:05.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:10:05.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:05.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:10:05.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T16:10:35.625+0000] {processor.py:157} INFO - Started process (PID=73380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:35.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:10:35.630+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:35.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:35.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:10:35.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:35.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:10:35.692+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:10:35.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:10:35.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-27T16:11:06.271+0000] {processor.py:157} INFO - Started process (PID=73406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:06.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:11:06.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:06.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:06.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:06.302+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:06.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:11:06.314+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:06.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:11:06.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T16:11:51.547+0000] {processor.py:157} INFO - Started process (PID=73431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:51.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:11:51.552+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:51.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:51.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:11:51.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:51.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:11:51.622+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:11:51.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:11:51.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-27T16:12:22.118+0000] {processor.py:157} INFO - Started process (PID=73458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:12:22.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:12:22.123+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:12:22.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:12:22.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:12:22.164+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:12:22.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:12:22.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:12:22.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:12:22.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-27T16:28:43.351+0000] {processor.py:157} INFO - Started process (PID=73483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:28:43.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:28:43.356+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:28:43.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:28:43.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:28:43.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:28:43.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:28:43.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:28:43.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:28:43.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T16:29:13.918+0000] {processor.py:157} INFO - Started process (PID=73508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:13.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:29:13.927+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:13.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:13.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:13.976+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:13.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:29:13.989+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:13.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:29:14.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T16:29:44.474+0000] {processor.py:157} INFO - Started process (PID=73533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:44.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:29:44.476+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:44.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:44.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:29:44.502+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:44.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:29:44.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:29:44.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:29:44.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T16:30:14.906+0000] {processor.py:157} INFO - Started process (PID=73558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:14.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:30:14.911+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:14.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:14.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:14.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:14.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:30:14.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:14.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:30:14.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T16:30:45.380+0000] {processor.py:157} INFO - Started process (PID=73583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:45.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:30:45.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:45.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:45.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:30:45.409+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:45.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:30:45.418+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:30:45.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:30:45.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T16:31:15.870+0000] {processor.py:157} INFO - Started process (PID=73608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:15.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:31:15.875+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:15.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:15.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:15.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:15.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:31:15.916+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:15.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:31:15.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T16:31:46.256+0000] {processor.py:157} INFO - Started process (PID=73633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:46.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:31:46.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:46.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:46.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:31:46.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:46.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:31:46.295+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:31:46.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:31:46.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T16:32:16.745+0000] {processor.py:157} INFO - Started process (PID=73658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:32:16.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:32:16.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:32:16.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:32:16.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:32:16.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:32:16.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:32:16.795+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:32:16.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:32:16.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T16:48:05.896+0000] {processor.py:157} INFO - Started process (PID=73683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:05.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:48:05.901+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:05.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:05.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:05.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:05.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:48:05.952+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:05.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:48:05.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T16:48:36.446+0000] {processor.py:157} INFO - Started process (PID=73709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:36.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:48:36.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:36.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:36.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:48:36.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:36.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:48:36.523+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:48:36.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:48:36.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T16:49:06.973+0000] {processor.py:157} INFO - Started process (PID=73735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:06.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:49:06.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:06.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:06.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:07.008+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:07.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:49:07.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:07.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:49:07.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T16:49:37.465+0000] {processor.py:157} INFO - Started process (PID=73760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:37.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T16:49:37.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:37.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:37.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T16:49:37.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:37.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T16:49:37.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T16:49:37.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T16:49:37.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T17:07:57.872+0000] {processor.py:157} INFO - Started process (PID=73786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:07:57.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:07:57.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:07:57.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:07:57.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:07:57.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:07:57.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:07:57.939+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:07:57.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:07:57.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-27T17:08:28.410+0000] {processor.py:157} INFO - Started process (PID=73812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:28.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:08:28.420+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:28.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:28.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:28.510+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:28.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:08:28.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:28.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:08:28.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-27T17:08:58.950+0000] {processor.py:157} INFO - Started process (PID=73837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:58.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:08:58.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:58.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:58.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:08:58.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:58.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:08:58.991+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:08:58.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:08:58.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T17:09:29.509+0000] {processor.py:157} INFO - Started process (PID=73861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:29.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:09:29.514+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:29.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:29.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:29.566+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:29.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:09:29.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:29.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:09:29.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T17:09:59.939+0000] {processor.py:157} INFO - Started process (PID=73887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:59.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:09:59.943+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:59.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:59.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:09:59.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:59.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:09:59.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:09:59.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:09:59.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T17:10:30.356+0000] {processor.py:157} INFO - Started process (PID=73912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:10:30.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:10:30.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:10:30.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:10:30.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:10:30.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:10:30.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:10:30.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:10:30.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:10:30.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T17:11:00.794+0000] {processor.py:157} INFO - Started process (PID=73937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:00.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:11:00.798+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:00.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:00.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:00.824+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:00.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:11:00.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:00.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:11:00.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T17:11:31.263+0000] {processor.py:157} INFO - Started process (PID=73962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:31.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:11:31.267+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:31.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:31.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:11:31.306+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:31.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:11:31.318+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:11:31.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:11:31.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T17:12:01.796+0000] {processor.py:157} INFO - Started process (PID=73987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:01.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:12:01.802+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:01.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:01.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:01.830+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:01.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:12:01.840+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:01.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:12:01.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T17:12:32.196+0000] {processor.py:157} INFO - Started process (PID=74012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:32.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:12:32.202+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:32.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:32.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:12:32.231+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:32.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:12:32.240+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:12:32.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:12:32.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T17:13:02.691+0000] {processor.py:157} INFO - Started process (PID=74037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:02.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:13:02.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:02.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:02.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:02.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:02.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:13:02.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:02.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:13:02.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T17:13:33.162+0000] {processor.py:157} INFO - Started process (PID=74062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:33.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:13:33.173+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:33.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:33.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:13:33.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:33.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:13:33.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:13:33.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:13:33.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T17:14:03.664+0000] {processor.py:157} INFO - Started process (PID=74087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:03.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:14:03.667+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:03.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:03.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:03.695+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:03.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:14:03.705+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:03.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:14:03.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T17:14:34.117+0000] {processor.py:157} INFO - Started process (PID=74112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:34.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:14:34.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:34.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:34.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:14:34.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:34.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:14:34.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:14:34.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:14:34.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T17:15:04.572+0000] {processor.py:157} INFO - Started process (PID=74136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:04.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:15:04.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:04.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:04.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:04.606+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:04.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:15:04.616+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:04.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:15:04.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T17:15:35.033+0000] {processor.py:157} INFO - Started process (PID=74162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:35.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:15:35.036+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:35.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:35.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:15:35.072+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:35.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:15:35.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:15:35.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:15:35.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T17:16:05.527+0000] {processor.py:157} INFO - Started process (PID=74187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:05.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:16:05.529+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:05.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:05.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:05.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:05.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:16:05.569+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:05.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:16:05.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T17:16:36.032+0000] {processor.py:157} INFO - Started process (PID=74212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:36.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:16:36.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:36.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:36.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:16:36.067+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:36.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:16:36.079+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:16:36.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:16:36.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T17:17:06.477+0000] {processor.py:157} INFO - Started process (PID=74237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:06.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:17:06.484+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:06.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:06.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:06.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:06.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:17:06.516+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:06.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:17:06.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T17:17:36.924+0000] {processor.py:157} INFO - Started process (PID=74262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:36.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:17:36.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:36.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:36.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:17:36.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:36.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:17:36.979+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:17:36.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:17:36.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T17:18:07.406+0000] {processor.py:157} INFO - Started process (PID=74287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:07.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:18:07.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:07.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:07.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:07.443+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:07.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:18:07.456+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:07.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:18:07.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T17:18:37.915+0000] {processor.py:157} INFO - Started process (PID=74312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:37.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:18:37.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:37.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:37.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:18:37.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:37.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:18:37.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:18:37.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:18:37.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T17:19:08.373+0000] {processor.py:157} INFO - Started process (PID=74337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:08.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:19:08.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:08.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:08.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:08.405+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:08.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:19:08.416+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:08.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:19:08.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T17:19:38.918+0000] {processor.py:157} INFO - Started process (PID=74362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:38.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:19:38.921+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:38.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:38.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:19:38.946+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:38.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:19:38.956+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:19:38.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:19:38.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T17:20:09.431+0000] {processor.py:157} INFO - Started process (PID=74387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:09.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:20:09.434+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:09.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:09.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:09.485+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:09.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:20:09.498+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:09.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:20:09.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T17:20:39.884+0000] {processor.py:157} INFO - Started process (PID=74412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:39.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:20:39.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:39.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:39.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:20:39.913+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:39.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:20:39.922+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:20:39.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:20:39.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T17:21:10.423+0000] {processor.py:157} INFO - Started process (PID=74437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:10.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:21:10.426+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:10.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:10.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:10.448+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:10.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:21:10.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:10.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:21:10.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T17:21:40.850+0000] {processor.py:157} INFO - Started process (PID=74462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:40.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:21:40.853+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:40.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:40.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:21:40.882+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:40.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:21:40.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:21:40.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:21:40.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T17:22:11.321+0000] {processor.py:157} INFO - Started process (PID=74487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:11.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:22:11.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:11.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:11.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:11.350+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:11.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:22:11.360+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:11.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:22:11.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T17:22:41.737+0000] {processor.py:157} INFO - Started process (PID=74512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:41.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:22:41.739+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:41.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:41.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:22:41.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:41.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:22:41.788+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:22:41.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:22:41.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T17:38:34.334+0000] {processor.py:157} INFO - Started process (PID=74537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:38:34.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:38:34.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:38:34.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:38:34.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:38:34.365+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:38:34.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:38:34.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:38:34.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:38:34.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T17:39:05.160+0000] {processor.py:157} INFO - Started process (PID=74564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:05.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:39:05.165+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:05.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:05.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:05.203+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:05.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:39:05.216+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:05.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:39:05.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T17:39:35.652+0000] {processor.py:157} INFO - Started process (PID=74589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:35.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:39:35.658+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:35.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:35.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:39:35.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:35.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:39:35.689+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:39:35.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:39:35.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T17:40:06.217+0000] {processor.py:157} INFO - Started process (PID=74613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:06.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:40:06.221+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:06.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:06.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:06.266+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:06.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:40:06.279+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:06.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:40:06.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-27T17:40:36.783+0000] {processor.py:157} INFO - Started process (PID=74639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:36.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:40:36.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:36.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:36.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:40:36.810+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:36.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:40:36.822+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:40:36.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:40:36.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T17:41:07.273+0000] {processor.py:157} INFO - Started process (PID=74663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:07.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:41:07.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:07.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:07.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:07.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:07.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:41:07.341+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:07.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:41:07.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T17:41:37.861+0000] {processor.py:157} INFO - Started process (PID=74689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:37.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:41:37.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:37.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:37.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:41:37.904+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:37.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:41:37.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:41:37.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:41:37.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T17:42:08.374+0000] {processor.py:157} INFO - Started process (PID=74714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:42:08.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:42:08.376+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:42:08.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:42:08.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:42:08.398+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:42:08.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:42:08.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:42:08.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:42:08.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T17:46:52.098+0000] {processor.py:157} INFO - Started process (PID=74741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:46:52.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:46:52.102+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:46:52.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:46:52.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:46:52.132+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:46:52.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:46:52.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:46:52.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:46:52.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T17:47:22.543+0000] {processor.py:157} INFO - Started process (PID=74765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:47:22.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T17:47:22.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:47:22.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:47:22.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T17:47:22.589+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:47:22.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T17:47:22.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T17:47:22.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T17:47:22.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T18:03:31.129+0000] {processor.py:157} INFO - Started process (PID=74791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:03:31.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:03:31.139+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:03:31.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:03:31.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:03:31.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:03:31.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:03:31.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:03:31.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:03:31.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-27T18:04:01.738+0000] {processor.py:157} INFO - Started process (PID=74816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:01.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:04:01.742+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:01.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:01.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:01.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:01.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:04:01.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:01.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:04:01.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T18:04:32.180+0000] {processor.py:157} INFO - Started process (PID=74841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:32.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:04:32.182+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:32.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:32.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:04:32.214+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:32.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:04:32.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:04:32.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:04:32.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T18:05:02.646+0000] {processor.py:157} INFO - Started process (PID=74866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:02.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:05:02.650+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:02.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:02.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:02.680+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:02.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:05:02.692+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:02.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:05:02.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T18:05:33.023+0000] {processor.py:157} INFO - Started process (PID=74891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:33.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:05:33.027+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:33.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:33.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:05:33.071+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:33.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:05:33.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:05:33.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:05:33.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-27T18:06:03.489+0000] {processor.py:157} INFO - Started process (PID=74916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:06:03.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:06:03.494+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:06:03.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:06:03.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:06:03.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:06:03.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:06:03.542+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:06:03.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:06:03.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T18:12:28.572+0000] {processor.py:157} INFO - Started process (PID=74941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:28.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:12:28.575+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:28.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:28.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:28.602+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:28.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:12:28.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:28.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:12:28.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:12:59.024+0000] {processor.py:157} INFO - Started process (PID=74965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:59.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:12:59.028+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:59.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:59.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:12:59.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:59.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:12:59.101+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:12:59.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:12:59.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-27T18:13:29.512+0000] {processor.py:157} INFO - Started process (PID=74991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:29.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:13:29.515+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:29.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:29.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:29.544+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:29.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:13:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:29.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:13:29.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:13:59.911+0000] {processor.py:157} INFO - Started process (PID=75016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:59.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:13:59.914+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:59.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:59.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:13:59.940+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:59.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:13:59.951+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:13:59.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:13:59.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:29:52.274+0000] {processor.py:157} INFO - Started process (PID=75040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:29:52.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:29:52.280+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:29:52.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:29:52.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:29:52.325+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:29:52.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:29:52.336+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:29:52.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:29:52.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-27T18:30:22.764+0000] {processor.py:157} INFO - Started process (PID=75068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:22.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:30:22.768+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:22.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:22.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:22.820+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:22.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:30:22.834+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:22.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:30:22.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-27T18:30:53.249+0000] {processor.py:157} INFO - Started process (PID=75093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:53.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:30:53.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:53.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:53.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:30:53.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:53.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:30:53.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:30:53.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:30:53.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:31:23.710+0000] {processor.py:157} INFO - Started process (PID=75118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:23.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:31:23.715+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:23.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:23.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:23.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:23.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:31:23.757+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:23.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:31:23.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T18:31:54.056+0000] {processor.py:157} INFO - Started process (PID=75143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:54.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:31:54.060+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:54.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:54.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:31:54.092+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:54.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:31:54.106+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:31:54.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:31:54.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T18:32:24.500+0000] {processor.py:157} INFO - Started process (PID=75168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:24.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:32:24.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:24.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:24.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:24.533+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:24.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:32:24.544+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:24.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:32:24.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T18:32:54.979+0000] {processor.py:157} INFO - Started process (PID=75193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:54.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:32:54.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:54.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:54.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:32:55.009+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:55.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:32:55.021+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:32:55.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:32:55.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T18:33:25.502+0000] {processor.py:157} INFO - Started process (PID=75218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:25.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:33:25.507+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:25.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:25.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:25.545+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:25.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:33:25.559+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:25.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:33:25.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T18:33:55.995+0000] {processor.py:157} INFO - Started process (PID=75243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:55.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:33:55.998+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:55.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:56.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:33:56.025+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:56.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:33:56.035+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:33:56.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:33:56.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T18:34:26.410+0000] {processor.py:157} INFO - Started process (PID=75268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:26.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:34:26.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:26.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:26.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:26.441+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:26.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:34:26.452+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:26.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:34:26.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:34:56.932+0000] {processor.py:157} INFO - Started process (PID=75293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:56.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:34:56.938+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:56.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:56.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:34:56.975+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:56.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:34:56.986+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:34:56.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:34:56.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T18:35:27.370+0000] {processor.py:157} INFO - Started process (PID=75318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:27.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:35:27.373+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:27.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:27.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:27.397+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:27.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:35:27.407+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:27.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:35:27.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T18:35:57.768+0000] {processor.py:157} INFO - Started process (PID=75343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:57.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:35:57.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:57.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:57.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:35:57.800+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:57.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:35:57.811+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:35:57.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:35:57.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:36:28.262+0000] {processor.py:157} INFO - Started process (PID=75368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:28.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:36:28.266+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:28.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:28.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:28.298+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:28.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:36:28.308+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:28.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:36:28.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T18:36:58.693+0000] {processor.py:157} INFO - Started process (PID=75393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:58.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:36:58.698+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:58.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:58.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:36:58.730+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:58.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:36:58.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:36:58.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:36:58.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T18:37:29.178+0000] {processor.py:157} INFO - Started process (PID=75418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:29.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:37:29.181+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:29.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:29.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:29.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:29.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:37:29.215+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:29.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:37:29.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T18:37:59.634+0000] {processor.py:157} INFO - Started process (PID=75443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:59.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:37:59.637+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:59.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:59.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:37:59.661+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:59.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:37:59.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:37:59.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:37:59.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T18:38:30.044+0000] {processor.py:157} INFO - Started process (PID=75468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:38:30.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:38:30.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:38:30.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:38:30.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:38:30.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:38:30.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:38:30.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:38:30.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:38:30.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T18:39:00.468+0000] {processor.py:157} INFO - Started process (PID=75493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:00.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:39:00.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:00.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:00.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:00.495+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:00.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:39:00.506+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:00.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:39:00.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T18:39:30.947+0000] {processor.py:157} INFO - Started process (PID=75518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:30.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:39:30.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:30.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:30.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:39:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:30.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:39:30.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:39:30.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:39:30.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T18:40:01.426+0000] {processor.py:157} INFO - Started process (PID=75543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:01.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:40:01.430+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:01.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:01.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:01.455+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:01.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:40:01.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:01.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:40:01.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T18:40:31.919+0000] {processor.py:157} INFO - Started process (PID=75568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:31.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:40:31.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:31.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:31.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:40:31.965+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:31.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:40:31.977+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:40:31.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:40:31.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T18:41:02.408+0000] {processor.py:157} INFO - Started process (PID=75593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:02.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:41:02.412+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:02.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:02.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:02.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:02.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:41:02.450+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:02.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:41:02.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:41:32.861+0000] {processor.py:157} INFO - Started process (PID=75618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:32.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:41:32.865+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:32.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:32.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:41:32.894+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:32.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:41:32.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:41:32.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:41:32.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:42:03.247+0000] {processor.py:157} INFO - Started process (PID=75643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:03.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:42:03.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:03.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:03.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:03.276+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:03.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:42:03.285+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:03.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:42:03.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T18:42:33.685+0000] {processor.py:157} INFO - Started process (PID=75668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:33.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:42:33.690+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:33.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:33.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:42:33.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:33.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:42:33.732+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:42:33.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:42:33.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T18:43:04.180+0000] {processor.py:157} INFO - Started process (PID=75693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:04.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:43:04.183+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:04.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:04.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:04.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:04.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:43:04.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:04.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:43:04.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T18:43:34.628+0000] {processor.py:157} INFO - Started process (PID=75718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:34.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:43:34.633+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:34.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:34.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:43:34.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:34.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:43:34.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:43:34.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:43:34.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T18:44:05.094+0000] {processor.py:157} INFO - Started process (PID=75743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:05.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:44:05.097+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:05.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:05.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:05.123+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:05.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:44:05.133+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:05.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:44:05.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T18:44:35.513+0000] {processor.py:157} INFO - Started process (PID=75768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:35.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:44:35.519+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:35.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:35.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:44:35.555+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:35.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:44:35.567+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:44:35.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:44:35.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T18:45:06.033+0000] {processor.py:157} INFO - Started process (PID=75793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:06.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:45:06.034+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:06.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:06.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:06.066+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:06.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:45:06.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:06.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:45:06.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T18:45:36.786+0000] {processor.py:157} INFO - Started process (PID=75818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:36.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:45:36.791+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:36.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:36.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:45:36.825+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:36.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:45:36.838+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:45:36.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:45:36.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T18:46:07.207+0000] {processor.py:157} INFO - Started process (PID=75843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:07.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:46:07.217+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:07.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:07.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:07.239+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:07.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:46:07.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:07.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:46:07.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:46:37.700+0000] {processor.py:157} INFO - Started process (PID=75868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:37.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:46:37.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:37.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:37.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:46:37.734+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:37.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:46:37.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:46:37.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:46:37.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:47:08.115+0000] {processor.py:157} INFO - Started process (PID=75893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:08.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:47:08.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:08.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:08.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:08.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:08.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:47:08.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:08.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:47:08.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:47:38.592+0000] {processor.py:157} INFO - Started process (PID=75918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:38.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:47:38.595+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:38.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:38.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:47:38.620+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:38.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:47:38.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:47:38.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:47:38.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T18:48:09.043+0000] {processor.py:157} INFO - Started process (PID=75943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:09.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:48:09.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:09.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:09.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:09.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:09.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:48:09.086+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:09.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:48:09.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T18:48:39.452+0000] {processor.py:157} INFO - Started process (PID=75968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:39.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:48:39.454+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:39.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:39.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:48:39.481+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:39.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:48:39.491+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:48:39.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:48:39.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T18:49:09.877+0000] {processor.py:157} INFO - Started process (PID=75993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:09.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:49:09.879+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:09.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:09.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:09.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:09.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:49:09.918+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:09.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:49:09.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:49:40.283+0000] {processor.py:157} INFO - Started process (PID=76018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:40.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:49:40.287+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:40.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:40.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:49:40.313+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:40.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:49:40.324+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:49:40.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:49:40.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T18:50:10.734+0000] {processor.py:157} INFO - Started process (PID=76043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:10.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:50:10.737+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:10.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:10.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:10.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:10.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:50:10.785+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:10.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:50:10.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-27T18:50:41.202+0000] {processor.py:157} INFO - Started process (PID=76068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:41.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:50:41.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:41.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:41.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:50:41.227+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:41.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:50:41.236+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:50:41.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:50:41.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T18:51:11.674+0000] {processor.py:157} INFO - Started process (PID=76093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:11.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:51:11.676+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:11.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:11.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:11.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:11.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:51:11.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:11.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:51:11.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T18:51:42.128+0000] {processor.py:157} INFO - Started process (PID=76118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:42.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:51:42.132+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:42.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:42.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:51:42.172+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:42.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:51:42.185+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:51:42.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:51:42.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-27T18:52:12.583+0000] {processor.py:157} INFO - Started process (PID=76143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:12.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:52:12.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:12.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:12.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:12.632+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:12.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:52:12.642+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:12.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:52:12.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T18:52:43.042+0000] {processor.py:157} INFO - Started process (PID=76167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:43.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:52:43.047+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:43.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:43.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:52:43.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:43.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:52:43.110+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:52:43.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:52:43.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-27T18:53:13.462+0000] {processor.py:157} INFO - Started process (PID=76193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:13.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:53:13.464+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:13.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:13.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:13.494+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:13.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:53:13.505+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:13.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:53:13.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:53:43.875+0000] {processor.py:157} INFO - Started process (PID=76218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:43.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:53:43.878+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:43.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:43.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:53:43.905+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:43.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:53:43.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:53:43.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:53:43.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T18:54:14.333+0000] {processor.py:157} INFO - Started process (PID=76243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:14.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:54:14.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:14.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:14.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:14.366+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:14.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:54:14.375+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:14.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:54:14.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T18:54:44.825+0000] {processor.py:157} INFO - Started process (PID=76268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:44.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:54:44.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:44.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:44.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:54:44.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:44.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:54:44.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:54:44.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:54:44.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T18:55:15.382+0000] {processor.py:157} INFO - Started process (PID=76293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:15.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:55:15.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:15.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:15.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:15.439+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:15.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:55:15.459+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:15.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:55:15.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T18:55:45.938+0000] {processor.py:157} INFO - Started process (PID=76318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:45.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:55:45.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:45.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:45.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:55:45.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:45.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:55:46.001+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:55:46.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:55:46.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T18:56:16.398+0000] {processor.py:157} INFO - Started process (PID=76343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:16.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:56:16.401+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:16.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:16.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:16.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:16.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:56:16.439+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:16.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:56:16.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T18:56:46.864+0000] {processor.py:157} INFO - Started process (PID=76368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:46.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:56:46.869+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:46.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:46.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:56:46.899+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:46.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:56:46.909+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:56:46.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:56:46.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T18:57:17.354+0000] {processor.py:157} INFO - Started process (PID=76393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:17.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:57:17.356+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:17.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:17.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:17.384+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:17.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:57:17.395+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:17.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:57:17.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T18:57:47.747+0000] {processor.py:157} INFO - Started process (PID=76418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:47.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:57:47.750+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:47.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:47.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:57:47.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:47.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:57:47.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:57:47.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:57:47.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T18:58:18.175+0000] {processor.py:157} INFO - Started process (PID=76443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:18.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:58:18.178+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:18.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:18.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:18.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:18.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:58:18.214+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:18.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:58:18.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T18:58:48.626+0000] {processor.py:157} INFO - Started process (PID=76468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:48.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:58:48.629+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:48.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:48.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:58:48.653+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:48.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:58:48.664+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:58:48.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:58:48.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T18:59:19.102+0000] {processor.py:157} INFO - Started process (PID=76493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:19.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:59:19.105+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:19.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:19.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:19.134+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:19.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:59:19.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:19.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:59:19.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T18:59:49.570+0000] {processor.py:157} INFO - Started process (PID=76518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:49.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T18:59:49.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:49.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:49.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T18:59:49.598+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:49.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T18:59:49.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T18:59:49.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T18:59:49.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T19:00:19.960+0000] {processor.py:157} INFO - Started process (PID=76543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:19.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:00:19.963+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:19.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:19.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:19.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:19.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:00:20.008+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:20.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:00:20.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T19:00:50.693+0000] {processor.py:157} INFO - Started process (PID=76568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:50.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:00:50.696+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:50.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:50.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:00:50.724+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:50.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:00:50.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:00:50.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:00:50.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:01:21.112+0000] {processor.py:157} INFO - Started process (PID=76593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:21.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:01:21.115+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:21.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:21.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:21.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:21.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:01:21.154+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:21.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:01:21.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:01:51.602+0000] {processor.py:157} INFO - Started process (PID=76618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:51.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:01:51.612+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:51.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:51.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:01:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:51.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:01:51.646+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:01:51.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:01:51.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:02:22.073+0000] {processor.py:157} INFO - Started process (PID=76643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:22.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:02:22.076+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:22.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:22.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:22.110+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:22.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:02:22.120+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:22.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:02:22.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T19:02:52.482+0000] {processor.py:157} INFO - Started process (PID=76668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:52.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:02:52.489+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:52.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:52.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:02:52.520+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:52.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:02:52.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:02:52.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:02:52.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T19:03:22.896+0000] {processor.py:157} INFO - Started process (PID=76693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:22.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:03:22.900+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:22.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:22.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:22.928+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:22.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:03:22.941+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:22.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:03:22.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T19:03:53.384+0000] {processor.py:157} INFO - Started process (PID=76718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:53.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:03:53.387+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:53.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:53.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:03:53.417+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:53.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:03:53.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:03:53.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:03:53.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T19:04:23.802+0000] {processor.py:157} INFO - Started process (PID=76743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:23.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:04:23.805+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:23.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:23.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:23.831+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:23.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:04:23.842+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:23.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:04:23.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:04:54.190+0000] {processor.py:157} INFO - Started process (PID=76768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:54.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:04:54.193+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:54.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:54.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:04:54.222+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:54.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:04:54.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:04:54.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:04:54.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:05:24.662+0000] {processor.py:157} INFO - Started process (PID=76793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:24.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:05:24.665+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:24.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:24.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:24.694+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:24.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:05:24.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:24.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:05:24.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:05:55.102+0000] {processor.py:157} INFO - Started process (PID=76818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:55.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:05:55.105+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:55.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:55.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:05:55.131+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:55.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:05:55.141+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:05:55.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:05:55.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T19:06:25.455+0000] {processor.py:157} INFO - Started process (PID=76843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:25.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:06:25.458+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:25.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:25.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:25.483+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:25.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:06:25.492+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:25.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:06:25.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T19:06:55.954+0000] {processor.py:157} INFO - Started process (PID=76868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:55.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:06:55.957+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:55.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:55.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:06:55.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:55.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:06:55.997+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:06:55.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:06:56.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:07:26.407+0000] {processor.py:157} INFO - Started process (PID=76893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:26.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:07:26.410+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:26.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:26.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:26.438+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:26.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:07:26.450+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:26.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:07:26.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:07:56.916+0000] {processor.py:157} INFO - Started process (PID=76918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:56.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:07:56.919+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:56.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:56.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:07:56.949+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:56.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:07:56.961+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:07:56.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:07:56.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T19:08:27.338+0000] {processor.py:157} INFO - Started process (PID=76943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:27.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:08:27.342+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:27.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:27.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:27.371+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:27.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:08:27.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:27.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:08:27.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:08:57.732+0000] {processor.py:157} INFO - Started process (PID=76968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:57.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:08:57.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:57.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:57.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:08:57.763+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:57.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:08:57.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:08:57.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:08:57.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:09:28.204+0000] {processor.py:157} INFO - Started process (PID=76993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:28.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:09:28.207+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:28.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:28.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:28.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:28.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:09:28.244+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:28.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:09:28.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T19:09:58.675+0000] {processor.py:157} INFO - Started process (PID=77018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:58.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:09:58.677+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:58.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:58.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:09:58.704+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:58.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:09:58.718+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:09:58.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:09:58.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:10:29.155+0000] {processor.py:157} INFO - Started process (PID=77043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:29.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:10:29.165+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:29.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:29.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:29.204+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:29.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:10:29.219+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:29.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:10:29.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-27T19:10:59.622+0000] {processor.py:157} INFO - Started process (PID=77068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:59.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:10:59.625+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:59.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:59.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:10:59.652+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:59.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:10:59.662+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:10:59.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:10:59.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:11:30.081+0000] {processor.py:157} INFO - Started process (PID=77093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:11:30.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:11:30.084+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:11:30.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:11:30.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:11:30.112+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:11:30.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:11:30.122+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:11:30.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:11:30.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T19:12:00.506+0000] {processor.py:157} INFO - Started process (PID=77118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:00.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:12:00.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:00.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:00.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:00.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:00.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:12:00.561+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:00.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:12:00.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T19:12:30.929+0000] {processor.py:157} INFO - Started process (PID=77143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:30.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:12:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:30.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:30.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:12:30.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:30.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:12:30.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:12:30.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:12:30.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:13:01.428+0000] {processor.py:157} INFO - Started process (PID=77168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:01.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:13:01.433+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:01.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:01.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:01.462+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:01.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:13:01.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:01.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:13:01.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T19:13:31.852+0000] {processor.py:157} INFO - Started process (PID=77193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:31.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:13:31.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:31.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:31.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:13:31.883+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:31.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:13:31.892+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:13:31.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:13:31.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:14:02.268+0000] {processor.py:157} INFO - Started process (PID=77218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:02.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:14:02.271+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:02.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:02.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:02.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:02.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:14:02.308+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:02.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:14:02.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T19:14:32.649+0000] {processor.py:157} INFO - Started process (PID=77243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:32.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:14:32.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:32.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:32.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:14:32.676+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:32.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:14:32.690+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:14:32.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:14:32.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:15:03.135+0000] {processor.py:157} INFO - Started process (PID=77268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:03.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:15:03.139+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:03.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:03.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:03.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:03.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:15:03.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:03.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:15:03.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:15:33.650+0000] {processor.py:157} INFO - Started process (PID=77293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:33.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:15:33.654+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:33.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:33.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:15:33.688+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:33.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:15:33.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:15:33.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:15:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T19:16:04.160+0000] {processor.py:157} INFO - Started process (PID=77318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:04.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:16:04.166+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:04.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:04.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:04.197+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:04.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:16:04.209+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:04.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:16:04.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T19:16:34.640+0000] {processor.py:157} INFO - Started process (PID=77343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:34.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:16:34.645+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:34.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:34.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:16:34.677+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:34.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:16:34.687+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:16:34.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:16:34.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T19:17:05.117+0000] {processor.py:157} INFO - Started process (PID=77368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:05.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:17:05.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:05.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:05.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:05.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:05.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:17:05.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:05.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:17:05.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:17:35.640+0000] {processor.py:157} INFO - Started process (PID=77393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:35.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:17:35.644+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:35.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:35.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:17:35.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:35.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:17:35.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:17:35.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:17:35.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:18:06.118+0000] {processor.py:157} INFO - Started process (PID=77418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:06.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:18:06.121+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:06.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:06.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:06.147+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:06.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:18:06.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:06.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:18:06.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:18:36.560+0000] {processor.py:157} INFO - Started process (PID=77443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:36.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:18:36.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:36.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:36.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:18:36.590+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:36.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:18:36.599+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:18:36.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:18:36.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:19:06.932+0000] {processor.py:157} INFO - Started process (PID=77468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:06.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:19:06.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:06.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:06.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:06.971+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:06.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:19:06.983+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:06.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:19:06.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T19:19:37.399+0000] {processor.py:157} INFO - Started process (PID=77493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:37.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:19:37.408+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:37.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:37.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:19:37.431+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:37.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:19:37.440+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:19:37.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:19:37.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:20:07.832+0000] {processor.py:157} INFO - Started process (PID=77518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:07.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:20:07.836+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:07.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:07.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:07.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:07.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:20:07.876+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:07.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:20:07.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:20:38.246+0000] {processor.py:157} INFO - Started process (PID=77543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:38.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:20:38.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:38.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:38.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:20:38.276+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:38.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:20:38.289+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:20:38.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:20:38.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:21:08.688+0000] {processor.py:157} INFO - Started process (PID=77568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:08.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:21:08.691+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:08.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:08.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:08.716+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:08.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:21:08.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:08.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:21:08.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:21:39.121+0000] {processor.py:157} INFO - Started process (PID=77593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:39.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:21:39.124+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:39.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:39.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:21:39.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:39.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:21:39.159+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:21:39.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:21:39.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:22:09.534+0000] {processor.py:157} INFO - Started process (PID=77618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:09.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:22:09.538+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:09.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:09.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:09.573+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:09.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:22:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:09.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:22:09.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T19:22:40.033+0000] {processor.py:157} INFO - Started process (PID=77643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:40.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:22:40.037+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:40.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:40.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:22:40.063+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:40.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:22:40.074+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:22:40.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:22:40.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:23:10.516+0000] {processor.py:157} INFO - Started process (PID=77668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:10.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:23:10.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:10.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:10.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:10.547+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:10.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:23:10.558+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:10.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:23:10.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:23:40.956+0000] {processor.py:157} INFO - Started process (PID=77693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:40.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:23:40.958+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:40.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:40.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:23:40.985+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:40.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:23:40.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:23:40.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:23:41.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T19:24:11.355+0000] {processor.py:157} INFO - Started process (PID=77718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:11.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:24:11.359+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:11.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:11.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:11.386+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:11.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:24:11.396+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:11.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:24:11.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T19:24:41.818+0000] {processor.py:157} INFO - Started process (PID=77743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:41.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:24:41.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:41.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:41.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:24:41.857+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:41.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:24:41.866+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:24:41.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:24:41.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T19:25:12.262+0000] {processor.py:157} INFO - Started process (PID=77768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:12.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:25:12.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:12.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:12.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:12.282+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:12.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:25:12.290+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:12.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:25:12.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.037 seconds
[2024-07-27T19:25:42.726+0000] {processor.py:157} INFO - Started process (PID=77793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:42.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:25:42.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:42.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:42.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:25:42.762+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:42.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:25:42.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:25:42.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:25:42.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T19:26:13.159+0000] {processor.py:157} INFO - Started process (PID=77818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:13.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:26:13.162+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:13.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:13.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:13.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:13.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:26:13.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:13.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:26:13.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T19:26:43.645+0000] {processor.py:157} INFO - Started process (PID=77843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:43.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:26:43.649+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:43.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:43.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:26:43.673+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:43.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:26:43.684+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:26:43.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:26:43.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T19:27:14.110+0000] {processor.py:157} INFO - Started process (PID=77868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:14.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:27:14.114+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:14.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:14.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:14.142+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:14.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:27:14.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:14.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:27:14.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T19:27:44.539+0000] {processor.py:157} INFO - Started process (PID=77893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:44.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:27:44.544+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:44.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:44.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:27:44.576+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:44.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:27:44.585+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:27:44.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:27:44.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-27T19:28:14.969+0000] {processor.py:157} INFO - Started process (PID=77918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:14.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:28:14.972+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:14.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:14.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:15.001+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:15.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:28:15.012+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:15.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:28:15.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T19:28:45.413+0000] {processor.py:157} INFO - Started process (PID=77943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:45.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:28:45.415+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:45.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:45.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:28:45.434+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:45.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:28:45.442+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:28:45.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:28:45.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.039 seconds
[2024-07-27T19:29:15.883+0000] {processor.py:157} INFO - Started process (PID=77968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:15.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:29:15.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:15.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:15.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:15.913+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:15.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:29:15.922+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:15.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:29:15.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T19:29:46.368+0000] {processor.py:157} INFO - Started process (PID=77993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:46.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:29:46.372+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:46.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:46.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:29:46.404+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:46.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:29:46.413+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:29:46.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:29:46.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T19:30:16.810+0000] {processor.py:157} INFO - Started process (PID=78018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:16.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:30:16.813+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:16.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:16.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:16.845+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:16.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:30:16.856+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:16.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:30:16.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T19:30:47.462+0000] {processor.py:157} INFO - Started process (PID=78043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:47.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:30:47.468+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:47.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:47.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:30:47.512+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:47.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:30:47.527+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:30:47.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:30:47.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T19:45:51.633+0000] {processor.py:157} INFO - Started process (PID=78070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:45:51.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T19:45:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:45:51.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:45:51.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T19:45:51.660+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:45:51.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T19:45:51.670+0000] {logging_mixin.py:151} INFO - [2024-07-27T19:45:51.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T19:45:51.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T20:01:37.253+0000] {processor.py:157} INFO - Started process (PID=78095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:01:37.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:01:37.259+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:01:37.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:01:37.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:01:37.343+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:01:37.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:01:37.382+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:01:37.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:01:37.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-27T20:02:07.940+0000] {processor.py:157} INFO - Started process (PID=78120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:07.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:02:07.945+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:07.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:07.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:07.982+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:07.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:02:07.995+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:07.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:02:08.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-27T20:02:38.421+0000] {processor.py:157} INFO - Started process (PID=78145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:38.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:02:38.423+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:38.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:38.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:02:38.449+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:38.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:02:38.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:02:38.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:02:38.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T20:03:08.855+0000] {processor.py:157} INFO - Started process (PID=78170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:08.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:03:08.859+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:08.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:08.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:08.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:08.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:03:08.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:08.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:03:08.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T20:03:39.274+0000] {processor.py:157} INFO - Started process (PID=78195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:39.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:03:39.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:39.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:39.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:03:39.301+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:39.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:03:39.310+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:03:39.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:03:39.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-27T20:13:23.588+0000] {processor.py:157} INFO - Started process (PID=78219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:23.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:13:23.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:23.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:23.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:23.659+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:23.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:13:23.699+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:23.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:13:23.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-07-27T20:13:54.228+0000] {processor.py:157} INFO - Started process (PID=78245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:54.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:13:54.234+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:54.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:54.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:13:54.273+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:54.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:13:54.286+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:13:54.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:13:54.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-27T20:14:24.711+0000] {processor.py:157} INFO - Started process (PID=78270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:24.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:14:24.713+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:24.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:24.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:24.741+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:24.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:14:24.752+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:24.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:14:24.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T20:14:55.139+0000] {processor.py:157} INFO - Started process (PID=78295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:55.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:14:55.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:55.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:55.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:14:55.175+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:55.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:14:55.187+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:14:55.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:14:55.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T20:15:25.548+0000] {processor.py:157} INFO - Started process (PID=78320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:25.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:15:25.552+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:25.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:25.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:25.586+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:25.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:15:25.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:25.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:15:25.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T20:15:55.996+0000] {processor.py:157} INFO - Started process (PID=78345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:55.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:15:55.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:55.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:56.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:15:56.028+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:56.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:15:56.039+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:15:56.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:15:56.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T20:33:18.168+0000] {processor.py:157} INFO - Started process (PID=78370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:18.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:33:18.177+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:18.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:18.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:18.249+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:18.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:33:18.270+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:18.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:33:18.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-27T20:33:49.079+0000] {processor.py:157} INFO - Started process (PID=78394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:49.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:33:49.087+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:49.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:49.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:33:49.144+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:49.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:33:49.156+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:33:49.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:33:49.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-27T20:34:19.576+0000] {processor.py:157} INFO - Started process (PID=78421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:19.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:34:19.578+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:19.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:19.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:19.598+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:19.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:34:19.607+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:19.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:34:19.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-27T20:34:50.044+0000] {processor.py:157} INFO - Started process (PID=78446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:50.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:34:50.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:50.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:50.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:34:50.073+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:50.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:34:50.082+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:34:50.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:34:50.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T20:35:20.445+0000] {processor.py:157} INFO - Started process (PID=78471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:35:20.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:35:20.447+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:35:20.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:35:20.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:35:20.469+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:35:20.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:35:20.479+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:35:20.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:35:20.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-27T20:52:55.201+0000] {processor.py:157} INFO - Started process (PID=78496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:52:55.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:52:55.206+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:52:55.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:52:55.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:52:55.238+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:52:55.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:52:55.251+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:52:55.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:52:55.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-27T20:53:25.726+0000] {processor.py:157} INFO - Started process (PID=78523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:25.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:53:25.731+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:25.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:25.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:25.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:25.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:53:25.786+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:25.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:53:25.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-27T20:53:56.196+0000] {processor.py:157} INFO - Started process (PID=78548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:56.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:53:56.199+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:56.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:56.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:53:56.226+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:56.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:53:56.235+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:53:56.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:53:56.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T20:54:26.699+0000] {processor.py:157} INFO - Started process (PID=78573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:26.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:54:26.703+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:26.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:26.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:26.740+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:26.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:54:26.754+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:26.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:54:26.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-27T20:54:57.136+0000] {processor.py:157} INFO - Started process (PID=78598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:57.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T20:54:57.138+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:57.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:57.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T20:54:57.164+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:57.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T20:54:57.176+0000] {logging_mixin.py:151} INFO - [2024-07-27T20:54:57.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T20:54:57.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T21:10:39.550+0000] {processor.py:157} INFO - Started process (PID=78625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:10:39.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:10:39.552+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:10:39.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:10:39.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:10:39.580+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:10:39.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:10:39.593+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:10:39.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:10:39.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T21:11:10.019+0000] {processor.py:157} INFO - Started process (PID=78650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:10.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:11:10.023+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:10.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:10.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:10.057+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:10.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:11:10.069+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:10.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:11:10.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T21:11:40.551+0000] {processor.py:157} INFO - Started process (PID=78675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:40.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:11:40.556+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:40.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:40.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:11:40.587+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:40.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:11:40.600+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:11:40.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:11:40.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T21:12:10.965+0000] {processor.py:157} INFO - Started process (PID=78700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:10.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:12:10.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:10.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:10.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:10.987+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:10.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:12:10.999+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:10.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:12:11.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-27T21:12:41.422+0000] {processor.py:157} INFO - Started process (PID=78725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:41.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:12:41.427+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:41.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:41.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:12:41.457+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:41.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:12:41.469+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:12:41.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:12:41.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T21:13:11.896+0000] {processor.py:157} INFO - Started process (PID=78750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:13:11.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:13:11.900+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:13:11.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:13:11.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:13:11.926+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:13:11.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:13:11.935+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:13:11.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:13:11.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T21:14:43.859+0000] {processor.py:157} INFO - Started process (PID=78775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:14:43.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:14:43.864+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:14:43.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:14:43.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:14:43.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:14:43.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:14:43.906+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:14:43.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:14:43.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T21:15:14.350+0000] {processor.py:157} INFO - Started process (PID=78801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:14.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:15:14.354+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:14.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:14.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:14.389+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:14.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:15:14.401+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:14.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:15:14.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T21:15:44.823+0000] {processor.py:157} INFO - Started process (PID=78826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:44.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:15:44.826+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:44.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:44.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:15:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:44.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:15:44.860+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:15:44.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:15:44.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T21:16:15.298+0000] {processor.py:157} INFO - Started process (PID=78851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:16:15.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:16:15.303+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:16:15.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:16:15.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:16:15.337+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:16:15.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:16:15.348+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:16:15.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:16:15.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-27T21:32:49.645+0000] {processor.py:157} INFO - Started process (PID=78878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:32:49.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:32:49.651+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:32:49.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:32:49.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:32:49.720+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:32:49.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:32:49.741+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:32:49.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:32:49.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-27T21:33:20.242+0000] {processor.py:157} INFO - Started process (PID=78903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:20.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:33:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:20.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:20.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:20.273+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:20.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:33:20.283+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:20.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:33:20.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T21:33:50.709+0000] {processor.py:157} INFO - Started process (PID=78928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:50.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:33:50.711+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:50.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:50.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:33:50.743+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:50.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:33:50.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:33:50.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:33:50.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T21:34:21.151+0000] {processor.py:157} INFO - Started process (PID=78953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:21.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:34:21.153+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:21.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:21.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:21.179+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:21.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:34:21.190+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:21.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:34:21.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T21:34:51.527+0000] {processor.py:157} INFO - Started process (PID=78978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:51.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:34:51.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:51.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:51.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:34:51.560+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:51.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:34:51.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:34:51.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:34:51.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T21:35:21.920+0000] {processor.py:157} INFO - Started process (PID=79003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:21.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:35:21.925+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:21.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:21.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:21.967+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:21.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:35:21.981+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:21.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:35:21.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T21:35:52.427+0000] {processor.py:157} INFO - Started process (PID=79028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:52.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:35:52.429+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:52.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:52.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:35:52.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:52.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:35:52.470+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:35:52.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:35:52.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T21:36:22.878+0000] {processor.py:157} INFO - Started process (PID=79052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:22.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:36:22.883+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:22.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:22.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:22.917+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:22.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:36:22.929+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:22.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:36:22.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T21:36:53.432+0000] {processor.py:157} INFO - Started process (PID=79078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:53.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:36:53.435+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:53.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:53.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:36:53.465+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:53.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:36:53.474+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:36:53.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:36:53.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T21:53:37.754+0000] {processor.py:157} INFO - Started process (PID=79102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:53:37.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:53:37.763+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:53:37.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:53:37.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:53:37.861+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:53:37.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:53:37.885+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:53:37.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:53:37.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-27T21:54:08.508+0000] {processor.py:157} INFO - Started process (PID=79128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:08.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:54:08.518+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:08.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:08.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:08.562+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:08.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:54:08.574+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:08.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:54:08.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-27T21:54:39.580+0000] {processor.py:157} INFO - Started process (PID=79153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:39.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:54:39.583+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:39.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:39.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:54:39.624+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:39.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:54:39.635+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:54:39.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:54:39.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T21:55:10.147+0000] {processor.py:157} INFO - Started process (PID=79178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:10.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:55:10.149+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:10.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:10.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:10.178+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:10.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:55:10.191+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:10.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:55:10.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T21:55:40.655+0000] {processor.py:157} INFO - Started process (PID=79203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:40.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:55:40.658+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:40.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:40.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:55:40.691+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:40.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:55:40.700+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:55:40.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:55:40.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T21:56:11.102+0000] {processor.py:157} INFO - Started process (PID=79228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:11.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:56:11.107+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:11.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:11.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:11.146+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:11.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:56:11.157+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:11.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:56:11.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T21:56:41.580+0000] {processor.py:157} INFO - Started process (PID=79253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:41.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:56:41.584+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:41.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:41.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:56:41.608+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:41.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:56:41.617+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:56:41.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:56:41.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T21:57:12.044+0000] {processor.py:157} INFO - Started process (PID=79278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:12.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:57:12.048+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:12.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:12.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:12.077+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:12.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:57:12.089+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:12.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:57:12.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-27T21:57:42.467+0000] {processor.py:157} INFO - Started process (PID=79303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:42.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:57:42.471+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:42.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:42.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:57:42.496+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:42.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:57:42.508+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:57:42.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:57:42.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T21:58:12.904+0000] {processor.py:157} INFO - Started process (PID=79328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:12.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:58:12.907+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:12.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:12.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:12.934+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:12.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:58:12.944+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:12.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:58:12.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T21:58:43.419+0000] {processor.py:157} INFO - Started process (PID=79353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:43.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T21:58:43.422+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:43.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:43.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T21:58:43.450+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:43.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T21:58:43.460+0000] {logging_mixin.py:151} INFO - [2024-07-27T21:58:43.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T21:58:43.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-27T22:14:36.452+0000] {processor.py:157} INFO - Started process (PID=79379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:14:36.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:14:36.461+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:14:36.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:14:36.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:14:36.539+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:14:36.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:14:36.571+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:14:36.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:14:36.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-07-27T22:15:07.058+0000] {processor.py:157} INFO - Started process (PID=79405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:07.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:15:07.063+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:07.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:07.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:07.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:07.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:15:07.106+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:07.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:15:07.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T22:15:37.551+0000] {processor.py:157} INFO - Started process (PID=79430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:37.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:15:37.567+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:37.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:37.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:15:37.601+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:37.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:15:37.613+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:15:37.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:15:37.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T22:16:08.054+0000] {processor.py:157} INFO - Started process (PID=79455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:08.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:16:08.056+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:08.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:08.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:08.085+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:08.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:16:08.095+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:08.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:16:08.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T22:16:38.481+0000] {processor.py:157} INFO - Started process (PID=79480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:38.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:16:38.484+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:38.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:38.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:16:38.511+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:38.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:16:38.521+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:16:38.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:16:38.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T22:32:33.207+0000] {processor.py:157} INFO - Started process (PID=79506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:32:33.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:32:33.210+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:32:33.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:32:33.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:32:33.242+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:32:33.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:32:33.254+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:32:33.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:32:33.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-27T22:33:03.739+0000] {processor.py:157} INFO - Started process (PID=79531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:03.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:33:03.744+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:03.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:03.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:03.784+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:03.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:33:03.797+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:03.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:33:03.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-27T22:33:34.243+0000] {processor.py:157} INFO - Started process (PID=79556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:34.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:33:34.247+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:34.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:34.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:33:34.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:34.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:33:34.284+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:33:34.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:33:34.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T22:34:04.664+0000] {processor.py:157} INFO - Started process (PID=79581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:04.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:34:04.669+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:04.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:04.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:04.708+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:04.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:34:04.721+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:04.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:34:04.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-27T22:34:35.221+0000] {processor.py:157} INFO - Started process (PID=79606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:35.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:34:35.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:35.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:35.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:34:35.258+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:35.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:34:35.274+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:34:35.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:34:35.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T22:51:02.662+0000] {processor.py:157} INFO - Started process (PID=79633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:02.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:51:02.667+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:02.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:02.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:02.729+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:02.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:51:02.756+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:02.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:51:02.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-27T22:51:33.234+0000] {processor.py:157} INFO - Started process (PID=79657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:33.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:51:33.238+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:33.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:33.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:51:33.277+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:33.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:51:33.299+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:51:33.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:51:33.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-27T22:52:03.702+0000] {processor.py:157} INFO - Started process (PID=79683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:03.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:52:03.707+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:03.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:03.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:03.735+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:03.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:52:03.747+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:03.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:52:03.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T22:52:34.141+0000] {processor.py:157} INFO - Started process (PID=79708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:34.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T22:52:34.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:34.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:34.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T22:52:34.180+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:34.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T22:52:34.194+0000] {logging_mixin.py:151} INFO - [2024-07-27T22:52:34.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T22:52:34.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-27T23:10:23.092+0000] {processor.py:157} INFO - Started process (PID=79735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:23.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:10:23.099+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:23.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:23.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:23.168+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:23.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:10:23.207+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:23.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:10:23.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-27T23:10:53.767+0000] {processor.py:157} INFO - Started process (PID=79760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:53.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:10:53.771+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:53.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:53.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:10:53.808+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:53.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:10:53.821+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:10:53.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:10:53.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-27T23:11:24.259+0000] {processor.py:157} INFO - Started process (PID=79785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:24.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:11:24.263+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:24.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:24.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:24.292+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:24.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:11:24.304+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:24.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:11:24.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-27T23:11:54.768+0000] {processor.py:157} INFO - Started process (PID=79810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:54.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:11:54.773+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:54.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:54.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:11:54.809+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:54.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:11:54.820+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:11:54.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:11:54.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-27T23:12:25.279+0000] {processor.py:157} INFO - Started process (PID=79835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:12:25.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:12:25.281+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:12:25.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:12:25.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:12:25.309+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:12:25.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:12:25.320+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:12:25.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:12:25.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-27T23:15:30.181+0000] {processor.py:157} INFO - Started process (PID=79859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:15:30.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:15:30.186+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:15:30.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:15:30.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:15:30.264+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:15:30.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:15:30.291+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:15:30.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:15:30.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-27T23:16:00.736+0000] {processor.py:157} INFO - Started process (PID=79887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:16:00.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:16:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:16:00.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:16:00.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:16:00.806+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:16:00.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:16:00.818+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:16:00.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:16:00.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-27T23:32:23.145+0000] {processor.py:157} INFO - Started process (PID=79913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:23.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:32:23.151+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:23.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:23.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:23.208+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:23.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:32:23.228+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:23.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:32:23.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-27T23:32:53.745+0000] {processor.py:157} INFO - Started process (PID=79939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:53.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:32:53.748+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:53.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:53.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:32:53.783+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:53.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:32:53.794+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:32:53.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:32:53.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-27T23:33:24.183+0000] {processor.py:157} INFO - Started process (PID=79964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:24.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:33:24.189+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:24.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:24.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:24.224+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:24.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:33:24.237+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:24.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:33:24.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-27T23:33:54.635+0000] {processor.py:157} INFO - Started process (PID=79989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:54.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:33:54.637+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:54.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:54.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:33:54.661+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:54.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:33:54.671+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:33:54.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:33:54.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-27T23:52:06.369+0000] {processor.py:157} INFO - Started process (PID=80013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:06.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:52:06.385+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:06.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:06.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:06.475+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:06.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:52:06.503+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:06.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:52:06.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-27T23:52:37.036+0000] {processor.py:157} INFO - Started process (PID=80039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:37.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:52:37.041+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:37.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:37.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:52:37.083+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:37.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:52:37.096+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:52:37.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:52:37.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-27T23:53:07.558+0000] {processor.py:157} INFO - Started process (PID=80064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:07.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:53:07.563+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:07.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:07.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:07.588+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:07.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:53:07.598+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:07.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:53:07.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T23:53:38.000+0000] {processor.py:157} INFO - Started process (PID=80089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:38.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:53:38.003+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:38.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:38.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:53:38.030+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:38.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:53:38.040+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:53:38.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:53:38.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-27T23:54:08.472+0000] {processor.py:157} INFO - Started process (PID=80114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:08.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:54:08.483+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:08.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:08.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:08.531+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:08.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:54:08.546+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:08.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:54:08.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-27T23:54:38.859+0000] {processor.py:157} INFO - Started process (PID=80139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:38.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:54:38.862+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:38.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:38.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:54:38.884+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:38.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:54:38.895+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:54:38.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:54:38.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-27T23:55:09.324+0000] {processor.py:157} INFO - Started process (PID=80164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:09.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:55:09.327+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:09.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:09.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:09.359+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:09.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:55:09.370+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:09.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:55:09.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-27T23:55:39.771+0000] {processor.py:157} INFO - Started process (PID=80189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:39.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:55:39.776+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:39.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:39.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:55:39.812+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:39.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:55:39.823+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:55:39.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:55:39.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-27T23:56:10.264+0000] {processor.py:157} INFO - Started process (PID=80214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:10.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:56:10.268+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:10.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:10.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:10.296+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:10.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:56:10.305+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:10.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:56:10.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-27T23:56:40.745+0000] {processor.py:157} INFO - Started process (PID=80239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:40.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:56:40.748+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:40.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:40.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:56:40.772+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:40.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:56:40.782+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:56:40.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:56:40.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-27T23:57:11.115+0000] {processor.py:157} INFO - Started process (PID=80264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:11.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:57:11.119+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:11.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:11.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:11.145+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:11.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:57:11.155+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:11.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:57:11.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-27T23:57:41.594+0000] {processor.py:157} INFO - Started process (PID=80289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:41.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:57:41.597+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:41.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:41.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:57:41.626+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:41.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:57:41.639+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:57:41.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:57:41.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-27T23:58:12.016+0000] {processor.py:157} INFO - Started process (PID=80314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:58:12.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-27T23:58:12.020+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:58:12.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:58:12.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-27T23:58:12.053+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:58:12.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-27T23:58:12.065+0000] {logging_mixin.py:151} INFO - [2024-07-27T23:58:12.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-27T01:00:00+00:00, run_after=2024-07-28T01:00:00+00:00
[2024-07-27T23:58:12.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
