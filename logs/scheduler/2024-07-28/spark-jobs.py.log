[2024-07-28T00:15:36.457+0000] {processor.py:157} INFO - Started process (PID=80338) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:15:36.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:15:36.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:15:36.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:15:36.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:15:36.572+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:15:36.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:15:36.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-28T00:16:07.334+0000] {processor.py:157} INFO - Started process (PID=80363) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:07.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:16:07.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:07.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:07.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:16:07.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:07.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:16:07.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T00:16:37.890+0000] {processor.py:157} INFO - Started process (PID=80388) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:37.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:16:37.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:37.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:16:37.923+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:16:37.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:16:37.933+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:16:37.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T00:17:08.331+0000] {processor.py:157} INFO - Started process (PID=80413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:08.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:17:08.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:08.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:08.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:17:08.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:08.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:17:08.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T00:17:38.822+0000] {processor.py:157} INFO - Started process (PID=80438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:38.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:17:38.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:38.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:17:38.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:17:38.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:17:38.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:17:38.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T00:34:00.755+0000] {processor.py:157} INFO - Started process (PID=80463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:00.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:34:00.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:00.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:00.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:34:00.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:00.803+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-27T00:30:00+00:00, run_after=2024-07-28T00:30:00+00:00
[2024-07-28T00:34:00.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T00:34:31.254+0000] {processor.py:157} INFO - Started process (PID=80889) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:31.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:34:31.263+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:31.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:31.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:34:31.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:34:31.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:34:31.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T00:35:01.744+0000] {processor.py:157} INFO - Started process (PID=80914) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:01.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:35:01.753+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:01.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:01.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:01.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:01.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:35:01.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T00:35:32.239+0000] {processor.py:157} INFO - Started process (PID=80939) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:32.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:35:32.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:32.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:32.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:35:32.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:35:32.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:35:32.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T00:36:02.698+0000] {processor.py:157} INFO - Started process (PID=80964) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:02.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:36:02.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:02.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:02.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:02.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:02.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:36:02.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T00:36:33.099+0000] {processor.py:157} INFO - Started process (PID=80992) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:33.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:36:33.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:33.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:36:33.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:36:33.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:36:33.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:36:33.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T00:37:03.583+0000] {processor.py:157} INFO - Started process (PID=81017) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:03.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:37:03.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:03.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:03.626+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:37:03.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:03.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:37:03.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T00:37:33.967+0000] {processor.py:157} INFO - Started process (PID=81042) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:33.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:37:33.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:33.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:33.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:37:33.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:33.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:37:34.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:37:34.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:37:34.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T00:38:04.484+0000] {processor.py:157} INFO - Started process (PID=81067) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:38:04.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:38:04.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:38:04.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:38:04.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:38:04.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:38:04.534+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:38:04.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T00:54:59.860+0000] {processor.py:157} INFO - Started process (PID=81092) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:54:59.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:54:59.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:54:59.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:54:59.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:54:59.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:54:59.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:54:59.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-28T00:55:30.568+0000] {processor.py:157} INFO - Started process (PID=81118) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:55:30.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:55:30.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:55:30.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:55:30.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:55:30.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:55:30.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:55:30.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T00:56:01.037+0000] {processor.py:157} INFO - Started process (PID=81143) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:01.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:56:01.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:01.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:01.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:56:01.091+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:01.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:56:01.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T00:56:31.579+0000] {processor.py:157} INFO - Started process (PID=81168) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:31.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:56:31.582+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:31.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:56:31.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:56:31.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:56:31.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:56:31.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T00:57:02.024+0000] {processor.py:157} INFO - Started process (PID=81193) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:57:02.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T00:57:02.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:57:02.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T00:57:02.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T00:57:02.069+0000] {logging_mixin.py:151} INFO - [2024-07-28T00:57:02.069+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T00:57:02.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T01:12:59.342+0000] {processor.py:157} INFO - Started process (PID=81218) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:12:59.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:12:59.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:12:59.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:12:59.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:12:59.408+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:12:59.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:12:59.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T01:13:29.914+0000] {processor.py:157} INFO - Started process (PID=81634) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:13:29.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:13:29.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:29.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:13:29.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:13:29.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:29.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:13:30.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:13:30.001+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:13:30.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T01:14:00.448+0000] {processor.py:157} INFO - Started process (PID=81659) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:00.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:14:00.452+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:00.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:00.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:14:00.486+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:00.486+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:14:00.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T01:14:30.927+0000] {processor.py:157} INFO - Started process (PID=81684) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:30.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:14:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:30.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:14:30.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:14:30.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:14:30.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:14:30.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T01:16:32.176+0000] {processor.py:157} INFO - Started process (PID=81709) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:16:32.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:16:32.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:16:32.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:16:32.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:16:32.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:16:32.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:16:32.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.158 seconds
[2024-07-28T01:17:02.909+0000] {processor.py:157} INFO - Started process (PID=81736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:02.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:17:02.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:02.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:02.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:17:02.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:02.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:17:02.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T01:17:33.454+0000] {processor.py:157} INFO - Started process (PID=81761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:33.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:17:33.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:33.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:17:33.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:17:33.495+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:17:33.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:17:33.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T01:18:03.960+0000] {processor.py:157} INFO - Started process (PID=81786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:03.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:18:03.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:03.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:03.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:03.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:03.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:18:04.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:04.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:18:04.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T01:18:34.500+0000] {processor.py:157} INFO - Started process (PID=81811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:34.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:18:34.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:34.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:18:34.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:18:34.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:18:34.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:18:34.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T01:35:04.879+0000] {processor.py:157} INFO - Started process (PID=81836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:04.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:35:04.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:04.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:35:04.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:04.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:35:04.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T01:35:35.391+0000] {processor.py:157} INFO - Started process (PID=81863) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:35.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:35:35.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:35.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:35:35.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:35:35.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:35:35.457+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:35:35.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-28T01:36:05.824+0000] {processor.py:157} INFO - Started process (PID=81888) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:05.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:36:05.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:05.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:05.861+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:36:05.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:05.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:36:05.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T01:36:36.267+0000] {processor.py:157} INFO - Started process (PID=81913) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:36.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:36:36.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:36.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:36:36.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:36:36.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:36:36.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:36:36.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T01:52:37.231+0000] {processor.py:157} INFO - Started process (PID=81938) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:52:37.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:52:37.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:52:37.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:52:37.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:52:37.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:52:37.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:52:37.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T01:53:07.729+0000] {processor.py:157} INFO - Started process (PID=81965) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:07.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:53:07.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:07.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:07.771+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:53:07.783+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:07.783+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:53:07.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T01:53:38.162+0000] {processor.py:157} INFO - Started process (PID=81990) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:38.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:53:38.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:38.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:53:38.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:53:38.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:53:38.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:53:38.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T01:54:08.594+0000] {processor.py:157} INFO - Started process (PID=82015) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:08.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:54:08.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:08.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:08.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:54:08.645+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:08.645+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:54:08.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T01:54:38.986+0000] {processor.py:157} INFO - Started process (PID=82040) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:38.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T01:54:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:38.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T01:54:39.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:39.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T01:54:39.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T01:54:39.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T01:54:39.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T02:08:38.396+0000] {processor.py:157} INFO - Started process (PID=82067) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:08:38.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:08:38.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:08:38.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:08:38.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:08:38.462+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:08:38.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:08:38.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T02:09:08.938+0000] {processor.py:157} INFO - Started process (PID=82092) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:08.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:09:08.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:08.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:08.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:09.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:09.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:09:09.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:09.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:09:09.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T02:09:39.481+0000] {processor.py:157} INFO - Started process (PID=82117) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:39.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:09:39.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:39.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:09:39.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:09:39.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:09:39.530+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:09:39.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T02:10:09.878+0000] {processor.py:157} INFO - Started process (PID=82142) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:09.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:10:09.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:09.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:09.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:10:09.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:09.917+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:10:09.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T02:10:40.329+0000] {processor.py:157} INFO - Started process (PID=82167) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:40.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:10:40.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:40.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:10:40.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:10:40.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:10:40.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:10:40.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T02:17:44.286+0000] {processor.py:157} INFO - Started process (PID=82194) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:17:44.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:17:44.292+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:17:44.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:17:44.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:17:44.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:17:44.393+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:17:44.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.148 seconds
[2024-07-28T02:18:15.139+0000] {processor.py:157} INFO - Started process (PID=82219) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:15.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:18:15.145+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:15.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:15.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:18:15.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:15.197+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:18:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T02:18:45.600+0000] {processor.py:157} INFO - Started process (PID=82244) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:45.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:18:45.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:45.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:18:45.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:18:45.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:18:45.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:18:45.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T02:19:16.036+0000] {processor.py:157} INFO - Started process (PID=82269) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:16.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:19:16.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:16.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:16.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:19:16.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:16.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:19:16.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T02:19:46.494+0000] {processor.py:157} INFO - Started process (PID=82294) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:46.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:19:46.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:46.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:19:46.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:19:46.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:19:46.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:19:46.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T02:37:22.613+0000] {processor.py:157} INFO - Started process (PID=82320) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:22.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:37:22.622+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:22.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:22.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:37:22.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:22.755+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:37:22.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.169 seconds
[2024-07-28T02:37:53.383+0000] {processor.py:157} INFO - Started process (PID=82345) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:53.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:37:53.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:53.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:37:53.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:37:53.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:37:53.445+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:37:53.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T02:38:23.851+0000] {processor.py:157} INFO - Started process (PID=82370) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:23.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:38:23.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:23.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:23.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:38:23.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:23.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:38:23.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T02:38:54.282+0000] {processor.py:157} INFO - Started process (PID=82395) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:54.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:38:54.286+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:54.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:38:54.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:38:54.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:38:54.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:38:54.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T02:54:35.267+0000] {processor.py:157} INFO - Started process (PID=82421) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:54:35.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:54:35.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:54:35.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:54:35.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:54:35.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:54:35.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:54:35.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-28T02:55:05.885+0000] {processor.py:157} INFO - Started process (PID=82447) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:05.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:55:05.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:05.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:05.952+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:55:05.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:05.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:55:05.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-28T02:55:36.373+0000] {processor.py:157} INFO - Started process (PID=82472) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:36.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:55:36.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:36.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:55:36.402+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:55:36.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:55:36.413+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:55:36.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T02:56:06.816+0000] {processor.py:157} INFO - Started process (PID=82497) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:06.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:56:06.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:06.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:06.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:56:06.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:06.856+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:56:06.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T02:56:37.323+0000] {processor.py:157} INFO - Started process (PID=82522) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:37.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T02:56:37.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:37.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T02:56:37.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T02:56:37.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T02:56:37.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T02:56:37.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T03:08:56.872+0000] {processor.py:157} INFO - Started process (PID=82549) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:08:56.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:08:56.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:08:56.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:08:56.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:08:56.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:08:56.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:08:56.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T03:09:27.497+0000] {processor.py:157} INFO - Started process (PID=82574) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:27.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:09:27.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:27.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:27.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:09:27.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:27.554+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:09:27.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T03:09:58.037+0000] {processor.py:157} INFO - Started process (PID=82599) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:58.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:09:58.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:58.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:09:58.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:09:58.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:09:58.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:09:58.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T03:10:28.549+0000] {processor.py:157} INFO - Started process (PID=82624) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:10:28.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:10:28.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:10:28.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:10:28.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:10:28.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:10:28.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:10:28.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T03:18:33.354+0000] {processor.py:157} INFO - Started process (PID=82649) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:18:33.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:18:33.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:18:33.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:18:33.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:18:33.472+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:18:33.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:18:33.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-28T03:19:03.986+0000] {processor.py:157} INFO - Started process (PID=82674) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:03.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:19:04.005+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:04.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:04.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:19:04.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:04.053+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:19:04.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T03:19:34.511+0000] {processor.py:157} INFO - Started process (PID=82699) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:34.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:19:34.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:34.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:19:34.543+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:19:34.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:19:34.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:19:34.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T03:20:04.952+0000] {processor.py:157} INFO - Started process (PID=82724) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:04.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:20:04.956+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:04.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:04.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:20:04.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:04.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:20:05.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T03:20:35.418+0000] {processor.py:157} INFO - Started process (PID=82749) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:35.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:20:35.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:35.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:20:35.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:20:35.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:20:35.460+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:20:35.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T03:37:19.002+0000] {processor.py:157} INFO - Started process (PID=82774) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:19.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:37:19.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:19.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:19.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:37:19.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:19.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:37:19.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.183 seconds
[2024-07-28T03:37:49.645+0000] {processor.py:157} INFO - Started process (PID=82799) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:49.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:37:49.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:49.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:37:49.693+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:37:49.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:37:49.707+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:37:49.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-28T03:38:20.101+0000] {processor.py:157} INFO - Started process (PID=82824) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:20.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:38:20.103+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:20.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:20.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:38:20.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:20.136+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:38:20.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T03:38:50.607+0000] {processor.py:157} INFO - Started process (PID=82849) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:50.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:38:50.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:50.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:38:50.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:38:50.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:38:50.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:38:50.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T03:55:09.451+0000] {processor.py:157} INFO - Started process (PID=82876) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:09.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:55:09.463+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:09.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:09.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:55:09.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:09.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:55:09.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-28T03:55:40.061+0000] {processor.py:157} INFO - Started process (PID=82901) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:40.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:55:40.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:40.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:55:40.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:55:40.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:55:40.142+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:55:40.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-28T03:56:10.560+0000] {processor.py:157} INFO - Started process (PID=82926) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:10.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:56:10.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:10.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:10.583+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:56:10.595+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:10.595+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:56:10.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T03:56:41.060+0000] {processor.py:157} INFO - Started process (PID=82951) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:41.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:56:41.066+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:41.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:56:41.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:56:41.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:56:41.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:56:41.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T03:57:11.511+0000] {processor.py:157} INFO - Started process (PID=82976) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:11.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:57:11.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:11.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:11.549+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:57:11.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:11.563+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:57:11.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T03:57:41.942+0000] {processor.py:157} INFO - Started process (PID=83001) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:41.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:57:41.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:41.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:57:41.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:57:41.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:57:41.984+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:57:41.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T03:58:12.453+0000] {processor.py:157} INFO - Started process (PID=83026) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:12.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:58:12.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:12.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:12.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:58:12.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:12.493+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:58:12.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T03:58:42.925+0000] {processor.py:157} INFO - Started process (PID=83051) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:42.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:58:42.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:42.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:58:42.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:58:42.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:58:42.971+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:58:42.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T03:59:13.359+0000] {processor.py:157} INFO - Started process (PID=83076) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:59:13.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T03:59:13.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:59:13.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T03:59:13.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T03:59:13.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T03:59:13.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T03:59:13.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T04:14:37.389+0000] {processor.py:157} INFO - Started process (PID=83101) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:14:37.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:14:37.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:14:37.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:14:37.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:14:37.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:14:37.486+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:14:37.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-28T04:15:08.005+0000] {processor.py:157} INFO - Started process (PID=83126) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:08.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:15:08.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:08.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:08.049+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:15:08.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:08.062+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:15:08.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T04:15:38.476+0000] {processor.py:157} INFO - Started process (PID=83151) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:38.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:15:38.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:38.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:15:38.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:15:38.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:15:38.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:15:38.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T04:16:08.981+0000] {processor.py:157} INFO - Started process (PID=83176) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:08.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:16:08.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:08.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:08.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:09.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:09.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:16:09.028+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:09.028+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:16:09.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T04:16:39.392+0000] {processor.py:157} INFO - Started process (PID=83201) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:39.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:16:39.396+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:39.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:16:39.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:16:39.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:16:39.436+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:16:39.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T04:19:33.714+0000] {processor.py:157} INFO - Started process (PID=83226) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:19:33.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:19:33.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:19:33.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:19:33.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:19:33.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:19:33.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:19:33.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T04:20:04.205+0000] {processor.py:157} INFO - Started process (PID=83252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:04.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:20:04.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:04.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:04.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:20:04.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:04.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:20:04.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T04:20:34.628+0000] {processor.py:157} INFO - Started process (PID=83277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:34.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:20:34.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:34.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:20:34.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:20:34.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:20:34.681+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:20:34.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T04:21:05.076+0000] {processor.py:157} INFO - Started process (PID=83302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:05.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:21:05.080+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:05.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:05.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:21:05.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:05.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:21:05.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T04:21:35.481+0000] {processor.py:157} INFO - Started process (PID=83327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:35.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:21:35.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:35.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:21:35.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:21:35.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:21:35.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:21:35.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T04:37:12.795+0000] {processor.py:157} INFO - Started process (PID=83352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:12.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:37:12.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:12.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:12.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:37:12.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:12.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:37:12.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T04:37:43.340+0000] {processor.py:157} INFO - Started process (PID=83379) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:43.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:37:43.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:43.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:37:43.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:37:43.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:37:43.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:37:43.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T04:38:13.864+0000] {processor.py:157} INFO - Started process (PID=83404) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:13.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:38:13.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:13.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:13.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:38:13.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:13.907+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:38:13.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T04:38:44.299+0000] {processor.py:157} INFO - Started process (PID=83429) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:44.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:38:44.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:44.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:38:44.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:38:44.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:38:44.348+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:38:44.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T04:39:14.771+0000] {processor.py:157} INFO - Started process (PID=83454) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:14.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:39:14.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:14.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:14.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:39:14.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:14.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:39:14.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T04:39:45.249+0000] {processor.py:157} INFO - Started process (PID=83479) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:45.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:39:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:45.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:39:45.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:39:45.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:39:45.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:39:45.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T04:40:15.610+0000] {processor.py:157} INFO - Started process (PID=83504) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:40:15.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:40:15.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:40:15.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:40:15.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:40:15.654+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:40:15.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:40:15.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T04:55:44.019+0000] {processor.py:157} INFO - Started process (PID=83531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:55:44.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:55:44.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:55:44.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:55:44.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:55:44.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:55:44.104+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:55:44.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T04:56:14.611+0000] {processor.py:157} INFO - Started process (PID=83556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:14.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:56:14.619+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:14.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:14.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:56:14.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:14.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:56:14.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T04:56:45.068+0000] {processor.py:157} INFO - Started process (PID=83581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:45.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:56:45.072+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:45.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:56:45.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:56:45.112+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:56:45.112+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:56:45.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T04:57:15.523+0000] {processor.py:157} INFO - Started process (PID=83606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:57:15.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T04:57:15.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:57:15.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T04:57:15.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T04:57:15.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T04:57:15.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T04:57:15.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-28T05:03:16.997+0000] {processor.py:157} INFO - Started process (PID=83631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:16.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:03:17.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:17.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:17.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:03:17.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:17.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:03:17.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T05:03:47.487+0000] {processor.py:157} INFO - Started process (PID=83656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:47.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:03:47.492+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:47.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:03:47.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:03:47.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:03:47.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:03:47.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T05:04:17.931+0000] {processor.py:157} INFO - Started process (PID=83681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:17.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:04:17.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:17.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:17.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:04:17.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:17.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:04:17.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T05:04:48.389+0000] {processor.py:157} INFO - Started process (PID=83706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:48.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:04:48.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:48.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:04:48.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:04:48.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:04:48.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:04:48.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:05:18.809+0000] {processor.py:157} INFO - Started process (PID=83731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:18.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:05:18.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:18.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:18.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:05:18.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:18.840+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:05:18.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T05:05:49.284+0000] {processor.py:157} INFO - Started process (PID=83756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:49.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:05:49.288+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:49.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:05:49.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:05:49.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:05:49.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:05:49.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:06:19.701+0000] {processor.py:157} INFO - Started process (PID=83781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:19.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:06:19.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:19.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:19.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:06:19.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:19.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:06:19.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:06:50.108+0000] {processor.py:157} INFO - Started process (PID=83806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:50.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:06:50.112+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:50.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:06:50.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:06:50.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:06:50.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:06:50.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T05:07:20.603+0000] {processor.py:157} INFO - Started process (PID=83831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:20.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:07:20.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:20.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:20.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:07:20.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:20.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:07:20.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T05:07:51.053+0000] {processor.py:157} INFO - Started process (PID=83856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:51.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:07:51.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:51.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:07:51.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:07:51.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:07:51.097+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:07:51.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:08:21.482+0000] {processor.py:157} INFO - Started process (PID=83881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:21.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:08:21.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:21.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:21.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:08:21.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:21.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:08:21.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:08:51.877+0000] {processor.py:157} INFO - Started process (PID=83906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:51.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:08:51.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:51.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:08:51.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:08:51.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:08:51.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:08:51.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-28T05:09:22.298+0000] {processor.py:157} INFO - Started process (PID=83931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:22.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:09:22.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:22.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:22.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:09:22.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:22.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:09:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T05:09:52.796+0000] {processor.py:157} INFO - Started process (PID=83956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:52.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:09:52.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:52.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:09:52.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:09:52.850+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:09:52.850+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:09:52.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T05:10:23.270+0000] {processor.py:157} INFO - Started process (PID=83981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:23.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:10:23.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:23.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:23.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:10:23.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:23.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:10:23.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:10:53.676+0000] {processor.py:157} INFO - Started process (PID=84006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:53.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:10:53.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:53.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:10:53.705+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:10:53.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:10:53.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:10:53.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T05:11:24.100+0000] {processor.py:157} INFO - Started process (PID=84031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:24.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:11:24.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:24.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:24.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:11:24.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:24.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:11:24.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T05:11:54.516+0000] {processor.py:157} INFO - Started process (PID=84056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:54.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:11:54.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:54.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:11:54.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:11:54.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:11:54.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:11:54.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:12:24.982+0000] {processor.py:157} INFO - Started process (PID=84081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:12:24.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:24.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:24.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:25.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:25.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:12:25.016+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:25.016+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:12:25.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-28T05:12:55.414+0000] {processor.py:157} INFO - Started process (PID=84106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:55.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:12:55.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:55.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:12:55.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:12:55.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:12:55.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:12:55.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:13:25.932+0000] {processor.py:157} INFO - Started process (PID=84131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:25.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:13:25.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:25.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:25.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:13:25.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:25.983+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:13:25.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T05:13:56.379+0000] {processor.py:157} INFO - Started process (PID=84156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:56.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:13:56.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:56.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:13:56.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:13:56.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:13:56.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:13:56.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:14:26.874+0000] {processor.py:157} INFO - Started process (PID=84181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:26.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:14:26.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:26.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:26.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:14:26.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:26.921+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:14:26.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T05:14:57.310+0000] {processor.py:157} INFO - Started process (PID=84206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:57.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:14:57.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:57.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:14:57.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:14:57.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:14:57.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:14:57.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:15:27.708+0000] {processor.py:157} INFO - Started process (PID=84231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:27.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:15:27.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:27.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:27.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:15:27.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:27.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:15:27.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T05:15:58.123+0000] {processor.py:157} INFO - Started process (PID=84256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:58.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:15:58.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:58.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:15:58.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:15:58.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:15:58.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:15:58.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T05:16:28.579+0000] {processor.py:157} INFO - Started process (PID=84281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:28.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:16:28.584+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:28.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:28.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:16:28.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:28.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:16:28.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T05:16:59.059+0000] {processor.py:157} INFO - Started process (PID=84306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:59.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:16:59.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:59.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:16:59.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:16:59.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:16:59.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:16:59.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:17:29.431+0000] {processor.py:157} INFO - Started process (PID=84331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:29.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:17:29.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:29.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:29.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:17:29.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:29.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:17:29.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:17:59.843+0000] {processor.py:157} INFO - Started process (PID=84356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:59.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:17:59.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:59.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:17:59.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:17:59.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:17:59.895+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:17:59.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T05:18:30.354+0000] {processor.py:157} INFO - Started process (PID=84381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:18:30.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:18:30.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:18:30.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:18:30.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:18:30.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:18:30.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:18:30.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T05:19:00.831+0000] {processor.py:157} INFO - Started process (PID=84406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:00.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:19:00.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:00.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:00.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:19:00.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:00.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:19:00.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T05:19:31.312+0000] {processor.py:157} INFO - Started process (PID=84431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:31.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:19:31.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:31.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:19:31.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:19:31.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:19:31.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:19:31.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T05:20:01.677+0000] {processor.py:157} INFO - Started process (PID=84456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:01.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:20:01.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:01.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:01.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:20:01.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:01.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:20:01.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-28T05:20:32.215+0000] {processor.py:157} INFO - Started process (PID=84481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:32.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:20:32.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:32.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:20:32.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:20:32.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:20:32.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:20:32.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T05:21:02.631+0000] {processor.py:157} INFO - Started process (PID=84506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:02.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:21:02.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:02.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:02.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:21:02.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:02.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:21:02.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:21:33.097+0000] {processor.py:157} INFO - Started process (PID=84531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:33.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:21:33.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:33.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:21:33.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:21:33.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:21:33.135+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:21:33.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:22:03.557+0000] {processor.py:157} INFO - Started process (PID=84556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:03.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:22:03.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:03.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:03.597+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:22:03.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:03.608+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:22:03.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T05:22:34.004+0000] {processor.py:157} INFO - Started process (PID=84581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:34.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:22:34.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:34.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:22:34.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:22:34.044+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:22:34.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:22:34.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:23:04.411+0000] {processor.py:157} INFO - Started process (PID=84606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:04.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:23:04.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:04.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:04.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:23:04.450+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:04.450+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:23:04.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T05:23:34.917+0000] {processor.py:157} INFO - Started process (PID=84631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:34.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:23:34.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:34.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:23:34.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:23:34.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:23:34.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:23:34.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:24:05.395+0000] {processor.py:157} INFO - Started process (PID=84656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:05.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:24:05.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:05.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:05.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:24:05.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:05.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:24:05.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:24:35.827+0000] {processor.py:157} INFO - Started process (PID=84681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:35.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:24:35.830+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:35.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:24:35.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:24:35.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:24:35.868+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:24:35.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T05:25:06.219+0000] {processor.py:157} INFO - Started process (PID=84706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:06.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:25:06.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:06.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:06.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:25:06.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:06.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:25:06.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T05:25:36.720+0000] {processor.py:157} INFO - Started process (PID=84731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:36.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:25:36.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:36.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:25:36.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:25:36.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:25:36.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:25:36.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T05:26:07.191+0000] {processor.py:157} INFO - Started process (PID=84756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:07.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:26:07.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:07.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:07.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:26:07.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:07.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:26:07.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:26:37.637+0000] {processor.py:157} INFO - Started process (PID=84781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:37.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:26:37.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:37.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:26:37.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:26:37.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:26:37.676+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:26:37.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:27:08.069+0000] {processor.py:157} INFO - Started process (PID=84806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:08.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:27:08.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:08.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:08.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:27:08.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:08.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:27:08.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-28T05:27:38.544+0000] {processor.py:157} INFO - Started process (PID=84831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:38.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:27:38.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:38.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:27:38.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:27:38.587+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:27:38.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:27:38.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:28:08.998+0000] {processor.py:157} INFO - Started process (PID=84856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:08.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:28:09.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:09.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:09.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:28:09.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:09.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:28:09.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T05:28:39.501+0000] {processor.py:157} INFO - Started process (PID=84881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:39.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:28:39.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:39.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:28:39.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:28:39.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:28:39.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:28:39.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T05:29:09.960+0000] {processor.py:157} INFO - Started process (PID=84906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:09.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:29:09.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:09.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:09.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:09.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:09.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:29:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:10.007+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:29:10.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T05:29:40.411+0000] {processor.py:157} INFO - Started process (PID=84931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:40.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:29:40.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:40.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:29:40.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:29:40.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:29:40.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:29:40.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:30:10.878+0000] {processor.py:157} INFO - Started process (PID=84956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:10.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:30:10.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:10.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:10.910+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:30:10.920+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:10.920+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:30:10.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:30:41.340+0000] {processor.py:157} INFO - Started process (PID=84981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:41.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:30:41.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:41.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:30:41.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:30:41.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:30:41.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:30:41.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T05:31:11.991+0000] {processor.py:157} INFO - Started process (PID=85006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:11.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:31:11.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:11.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:12.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:12.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:12.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:31:12.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:12.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:31:12.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T05:31:42.460+0000] {processor.py:157} INFO - Started process (PID=85031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:42.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:31:42.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:42.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:31:42.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:31:42.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:31:42.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:31:42.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T05:32:12.935+0000] {processor.py:157} INFO - Started process (PID=85056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:12.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:32:12.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:12.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:12.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:32:12.978+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:12.978+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:32:12.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:32:43.348+0000] {processor.py:157} INFO - Started process (PID=85081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:43.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:32:43.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:43.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:32:43.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:32:43.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:32:43.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:32:43.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:33:13.796+0000] {processor.py:157} INFO - Started process (PID=85106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:13.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:33:13.803+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:13.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:13.841+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:33:13.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:13.853+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:33:13.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T05:33:44.261+0000] {processor.py:157} INFO - Started process (PID=85131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:44.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:33:44.263+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:44.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:33:44.281+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:33:44.290+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:33:44.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:33:44.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.038 seconds
[2024-07-28T05:34:14.681+0000] {processor.py:157} INFO - Started process (PID=85156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:14.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:34:14.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:14.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:14.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:34:14.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:14.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:34:14.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:34:45.139+0000] {processor.py:157} INFO - Started process (PID=85181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:45.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:34:45.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:45.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:34:45.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:34:45.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:34:45.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:34:45.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T05:35:15.560+0000] {processor.py:157} INFO - Started process (PID=85206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:15.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:35:15.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:15.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:15.600+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:35:15.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:15.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:35:15.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T05:35:46.003+0000] {processor.py:157} INFO - Started process (PID=85231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:46.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:35:46.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:46.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:35:46.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:35:46.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:35:46.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:35:46.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:36:16.412+0000] {processor.py:157} INFO - Started process (PID=85256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:16.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:36:16.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:16.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:16.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:36:16.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:16.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:36:16.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:36:46.898+0000] {processor.py:157} INFO - Started process (PID=85281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:46.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:36:46.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:46.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:36:46.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:36:46.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:36:46.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:36:46.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:37:17.337+0000] {processor.py:157} INFO - Started process (PID=85306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:17.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:37:17.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:17.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:17.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:37:17.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:17.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:37:17.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:37:47.749+0000] {processor.py:157} INFO - Started process (PID=85331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:47.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:37:47.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:47.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:37:47.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:37:47.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:37:47.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:37:47.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:38:18.174+0000] {processor.py:157} INFO - Started process (PID=85356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:18.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:38:18.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:18.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:18.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:38:18.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:18.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:38:18.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T05:38:48.617+0000] {processor.py:157} INFO - Started process (PID=85381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:48.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:38:48.619+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:48.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:38:48.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:38:48.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:38:48.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:38:48.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:39:19.109+0000] {processor.py:157} INFO - Started process (PID=85406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:19.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:39:19.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:19.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:19.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:39:19.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:19.195+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:39:19.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T05:39:49.681+0000] {processor.py:157} INFO - Started process (PID=85431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:49.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:39:49.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:49.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:39:49.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:39:49.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:39:49.738+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:39:49.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T05:40:20.164+0000] {processor.py:157} INFO - Started process (PID=85456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:20.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:40:20.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:20.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:20.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:40:20.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:20.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:40:20.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:40:50.599+0000] {processor.py:157} INFO - Started process (PID=85481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:50.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:40:50.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:50.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:40:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:40:50.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:40:50.628+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:40:50.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-28T05:41:21.068+0000] {processor.py:157} INFO - Started process (PID=85506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:21.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:41:21.073+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:21.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:21.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:41:21.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:21.125+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:41:21.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T05:41:51.600+0000] {processor.py:157} INFO - Started process (PID=85531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:51.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:41:51.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:51.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:41:51.656+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:41:51.667+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:41:51.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:41:51.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T05:42:22.080+0000] {processor.py:157} INFO - Started process (PID=85556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:22.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:42:22.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:22.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:22.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:42:22.119+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:22.119+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:42:22.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:42:52.510+0000] {processor.py:157} INFO - Started process (PID=85581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:52.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:42:52.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:52.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:42:52.543+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:42:52.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:42:52.552+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:42:52.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T05:43:22.941+0000] {processor.py:157} INFO - Started process (PID=85606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:22.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:43:22.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:22.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:22.976+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:43:22.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:22.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:43:22.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T05:43:53.440+0000] {processor.py:157} INFO - Started process (PID=85631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:53.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:43:53.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:53.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:43:53.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:43:53.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:43:53.487+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:43:53.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T05:44:23.868+0000] {processor.py:157} INFO - Started process (PID=85656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:23.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:44:23.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:23.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:23.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:44:23.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:23.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:44:23.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-28T05:44:54.308+0000] {processor.py:157} INFO - Started process (PID=85681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:54.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:44:54.311+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:54.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:44:54.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:44:54.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:44:54.352+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:44:54.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:45:24.730+0000] {processor.py:157} INFO - Started process (PID=85706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:24.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:45:24.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:24.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:24.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:45:24.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:24.772+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:45:24.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:45:55.227+0000] {processor.py:157} INFO - Started process (PID=85731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:55.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:45:55.231+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:55.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:45:55.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:45:55.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:45:55.268+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:45:55.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:46:25.760+0000] {processor.py:157} INFO - Started process (PID=85756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:25.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:46:25.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:25.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:46:25.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:25.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:46:25.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:46:56.189+0000] {processor.py:157} INFO - Started process (PID=85781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:56.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:46:56.192+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:56.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:46:56.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:46:56.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:46:56.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:46:56.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:47:26.676+0000] {processor.py:157} INFO - Started process (PID=85806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:26.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:47:26.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:26.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:26.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:47:26.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:26.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:47:26.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T05:47:57.061+0000] {processor.py:157} INFO - Started process (PID=85831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:57.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:47:57.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:57.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:47:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:47:57.093+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:47:57.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:47:57.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T05:48:27.506+0000] {processor.py:157} INFO - Started process (PID=85856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:27.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:48:27.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:27.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:27.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:48:27.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:27.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:48:27.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T05:48:57.970+0000] {processor.py:157} INFO - Started process (PID=85881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:57.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:48:57.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:57.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:57.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:48:58.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:58.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:48:58.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:48:58.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:48:58.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:49:28.406+0000] {processor.py:157} INFO - Started process (PID=85906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:28.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:49:28.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:28.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:28.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:49:28.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:28.446+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:49:28.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:49:58.885+0000] {processor.py:157} INFO - Started process (PID=85931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:58.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:49:58.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:58.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:49:58.918+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:49:58.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:49:58.930+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:49:58.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T05:50:29.311+0000] {processor.py:157} INFO - Started process (PID=85956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:29.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:50:29.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:29.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:29.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:50:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:29.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:50:29.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T05:50:59.794+0000] {processor.py:157} INFO - Started process (PID=85981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:59.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:50:59.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:59.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:50:59.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:50:59.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:50:59.835+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:50:59.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:51:30.243+0000] {processor.py:157} INFO - Started process (PID=86006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:51:30.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:51:30.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:51:30.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:51:30.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:51:30.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:51:30.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:51:30.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T05:52:00.707+0000] {processor.py:157} INFO - Started process (PID=86031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:00.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:52:00.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:00.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:00.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:52:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:00.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:52:00.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:52:31.167+0000] {processor.py:157} INFO - Started process (PID=86056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:31.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:52:31.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:31.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:52:31.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:52:31.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:52:31.209+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:52:31.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:53:01.538+0000] {processor.py:157} INFO - Started process (PID=86081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:01.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:53:01.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:01.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:01.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:53:01.579+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:01.579+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:53:01.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:53:31.994+0000] {processor.py:157} INFO - Started process (PID=86106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:31.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:53:31.997+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:31.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:32.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:53:32.028+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:32.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:53:32.038+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:53:32.038+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:53:32.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:54:02.439+0000] {processor.py:157} INFO - Started process (PID=86131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:02.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:54:02.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:02.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:02.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:54:02.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:02.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:54:02.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T05:54:32.866+0000] {processor.py:157} INFO - Started process (PID=86156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:32.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:54:32.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:32.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:54:32.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:54:32.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:54:32.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:54:32.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:55:03.318+0000] {processor.py:157} INFO - Started process (PID=86181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:03.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:55:03.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:03.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:03.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:55:03.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:03.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:55:03.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T05:55:33.675+0000] {processor.py:157} INFO - Started process (PID=86206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:33.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:55:33.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:33.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:55:33.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:55:33.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:55:33.721+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:55:33.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T05:56:04.154+0000] {processor.py:157} INFO - Started process (PID=86231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:04.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:56:04.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:04.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:04.190+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:56:04.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:04.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:56:04.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T05:56:34.574+0000] {processor.py:157} INFO - Started process (PID=86256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:34.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:56:34.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:34.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:56:34.604+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:56:34.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:56:34.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:56:34.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T05:57:04.998+0000] {processor.py:157} INFO - Started process (PID=86281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:04.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:57:05.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:05.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:05.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:57:05.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:05.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:57:05.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T05:57:35.466+0000] {processor.py:157} INFO - Started process (PID=86306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:35.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:57:35.470+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:35.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:57:35.498+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:57:35.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:57:35.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:57:35.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T05:58:05.929+0000] {processor.py:157} INFO - Started process (PID=86331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:05.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:58:05.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:05.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:05.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:58:05.979+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:05.979+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:58:05.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T05:58:36.386+0000] {processor.py:157} INFO - Started process (PID=86356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:36.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:58:36.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:36.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:58:36.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:58:36.427+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:58:36.427+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:58:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:59:06.797+0000] {processor.py:157} INFO - Started process (PID=86381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:06.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:59:06.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:06.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:06.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:59:06.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:06.834+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:59:06.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T05:59:37.266+0000] {processor.py:157} INFO - Started process (PID=86406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:37.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T05:59:37.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:37.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T05:59:37.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T05:59:37.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T05:59:37.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T05:59:37.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T06:00:07.684+0000] {processor.py:157} INFO - Started process (PID=86431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:07.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:00:07.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:07.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:07.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:00:07.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:07.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:00:07.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T06:00:38.097+0000] {processor.py:157} INFO - Started process (PID=86456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:38.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:00:38.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:38.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:00:38.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:00:38.139+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:00:38.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:00:38.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T06:01:08.584+0000] {processor.py:157} INFO - Started process (PID=86481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:08.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:01:08.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:08.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:08.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:01:08.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:08.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:01:08.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T06:01:39.036+0000] {processor.py:157} INFO - Started process (PID=86506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:39.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:01:39.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:39.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:01:39.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:01:39.091+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:01:39.091+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:01:39.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T06:02:09.534+0000] {processor.py:157} INFO - Started process (PID=86531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:09.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:02:09.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:09.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:09.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:02:09.577+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:09.577+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:02:09.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T06:02:39.922+0000] {processor.py:157} INFO - Started process (PID=86556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:39.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:02:39.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:39.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:02:39.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:02:39.958+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:02:39.958+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:02:39.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T06:03:10.342+0000] {processor.py:157} INFO - Started process (PID=86581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:10.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:03:10.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:10.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:10.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:03:10.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:10.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:03:10.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T06:03:40.846+0000] {processor.py:157} INFO - Started process (PID=86606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:40.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:03:40.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:40.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:03:40.881+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:03:40.892+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:03:40.892+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:03:40.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T06:04:11.321+0000] {processor.py:157} INFO - Started process (PID=86631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:04:11.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:04:11.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:04:11.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:04:11.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:04:11.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:04:11.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:04:11.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T06:19:25.304+0000] {processor.py:157} INFO - Started process (PID=86656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:25.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:19:25.309+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:25.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:25.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:19:25.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:25.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:19:25.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T06:19:55.818+0000] {processor.py:157} INFO - Started process (PID=86683) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:55.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:19:55.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:55.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:19:55.861+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:19:55.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:19:55.874+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:19:55.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T06:20:26.270+0000] {processor.py:157} INFO - Started process (PID=86708) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:26.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:20:26.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:26.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:26.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:20:26.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:26.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:20:26.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T06:20:56.716+0000] {processor.py:157} INFO - Started process (PID=86733) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:56.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:20:56.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:56.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:20:56.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:20:56.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:20:56.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:20:56.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T06:21:27.177+0000] {processor.py:157} INFO - Started process (PID=86758) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:21:27.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:21:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:21:27.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:21:27.209+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:21:27.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:21:27.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:21:27.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T06:37:54.078+0000] {processor.py:157} INFO - Started process (PID=86784) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:37:54.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:37:54.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:37:54.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:37:54.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:37:54.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:37:54.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:37:54.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T06:38:24.561+0000] {processor.py:157} INFO - Started process (PID=86809) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:38:24.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:38:24.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:38:24.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:38:24.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:38:24.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:38:24.613+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:38:24.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T06:54:14.734+0000] {processor.py:157} INFO - Started process (PID=86834) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:14.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:54:14.740+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:14.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:14.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:54:14.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:14.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:54:14.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T06:54:45.212+0000] {processor.py:157} INFO - Started process (PID=86859) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:45.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T06:54:45.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:45.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T06:54:45.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T06:54:45.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T06:54:45.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T06:54:45.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T07:11:06.653+0000] {processor.py:157} INFO - Started process (PID=86886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:06.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:11:06.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:06.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:06.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:11:06.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:06.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:11:06.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-28T07:11:37.170+0000] {processor.py:157} INFO - Started process (PID=86911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:37.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:11:37.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:37.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:11:37.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:11:37.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:11:37.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:11:37.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T07:12:07.672+0000] {processor.py:157} INFO - Started process (PID=86936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:07.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:12:07.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:07.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:07.705+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:12:07.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:07.715+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:12:07.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T07:12:38.114+0000] {processor.py:157} INFO - Started process (PID=86961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:38.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:12:38.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:38.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:12:38.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:12:38.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:12:38.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:12:38.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T07:20:41.120+0000] {processor.py:157} INFO - Started process (PID=86988) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:20:41.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:20:41.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:20:41.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:20:41.186+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:20:41.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:20:41.219+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:20:41.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T07:21:11.684+0000] {processor.py:157} INFO - Started process (PID=87013) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:11.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:21:11.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:11.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:11.721+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:21:11.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:11.732+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:21:11.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T07:21:42.145+0000] {processor.py:157} INFO - Started process (PID=87038) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:42.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:21:42.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:42.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:21:42.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:21:42.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:21:42.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:21:42.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T07:22:12.622+0000] {processor.py:157} INFO - Started process (PID=87063) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:12.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:22:12.626+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:12.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:12.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:22:12.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:12.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:22:12.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T07:22:43.091+0000] {processor.py:157} INFO - Started process (PID=87088) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:43.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:22:43.095+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:43.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:22:43.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:22:43.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:22:43.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:22:43.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T07:38:24.511+0000] {processor.py:157} INFO - Started process (PID=87115) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:24.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:38:24.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:24.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:24.590+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:38:24.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:24.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:38:24.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-28T07:38:55.188+0000] {processor.py:157} INFO - Started process (PID=87140) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:55.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:38:55.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:55.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:38:55.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:38:55.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:38:55.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:38:55.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T07:39:25.628+0000] {processor.py:157} INFO - Started process (PID=87165) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:25.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:39:25.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:25.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:25.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:39:25.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:25.679+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:39:25.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T07:39:56.075+0000] {processor.py:157} INFO - Started process (PID=87190) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:56.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:39:56.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:56.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:39:56.104+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:39:56.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:39:56.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:39:56.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T07:40:26.689+0000] {processor.py:157} INFO - Started process (PID=87215) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:40:26.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:40:26.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:40:26.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:40:26.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:40:26.735+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:40:26.735+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:40:26.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T07:57:10.268+0000] {processor.py:157} INFO - Started process (PID=87240) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:10.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:57:10.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:10.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:10.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:57:10.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:10.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:57:10.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T07:57:40.773+0000] {processor.py:157} INFO - Started process (PID=87267) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:40.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:57:40.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:40.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:57:40.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:57:40.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:57:40.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:57:40.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T07:58:11.200+0000] {processor.py:157} INFO - Started process (PID=87292) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:11.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:58:11.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:11.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:11.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:58:11.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:11.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:58:11.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T07:58:41.690+0000] {processor.py:157} INFO - Started process (PID=87317) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:41.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T07:58:41.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:41.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T07:58:41.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T07:58:41.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T07:58:41.739+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T07:58:41.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T08:14:57.848+0000] {processor.py:157} INFO - Started process (PID=87342) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:14:57.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:14:57.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:14:57.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:14:57.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:14:57.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:14:57.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:14:57.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T08:15:28.343+0000] {processor.py:157} INFO - Started process (PID=87369) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:28.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:15:28.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:28.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:28.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:15:28.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:28.441+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:15:28.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-28T08:15:58.858+0000] {processor.py:157} INFO - Started process (PID=87394) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:58.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:15:58.862+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:58.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:15:58.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:15:58.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:15:58.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:15:58.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T08:16:29.285+0000] {processor.py:157} INFO - Started process (PID=87419) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:29.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:16:29.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:29.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:29.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:16:29.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:29.324+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:16:29.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T08:16:59.797+0000] {processor.py:157} INFO - Started process (PID=87444) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:59.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:16:59.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:59.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:16:59.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:16:59.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:16:59.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:16:59.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T08:21:44.741+0000] {processor.py:157} INFO - Started process (PID=87471) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:21:44.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:21:44.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:21:44.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:21:44.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:21:44.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:21:44.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:21:44.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T08:22:15.335+0000] {processor.py:157} INFO - Started process (PID=87496) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:22:15.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:22:15.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:22:15.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:22:15.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:22:15.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:22:15.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:22:15.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T08:40:09.172+0000] {processor.py:157} INFO - Started process (PID=87521) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:09.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:40:09.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:09.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:09.251+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:40:09.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:09.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:40:09.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T08:40:39.805+0000] {processor.py:157} INFO - Started process (PID=87546) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:39.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:40:39.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:39.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:40:39.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:40:39.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:40:39.848+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:40:39.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T08:41:10.251+0000] {processor.py:157} INFO - Started process (PID=87571) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:10.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:41:10.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:10.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:10.292+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:41:10.305+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:10.305+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:41:10.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T08:41:40.808+0000] {processor.py:157} INFO - Started process (PID=87596) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:40.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:41:40.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:40.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:41:40.841+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:41:40.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:41:40.855+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:41:40.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T08:58:24.359+0000] {processor.py:157} INFO - Started process (PID=87621) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:24.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:58:24.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:24.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:24.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:58:24.455+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:24.455+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:58:24.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-28T08:58:54.995+0000] {processor.py:157} INFO - Started process (PID=87646) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:54.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:58:54.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:54.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:55.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:58:55.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:55.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:58:55.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:58:55.047+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:58:55.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T08:59:25.388+0000] {processor.py:157} INFO - Started process (PID=87671) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:25.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:59:25.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:25.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:25.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:59:25.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:25.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:59:25.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T08:59:55.906+0000] {processor.py:157} INFO - Started process (PID=87696) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:55.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T08:59:55.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:55.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T08:59:55.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T08:59:55.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T08:59:55.955+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T08:59:55.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T09:16:50.301+0000] {processor.py:157} INFO - Started process (PID=87723) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:16:50.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:16:50.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:16:50.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:16:50.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:16:50.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:16:50.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:16:50.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-28T09:17:20.962+0000] {processor.py:157} INFO - Started process (PID=87748) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:20.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:17:20.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:20.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:20.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:21.005+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:21.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:17:21.017+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:21.017+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:17:21.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T09:17:51.386+0000] {processor.py:157} INFO - Started process (PID=87773) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:51.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:17:51.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:51.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:17:51.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:17:51.429+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:17:51.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:17:51.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T09:18:21.864+0000] {processor.py:157} INFO - Started process (PID=87798) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:21.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:18:21.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:21.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:21.896+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:18:21.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:21.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:18:21.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T09:18:52.235+0000] {processor.py:157} INFO - Started process (PID=87823) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:52.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:18:52.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:52.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:18:52.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:18:52.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:18:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:18:52.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T09:22:36.303+0000] {processor.py:157} INFO - Started process (PID=87850) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:22:36.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:22:36.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:22:36.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:22:36.332+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:22:36.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:22:36.344+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:22:36.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T09:23:06.681+0000] {processor.py:157} INFO - Started process (PID=87875) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:23:06.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:23:06.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:23:06.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:23:06.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:23:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:23:06.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:23:06.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T09:39:42.463+0000] {processor.py:157} INFO - Started process (PID=87900) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:39:42.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:39:42.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:39:42.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:39:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:39:42.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:39:42.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:39:42.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.216 seconds
[2024-07-28T09:40:13.157+0000] {processor.py:157} INFO - Started process (PID=87925) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:13.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:40:13.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:13.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:13.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:40:13.213+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:13.213+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:40:13.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T09:40:43.646+0000] {processor.py:157} INFO - Started process (PID=87950) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:43.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:40:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:43.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:40:43.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:40:43.687+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:40:43.687+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:40:43.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T09:41:14.138+0000] {processor.py:157} INFO - Started process (PID=87975) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:41:14.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:41:14.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:41:14.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:41:14.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:41:14.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:41:14.176+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:41:14.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T09:57:06.354+0000] {processor.py:157} INFO - Started process (PID=88000) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:06.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:57:06.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:06.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:06.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:57:06.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:06.439+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:57:06.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T09:57:36.884+0000] {processor.py:157} INFO - Started process (PID=88025) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:36.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:57:36.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:36.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:57:36.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:57:36.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:57:36.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:57:36.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T09:58:07.375+0000] {processor.py:157} INFO - Started process (PID=88050) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:07.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:58:07.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:07.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:07.412+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:58:07.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:07.422+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:58:07.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T09:58:37.882+0000] {processor.py:157} INFO - Started process (PID=88075) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:37.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:58:37.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:37.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:58:37.920+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:58:37.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:58:37.930+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:58:37.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T09:59:08.420+0000] {processor.py:157} INFO - Started process (PID=88100) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:59:08.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T09:59:08.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:59:08.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T09:59:08.447+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T09:59:08.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T09:59:08.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T09:59:08.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-28T10:00:36.838+0000] {processor.py:157} INFO - Started process (PID=88125) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:00:36.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:00:36.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:00:36.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:00:36.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:00:36.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:00:36.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:00:36.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T10:01:07.924+0000] {processor.py:157} INFO - Started process (PID=88152) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:07.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:01:07.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:07.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:07.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:07.997+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:07.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:01:08.013+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:08.013+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:01:08.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-28T10:01:38.447+0000] {processor.py:157} INFO - Started process (PID=88177) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:38.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:01:38.454+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:38.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:01:38.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:01:38.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:01:38.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:01:38.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T10:02:08.947+0000] {processor.py:157} INFO - Started process (PID=88202) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:08.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:02:08.950+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:08.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:08.980+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:02:08.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:08.989+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:02:08.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T10:02:39.463+0000] {processor.py:157} INFO - Started process (PID=88227) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:39.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:02:39.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:39.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:02:39.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:02:39.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:02:39.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:02:39.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T10:03:09.933+0000] {processor.py:157} INFO - Started process (PID=88252) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:09.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:03:09.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:09.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:09.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:10.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:10.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:03:10.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:10.031+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:03:10.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T10:03:40.399+0000] {processor.py:157} INFO - Started process (PID=88277) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:40.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:03:40.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:40.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:03:40.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:03:40.447+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:03:40.447+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:03:40.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T10:04:10.815+0000] {processor.py:157} INFO - Started process (PID=88302) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:10.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:04:10.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:10.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:10.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:04:10.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:10.902+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:04:10.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-28T10:04:41.290+0000] {processor.py:157} INFO - Started process (PID=88327) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:41.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:04:41.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:41.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:04:41.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:04:41.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:04:41.337+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:04:41.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T10:05:11.789+0000] {processor.py:157} INFO - Started process (PID=88352) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:11.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:05:11.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:11.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:11.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:05:11.833+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:11.833+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:05:11.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T10:05:42.279+0000] {processor.py:157} INFO - Started process (PID=88377) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:42.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:05:42.283+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:42.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:05:42.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:05:42.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:05:42.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:05:42.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T10:06:12.709+0000] {processor.py:157} INFO - Started process (PID=88402) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:12.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:06:12.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:12.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:12.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:06:12.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:12.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:06:12.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T10:06:43.110+0000] {processor.py:157} INFO - Started process (PID=88427) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:43.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:06:43.114+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:43.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:06:43.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:06:43.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:06:43.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:06:43.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T10:07:13.622+0000] {processor.py:157} INFO - Started process (PID=88452) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:13.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:07:13.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:13.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:13.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:07:13.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:13.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:07:13.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T10:07:44.065+0000] {processor.py:157} INFO - Started process (PID=88477) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:44.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:07:44.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:44.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:07:44.095+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:07:44.108+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:07:44.108+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:07:44.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T10:08:14.519+0000] {processor.py:157} INFO - Started process (PID=88502) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:14.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:08:14.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:14.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:14.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:08:14.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:14.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:08:14.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T10:08:44.930+0000] {processor.py:157} INFO - Started process (PID=88527) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:44.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:08:44.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:44.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:08:44.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:08:44.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:08:44.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:08:44.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.046 seconds
[2024-07-28T10:09:15.289+0000] {processor.py:157} INFO - Started process (PID=88552) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:15.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:09:15.295+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:15.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:15.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:09:15.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:15.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:09:15.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T10:09:45.815+0000] {processor.py:157} INFO - Started process (PID=88577) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:45.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:09:45.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:45.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:09:45.844+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:09:45.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:09:45.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:09:45.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T10:10:16.249+0000] {processor.py:157} INFO - Started process (PID=88602) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:16.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:10:16.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:16.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:16.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:10:16.290+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:16.290+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:10:16.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T10:10:46.722+0000] {processor.py:157} INFO - Started process (PID=88627) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:46.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:10:46.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:46.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:10:46.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:10:46.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:10:46.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:10:46.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T10:11:17.113+0000] {processor.py:157} INFO - Started process (PID=88652) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:17.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:11:17.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:17.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:17.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:11:17.172+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:17.172+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:11:17.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T10:11:47.612+0000] {processor.py:157} INFO - Started process (PID=88677) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:47.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:11:47.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:47.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:11:47.643+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:11:47.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:11:47.653+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:11:47.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T10:12:18.077+0000] {processor.py:157} INFO - Started process (PID=88702) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:18.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:12:18.080+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:18.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:18.104+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:12:18.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:18.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:12:18.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T10:12:48.667+0000] {processor.py:157} INFO - Started process (PID=88727) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:48.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:12:48.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:48.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:12:48.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:12:48.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:12:48.739+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:12:48.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T10:43:42.549+0000] {processor.py:157} INFO - Started process (PID=88752) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:43:42.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T10:43:42.555+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:43:42.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T10:43:42.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T10:43:42.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T10:43:42.602+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T10:43:42.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T11:02:12.727+0000] {processor.py:157} INFO - Started process (PID=88781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:12.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:02:12.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:12.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:12.788+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:02:12.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:12.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:02:12.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T11:02:43.238+0000] {processor.py:157} INFO - Started process (PID=88806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:43.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:02:43.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:43.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:02:43.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:02:43.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:02:43.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:02:43.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T11:03:13.671+0000] {processor.py:157} INFO - Started process (PID=88831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:13.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:03:13.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:13.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:13.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:03:13.720+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:13.720+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:03:13.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T11:03:44.143+0000] {processor.py:157} INFO - Started process (PID=88856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:44.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:03:44.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:44.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:03:44.178+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:03:44.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:03:44.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:03:44.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T11:04:14.569+0000] {processor.py:157} INFO - Started process (PID=88881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:14.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:04:14.572+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:14.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:14.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:04:14.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:14.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:04:14.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:04:45.032+0000] {processor.py:157} INFO - Started process (PID=88906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:45.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:04:45.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:45.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:04:45.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:04:45.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:04:45.077+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:04:45.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T11:05:15.448+0000] {processor.py:157} INFO - Started process (PID=88931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:15.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:05:15.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:15.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:15.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:05:15.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:15.499+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:05:15.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T11:05:45.873+0000] {processor.py:157} INFO - Started process (PID=88956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:45.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:05:45.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:45.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:05:45.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:05:45.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:05:45.926+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:05:45.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T11:06:16.344+0000] {processor.py:157} INFO - Started process (PID=88981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:16.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:06:16.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:16.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:16.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:06:16.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:16.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:06:16.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T11:06:46.733+0000] {processor.py:157} INFO - Started process (PID=89006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:46.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:06:46.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:46.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:06:46.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:06:46.775+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:06:46.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:06:46.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T11:07:17.167+0000] {processor.py:157} INFO - Started process (PID=89031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:17.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:07:17.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:17.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:17.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:07:17.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:17.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:07:17.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T11:07:47.602+0000] {processor.py:157} INFO - Started process (PID=89056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:47.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:07:47.604+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:47.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:07:47.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:07:47.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:07:47.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:07:47.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:08:18.077+0000] {processor.py:157} INFO - Started process (PID=89081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:18.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:08:18.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:18.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:18.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:08:18.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:18.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:08:18.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T11:08:48.480+0000] {processor.py:157} INFO - Started process (PID=89106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:48.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:08:48.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:48.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:08:48.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:08:48.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:08:48.514+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:08:48.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T11:09:18.851+0000] {processor.py:157} INFO - Started process (PID=89131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:18.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:09:18.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:18.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:18.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:09:18.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:18.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:09:18.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T11:09:49.314+0000] {processor.py:157} INFO - Started process (PID=89156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:49.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:09:49.318+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:49.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:09:49.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:09:49.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:09:49.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:09:49.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:10:19.721+0000] {processor.py:157} INFO - Started process (PID=89181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:19.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:10:19.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:19.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:19.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:10:19.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:19.766+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:10:19.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:10:50.185+0000] {processor.py:157} INFO - Started process (PID=89206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:50.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:10:50.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:50.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:10:50.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:10:50.228+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:10:50.228+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:10:50.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:11:20.595+0000] {processor.py:157} INFO - Started process (PID=89231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:20.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:11:20.597+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:20.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:20.622+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:11:20.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:20.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:11:20.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T11:11:50.988+0000] {processor.py:157} INFO - Started process (PID=89256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:50.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:11:50.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:50.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:11:51.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:51.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:11:51.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:11:51.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:11:51.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T11:12:21.494+0000] {processor.py:157} INFO - Started process (PID=89281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:21.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:12:21.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:21.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:21.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:12:21.532+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:21.532+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:12:21.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T11:12:51.898+0000] {processor.py:157} INFO - Started process (PID=89306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:51.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:12:51.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:51.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:12:51.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:12:51.937+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:12:51.937+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:12:51.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T11:13:22.357+0000] {processor.py:157} INFO - Started process (PID=89331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:22.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:13:22.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:22.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:22.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:13:22.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:22.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:13:22.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T11:13:52.766+0000] {processor.py:157} INFO - Started process (PID=89356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:52.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:13:52.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:52.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:13:52.805+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:13:52.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:13:52.817+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:13:52.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T11:14:23.237+0000] {processor.py:157} INFO - Started process (PID=89381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:23.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:14:23.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:23.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:23.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:14:23.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:23.289+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:14:23.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T11:14:53.670+0000] {processor.py:157} INFO - Started process (PID=89406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:53.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:14:53.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:53.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:14:53.702+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:14:53.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:14:53.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:14:53.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T11:15:24.127+0000] {processor.py:157} INFO - Started process (PID=89431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:24.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:15:24.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:24.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:24.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:15:24.177+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:24.177+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:15:24.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T11:15:54.584+0000] {processor.py:157} INFO - Started process (PID=89456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:54.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:15:54.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:54.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:15:54.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:15:54.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:15:54.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:15:54.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T11:16:25.025+0000] {processor.py:157} INFO - Started process (PID=89481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:25.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:16:25.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:25.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:25.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:16:25.065+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:25.065+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:16:25.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T11:16:55.443+0000] {processor.py:157} INFO - Started process (PID=89506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:55.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:16:55.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:55.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:16:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:16:55.495+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:16:55.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:16:55.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T11:17:25.895+0000] {processor.py:157} INFO - Started process (PID=89531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:25.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:17:25.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:25.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:25.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:17:25.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:25.938+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:17:25.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:17:56.332+0000] {processor.py:157} INFO - Started process (PID=89556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:56.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:17:56.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:56.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:17:56.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:17:56.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:17:56.374+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:17:56.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:18:26.814+0000] {processor.py:157} INFO - Started process (PID=89581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:26.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:18:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:26.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:26.844+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:18:26.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:26.857+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:18:26.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T11:18:57.210+0000] {processor.py:157} INFO - Started process (PID=89606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:57.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:18:57.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:57.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:18:57.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:18:57.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:18:57.250+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:18:57.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T11:19:27.698+0000] {processor.py:157} INFO - Started process (PID=89631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:27.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:19:27.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:27.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:27.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:19:27.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:27.744+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:19:27.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:19:58.102+0000] {processor.py:157} INFO - Started process (PID=89656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:58.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:19:58.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:58.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:19:58.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:19:58.138+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:19:58.138+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:19:58.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T11:20:28.530+0000] {processor.py:157} INFO - Started process (PID=89681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:28.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:20:28.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:28.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:28.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:20:28.572+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:28.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:20:28.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:20:59.017+0000] {processor.py:157} INFO - Started process (PID=89706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:59.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:20:59.021+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:59.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:20:59.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:20:59.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:20:59.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:20:59.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:21:29.454+0000] {processor.py:157} INFO - Started process (PID=89731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:29.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:21:29.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:29.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:29.494+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:21:29.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:29.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:21:29.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T11:21:59.909+0000] {processor.py:157} INFO - Started process (PID=89756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:59.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:21:59.912+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:59.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:21:59.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:21:59.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:21:59.948+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:21:59.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T11:22:30.339+0000] {processor.py:157} INFO - Started process (PID=89781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:22:30.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:22:30.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:22:30.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:22:30.369+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:22:30.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:22:30.378+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:22:30.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T11:23:00.716+0000] {processor.py:157} INFO - Started process (PID=89806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:00.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:23:00.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:00.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:00.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:23:00.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:00.763+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:23:00.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:23:31.139+0000] {processor.py:157} INFO - Started process (PID=89831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:31.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:23:31.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:31.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:23:31.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:23:31.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:23:31.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:23:31.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-28T11:24:01.493+0000] {processor.py:157} INFO - Started process (PID=89856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:01.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:24:01.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:01.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:01.523+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:24:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:01.533+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:24:01.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T11:24:31.934+0000] {processor.py:157} INFO - Started process (PID=89881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:31.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:24:31.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:31.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:24:31.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:24:31.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:24:31.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:24:31.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T11:25:02.284+0000] {processor.py:157} INFO - Started process (PID=89906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:02.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:25:02.288+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:02.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:02.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:25:02.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:02.325+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:25:02.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T11:25:32.773+0000] {processor.py:157} INFO - Started process (PID=89931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:32.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:25:32.776+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:32.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:25:32.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:25:32.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:25:32.819+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:25:32.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:26:03.242+0000] {processor.py:157} INFO - Started process (PID=89956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:03.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:26:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:03.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:03.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:26:03.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:03.298+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:26:03.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T11:26:33.720+0000] {processor.py:157} INFO - Started process (PID=89981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:33.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:26:33.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:33.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:26:33.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:26:33.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:26:33.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:26:33.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:27:04.132+0000] {processor.py:157} INFO - Started process (PID=90006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:04.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:27:04.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:04.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:04.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:27:04.173+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:04.173+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:27:04.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T11:27:34.532+0000] {processor.py:157} INFO - Started process (PID=90031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:34.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:27:34.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:34.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:27:34.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:27:34.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:27:34.572+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:27:34.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T11:28:04.999+0000] {processor.py:157} INFO - Started process (PID=90056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:05.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:28:05.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:05.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:05.030+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:28:05.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:05.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:28:05.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T11:28:35.381+0000] {processor.py:157} INFO - Started process (PID=90081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:35.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:28:35.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:35.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:28:35.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:28:35.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:28:35.421+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:28:35.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T11:29:05.809+0000] {processor.py:157} INFO - Started process (PID=90106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:05.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:29:05.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:05.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:29:05.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:05.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:29:05.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T11:29:36.289+0000] {processor.py:157} INFO - Started process (PID=90131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:36.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:29:36.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:36.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:29:36.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:29:36.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:29:36.335+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:29:36.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:30:06.704+0000] {processor.py:157} INFO - Started process (PID=90156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:06.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:30:06.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:06.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:06.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:30:06.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:06.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:30:06.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T11:30:37.159+0000] {processor.py:157} INFO - Started process (PID=90181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:37.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:30:37.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:37.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:30:37.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:30:37.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:30:37.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:30:37.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-28T11:31:07.546+0000] {processor.py:157} INFO - Started process (PID=90206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:07.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:31:07.549+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:07.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:07.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:31:07.607+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:07.607+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:31:07.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T11:31:37.964+0000] {processor.py:157} INFO - Started process (PID=90231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:37.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:31:37.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:37.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:37.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:31:38.018+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:38.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:31:38.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:31:38.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:31:38.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T11:32:08.499+0000] {processor.py:157} INFO - Started process (PID=90256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:08.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:32:08.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:08.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:08.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:32:08.571+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:08.571+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:32:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-28T11:32:39.201+0000] {processor.py:157} INFO - Started process (PID=90281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:39.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:32:39.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:39.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:32:39.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:32:39.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:32:39.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:32:39.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T11:33:09.758+0000] {processor.py:157} INFO - Started process (PID=90306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:09.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:33:09.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:09.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:09.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:33:09.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:09.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:33:09.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-28T11:33:40.249+0000] {processor.py:157} INFO - Started process (PID=90331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:40.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:33:40.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:40.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:33:40.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:33:40.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:33:40.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:33:40.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T11:34:10.795+0000] {processor.py:157} INFO - Started process (PID=90356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:10.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:34:10.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:10.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:10.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:34:10.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:10.871+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:34:10.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T11:34:41.359+0000] {processor.py:157} INFO - Started process (PID=90381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:41.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:34:41.369+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:41.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:34:41.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:34:41.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:34:41.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:34:41.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-28T11:35:11.810+0000] {processor.py:157} INFO - Started process (PID=90406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:11.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:35:11.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:11.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:11.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:35:11.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:11.884+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:35:11.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-28T11:35:42.357+0000] {processor.py:157} INFO - Started process (PID=90431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:42.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:35:42.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:42.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:35:42.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:35:42.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:35:42.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:35:42.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T11:36:12.840+0000] {processor.py:157} INFO - Started process (PID=90456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:12.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:36:12.850+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:12.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:12.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:36:12.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:12.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:36:12.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-28T11:36:43.418+0000] {processor.py:157} INFO - Started process (PID=90481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:43.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:36:43.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:43.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:36:43.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:36:43.492+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:36:43.492+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:36:43.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T11:37:13.763+0000] {processor.py:157} INFO - Started process (PID=90506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:13.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:37:13.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:13.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:13.784+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:37:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:13.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:37:13.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-28T11:37:44.243+0000] {processor.py:157} INFO - Started process (PID=90531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:44.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:37:44.251+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:44.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:37:44.291+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:37:44.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:37:44.303+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:37:44.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T11:38:14.712+0000] {processor.py:157} INFO - Started process (PID=90556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:14.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:38:14.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:14.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:14.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:38:14.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:14.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:38:14.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T11:38:45.163+0000] {processor.py:157} INFO - Started process (PID=90581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:45.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:38:45.166+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:45.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:38:45.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:38:45.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:38:45.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:38:45.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T11:39:15.704+0000] {processor.py:157} INFO - Started process (PID=90606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:15.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:39:15.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:15.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:15.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:39:15.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:15.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:39:15.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T11:39:46.195+0000] {processor.py:157} INFO - Started process (PID=90631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:46.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:39:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:46.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:39:46.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:39:46.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:39:46.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:39:46.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-28T11:40:16.717+0000] {processor.py:157} INFO - Started process (PID=90656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:16.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:40:16.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:16.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:16.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:40:16.830+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:16.830+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:40:16.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-28T11:40:47.374+0000] {processor.py:157} INFO - Started process (PID=90681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:47.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:40:47.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:47.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:40:47.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:40:47.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:40:47.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:40:47.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.115 seconds
[2024-07-28T11:41:18.068+0000] {processor.py:157} INFO - Started process (PID=90706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:18.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:41:18.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:18.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:18.124+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:41:18.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:18.144+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:41:18.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T11:41:48.596+0000] {processor.py:157} INFO - Started process (PID=90731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:48.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:41:48.612+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:48.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:41:48.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:41:48.667+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:41:48.667+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:41:48.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T11:42:19.020+0000] {processor.py:157} INFO - Started process (PID=90756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:19.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:42:19.026+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:19.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:19.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:42:19.070+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:19.070+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:42:19.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T11:42:49.443+0000] {processor.py:157} INFO - Started process (PID=90781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:49.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:42:49.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:49.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:42:49.474+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:42:49.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:42:49.484+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:42:49.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:43:19.843+0000] {processor.py:157} INFO - Started process (PID=90806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:19.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:43:19.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:19.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:19.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:43:19.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:19.885+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:43:19.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T11:43:50.403+0000] {processor.py:157} INFO - Started process (PID=90831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:50.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:43:50.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:50.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:43:50.462+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:43:50.488+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:43:50.488+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:43:50.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T11:44:20.907+0000] {processor.py:157} INFO - Started process (PID=90856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:20.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:44:20.914+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:20.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:20.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:44:20.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:20.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:44:20.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-28T11:44:51.283+0000] {processor.py:157} INFO - Started process (PID=90881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:51.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:44:51.286+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:51.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:44:51.316+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:44:51.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:44:51.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:44:51.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T11:45:21.711+0000] {processor.py:157} INFO - Started process (PID=90906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:21.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:45:21.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:21.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:21.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:45:21.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:21.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:45:21.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:45:52.097+0000] {processor.py:157} INFO - Started process (PID=90931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:52.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:45:52.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:52.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:45:52.131+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:45:52.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:45:52.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:45:52.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:46:22.505+0000] {processor.py:157} INFO - Started process (PID=90956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:22.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:46:22.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:22.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:22.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:46:22.564+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:22.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:46:22.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T11:46:52.961+0000] {processor.py:157} INFO - Started process (PID=90981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:52.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:46:52.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:52.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:52.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:46:52.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:52.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:46:53.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:46:53.011+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:46:53.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T11:47:23.348+0000] {processor.py:157} INFO - Started process (PID=91006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:23.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:47:23.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:23.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:23.374+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:47:23.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:23.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:47:23.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T11:47:53.773+0000] {processor.py:157} INFO - Started process (PID=91031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:53.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:47:53.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:53.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:47:53.806+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:47:53.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:47:53.815+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:47:53.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T11:48:24.191+0000] {processor.py:157} INFO - Started process (PID=91056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:24.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:48:24.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:24.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:24.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:48:24.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:24.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:48:24.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T11:48:54.610+0000] {processor.py:157} INFO - Started process (PID=91081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:54.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:48:54.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:54.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:48:54.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:48:54.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:48:54.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:48:54.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T11:49:25.048+0000] {processor.py:157} INFO - Started process (PID=91106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:25.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:49:25.054+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:25.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:25.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:49:25.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:25.095+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:49:25.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:49:55.479+0000] {processor.py:157} INFO - Started process (PID=91131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:55.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:49:55.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:55.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:49:55.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:49:55.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:49:55.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:49:55.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T11:50:25.911+0000] {processor.py:157} INFO - Started process (PID=91156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:25.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:50:25.913+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:25.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:25.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:50:25.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:25.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:50:25.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:50:56.296+0000] {processor.py:157} INFO - Started process (PID=91181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:56.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:50:56.298+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:56.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:50:56.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:50:56.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:50:56.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:50:56.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T11:51:26.704+0000] {processor.py:157} INFO - Started process (PID=91206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:26.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:51:26.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:26.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:26.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:51:26.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:26.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:51:26.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T11:51:57.180+0000] {processor.py:157} INFO - Started process (PID=91231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:57.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:51:57.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:57.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:51:57.211+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:51:57.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:51:57.221+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:51:57.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T11:52:27.596+0000] {processor.py:157} INFO - Started process (PID=91256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:27.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:52:27.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:27.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:27.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:52:27.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:27.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:52:27.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T11:52:57.997+0000] {processor.py:157} INFO - Started process (PID=91281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:57.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:52:58.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:58.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:52:58.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:52:58.039+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:52:58.039+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:52:58.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T11:53:28.417+0000] {processor.py:157} INFO - Started process (PID=91306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:28.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:53:28.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:28.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:28.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:53:28.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:28.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:53:28.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T11:53:58.775+0000] {processor.py:157} INFO - Started process (PID=91331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:58.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:53:58.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:58.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:53:58.809+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:53:58.821+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:53:58.821+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:53:58.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T11:54:29.227+0000] {processor.py:157} INFO - Started process (PID=91356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:29.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:54:29.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:29.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:29.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:54:29.286+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:29.286+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:54:29.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T11:54:59.679+0000] {processor.py:157} INFO - Started process (PID=91381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:59.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:54:59.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:59.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:54:59.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:54:59.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:54:59.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:54:59.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T11:55:30.204+0000] {processor.py:157} INFO - Started process (PID=91406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:55:30.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:55:30.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:55:30.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:55:30.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:55:30.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:55:30.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:55:30.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T11:56:00.751+0000] {processor.py:157} INFO - Started process (PID=91431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:00.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:56:00.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:00.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:00.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:56:00.851+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:00.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:56:00.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-28T11:56:31.210+0000] {processor.py:157} INFO - Started process (PID=91456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:31.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:56:31.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:31.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:56:31.309+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:56:31.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:56:31.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:56:31.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.144 seconds
[2024-07-28T11:57:01.639+0000] {processor.py:157} INFO - Started process (PID=91481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:01.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:57:01.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:01.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:01.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:57:01.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:01.739+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:57:01.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T11:57:32.085+0000] {processor.py:157} INFO - Started process (PID=91506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:32.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:57:32.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:32.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:57:32.162+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:57:32.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:57:32.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:57:32.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-28T11:58:02.453+0000] {processor.py:157} INFO - Started process (PID=91531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:02.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:58:02.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:02.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:02.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:58:02.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:02.512+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:58:02.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T11:58:32.796+0000] {processor.py:157} INFO - Started process (PID=91556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:32.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:58:32.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:32.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:58:32.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:58:32.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:58:32.856+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:58:32.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T11:59:03.274+0000] {processor.py:157} INFO - Started process (PID=91581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:03.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:59:03.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:03.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:03.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:59:03.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:03.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:59:03.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-28T11:59:33.668+0000] {processor.py:157} INFO - Started process (PID=91606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:33.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T11:59:33.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:33.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T11:59:33.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T11:59:33.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T11:59:33.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T11:59:33.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.151 seconds
[2024-07-28T12:00:04.101+0000] {processor.py:157} INFO - Started process (PID=91631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:04.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:00:04.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:04.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:04.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:00:04.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:04.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:00:04.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T12:00:34.580+0000] {processor.py:157} INFO - Started process (PID=91656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:34.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:00:34.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:34.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:00:34.645+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:00:34.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:00:34.662+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:00:34.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-28T12:01:04.957+0000] {processor.py:157} INFO - Started process (PID=91681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:04.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:01:04.977+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:04.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:04.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:05.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:05.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:01:05.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:05.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:01:05.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T12:01:35.383+0000] {processor.py:157} INFO - Started process (PID=91706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:35.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:01:35.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:35.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:01:35.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:01:35.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:01:35.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:01:35.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-28T12:02:05.771+0000] {processor.py:157} INFO - Started process (PID=91731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:05.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:02:05.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:05.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:05.929+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:02:05.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:05.946+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:02:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.196 seconds
[2024-07-28T12:02:36.233+0000] {processor.py:157} INFO - Started process (PID=91756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:36.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:02:36.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:36.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:02:36.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:02:36.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:02:36.322+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:02:36.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-28T12:03:06.622+0000] {processor.py:157} INFO - Started process (PID=91781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:06.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:03:06.630+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:06.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:06.687+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:03:06.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:06.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:03:06.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T12:03:37.126+0000] {processor.py:157} INFO - Started process (PID=91806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:37.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:03:37.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:37.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:03:37.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:03:37.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:03:37.200+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:03:37.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T12:04:07.581+0000] {processor.py:157} INFO - Started process (PID=91831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:07.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:04:07.590+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:07.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:07.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:04:07.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:07.680+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:04:07.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-28T12:04:37.994+0000] {processor.py:157} INFO - Started process (PID=91856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:37.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:04:38.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:38.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:04:38.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:04:38.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:04:38.090+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:04:38.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-28T12:05:08.402+0000] {processor.py:157} INFO - Started process (PID=91881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:08.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:05:08.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:08.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:08.484+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:05:08.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:08.505+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:05:08.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.125 seconds
[2024-07-28T12:05:38.913+0000] {processor.py:157} INFO - Started process (PID=91906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:38.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:05:38.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:38.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:05:38.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:05:38.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:05:38.987+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:05:39.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T12:06:09.393+0000] {processor.py:157} INFO - Started process (PID=91931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:09.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:06:09.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:09.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:09.445+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:06:09.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:09.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:06:09.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T12:06:39.746+0000] {processor.py:157} INFO - Started process (PID=91956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:39.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:06:39.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:39.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:06:39.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:06:39.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:06:39.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:06:39.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T12:07:10.277+0000] {processor.py:157} INFO - Started process (PID=91981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:10.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:07:10.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:10.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:10.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:07:10.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:10.345+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:07:10.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T12:07:40.770+0000] {processor.py:157} INFO - Started process (PID=92006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:40.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:07:40.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:40.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:07:40.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:07:40.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:07:40.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:07:40.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T12:08:11.136+0000] {processor.py:157} INFO - Started process (PID=92031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:11.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:08:11.173+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:11.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:11.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:08:11.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:11.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:08:11.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-28T12:08:41.556+0000] {processor.py:157} INFO - Started process (PID=92056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:41.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:08:41.564+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:41.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:08:41.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:08:41.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:08:41.663+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:08:41.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.134 seconds
[2024-07-28T12:09:11.914+0000] {processor.py:157} INFO - Started process (PID=92081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:11.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:09:11.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:11.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:11.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:09:11.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:11.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:09:11.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T12:09:42.313+0000] {processor.py:157} INFO - Started process (PID=92106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:42.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:09:42.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:42.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:09:42.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:09:42.401+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:09:42.401+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:09:42.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T12:10:12.805+0000] {processor.py:157} INFO - Started process (PID=92131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:12.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:10:12.810+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:12.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:12.860+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:10:12.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:12.878+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:10:12.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T12:10:43.247+0000] {processor.py:157} INFO - Started process (PID=92156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:43.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:10:43.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:43.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:10:43.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:10:43.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:10:43.317+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:10:43.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T12:11:13.639+0000] {processor.py:157} INFO - Started process (PID=92181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:13.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:11:13.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:13.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:13.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:11:13.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:13.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:11:13.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T12:11:44.021+0000] {processor.py:157} INFO - Started process (PID=92206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:44.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:11:44.031+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:44.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:11:44.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:11:44.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:11:44.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:11:44.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T12:12:14.564+0000] {processor.py:157} INFO - Started process (PID=92231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:14.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:12:14.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:14.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:14.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:12:14.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:14.636+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:12:14.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T12:12:44.973+0000] {processor.py:157} INFO - Started process (PID=92256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:44.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:12:44.978+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:44.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:44.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:12:45.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:45.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:12:45.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:12:45.040+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:12:45.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-28T12:13:15.310+0000] {processor.py:157} INFO - Started process (PID=92281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:15.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:13:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:15.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:15.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:13:15.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:15.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:13:15.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:13:45.691+0000] {processor.py:157} INFO - Started process (PID=92306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:45.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:13:45.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:45.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:13:45.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:13:45.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:13:45.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:13:45.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T12:14:16.094+0000] {processor.py:157} INFO - Started process (PID=92331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:16.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:14:16.103+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:16.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:16.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:14:16.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:16.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:14:16.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-28T12:14:46.447+0000] {processor.py:157} INFO - Started process (PID=92356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:46.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:14:46.454+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:46.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:14:46.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:14:46.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:14:46.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:14:46.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T12:15:16.816+0000] {processor.py:157} INFO - Started process (PID=92381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:16.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:15:16.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:16.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:16.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:15:16.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:16.927+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:15:16.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-28T12:15:47.388+0000] {processor.py:157} INFO - Started process (PID=92406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:47.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:15:47.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:47.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:15:47.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:15:47.530+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:15:47.529+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:15:47.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.203 seconds
[2024-07-28T12:16:17.825+0000] {processor.py:157} INFO - Started process (PID=92431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:17.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:16:17.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:17.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:17.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:16:17.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:17.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:16:17.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.165 seconds
[2024-07-28T12:16:48.187+0000] {processor.py:157} INFO - Started process (PID=92456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:48.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:16:48.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:48.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:16:48.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:16:48.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:16:48.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:16:48.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-28T12:17:18.692+0000] {processor.py:157} INFO - Started process (PID=92481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:18.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:17:18.698+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:18.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:18.745+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:17:18.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:18.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:17:18.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T12:17:49.068+0000] {processor.py:157} INFO - Started process (PID=92506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:49.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:17:49.080+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:49.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:17:49.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:17:49.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:17:49.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:17:49.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-28T12:18:19.441+0000] {processor.py:157} INFO - Started process (PID=92531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:19.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:18:19.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:19.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:19.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:18:19.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:19.538+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:18:19.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-28T12:18:49.828+0000] {processor.py:157} INFO - Started process (PID=92556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:49.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:18:49.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:49.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:18:49.927+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:18:49.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:18:49.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:18:49.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.131 seconds
[2024-07-28T12:19:20.195+0000] {processor.py:157} INFO - Started process (PID=92581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:20.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:19:20.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:20.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:20.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:19:20.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:20.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:19:20.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T12:19:50.680+0000] {processor.py:157} INFO - Started process (PID=92606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:50.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:19:50.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:50.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:19:50.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:19:50.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:19:50.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:19:50.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T12:20:21.115+0000] {processor.py:157} INFO - Started process (PID=92631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:21.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:20:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:21.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:21.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:20:21.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:21.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:20:21.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T12:20:51.427+0000] {processor.py:157} INFO - Started process (PID=92656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:51.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:20:51.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:51.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:20:51.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:20:51.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:20:51.468+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:20:51.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T12:21:21.827+0000] {processor.py:157} INFO - Started process (PID=92681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:21.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:21:21.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:21.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:21.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:21:21.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:21.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:21:21.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.139 seconds
[2024-07-28T12:21:52.215+0000] {processor.py:157} INFO - Started process (PID=92706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:52.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:21:52.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:52.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:21:52.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:21:52.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:21:52.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:21:52.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T12:22:22.688+0000] {processor.py:157} INFO - Started process (PID=92731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:22.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:22:22.705+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:22.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:22.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:22:22.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:22.808+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:22:22.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.143 seconds
[2024-07-28T12:22:53.114+0000] {processor.py:157} INFO - Started process (PID=92756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:53.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:22:53.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:53.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:22:53.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:22:53.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:22:53.220+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:22:53.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T12:23:23.681+0000] {processor.py:157} INFO - Started process (PID=92781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:23.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:23:23.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:23.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:23.813+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:23:23.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:23.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:23:23.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.202 seconds
[2024-07-28T12:23:54.063+0000] {processor.py:157} INFO - Started process (PID=92806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:54.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:23:54.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:54.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:23:54.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:23:54.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:23:54.151+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:23:54.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T12:24:24.656+0000] {processor.py:157} INFO - Started process (PID=92831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:24.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:24:24.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:24.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:24.711+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:24:24.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:24.733+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:24:24.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T12:24:55.291+0000] {processor.py:157} INFO - Started process (PID=92856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:55.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:24:55.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:55.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:24:55.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:24:55.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:24:55.386+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:24:55.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-28T12:25:25.727+0000] {processor.py:157} INFO - Started process (PID=92881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:25.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:25:25.735+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:25.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:25.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:25:25.805+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:25.805+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:25:25.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-28T12:25:56.078+0000] {processor.py:157} INFO - Started process (PID=92906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:56.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:25:56.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:56.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:25:56.128+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:25:56.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:25:56.143+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:25:56.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T12:26:26.540+0000] {processor.py:157} INFO - Started process (PID=92931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:26.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:26:26.554+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:26.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:26.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:26:26.635+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:26.635+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:26:26.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-28T12:26:57.054+0000] {processor.py:157} INFO - Started process (PID=92956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:57.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:26:57.059+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:57.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:26:57.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:26:57.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:26:57.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:26:57.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:27:27.553+0000] {processor.py:157} INFO - Started process (PID=92981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:27.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:27:27.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:27.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:27.598+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:27:27.611+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:27.611+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:27:27.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T12:27:57.995+0000] {processor.py:157} INFO - Started process (PID=93006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:57.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:27:58.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:58.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:27:58.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:27:58.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:27:58.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:27:58.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:28:28.474+0000] {processor.py:157} INFO - Started process (PID=93031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:28.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:28:28.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:28.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:28.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:28:28.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:28.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:28:28.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-28T12:28:58.963+0000] {processor.py:157} INFO - Started process (PID=93056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:58.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:28:58.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:58.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:58.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:28:59.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:59.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:28:59.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:28:59.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:28:59.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T12:29:29.340+0000] {processor.py:157} INFO - Started process (PID=93081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:29.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:29:29.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:29.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:29.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:29:29.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:29.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:29:29.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T12:29:59.670+0000] {processor.py:157} INFO - Started process (PID=93106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:59.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:29:59.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:59.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:29:59.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:29:59.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:29:59.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:29:59.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T12:30:30.101+0000] {processor.py:157} INFO - Started process (PID=93131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:30:30.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:30:30.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:30:30.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:30:30.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:30:30.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:30:30.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:30:30.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-28T12:31:00.507+0000] {processor.py:157} INFO - Started process (PID=93156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:00.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:31:00.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:00.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:00.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:31:00.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:00.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:31:00.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T12:31:30.936+0000] {processor.py:157} INFO - Started process (PID=93181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:30.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:31:30.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:30.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:31:30.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:31:30.994+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:31:30.994+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:31:31.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T12:32:01.326+0000] {processor.py:157} INFO - Started process (PID=93206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:01.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:32:01.333+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:01.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:01.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:32:01.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:01.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:32:01.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T12:32:31.846+0000] {processor.py:157} INFO - Started process (PID=93231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:31.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:32:31.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:31.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:32:31.892+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:32:31.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:32:31.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:32:31.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T12:33:02.230+0000] {processor.py:157} INFO - Started process (PID=93256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:02.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:33:02.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:02.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:02.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:33:02.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:02.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:33:02.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T12:33:32.653+0000] {processor.py:157} INFO - Started process (PID=93281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:32.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:33:32.658+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:32.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:33:32.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:33:32.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:33:32.710+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:33:32.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T12:34:03.068+0000] {processor.py:157} INFO - Started process (PID=93306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:03.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:34:03.072+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:03.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:03.112+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:34:03.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:03.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:34:03.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T12:34:33.594+0000] {processor.py:157} INFO - Started process (PID=93331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:33.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:34:33.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:33.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:34:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:34:33.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:34:33.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:34:33.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.161 seconds
[2024-07-28T12:35:04.079+0000] {processor.py:157} INFO - Started process (PID=93356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:04.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:35:04.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:04.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:04.146+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:35:04.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:04.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:35:04.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T12:35:34.633+0000] {processor.py:157} INFO - Started process (PID=93381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:34.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:35:34.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:34.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:35:34.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:35:34.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:35:34.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:35:34.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.184 seconds
[2024-07-28T12:36:04.950+0000] {processor.py:157} INFO - Started process (PID=93406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:04.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:36:04.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:04.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:04.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:05.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:05.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:36:05.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:05.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:36:05.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-28T12:36:35.322+0000] {processor.py:157} INFO - Started process (PID=93431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:35.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:36:35.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:35.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:36:35.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:36:35.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:36:35.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:36:35.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T12:37:05.812+0000] {processor.py:157} INFO - Started process (PID=93456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:05.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:37:05.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:05.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:05.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:37:05.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:05.889+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:37:05.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T12:37:36.181+0000] {processor.py:157} INFO - Started process (PID=93481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:36.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:37:36.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:36.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:37:36.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:37:36.276+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:37:36.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:37:36.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-28T12:38:06.665+0000] {processor.py:157} INFO - Started process (PID=93506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:06.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:38:06.671+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:06.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:06.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:38:06.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:06.728+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:38:06.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:38:36.984+0000] {processor.py:157} INFO - Started process (PID=93531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:36.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:38:36.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:36.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:38:37.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:37.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:38:37.054+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:38:37.054+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:38:37.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T12:39:07.383+0000] {processor.py:157} INFO - Started process (PID=93556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:07.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:39:07.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:07.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:07.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:39:07.498+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:07.498+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:39:07.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.149 seconds
[2024-07-28T12:39:37.940+0000] {processor.py:157} INFO - Started process (PID=93581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:37.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:39:37.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:37.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:37.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:39:37.986+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:37.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:39:37.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:39:37.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:39:38.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T12:40:08.315+0000] {processor.py:157} INFO - Started process (PID=93606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:08.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:40:08.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:08.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:08.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:40:08.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:08.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:40:08.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-28T12:40:38.709+0000] {processor.py:157} INFO - Started process (PID=93631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:38.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:40:38.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:38.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:40:38.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:40:38.788+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:40:38.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:40:38.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-28T12:41:09.184+0000] {processor.py:157} INFO - Started process (PID=93656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:09.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:41:09.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:09.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:09.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:41:09.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:09.281+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:41:09.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.142 seconds
[2024-07-28T12:41:39.764+0000] {processor.py:157} INFO - Started process (PID=93681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:39.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:41:39.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:39.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:41:39.874+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:41:39.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:41:39.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:41:39.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.181 seconds
[2024-07-28T12:42:10.110+0000] {processor.py:157} INFO - Started process (PID=93706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:10.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:42:10.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:10.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:10.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:42:10.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:10.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:42:10.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T12:42:40.477+0000] {processor.py:157} INFO - Started process (PID=93731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:40.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:42:40.483+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:40.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:42:40.523+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:42:40.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:42:40.536+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:42:40.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T12:43:10.843+0000] {processor.py:157} INFO - Started process (PID=93756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:10.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:43:10.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:10.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:10.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:43:10.922+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:10.922+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:43:10.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-28T12:43:41.323+0000] {processor.py:157} INFO - Started process (PID=93781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:41.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:43:41.330+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:41.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:43:41.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:43:41.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:43:41.392+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:43:41.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T12:44:11.697+0000] {processor.py:157} INFO - Started process (PID=93806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:11.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:44:11.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:11.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:11.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:44:11.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:11.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:44:11.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T12:44:42.213+0000] {processor.py:157} INFO - Started process (PID=93831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:42.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:44:42.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:42.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:44:42.266+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:44:42.280+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:44:42.280+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:44:42.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T12:45:12.665+0000] {processor.py:157} INFO - Started process (PID=93856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:12.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:45:12.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:12.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:12.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:45:12.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:12.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:45:12.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T12:45:43.164+0000] {processor.py:157} INFO - Started process (PID=93881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:43.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:45:43.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:43.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:45:43.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:45:43.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:45:43.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:45:43.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T12:46:13.501+0000] {processor.py:157} INFO - Started process (PID=93906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:13.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:46:13.503+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:13.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:13.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:46:13.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:13.544+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:46:13.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T12:46:43.878+0000] {processor.py:157} INFO - Started process (PID=93931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:43.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:46:43.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:43.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:46:43.978+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:46:43.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:46:43.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:46:44.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T12:47:14.194+0000] {processor.py:157} INFO - Started process (PID=93956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:14.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:47:14.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:14.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:14.236+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:47:14.249+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:14.249+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:47:14.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:47:44.656+0000] {processor.py:157} INFO - Started process (PID=93981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:44.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:47:44.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:44.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:47:44.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:47:44.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:47:44.701+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:47:44.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T12:48:15.035+0000] {processor.py:157} INFO - Started process (PID=94006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:15.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:48:15.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:15.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:15.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:48:15.088+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:15.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:48:15.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T12:48:45.430+0000] {processor.py:157} INFO - Started process (PID=94031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:45.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:48:45.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:45.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:48:45.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:48:45.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:48:45.525+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:48:45.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-28T12:49:15.850+0000] {processor.py:157} INFO - Started process (PID=94056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:15.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:49:15.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:15.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:15.917+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:49:15.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:15.932+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:49:15.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-28T12:49:46.203+0000] {processor.py:157} INFO - Started process (PID=94081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:46.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:49:46.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:46.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:49:46.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:49:46.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:49:46.259+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:49:46.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T12:50:16.589+0000] {processor.py:157} INFO - Started process (PID=94106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:16.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:50:16.591+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:16.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:16.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:50:16.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:16.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:50:16.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T12:50:46.979+0000] {processor.py:157} INFO - Started process (PID=94131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:46.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:50:46.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:46.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:46.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:50:47.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:47.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:50:47.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:50:47.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:50:47.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T12:51:17.278+0000] {processor.py:157} INFO - Started process (PID=94156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:17.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:51:17.281+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:17.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:17.313+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:51:17.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:17.323+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:51:17.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T12:51:47.702+0000] {processor.py:157} INFO - Started process (PID=94181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:47.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:51:47.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:47.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:51:47.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:51:47.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:51:47.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:51:47.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T12:52:18.310+0000] {processor.py:157} INFO - Started process (PID=94206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:18.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:52:18.332+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:18.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:18.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:52:18.400+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:18.400+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:52:18.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T12:52:49.045+0000] {processor.py:157} INFO - Started process (PID=94231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:49.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:52:49.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:49.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:52:49.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:52:49.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:52:49.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:52:49.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T12:53:19.423+0000] {processor.py:157} INFO - Started process (PID=94256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:19.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:53:19.435+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:19.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:19.504+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:53:19.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:19.520+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:53:19.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-28T12:53:49.824+0000] {processor.py:157} INFO - Started process (PID=94281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:49.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:53:49.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:49.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:53:49.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:53:49.887+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:53:49.887+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:53:49.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T12:54:20.175+0000] {processor.py:157} INFO - Started process (PID=94306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:20.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:54:20.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:20.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:20.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:54:20.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:20.232+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:54:20.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T12:54:50.615+0000] {processor.py:157} INFO - Started process (PID=94331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:50.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:54:50.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:50.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:54:50.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:54:50.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:54:50.655+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:54:50.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T12:55:20.959+0000] {processor.py:157} INFO - Started process (PID=94356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:20.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:55:20.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:20.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:20.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:21.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:21.002+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:55:21.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:21.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:55:21.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T12:55:51.390+0000] {processor.py:157} INFO - Started process (PID=94381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:51.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:55:51.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:51.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:55:51.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:55:51.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:55:51.434+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:55:51.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T12:56:21.784+0000] {processor.py:157} INFO - Started process (PID=94406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:21.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:56:21.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:21.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:21.817+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:56:21.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:21.827+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:56:21.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T12:56:52.219+0000] {processor.py:157} INFO - Started process (PID=94431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:52.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:56:52.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:52.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:56:52.251+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:56:52.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:56:52.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:56:52.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T12:57:22.614+0000] {processor.py:157} INFO - Started process (PID=94456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:22.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:57:22.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:22.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:22.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:57:22.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:22.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:57:22.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T12:57:53.003+0000] {processor.py:157} INFO - Started process (PID=94481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:53.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:57:53.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:53.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:57:53.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:57:53.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:57:53.045+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:57:53.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T12:58:23.375+0000] {processor.py:157} INFO - Started process (PID=94506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:23.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:58:23.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:23.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:23.408+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:58:23.418+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:23.418+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:58:23.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T12:58:53.796+0000] {processor.py:157} INFO - Started process (PID=94531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:53.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:58:53.798+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:53.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:58:53.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:58:53.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:58:53.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:58:53.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T12:59:24.184+0000] {processor.py:157} INFO - Started process (PID=94556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:24.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:59:24.187+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:24.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:24.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:59:24.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:24.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:59:24.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T12:59:54.584+0000] {processor.py:157} INFO - Started process (PID=94581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:54.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T12:59:54.587+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:54.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T12:59:54.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T12:59:54.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T12:59:54.627+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T12:59:54.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:00:25.007+0000] {processor.py:157} INFO - Started process (PID=94606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:25.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:00:25.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:25.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:25.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:00:25.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:25.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:00:25.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T13:00:55.516+0000] {processor.py:157} INFO - Started process (PID=94631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:55.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:00:55.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:55.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:00:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:00:55.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:00:55.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:00:55.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T13:01:25.896+0000] {processor.py:157} INFO - Started process (PID=94656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:25.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:01:25.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:25.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:25.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:01:25.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:25.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:01:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T13:01:56.370+0000] {processor.py:157} INFO - Started process (PID=94681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:56.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:01:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:56.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:01:56.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:01:56.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:01:56.416+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:01:56.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T13:02:26.798+0000] {processor.py:157} INFO - Started process (PID=94706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:26.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:02:26.802+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:26.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:26.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:02:26.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:26.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:02:26.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T13:02:57.227+0000] {processor.py:157} INFO - Started process (PID=94731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:57.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:02:57.231+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:57.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:02:57.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:02:57.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:02:57.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:02:57.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:03:27.660+0000] {processor.py:157} INFO - Started process (PID=94756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:27.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:03:27.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:27.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:27.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:03:27.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:27.708+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:03:27.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:03:58.046+0000] {processor.py:157} INFO - Started process (PID=94781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:58.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:03:58.051+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:58.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:03:58.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:03:58.093+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:03:58.093+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:03:58.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:04:28.494+0000] {processor.py:157} INFO - Started process (PID=94806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:28.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:04:28.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:28.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:28.527+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:04:28.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:28.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:04:28.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:04:58.877+0000] {processor.py:157} INFO - Started process (PID=94831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:58.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:04:58.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:58.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:04:58.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:04:58.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:04:58.911+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:04:58.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T13:05:29.330+0000] {processor.py:157} INFO - Started process (PID=94856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:29.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:05:29.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:29.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:29.363+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:05:29.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:29.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:05:29.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:05:59.804+0000] {processor.py:157} INFO - Started process (PID=94881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:59.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:05:59.809+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:59.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:05:59.845+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:05:59.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:05:59.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:05:59.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T13:06:30.150+0000] {processor.py:157} INFO - Started process (PID=94906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:06:30.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:06:30.155+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:06:30.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:06:30.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:06:30.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:06:30.196+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:06:30.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T13:07:00.561+0000] {processor.py:157} INFO - Started process (PID=94931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:00.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:07:00.564+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:00.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:00.595+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:07:00.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:00.606+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:07:00.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:07:30.968+0000] {processor.py:157} INFO - Started process (PID=94956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:30.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:07:30.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:30.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:30.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:07:30.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:30.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:07:31.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:07:31.006+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:07:31.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T13:08:01.372+0000] {processor.py:157} INFO - Started process (PID=94981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:01.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:08:01.376+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:01.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:01.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:08:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:01.414+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:08:01.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:08:31.743+0000] {processor.py:157} INFO - Started process (PID=95006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:31.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:08:31.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:31.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:08:31.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:08:31.782+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:08:31.782+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:08:31.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:09:02.133+0000] {processor.py:157} INFO - Started process (PID=95031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:02.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:09:02.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:02.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:02.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:09:02.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:02.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:09:02.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-28T13:09:32.533+0000] {processor.py:157} INFO - Started process (PID=95056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:32.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:09:32.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:32.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:09:32.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:09:32.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:09:32.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:09:32.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T13:10:02.956+0000] {processor.py:157} INFO - Started process (PID=95081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:02.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:10:02.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:02.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:02.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:02.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:02.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:10:03.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:02.999+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:10:03.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T13:10:33.360+0000] {processor.py:157} INFO - Started process (PID=95106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:33.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:10:33.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:33.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:10:33.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:10:33.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:10:33.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:10:33.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T13:11:03.771+0000] {processor.py:157} INFO - Started process (PID=95131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:03.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:11:03.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:03.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:03.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:11:03.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:03.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:11:03.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T13:11:34.108+0000] {processor.py:157} INFO - Started process (PID=95156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:34.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:11:34.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:34.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:11:34.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:11:34.159+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:11:34.159+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:11:34.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:12:04.518+0000] {processor.py:157} INFO - Started process (PID=95181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:04.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:12:04.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:04.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:04.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:12:04.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:04.561+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:12:04.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:12:34.980+0000] {processor.py:157} INFO - Started process (PID=95206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:34.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:12:34.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:34.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:34.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:12:35.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:35.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:12:35.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:12:35.022+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:12:35.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:13:05.354+0000] {processor.py:157} INFO - Started process (PID=95231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:05.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:13:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:05.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:05.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:13:05.391+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:05.391+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:13:05.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T13:13:35.755+0000] {processor.py:157} INFO - Started process (PID=95256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:35.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:13:35.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:35.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:13:35.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:13:35.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:13:35.794+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:13:35.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:14:06.221+0000] {processor.py:157} INFO - Started process (PID=95281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:06.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:14:06.225+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:06.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:06.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:14:06.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:06.275+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:14:06.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T13:14:36.669+0000] {processor.py:157} INFO - Started process (PID=95306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:36.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:14:36.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:36.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:14:36.702+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:14:36.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:14:36.713+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:14:36.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:15:07.130+0000] {processor.py:157} INFO - Started process (PID=95331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:07.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:15:07.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:07.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:07.161+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:15:07.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:07.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:15:07.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:15:37.472+0000] {processor.py:157} INFO - Started process (PID=95356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:37.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:15:37.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:37.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:15:37.505+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:15:37.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:15:37.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:15:37.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:16:07.930+0000] {processor.py:157} INFO - Started process (PID=95381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:07.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:16:07.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:07.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:07.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:16:07.976+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:07.976+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:16:07.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T13:16:38.331+0000] {processor.py:157} INFO - Started process (PID=95406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:38.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:16:38.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:38.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:16:38.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:16:38.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:16:38.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:16:38.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:17:08.698+0000] {processor.py:157} INFO - Started process (PID=95431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:08.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:17:08.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:08.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:08.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:17:08.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:08.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:17:08.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T13:17:39.174+0000] {processor.py:157} INFO - Started process (PID=95456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:39.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:17:39.179+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:39.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:17:39.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:17:39.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:17:39.217+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:17:39.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:18:09.530+0000] {processor.py:157} INFO - Started process (PID=95481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:09.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:18:09.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:09.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:09.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:18:09.570+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:09.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:18:09.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T13:18:39.956+0000] {processor.py:157} INFO - Started process (PID=95506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:39.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:18:39.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:39.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:39.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:18:39.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:39.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:18:40.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:18:40.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:18:40.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:19:10.351+0000] {processor.py:157} INFO - Started process (PID=95531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:10.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:19:10.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:10.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:10.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:19:10.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:10.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:19:10.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T13:19:40.723+0000] {processor.py:157} INFO - Started process (PID=95556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:40.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:19:40.730+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:40.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:19:40.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:19:40.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:19:40.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:19:40.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T13:20:11.170+0000] {processor.py:157} INFO - Started process (PID=95581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:11.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:20:11.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:11.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:11.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:20:11.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:11.210+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:20:11.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:20:41.529+0000] {processor.py:157} INFO - Started process (PID=95606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:41.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:20:41.532+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:41.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:20:41.552+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:20:41.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:20:41.562+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:20:41.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T13:21:11.952+0000] {processor.py:157} INFO - Started process (PID=95631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:11.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:21:11.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:11.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:11.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:21:11.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:11.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:21:12.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:21:42.378+0000] {processor.py:157} INFO - Started process (PID=95656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:42.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:21:42.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:42.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:21:42.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:21:42.417+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:21:42.417+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:21:42.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T13:22:12.720+0000] {processor.py:157} INFO - Started process (PID=95681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:12.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:22:12.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:12.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:12.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:22:12.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:12.761+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:22:12.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:22:43.189+0000] {processor.py:157} INFO - Started process (PID=95706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:43.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:22:43.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:43.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:22:43.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:22:43.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:22:43.235+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:22:43.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T13:23:13.648+0000] {processor.py:157} INFO - Started process (PID=95731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:13.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:23:13.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:13.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:13.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:23:13.698+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:13.698+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:23:13.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T13:23:44.042+0000] {processor.py:157} INFO - Started process (PID=95756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:44.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:23:44.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:44.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:23:44.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:23:44.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:23:44.090+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:23:44.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:24:14.489+0000] {processor.py:157} INFO - Started process (PID=95781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:14.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:24:14.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:14.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:14.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:24:14.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:14.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:24:14.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:24:44.873+0000] {processor.py:157} INFO - Started process (PID=95806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:44.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:24:44.875+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:44.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:24:44.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:24:44.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:24:44.908+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:24:44.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T13:25:15.315+0000] {processor.py:157} INFO - Started process (PID=95831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:15.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:25:15.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:15.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:15.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:25:15.356+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:15.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:25:15.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:25:45.722+0000] {processor.py:157} INFO - Started process (PID=95856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:45.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:25:45.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:45.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:25:45.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:25:45.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:25:45.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:25:45.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T13:26:16.144+0000] {processor.py:157} INFO - Started process (PID=95881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:16.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:26:16.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:16.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:16.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:26:16.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:16.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:26:16.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:26:46.560+0000] {processor.py:157} INFO - Started process (PID=95906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:46.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:26:46.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:46.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:26:46.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:26:46.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:26:46.649+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:26:46.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T13:27:16.881+0000] {processor.py:157} INFO - Started process (PID=95931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:16.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:27:16.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:16.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:16.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:27:16.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:16.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:27:16.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T13:27:47.231+0000] {processor.py:157} INFO - Started process (PID=95956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:47.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:27:47.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:47.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:27:47.264+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:27:47.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:27:47.278+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:27:47.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T13:28:17.659+0000] {processor.py:157} INFO - Started process (PID=95981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:17.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:28:17.663+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:17.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:17.690+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:28:17.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:17.700+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:28:17.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:28:48.055+0000] {processor.py:157} INFO - Started process (PID=96006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:48.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:28:48.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:48.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:28:48.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:28:48.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:28:48.106+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:28:48.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T13:29:18.509+0000] {processor.py:157} INFO - Started process (PID=96031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:18.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:29:18.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:18.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:18.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:29:18.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:18.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:29:18.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:29:48.898+0000] {processor.py:157} INFO - Started process (PID=96056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:48.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:29:48.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:48.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:29:48.930+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:29:48.940+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:29:48.940+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:29:48.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:30:19.343+0000] {processor.py:157} INFO - Started process (PID=96081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:19.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:30:19.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:19.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:19.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:30:19.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:19.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:30:19.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:30:49.782+0000] {processor.py:157} INFO - Started process (PID=96106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:49.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:30:49.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:49.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:30:49.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:30:49.826+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:30:49.826+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:30:49.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:31:20.168+0000] {processor.py:157} INFO - Started process (PID=96131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:20.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:31:20.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:20.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:20.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:31:20.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:20.207+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:31:20.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:31:50.602+0000] {processor.py:157} INFO - Started process (PID=96156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:50.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:31:50.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:50.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:31:50.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:31:50.644+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:31:50.644+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:31:50.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:32:20.980+0000] {processor.py:157} INFO - Started process (PID=96181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:20.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:32:20.981+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:20.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:20.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:21.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:21.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:32:21.012+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:21.012+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:32:21.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T13:32:51.321+0000] {processor.py:157} INFO - Started process (PID=96206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:51.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:32:51.326+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:51.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:32:51.363+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:32:51.375+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:32:51.375+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:32:51.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T13:33:21.682+0000] {processor.py:157} INFO - Started process (PID=96231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:21.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:33:21.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:21.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:21.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:33:21.719+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:21.719+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:33:21.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T13:33:52.071+0000] {processor.py:157} INFO - Started process (PID=96256) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:52.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:33:52.073+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:52.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:33:52.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:33:52.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:33:52.110+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:33:52.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T13:34:22.521+0000] {processor.py:157} INFO - Started process (PID=96281) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:22.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:34:22.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:22.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:22.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:34:22.568+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:22.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:34:22.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:34:52.958+0000] {processor.py:157} INFO - Started process (PID=96306) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:52.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:34:52.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:52.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:52.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:34:52.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:52.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:34:53.001+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:34:53.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:34:53.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T13:35:23.338+0000] {processor.py:157} INFO - Started process (PID=96331) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:23.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:35:23.342+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:23.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:23.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:35:23.380+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:23.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:35:23.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T13:35:53.725+0000] {processor.py:157} INFO - Started process (PID=96356) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:53.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:35:53.728+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:53.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:35:53.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:35:53.768+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:35:53.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:35:53.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T13:36:24.123+0000] {processor.py:157} INFO - Started process (PID=96381) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:24.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:36:24.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:24.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:24.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:36:24.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:24.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:36:24.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.043 seconds
[2024-07-28T13:36:54.662+0000] {processor.py:157} INFO - Started process (PID=96406) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:54.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:36:54.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:54.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:36:54.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:36:54.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:36:54.742+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:36:54.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T13:37:25.166+0000] {processor.py:157} INFO - Started process (PID=96431) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:25.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:37:25.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:25.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:25.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:37:25.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:25.234+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:37:25.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T13:37:55.525+0000] {processor.py:157} INFO - Started process (PID=96456) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:55.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:37:55.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:55.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:37:55.601+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:37:55.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:37:55.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:37:55.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-28T13:38:25.957+0000] {processor.py:157} INFO - Started process (PID=96481) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:25.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:38:25.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:25.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:25.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:26.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:26.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:38:26.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:26.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:38:26.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T13:38:56.419+0000] {processor.py:157} INFO - Started process (PID=96506) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:56.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:38:56.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:56.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:38:56.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:38:56.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:38:56.481+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:38:56.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T13:39:26.960+0000] {processor.py:157} INFO - Started process (PID=96531) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:26.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:39:26.975+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:26.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:27.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:27.042+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:27.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:39:27.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:27.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:39:27.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-28T13:39:57.312+0000] {processor.py:157} INFO - Started process (PID=96556) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:57.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:39:57.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:57.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:39:57.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:39:57.382+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:39:57.382+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:39:57.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T13:40:27.712+0000] {processor.py:157} INFO - Started process (PID=96581) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:27.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:40:27.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:27.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:27.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:40:27.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:27.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:40:27.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T13:40:58.142+0000] {processor.py:157} INFO - Started process (PID=96606) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:58.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:40:58.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:58.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:40:58.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:40:58.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:40:58.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:40:58.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:41:28.620+0000] {processor.py:157} INFO - Started process (PID=96631) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:28.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:41:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:28.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:28.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:41:28.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:28.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:41:28.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.141 seconds
[2024-07-28T13:41:59.012+0000] {processor.py:157} INFO - Started process (PID=96656) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:59.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:41:59.017+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:59.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:41:59.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:41:59.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:41:59.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:41:59.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T13:42:29.471+0000] {processor.py:157} INFO - Started process (PID=96681) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:29.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:42:29.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:29.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:29.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:42:29.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:29.553+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:42:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T13:42:59.836+0000] {processor.py:157} INFO - Started process (PID=96706) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:59.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:42:59.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:59.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:42:59.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:42:59.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:42:59.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:42:59.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T13:43:30.331+0000] {processor.py:157} INFO - Started process (PID=96731) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:43:30.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:43:30.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:43:30.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:43:30.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:43:30.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:43:30.442+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:43:30.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-28T13:44:00.759+0000] {processor.py:157} INFO - Started process (PID=96756) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:00.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:44:00.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:00.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:00.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:44:00.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:00.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:44:00.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T13:44:31.267+0000] {processor.py:157} INFO - Started process (PID=96781) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:31.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:44:31.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:31.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:44:31.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:44:31.370+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:44:31.370+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:44:31.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-28T13:45:01.822+0000] {processor.py:157} INFO - Started process (PID=96806) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:01.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:45:01.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:01.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:01.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:45:01.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:01.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:45:01.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T13:45:32.208+0000] {processor.py:157} INFO - Started process (PID=96831) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:32.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:45:32.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:32.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:45:32.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:45:32.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:45:32.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:45:32.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T13:46:02.641+0000] {processor.py:157} INFO - Started process (PID=96856) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:02.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:46:02.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:02.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:02.695+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:46:02.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:02.709+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:46:02.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T13:46:33.019+0000] {processor.py:157} INFO - Started process (PID=96881) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:33.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:46:33.025+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:33.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:46:33.054+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:46:33.065+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:46:33.065+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:46:33.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T13:47:03.383+0000] {processor.py:157} INFO - Started process (PID=96906) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:03.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:47:03.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:03.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:47:03.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:03.425+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:47:03.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T13:47:33.840+0000] {processor.py:157} INFO - Started process (PID=96931) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:33.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:47:33.848+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:33.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:47:33.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:47:33.923+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:47:33.923+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:47:33.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-28T13:48:04.305+0000] {processor.py:157} INFO - Started process (PID=96956) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:04.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:48:04.311+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:04.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:04.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:48:04.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:04.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:48:04.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-28T13:48:34.682+0000] {processor.py:157} INFO - Started process (PID=96981) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:34.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:48:34.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:34.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:48:34.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:48:34.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:48:34.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:48:34.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-28T13:49:05.298+0000] {processor.py:157} INFO - Started process (PID=97006) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:05.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:49:05.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:05.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:05.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:49:05.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:05.357+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:49:05.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T13:49:35.740+0000] {processor.py:157} INFO - Started process (PID=97031) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:35.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:49:35.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:35.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:49:35.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:49:35.806+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:49:35.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:49:35.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-28T13:50:06.215+0000] {processor.py:157} INFO - Started process (PID=97056) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:06.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:50:06.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:06.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:06.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:50:06.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:06.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:50:06.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T13:50:36.615+0000] {processor.py:157} INFO - Started process (PID=97081) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:36.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:50:36.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:36.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:50:36.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:50:36.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:50:36.650+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:50:36.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T13:51:07.043+0000] {processor.py:157} INFO - Started process (PID=97106) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:07.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:51:07.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:07.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:07.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:51:07.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:07.085+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:51:07.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T13:51:37.489+0000] {processor.py:157} INFO - Started process (PID=97131) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:37.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:51:37.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:37.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:51:37.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:51:37.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:51:37.539+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:51:37.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T13:52:07.832+0000] {processor.py:157} INFO - Started process (PID=97156) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:07.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:52:07.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:07.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:07.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:52:07.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:07.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:52:07.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T13:52:38.201+0000] {processor.py:157} INFO - Started process (PID=97181) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:38.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:52:38.204+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:38.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:52:38.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:52:38.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:52:38.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:52:38.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T13:53:08.685+0000] {processor.py:157} INFO - Started process (PID=97206) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:08.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:53:08.693+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:08.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:08.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:53:08.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:08.760+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:53:08.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T13:53:38.902+0000] {processor.py:157} INFO - Started process (PID=97231) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:38.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:53:38.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:38.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:53:38.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:53:38.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:53:38.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:53:38.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T13:55:31.576+0000] {processor.py:157} INFO - Started process (PID=97258) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:55:31.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:55:31.582+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:55:31.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:55:31.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:55:31.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:55:31.624+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:55:31.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T13:56:02.014+0000] {processor.py:157} INFO - Started process (PID=97283) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:56:02.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:56:02.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:56:02.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:56:02.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:56:02.057+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:56:02.057+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:56:02.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T13:57:47.382+0000] {processor.py:157} INFO - Started process (PID=97309) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:57:47.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T13:57:47.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:57:47.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T13:57:47.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T13:57:47.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T13:57:47.419+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T13:57:47.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T14:14:12.707+0000] {processor.py:157} INFO - Started process (PID=97335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:12.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:14:12.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:12.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:12.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:14:12.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:12.792+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:14:12.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T14:14:43.261+0000] {processor.py:157} INFO - Started process (PID=97360) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:43.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:14:43.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:43.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:14:43.342+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:14:43.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:14:43.362+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:14:43.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-28T14:15:13.761+0000] {processor.py:157} INFO - Started process (PID=97385) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:13.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:15:13.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:13.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:13.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:15:13.806+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:13.806+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:15:13.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T14:15:44.220+0000] {processor.py:157} INFO - Started process (PID=97410) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:44.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:15:44.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:44.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:15:44.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:15:44.269+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:15:44.269+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:15:44.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T14:16:14.684+0000] {processor.py:157} INFO - Started process (PID=97435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:14.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:16:14.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:14.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:14.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:16:14.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:14.725+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:16:14.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T14:16:45.161+0000] {processor.py:157} INFO - Started process (PID=97460) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:45.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:16:45.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:45.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:16:45.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:16:45.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:16:45.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:16:45.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T14:32:56.424+0000] {processor.py:157} INFO - Started process (PID=97485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:32:56.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:32:56.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:32:56.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:32:56.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:32:56.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:32:56.495+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:32:56.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T14:37:15.239+0000] {processor.py:157} INFO - Started process (PID=97510) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:15.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:37:15.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:15.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:37:15.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:15.346+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:37:15.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-28T14:37:45.834+0000] {processor.py:157} INFO - Started process (PID=97535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:45.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:37:45.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:45.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:37:45.897+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:37:45.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:37:45.909+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:37:45.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T14:38:16.361+0000] {processor.py:157} INFO - Started process (PID=97560) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:16.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:38:16.366+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:16.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:16.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:38:16.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:16.407+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:38:16.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T14:38:46.758+0000] {processor.py:157} INFO - Started process (PID=97585) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:46.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:38:46.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:46.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:38:46.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:38:46.790+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:38:46.790+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:38:46.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T14:39:17.118+0000] {processor.py:157} INFO - Started process (PID=97610) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:17.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:39:17.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:17.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:17.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:39:17.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:17.165+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:39:17.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T14:39:47.602+0000] {processor.py:157} INFO - Started process (PID=97635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:47.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:39:47.608+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:47.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:39:47.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:39:47.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:39:47.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:39:47.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T14:40:17.960+0000] {processor.py:157} INFO - Started process (PID=97660) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:17.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:40:17.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:17.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:17.987+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:40:17.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:17.995+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:40:18.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T14:40:48.403+0000] {processor.py:157} INFO - Started process (PID=97685) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:48.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:40:48.407+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:48.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:40:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:40:48.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:40:48.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:40:48.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T14:41:18.840+0000] {processor.py:157} INFO - Started process (PID=97710) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:18.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:41:18.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:18.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:18.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:41:18.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:18.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:41:18.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T14:41:49.292+0000] {processor.py:157} INFO - Started process (PID=97735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:49.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:41:49.295+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:49.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:41:49.325+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:41:49.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:41:49.334+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:41:49.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T14:42:19.672+0000] {processor.py:157} INFO - Started process (PID=97760) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:19.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:42:19.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:19.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:19.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:42:19.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:19.718+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:42:19.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T14:42:50.105+0000] {processor.py:157} INFO - Started process (PID=97785) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:50.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:42:50.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:50.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:42:50.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:42:50.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:42:50.150+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:42:50.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T14:43:20.547+0000] {processor.py:157} INFO - Started process (PID=97810) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:20.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:43:20.553+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:20.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:20.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:43:20.590+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:20.590+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:43:20.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T14:43:50.993+0000] {processor.py:157} INFO - Started process (PID=97835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:50.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:43:51.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:50.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:51.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:43:51.050+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:51.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:43:51.065+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:43:51.064+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:43:51.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T14:44:21.484+0000] {processor.py:157} INFO - Started process (PID=97860) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:21.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:44:21.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:21.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:21.520+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:44:21.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:21.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:44:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T14:44:52.019+0000] {processor.py:157} INFO - Started process (PID=97885) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:52.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:44:52.027+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:52.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:44:52.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:44:52.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:44:52.078+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:44:52.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T14:45:22.504+0000] {processor.py:157} INFO - Started process (PID=97910) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:22.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:45:22.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:22.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:22.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:45:22.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:22.547+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:45:22.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T14:45:53.009+0000] {processor.py:157} INFO - Started process (PID=97935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:53.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:45:53.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:53.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:45:53.044+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:45:53.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:45:53.055+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:45:53.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T14:46:23.468+0000] {processor.py:157} INFO - Started process (PID=97960) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:23.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:46:23.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:23.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:23.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:46:23.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:23.509+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:46:23.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T14:46:53.933+0000] {processor.py:157} INFO - Started process (PID=97985) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:53.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:46:53.937+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:53.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:46:53.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:46:53.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:46:53.974+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:46:53.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T14:47:24.297+0000] {processor.py:157} INFO - Started process (PID=98010) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:24.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:47:24.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:24.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:24.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:47:24.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:24.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:47:24.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-28T14:47:54.733+0000] {processor.py:157} INFO - Started process (PID=98035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:54.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:47:54.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:54.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:47:54.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:47:54.776+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:47:54.775+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:47:54.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T14:48:25.215+0000] {processor.py:157} INFO - Started process (PID=98060) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:25.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:48:25.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:25.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:25.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:48:25.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:25.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:48:25.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T14:48:55.756+0000] {processor.py:157} INFO - Started process (PID=98085) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:55.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:48:55.763+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:55.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:48:55.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:48:55.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:48:55.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:48:55.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T14:49:26.230+0000] {processor.py:157} INFO - Started process (PID=98110) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:26.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:49:26.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:26.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:26.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:49:26.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:26.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:49:26.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T14:49:56.645+0000] {processor.py:157} INFO - Started process (PID=98135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:56.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:49:56.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:56.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:49:56.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:49:56.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:49:56.688+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:49:56.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T14:50:27.178+0000] {processor.py:157} INFO - Started process (PID=98160) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:27.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:50:27.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:27.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:27.211+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:50:27.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:27.223+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:50:27.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T14:50:57.634+0000] {processor.py:157} INFO - Started process (PID=98185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:57.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:50:57.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:57.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:50:57.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:50:57.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:50:57.672+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:50:57.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T14:51:28.081+0000] {processor.py:157} INFO - Started process (PID=98210) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:28.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:51:28.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:28.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:28.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:51:28.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:28.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:51:28.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T14:51:58.442+0000] {processor.py:157} INFO - Started process (PID=98235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:58.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:51:58.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:58.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:51:58.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:51:58.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:51:58.497+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:51:58.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T14:52:28.939+0000] {processor.py:157} INFO - Started process (PID=98260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:28.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:52:28.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:28.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:28.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:52:28.981+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:28.981+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:52:28.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T14:52:59.428+0000] {processor.py:157} INFO - Started process (PID=98285) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:59.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:52:59.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:59.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:52:59.461+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:52:59.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:52:59.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:52:59.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T14:53:29.921+0000] {processor.py:157} INFO - Started process (PID=98310) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:53:29.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:53:29.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:53:29.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:53:29.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:53:29.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:53:29.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:53:29.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T14:54:00.356+0000] {processor.py:157} INFO - Started process (PID=98335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:00.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:54:00.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:00.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:00.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:54:00.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:00.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:54:00.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T14:54:30.706+0000] {processor.py:157} INFO - Started process (PID=98360) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:30.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:54:30.710+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:30.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:54:30.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:54:30.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:54:30.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:54:30.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T14:55:01.179+0000] {processor.py:157} INFO - Started process (PID=98385) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:01.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:55:01.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:01.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:01.220+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:55:01.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:01.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:55:01.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T14:55:31.669+0000] {processor.py:157} INFO - Started process (PID=98410) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:31.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:55:31.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:31.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:55:31.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:55:31.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:55:31.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:55:31.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T14:56:02.098+0000] {processor.py:157} INFO - Started process (PID=98435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:02.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:56:02.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:02.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:02.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:56:02.146+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:02.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:56:02.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T14:56:32.547+0000] {processor.py:157} INFO - Started process (PID=98460) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:32.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:56:32.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:32.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:56:32.579+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:56:32.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:56:32.589+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:56:32.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T14:57:02.981+0000] {processor.py:157} INFO - Started process (PID=98485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:02.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:57:02.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:02.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:02.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:03.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:03.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:57:03.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:03.018+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:57:03.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T14:57:33.437+0000] {processor.py:157} INFO - Started process (PID=98510) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:33.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:57:33.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:33.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:57:33.470+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:57:33.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:57:33.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:57:33.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T14:58:03.954+0000] {processor.py:157} INFO - Started process (PID=98535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:03.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:58:03.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:03.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:03.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:03.987+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:03.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:58:03.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:03.996+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:58:04.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T14:58:34.471+0000] {processor.py:157} INFO - Started process (PID=98560) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:34.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:58:34.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:34.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:58:34.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:58:34.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:58:34.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:58:34.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T14:59:04.902+0000] {processor.py:157} INFO - Started process (PID=98585) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:04.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:59:04.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:04.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:04.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:59:04.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:04.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:59:04.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T14:59:35.307+0000] {processor.py:157} INFO - Started process (PID=98610) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:35.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T14:59:35.313+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:35.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T14:59:35.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T14:59:35.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T14:59:35.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T14:59:35.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:00:05.746+0000] {processor.py:157} INFO - Started process (PID=98635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:05.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:00:05.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:05.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:05.776+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:00:05.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:05.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:00:05.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T15:00:36.247+0000] {processor.py:157} INFO - Started process (PID=98660) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:36.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:00:36.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:36.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:00:36.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:00:36.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:00:36.293+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:00:36.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:01:06.738+0000] {processor.py:157} INFO - Started process (PID=98685) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:06.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:01:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:06.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:06.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:01:06.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:06.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:01:06.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T15:01:37.208+0000] {processor.py:157} INFO - Started process (PID=98710) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:37.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:01:37.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:37.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:01:37.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:01:37.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:01:37.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:01:37.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:02:07.649+0000] {processor.py:157} INFO - Started process (PID=98735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:07.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:02:07.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:07.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:07.676+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:02:07.686+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:07.686+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:02:07.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T15:02:38.110+0000] {processor.py:157} INFO - Started process (PID=98760) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:38.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:02:38.113+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:38.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:02:38.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:02:38.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:02:38.156+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:02:38.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T15:03:08.625+0000] {processor.py:157} INFO - Started process (PID=98785) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:08.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:03:08.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:08.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:08.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:03:08.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:08.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:03:08.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:03:39.106+0000] {processor.py:157} INFO - Started process (PID=98810) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:39.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:03:39.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:39.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:03:39.136+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:03:39.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:03:39.148+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:03:39.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T15:04:09.538+0000] {processor.py:157} INFO - Started process (PID=98835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:09.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:04:09.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:09.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:09.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:04:09.576+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:09.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:04:09.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T15:04:40.004+0000] {processor.py:157} INFO - Started process (PID=98860) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:40.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:04:40.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:40.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:04:40.046+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:04:40.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:04:40.058+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:04:40.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T15:05:10.484+0000] {processor.py:157} INFO - Started process (PID=98885) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:10.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:05:10.489+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:10.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:10.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:05:10.524+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:10.524+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:05:10.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T15:05:40.922+0000] {processor.py:157} INFO - Started process (PID=98910) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:40.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:05:40.928+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:40.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:05:40.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:05:40.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:05:40.965+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:05:40.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:06:11.338+0000] {processor.py:157} INFO - Started process (PID=98935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:11.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:06:11.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:11.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:11.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:06:11.403+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:11.402+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:06:11.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T15:06:41.862+0000] {processor.py:157} INFO - Started process (PID=98960) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:41.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:06:41.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:41.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:06:41.918+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:06:41.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:06:41.931+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:06:41.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T15:07:12.346+0000] {processor.py:157} INFO - Started process (PID=98985) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:12.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:07:12.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:12.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:12.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:07:12.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:12.394+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:07:12.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T15:07:42.848+0000] {processor.py:157} INFO - Started process (PID=99010) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:42.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:07:42.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:42.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:07:42.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:07:42.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:07:42.906+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:07:42.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T15:08:13.355+0000] {processor.py:157} INFO - Started process (PID=99035) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:13.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:08:13.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:13.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:13.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:08:13.390+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:13.389+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:08:13.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T15:08:43.829+0000] {processor.py:157} INFO - Started process (PID=99060) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:43.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:08:43.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:43.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:08:43.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:08:43.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:08:43.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:08:43.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T15:09:14.250+0000] {processor.py:157} INFO - Started process (PID=99085) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:14.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:09:14.253+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:14.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:14.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:09:14.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:14.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:09:14.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:09:44.750+0000] {processor.py:157} INFO - Started process (PID=99110) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:44.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:09:44.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:44.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:09:44.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:09:44.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:09:44.804+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:09:44.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T15:10:15.220+0000] {processor.py:157} INFO - Started process (PID=99135) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:15.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:10:15.228+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:15.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:15.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:10:15.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:15.274+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:10:15.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T15:10:45.656+0000] {processor.py:157} INFO - Started process (PID=99160) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:45.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:10:45.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:45.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:10:45.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:10:45.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:10:45.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:10:45.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:11:16.081+0000] {processor.py:157} INFO - Started process (PID=99185) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:16.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:11:16.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:16.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:16.127+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:11:16.139+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:16.139+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:11:16.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T15:11:46.497+0000] {processor.py:157} INFO - Started process (PID=99210) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:46.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:11:46.500+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:46.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:11:46.529+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:11:46.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:11:46.540+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:11:46.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:12:16.984+0000] {processor.py:157} INFO - Started process (PID=99235) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:16.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:12:16.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:16.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:17.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:17.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:17.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:12:17.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:17.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:12:17.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T15:12:47.455+0000] {processor.py:157} INFO - Started process (PID=99260) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:47.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:12:47.460+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:47.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:12:47.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:12:47.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:12:47.502+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:12:47.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:13:17.897+0000] {processor.py:157} INFO - Started process (PID=99285) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:17.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:13:17.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:17.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:17.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:13:17.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:17.945+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:13:17.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T15:13:48.310+0000] {processor.py:157} INFO - Started process (PID=99310) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:48.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:13:48.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:48.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:13:48.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:13:48.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:13:48.355+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:13:48.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T15:14:18.788+0000] {processor.py:157} INFO - Started process (PID=99335) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:18.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:14:18.794+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:18.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:18.834+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:14:18.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:18.847+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:14:18.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T15:14:49.330+0000] {processor.py:157} INFO - Started process (PID=99360) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:49.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:14:49.334+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:49.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:14:49.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:14:49.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:14:49.372+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:14:49.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T15:15:19.689+0000] {processor.py:157} INFO - Started process (PID=99385) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:19.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:15:19.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:19.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:19.713+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:15:19.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:19.722+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:15:19.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T15:15:50.161+0000] {processor.py:157} INFO - Started process (PID=99410) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:50.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:15:50.165+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:50.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:15:50.194+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:15:50.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:15:50.203+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:15:50.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T15:16:20.562+0000] {processor.py:157} INFO - Started process (PID=99435) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:20.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:16:20.568+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:20.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:20.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:16:20.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:20.615+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:16:20.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T15:16:51.067+0000] {processor.py:157} INFO - Started process (PID=99460) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:51.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:16:51.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:51.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:16:51.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:16:51.107+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:16:51.107+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:16:51.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:17:21.480+0000] {processor.py:157} INFO - Started process (PID=99485) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:21.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:17:21.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:21.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:21.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:17:21.522+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:21.522+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:17:21.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T15:17:51.986+0000] {processor.py:157} INFO - Started process (PID=99510) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:51.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:17:51.990+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:51.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:52.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:17:52.020+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:52.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:17:52.030+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:17:52.029+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:17:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:18:22.429+0000] {processor.py:157} INFO - Started process (PID=99535) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:22.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:18:22.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:22.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:22.458+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:18:22.469+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:22.469+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:18:22.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T15:18:52.835+0000] {processor.py:157} INFO - Started process (PID=99560) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:52.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:18:52.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:52.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:18:52.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:18:52.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:18:52.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:18:52.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T15:19:23.316+0000] {processor.py:157} INFO - Started process (PID=99585) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:23.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:19:23.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:23.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:23.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:19:23.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:23.361+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:19:23.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:19:53.769+0000] {processor.py:157} INFO - Started process (PID=99610) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:53.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:19:53.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:53.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:19:53.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:19:53.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:19:53.812+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:19:53.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:20:24.261+0000] {processor.py:157} INFO - Started process (PID=99635) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:24.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:20:24.265+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:24.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:24.296+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:20:24.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:24.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:20:24.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T15:20:54.762+0000] {processor.py:157} INFO - Started process (PID=99660) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:54.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:20:54.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:54.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:20:54.803+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:20:54.818+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:20:54.818+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:20:54.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T15:21:25.243+0000] {processor.py:157} INFO - Started process (PID=99685) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:25.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:21:25.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:25.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:25.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:21:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:25.287+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:21:25.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:21:55.723+0000] {processor.py:157} INFO - Started process (PID=99710) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:55.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:21:55.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:55.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:21:55.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:21:55.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:21:55.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:21:55.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:22:26.198+0000] {processor.py:157} INFO - Started process (PID=99735) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:26.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:22:26.202+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:26.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:26.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:22:26.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:26.244+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:22:26.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T15:22:56.708+0000] {processor.py:157} INFO - Started process (PID=99760) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:56.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:22:56.715+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:56.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:22:56.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:22:56.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:22:56.762+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:22:56.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T15:23:27.155+0000] {processor.py:157} INFO - Started process (PID=99785) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:27.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:23:27.159+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:27.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:27.187+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:23:27.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:27.196+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:23:27.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:23:57.607+0000] {processor.py:157} INFO - Started process (PID=99810) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:57.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:23:57.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:57.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:23:57.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:23:57.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:23:57.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:23:57.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T15:24:28.074+0000] {processor.py:157} INFO - Started process (PID=99835) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:28.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:24:28.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:28.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:28.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:24:28.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:28.121+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:24:28.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T15:24:58.614+0000] {processor.py:157} INFO - Started process (PID=99860) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:58.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:24:58.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:58.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:24:58.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:24:58.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:24:58.691+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:24:58.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T15:25:29.093+0000] {processor.py:157} INFO - Started process (PID=99885) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:29.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:25:29.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:29.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:29.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:25:29.129+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:29.129+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:25:29.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T15:25:59.553+0000] {processor.py:157} INFO - Started process (PID=99910) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:59.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:25:59.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:59.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:25:59.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:25:59.596+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:25:59.596+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:25:59.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:26:29.977+0000] {processor.py:157} INFO - Started process (PID=99935) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:26:29.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:26:29.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:29.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:26:29.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:26:30.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:30.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:26:30.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:26:30.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:26:30.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T15:27:00.409+0000] {processor.py:157} INFO - Started process (PID=99960) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:00.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:27:00.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:00.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:00.442+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:27:00.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:00.451+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:27:00.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:27:30.894+0000] {processor.py:157} INFO - Started process (PID=99985) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:30.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:27:30.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:30.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:27:30.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:27:30.941+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:27:30.941+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:27:30.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T15:28:01.293+0000] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:01.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:28:01.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:01.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:01.322+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:28:01.333+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:01.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:28:01.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:28:31.762+0000] {processor.py:157} INFO - Started process (PID=336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:31.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:28:31.766+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:31.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:28:31.809+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:28:31.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:28:31.837+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:28:31.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T15:29:02.230+0000] {processor.py:157} INFO - Started process (PID=361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:02.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:29:02.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:02.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:02.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:29:02.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:02.262+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:29:02.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.042 seconds
[2024-07-28T15:29:32.708+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:32.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:29:32.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:32.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:29:32.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:29:32.753+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:29:32.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:29:32.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T15:30:03.211+0000] {processor.py:157} INFO - Started process (PID=411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:03.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:30:03.216+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:03.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:03.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:30:03.258+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:03.258+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:30:03.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:30:33.695+0000] {processor.py:157} INFO - Started process (PID=436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:33.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:30:33.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:33.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:30:33.729+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:30:33.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:30:33.743+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:30:33.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:31:04.144+0000] {processor.py:157} INFO - Started process (PID=461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:04.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:31:04.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:04.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:04.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:31:04.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:04.201+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:31:04.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T15:31:34.619+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:34.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:31:34.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:34.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:31:34.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:31:34.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:31:34.666+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:31:34.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:32:05.126+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:05.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:32:05.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:05.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:05.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:32:05.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:05.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:32:05.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:32:35.581+0000] {processor.py:157} INFO - Started process (PID=536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:35.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:32:35.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:35.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:32:35.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:32:35.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:32:35.623+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:32:35.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T15:33:06.092+0000] {processor.py:157} INFO - Started process (PID=561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:06.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:33:06.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:06.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:06.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:33:06.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:06.169+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:33:06.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T15:33:36.591+0000] {processor.py:157} INFO - Started process (PID=586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:36.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:33:36.596+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:36.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:33:36.627+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:33:36.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:33:36.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:33:36.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T15:34:07.099+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:07.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:34:07.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.104+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:07.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:07.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:34:07.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:07.155+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:34:07.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T15:34:37.588+0000] {processor.py:157} INFO - Started process (PID=636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:37.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:34:37.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:37.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:34:37.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:34:37.637+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:34:37.637+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:34:37.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T15:35:08.113+0000] {processor.py:157} INFO - Started process (PID=661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:08.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:35:08.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:08.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:08.178+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:35:08.191+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:08.191+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:35:08.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T15:35:38.572+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:38.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:35:38.576+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:38.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:35:38.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:35:38.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:35:38.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:35:38.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T15:36:09.110+0000] {processor.py:157} INFO - Started process (PID=711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:09.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:36:09.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:09.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:09.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:36:09.169+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:09.168+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:36:09.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T15:36:39.629+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:39.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:36:39.634+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:39.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:36:39.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:36:39.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:36:39.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:36:39.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T15:37:10.161+0000] {processor.py:157} INFO - Started process (PID=761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:10.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:37:10.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:10.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:10.196+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:37:10.206+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:10.206+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:37:10.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:37:40.627+0000] {processor.py:157} INFO - Started process (PID=786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:40.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:37:40.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:40.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:37:40.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:37:40.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:37:40.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:37:40.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T15:38:11.111+0000] {processor.py:157} INFO - Started process (PID=811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:11.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:38:11.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:11.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:11.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:38:11.152+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:11.152+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:38:11.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T15:38:41.614+0000] {processor.py:157} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:41.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:38:41.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:41.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:38:41.648+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:38:41.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:38:41.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:38:41.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T15:39:12.031+0000] {processor.py:157} INFO - Started process (PID=861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:12.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:39:12.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:12.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:12.067+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:39:12.078+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:12.078+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:39:12.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T15:39:42.508+0000] {processor.py:157} INFO - Started process (PID=886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:42.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:39:42.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:42.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:39:42.539+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:39:42.549+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:39:42.549+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:39:42.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:40:12.897+0000] {processor.py:157} INFO - Started process (PID=911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:12.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:40:12.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:12.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:12.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:40:12.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:12.952+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:40:12.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T15:40:43.384+0000] {processor.py:157} INFO - Started process (PID=936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:43.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:40:43.389+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:43.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:40:43.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:40:43.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:40:43.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:40:43.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T15:41:13.858+0000] {processor.py:157} INFO - Started process (PID=961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:13.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:41:13.861+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:13.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:13.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:41:13.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:13.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:41:13.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T15:41:44.332+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:44.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:41:44.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:44.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:41:44.368+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:41:44.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:41:44.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:41:44.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:42:14.830+0000] {processor.py:157} INFO - Started process (PID=1011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:14.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:42:14.833+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:14.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:14.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:42:14.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:14.867+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:42:14.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T15:42:45.271+0000] {processor.py:157} INFO - Started process (PID=1036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:45.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:42:45.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:45.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:42:45.308+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:42:45.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:42:45.319+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:42:45.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:43:15.787+0000] {processor.py:157} INFO - Started process (PID=1061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:15.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:43:15.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:15.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:15.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:43:15.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:15.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:43:15.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:43:46.141+0000] {processor.py:157} INFO - Started process (PID=1086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:46.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:43:46.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:46.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:43:46.174+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:43:46.186+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:43:46.186+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:43:46.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:44:16.624+0000] {processor.py:157} INFO - Started process (PID=1111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:16.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:44:16.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:16.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:16.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:44:16.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:16.670+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:44:16.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:44:47.119+0000] {processor.py:157} INFO - Started process (PID=1136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:47.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:44:47.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:47.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:44:47.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:44:47.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:44:47.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:44:47.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.101 seconds
[2024-07-28T15:45:17.739+0000] {processor.py:157} INFO - Started process (PID=1161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:17.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:45:17.744+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:17.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:17.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:45:17.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:17.816+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:45:17.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T15:45:48.205+0000] {processor.py:157} INFO - Started process (PID=1186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:48.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:45:48.212+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:48.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:45:48.243+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:45:48.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:45:48.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:45:48.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:46:18.709+0000] {processor.py:157} INFO - Started process (PID=1211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:18.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:46:18.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:18.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:18.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:46:18.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:18.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:46:18.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:46:49.161+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:49.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:46:49.166+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:49.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:46:49.205+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:46:49.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:46:49.218+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:46:49.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T15:47:19.651+0000] {processor.py:157} INFO - Started process (PID=1261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:19.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:47:19.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:19.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:19.683+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:47:19.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:19.692+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:47:19.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:47:50.134+0000] {processor.py:157} INFO - Started process (PID=1286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:50.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:47:50.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:50.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:47:50.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:47:50.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:47:50.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:47:50.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T15:48:20.619+0000] {processor.py:157} INFO - Started process (PID=1311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:20.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:48:20.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:20.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:20.654+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:48:20.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:20.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:48:20.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:48:51.066+0000] {processor.py:157} INFO - Started process (PID=1336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:51.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:48:51.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:51.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:48:51.100+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:48:51.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:48:51.109+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:48:51.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T15:49:21.436+0000] {processor.py:157} INFO - Started process (PID=1361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:21.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:49:21.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:21.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:21.462+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:49:21.471+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:21.471+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:49:21.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T15:49:51.852+0000] {processor.py:157} INFO - Started process (PID=1386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:51.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:49:51.857+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:51.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:49:51.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:49:51.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:49:51.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:49:51.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:50:22.265+0000] {processor.py:157} INFO - Started process (PID=1411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:22.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:50:22.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:22.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:22.301+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:50:22.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:22.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:50:22.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T15:50:52.773+0000] {processor.py:157} INFO - Started process (PID=1436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:52.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:50:52.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:52.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:50:52.813+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:50:52.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:50:52.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:50:52.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T15:51:23.223+0000] {processor.py:157} INFO - Started process (PID=1461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:23.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:51:23.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:23.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:23.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:51:23.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:23.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:51:23.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:51:53.635+0000] {processor.py:157} INFO - Started process (PID=1486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:53.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:51:53.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:53.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:51:53.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:51:53.678+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:51:53.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:51:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T15:52:24.117+0000] {processor.py:157} INFO - Started process (PID=1511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:24.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:52:24.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:24.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:24.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:52:24.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:24.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:52:24.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T15:52:54.543+0000] {processor.py:157} INFO - Started process (PID=1536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:54.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:52:54.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:54.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:52:54.581+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:52:54.592+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:52:54.592+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:52:54.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T15:53:25.054+0000] {processor.py:157} INFO - Started process (PID=1561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:25.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:53:25.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:25.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:25.090+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:53:25.105+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:25.105+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:53:25.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T15:53:55.524+0000] {processor.py:157} INFO - Started process (PID=1586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:55.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:53:55.529+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:55.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:53:55.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:53:55.568+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:53:55.568+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:53:55.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:54:26.045+0000] {processor.py:157} INFO - Started process (PID=1611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:26.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:54:26.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:26.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:26.077+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:54:26.089+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:26.089+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:54:26.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:54:56.505+0000] {processor.py:157} INFO - Started process (PID=1636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:56.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:54:56.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:56.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:54:56.544+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:54:56.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:54:56.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:54:56.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T15:55:26.974+0000] {processor.py:157} INFO - Started process (PID=1661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:26.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:55:26.981+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:26.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:26.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:27.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:27.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:55:27.019+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:27.019+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:55:27.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:55:57.463+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:57.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:55:57.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:57.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:55:57.500+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:55:57.511+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:55:57.511+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:55:57.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T15:56:27.831+0000] {processor.py:157} INFO - Started process (PID=1711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:27.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:56:27.835+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:27.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:27.858+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:56:27.870+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:27.870+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:56:27.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T15:56:58.265+0000] {processor.py:157} INFO - Started process (PID=1736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:58.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:56:58.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:58.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:56:58.301+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:56:58.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:56:58.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:56:58.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T15:57:28.744+0000] {processor.py:157} INFO - Started process (PID=1761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:28.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:57:28.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:28.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:28.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:57:28.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:28.787+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:57:28.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:57:59.206+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:59.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:57:59.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:59.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:57:59.245+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:57:59.255+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:57:59.255+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:57:59.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T15:58:29.694+0000] {processor.py:157} INFO - Started process (PID=1811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:58:29.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:58:29.697+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:58:29.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:58:29.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:58:29.736+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:58:29.736+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:58:29.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T15:59:00.103+0000] {processor.py:157} INFO - Started process (PID=1836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:00.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:59:00.109+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:00.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:00.138+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:59:00.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:00.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:59:00.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T15:59:30.608+0000] {processor.py:157} INFO - Started process (PID=1861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:30.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T15:59:30.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:30.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T15:59:30.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T15:59:30.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T15:59:30.651+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T15:59:30.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T16:00:01.078+0000] {processor.py:157} INFO - Started process (PID=1886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:01.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:00:01.083+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:01.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:01.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:00:01.126+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:01.126+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:00:01.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T16:00:31.527+0000] {processor.py:157} INFO - Started process (PID=1911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:31.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:00:31.533+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:31.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:00:31.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:00:31.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:00:31.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:00:31.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T16:01:01.950+0000] {processor.py:157} INFO - Started process (PID=1936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:01.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:01:01.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:01.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:01.986+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:01:01.998+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:01.998+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:01:02.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T16:01:32.468+0000] {processor.py:157} INFO - Started process (PID=1961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:32.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:01:32.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:32.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:01:32.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:01:32.513+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:01:32.513+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:01:32.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T16:02:02.933+0000] {processor.py:157} INFO - Started process (PID=1986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:02.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:02:02.940+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:02.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:02.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:02:02.979+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:02.979+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:02:02.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T16:02:33.381+0000] {processor.py:157} INFO - Started process (PID=2011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:33.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:02:33.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:33.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:02:33.413+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:02:33.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:02:33.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:02:33.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T16:03:03.847+0000] {processor.py:157} INFO - Started process (PID=2036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:03.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:03:03.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:03.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:03.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:03:03.897+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:03.897+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:03:03.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T16:03:34.323+0000] {processor.py:157} INFO - Started process (PID=2061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:34.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:03:34.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:34.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:03:34.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:03:34.365+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:03:34.365+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:03:34.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T16:04:04.732+0000] {processor.py:157} INFO - Started process (PID=2086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:04.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:04:04.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:04.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:04.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:04:04.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:04.781+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:04:04.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T16:04:35.148+0000] {processor.py:157} INFO - Started process (PID=2111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:35.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:04:35.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:35.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:04:35.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:04:35.193+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:04:35.193+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:04:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T16:05:05.728+0000] {processor.py:157} INFO - Started process (PID=2136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:05.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:05:05.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:05.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:05.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:05:05.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:05.798+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:05:05.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-28T16:05:36.309+0000] {processor.py:157} INFO - Started process (PID=2161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:36.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:05:36.343+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:36.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:05:36.411+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:05:36.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:05:36.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:05:36.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.146 seconds
[2024-07-28T16:06:07.064+0000] {processor.py:157} INFO - Started process (PID=2186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:07.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:06:07.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:07.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:07.116+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:06:07.141+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:07.141+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:06:07.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-28T16:06:37.559+0000] {processor.py:157} INFO - Started process (PID=2211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:37.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:06:37.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:37.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:06:37.624+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:06:37.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:06:37.640+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:06:37.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T16:07:08.042+0000] {processor.py:157} INFO - Started process (PID=2236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:08.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:07:08.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:08.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:08.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:07:08.086+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:08.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:07:08.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T16:07:38.406+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:38.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:07:38.415+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:38.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:07:38.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:07:38.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:07:38.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:07:38.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.103 seconds
[2024-07-28T16:08:08.908+0000] {processor.py:157} INFO - Started process (PID=2286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:08.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:08:08.911+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:08.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:08.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:08:08.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:08.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:08:08.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T16:08:39.408+0000] {processor.py:157} INFO - Started process (PID=2311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:39.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:08:39.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:39.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:08:39.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:08:39.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:08:39.551+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:08:39.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.193 seconds
[2024-07-28T16:09:10.030+0000] {processor.py:157} INFO - Started process (PID=2336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:10.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:09:10.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:10.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:10.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:09:10.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:10.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:09:10.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T16:09:40.654+0000] {processor.py:157} INFO - Started process (PID=2361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:40.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:09:40.671+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:40.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:09:40.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:09:40.756+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:09:40.756+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:09:40.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.124 seconds
[2024-07-28T16:10:11.227+0000] {processor.py:157} INFO - Started process (PID=2386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:11.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:10:11.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:11.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:11.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:10:11.300+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:11.299+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:10:11.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T16:10:41.884+0000] {processor.py:157} INFO - Started process (PID=2411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:41.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:10:41.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:41.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:10:41.954+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:10:41.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:10:41.968+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:10:41.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-28T16:11:12.382+0000] {processor.py:157} INFO - Started process (PID=2436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:12.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:11:12.388+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:12.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:12.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:11:12.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:12.432+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:11:12.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T16:11:42.826+0000] {processor.py:157} INFO - Started process (PID=2461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:42.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:11:42.833+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:42.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:11:42.871+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:11:42.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:11:42.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:11:42.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T16:12:13.265+0000] {processor.py:157} INFO - Started process (PID=2486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:13.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:12:13.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:13.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:13.299+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:12:13.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:13.310+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:12:13.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T16:12:43.810+0000] {processor.py:157} INFO - Started process (PID=2511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:43.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:12:43.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:43.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:12:43.878+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:12:43.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:12:43.891+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:12:43.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-28T16:13:14.292+0000] {processor.py:157} INFO - Started process (PID=2536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:14.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:13:14.301+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:14.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:14.355+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:13:14.376+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:14.376+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:13:14.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-28T16:13:44.736+0000] {processor.py:157} INFO - Started process (PID=2561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:44.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:13:44.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:44.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:13:44.816+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:13:44.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:13:44.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:13:44.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-28T16:14:15.253+0000] {processor.py:157} INFO - Started process (PID=2586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:15.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:14:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:15.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:14:15.321+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:15.321+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:14:15.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T16:14:45.709+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:45.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:14:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:45.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:14:45.761+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:14:45.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:14:45.778+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:14:45.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T16:15:16.179+0000] {processor.py:157} INFO - Started process (PID=2636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:16.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:15:16.183+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:16.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:16.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:15:16.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:16.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:15:16.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T16:15:46.655+0000] {processor.py:157} INFO - Started process (PID=2661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:46.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:15:46.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:46.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:15:46.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:15:46.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:15:46.731+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:15:46.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T16:16:17.134+0000] {processor.py:157} INFO - Started process (PID=2686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:17.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:16:17.140+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:17.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:17.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:16:17.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:17.189+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:16:17.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T16:16:47.575+0000] {processor.py:157} INFO - Started process (PID=2711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:47.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:16:47.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:47.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:16:47.653+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:16:47.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:16:47.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:16:47.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.126 seconds
[2024-07-28T16:17:18.042+0000] {processor.py:157} INFO - Started process (PID=2736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:18.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:17:18.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:18.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:18.087+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:17:18.099+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:18.099+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:17:18.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T16:17:48.600+0000] {processor.py:157} INFO - Started process (PID=2761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:48.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:17:48.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:48.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:17:48.674+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:17:48.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:17:48.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:17:48.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-28T16:18:19.088+0000] {processor.py:157} INFO - Started process (PID=2786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:19.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:18:19.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:19.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:19.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:18:19.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:19.199+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:18:19.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-28T16:18:49.656+0000] {processor.py:157} INFO - Started process (PID=2811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:49.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:18:49.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:49.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:18:49.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:18:49.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:18:49.745+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:18:49.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-28T16:19:20.187+0000] {processor.py:157} INFO - Started process (PID=2836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:20.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:19:20.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:20.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:20.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:19:20.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:20.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:19:20.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.155 seconds
[2024-07-28T16:19:50.718+0000] {processor.py:157} INFO - Started process (PID=2861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:50.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:19:50.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:50.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:19:50.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:19:50.785+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:19:50.785+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:19:50.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.085 seconds
[2024-07-28T16:20:21.207+0000] {processor.py:157} INFO - Started process (PID=2886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:21.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:20:21.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:21.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:21.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:20:21.308+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:21.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:20:21.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.118 seconds
[2024-07-28T16:20:51.719+0000] {processor.py:157} INFO - Started process (PID=2911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:51.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:20:51.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:51.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:20:51.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:20:51.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:20:51.779+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:20:51.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T16:21:22.213+0000] {processor.py:157} INFO - Started process (PID=2936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:22.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:21:22.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:22.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:22.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:21:22.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:22.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:21:22.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.137 seconds
[2024-07-28T16:21:52.772+0000] {processor.py:157} INFO - Started process (PID=2961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:52.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:21:52.791+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:52.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:21:52.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:21:52.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:21:52.953+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:21:52.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.219 seconds
[2024-07-28T16:22:23.384+0000] {processor.py:157} INFO - Started process (PID=2986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:23.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:22:23.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:23.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:23.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:22:23.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:23.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:22:23.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T16:22:53.888+0000] {processor.py:157} INFO - Started process (PID=3011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:53.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:22:53.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:53.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:22:53.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:22:53.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:22:53.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:22:53.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T16:23:24.388+0000] {processor.py:157} INFO - Started process (PID=3036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:24.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:23:24.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:24.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:24.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:23:24.464+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:24.464+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:23:24.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.097 seconds
[2024-07-28T16:23:54.888+0000] {processor.py:157} INFO - Started process (PID=3061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:54.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:23:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:54.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:23:54.939+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:23:54.956+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:23:54.956+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:23:54.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T16:24:25.389+0000] {processor.py:157} INFO - Started process (PID=3086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:25.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:24:25.393+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:25.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:25.425+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:24:25.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:25.437+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:24:25.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T16:24:55.871+0000] {processor.py:157} INFO - Started process (PID=3111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:55.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:24:55.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:55.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:24:55.944+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:24:55.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:24:55.966+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:24:55.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.120 seconds
[2024-07-28T16:25:26.396+0000] {processor.py:157} INFO - Started process (PID=3136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:26.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:25:26.406+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:26.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:26.466+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:25:26.489+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:26.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:25:26.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-28T16:25:56.984+0000] {processor.py:157} INFO - Started process (PID=3161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:56.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:25:56.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:56.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:57.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:25:57.062+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:57.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:25:57.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:25:57.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:25:57.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.119 seconds
[2024-07-28T16:26:27.527+0000] {processor.py:157} INFO - Started process (PID=3186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:27.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:26:27.535+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:27.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:27.594+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:26:27.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:27.605+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:26:27.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T16:26:58.036+0000] {processor.py:157} INFO - Started process (PID=3211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:58.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:26:58.045+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:58.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:26:58.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:26:58.115+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:26:58.115+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:26:58.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.098 seconds
[2024-07-28T16:27:28.462+0000] {processor.py:157} INFO - Started process (PID=3236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:28.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:27:28.471+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:28.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:28.514+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:27:28.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:28.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:27:28.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T16:27:58.958+0000] {processor.py:157} INFO - Started process (PID=3261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:58.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:27:58.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:58.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:58.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:27:58.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:58.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:27:59.004+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:27:59.004+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:27:59.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T16:28:29.425+0000] {processor.py:157} INFO - Started process (PID=3286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:28:29.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:28:29.433+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:28:29.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:28:29.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:28:29.491+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:29.491+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:28:29.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-28T16:28:59.944+0000] {processor.py:157} INFO - Started process (PID=3311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:28:59.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:28:59.959+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:28:59.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:28:59.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:29:00.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:00.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:29:00.041+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:00.041+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:29:00.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.122 seconds
[2024-07-28T16:29:30.430+0000] {processor.py:157} INFO - Started process (PID=3336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:29:30.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:29:30.441+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:29:30.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:29:30.501+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:29:30.519+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:29:30.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:29:30.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T16:30:00.886+0000] {processor.py:157} INFO - Started process (PID=3361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:00.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:30:00.894+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:00.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:00.948+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:30:00.964+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:00.964+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:30:00.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.096 seconds
[2024-07-28T16:30:31.518+0000] {processor.py:157} INFO - Started process (PID=3386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:31.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:30:31.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:31.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:30:31.572+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:30:31.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:30:31.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:30:31.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T16:31:01.988+0000] {processor.py:157} INFO - Started process (PID=3411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:01.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:31:01.994+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:01.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:02.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:02.040+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:02.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:31:02.056+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:02.056+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:31:02.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T16:31:32.408+0000] {processor.py:157} INFO - Started process (PID=3436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:32.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:31:32.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:32.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:31:32.463+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:31:32.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:31:32.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:31:32.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T16:32:02.898+0000] {processor.py:157} INFO - Started process (PID=3461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:02.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:32:02.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:02.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:02.934+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:32:02.947+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:02.947+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:32:02.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T16:32:33.306+0000] {processor.py:157} INFO - Started process (PID=3486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:33.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:32:33.312+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:33.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:32:33.361+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:32:33.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:32:33.379+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:32:33.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T16:33:03.782+0000] {processor.py:157} INFO - Started process (PID=3511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:03.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:33:03.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:03.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:03.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:33:03.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:03.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:33:03.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T16:33:34.283+0000] {processor.py:157} INFO - Started process (PID=3536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:34.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:33:34.288+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:34.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:33:34.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:33:34.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:33:34.327+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:33:34.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T16:34:04.712+0000] {processor.py:157} INFO - Started process (PID=3561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:04.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:34:04.725+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:04.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:04.784+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:34:04.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:04.801+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:34:04.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T16:34:35.200+0000] {processor.py:157} INFO - Started process (PID=3586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:35.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:34:35.210+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:35.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:34:35.282+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:34:35.314+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:34:35.314+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:34:35.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.153 seconds
[2024-07-28T16:35:05.817+0000] {processor.py:157} INFO - Started process (PID=3611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:05.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:35:05.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:05.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:05.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:35:05.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:05.894+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:35:05.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.092 seconds
[2024-07-28T16:35:36.346+0000] {processor.py:157} INFO - Started process (PID=3636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:36.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:35:36.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:36.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:35:36.395+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:35:36.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:35:36.408+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:35:36.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T16:36:06.804+0000] {processor.py:157} INFO - Started process (PID=3661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:06.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:36:06.813+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:06.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:06.897+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:36:06.916+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:06.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:36:06.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.140 seconds
[2024-07-28T16:36:37.387+0000] {processor.py:157} INFO - Started process (PID=3686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:37.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:36:37.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:37.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:36:37.449+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:36:37.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:36:37.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:36:37.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T16:37:07.901+0000] {processor.py:157} INFO - Started process (PID=3711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:07.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:37:07.909+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:07.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:07.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:37:07.968+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:07.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:37:07.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.086 seconds
[2024-07-28T16:37:38.426+0000] {processor.py:157} INFO - Started process (PID=3736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:38.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:37:38.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:38.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:37:38.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:37:38.532+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:37:38.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:37:38.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.129 seconds
[2024-07-28T16:38:08.932+0000] {processor.py:157} INFO - Started process (PID=3761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:08.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:38:08.945+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:08.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:08.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:08.999+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:08.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:38:09.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:09.014+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:38:09.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T16:38:39.459+0000] {processor.py:157} INFO - Started process (PID=3786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:39.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:38:39.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:39.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:38:39.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:38:39.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:38:39.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:38:39.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.135 seconds
[2024-07-28T16:39:10.001+0000] {processor.py:157} INFO - Started process (PID=3811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:10.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:39:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:10.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:10.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:39:10.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:10.079+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:39:10.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T16:39:40.461+0000] {processor.py:157} INFO - Started process (PID=3836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:40.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:39:40.468+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:40.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:39:40.516+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:39:40.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:39:40.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:39:40.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T16:40:10.963+0000] {processor.py:157} INFO - Started process (PID=3861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:10.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:40:10.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:10.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:10.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:11.029+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:11.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:40:11.047+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:11.047+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:40:11.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T16:40:41.436+0000] {processor.py:157} INFO - Started process (PID=3886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:41.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:40:41.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:41.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:40:41.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:40:41.508+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:40:41.507+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:40:41.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T16:41:11.877+0000] {processor.py:157} INFO - Started process (PID=3911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:11.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:41:11.879+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:11.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:11.903+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:41:11.914+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:11.914+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:41:11.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T16:41:42.252+0000] {processor.py:157} INFO - Started process (PID=3936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:42.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:41:42.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:42.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:41:42.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:41:42.333+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:41:42.333+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:41:42.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-28T16:42:12.667+0000] {processor.py:157} INFO - Started process (PID=3961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:12.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:42:12.671+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:12.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:12.701+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:42:12.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:12.712+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:42:12.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T16:42:43.144+0000] {processor.py:157} INFO - Started process (PID=3986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:43.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:42:43.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:43.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:42:43.197+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:42:43.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:42:43.230+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:42:43.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.107 seconds
[2024-07-28T16:43:13.669+0000] {processor.py:157} INFO - Started process (PID=4011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:13.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:43:13.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:13.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:13.739+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:43:13.753+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:13.753+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:43:13.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T16:43:44.158+0000] {processor.py:157} INFO - Started process (PID=4036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:44.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:43:44.166+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:44.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:43:44.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:43:44.239+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:43:44.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:43:44.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T16:44:14.595+0000] {processor.py:157} INFO - Started process (PID=4061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:14.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:44:14.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:14.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:14.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:44:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:14.656+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:44:14.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.080 seconds
[2024-07-28T16:44:45.123+0000] {processor.py:157} INFO - Started process (PID=4086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:45.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:44:45.130+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:45.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:44:45.168+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:44:45.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:44:45.181+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:44:45.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T16:45:15.575+0000] {processor.py:157} INFO - Started process (PID=4111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:15.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:45:15.578+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:15.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:15.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:45:15.621+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:15.621+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:45:15.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T16:45:45.979+0000] {processor.py:157} INFO - Started process (PID=4136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:45.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:45:45.986+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:45.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:46.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:45:46.035+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:46.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:45:46.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:45:46.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:45:46.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.087 seconds
[2024-07-28T16:46:16.435+0000] {processor.py:157} INFO - Started process (PID=4161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:16.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:46:16.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:16.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:16.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:46:16.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:16.482+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:46:16.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T16:46:46.845+0000] {processor.py:157} INFO - Started process (PID=4186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:46.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:46:46.850+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:46.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:46:46.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:46:46.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:46:46.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:46:46.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T16:47:17.392+0000] {processor.py:157} INFO - Started process (PID=4211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:17.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:47:17.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:17.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:17.443+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:47:17.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:17.459+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:47:17.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T16:47:47.832+0000] {processor.py:157} INFO - Started process (PID=4236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:47.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:47:47.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:47.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:47:47.873+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:47:47.886+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:47:47.886+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:47:47.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T16:48:18.319+0000] {processor.py:157} INFO - Started process (PID=4261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:18.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:48:18.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:18.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:18.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:48:18.369+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:18.369+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:48:18.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T16:48:48.797+0000] {processor.py:157} INFO - Started process (PID=4286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:48.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:48:48.805+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:48.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:48:48.842+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:48:48.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:48:48.854+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:48:48.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T16:49:19.228+0000] {processor.py:157} INFO - Started process (PID=4311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:19.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:49:19.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:19.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:19.262+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:49:19.272+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:19.272+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:49:19.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T16:49:49.704+0000] {processor.py:157} INFO - Started process (PID=4336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:49.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:49:49.709+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:49.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:49:49.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:49:49.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:49:49.754+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:49:49.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T16:50:20.197+0000] {processor.py:157} INFO - Started process (PID=4361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:20.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:50:20.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:20.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:20.236+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:50:20.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:20.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:50:20.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T16:50:50.661+0000] {processor.py:157} INFO - Started process (PID=4386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:50.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:50:50.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:50.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:50:50.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:50:50.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:50:50.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:50:50.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T16:51:21.067+0000] {processor.py:157} INFO - Started process (PID=4411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:21.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:51:21.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:21.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:21.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:51:21.125+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:21.124+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:51:21.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T16:51:51.525+0000] {processor.py:157} INFO - Started process (PID=4436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:51.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:51:51.532+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:51.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:51:51.559+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:51:51.570+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:51:51.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:51:51.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T16:52:21.960+0000] {processor.py:157} INFO - Started process (PID=4461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:21.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:52:21.966+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:21.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:21.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:21.996+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:21.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:52:22.008+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:22.008+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:52:22.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T16:52:52.412+0000] {processor.py:157} INFO - Started process (PID=4486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:52.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:52:52.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:52.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:52:52.459+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:52:52.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:52:52.473+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:52:52.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T16:53:22.879+0000] {processor.py:157} INFO - Started process (PID=4511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:22.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:53:22.884+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:22.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:22.913+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:53:22.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:22.925+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:53:22.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T16:53:53.315+0000] {processor.py:157} INFO - Started process (PID=4536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:53.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:53:53.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:53.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:53:53.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:53:53.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:53:53.359+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:53:53.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T16:54:23.807+0000] {processor.py:157} INFO - Started process (PID=4561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:23.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:54:23.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:23.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:23.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:54:23.851+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:23.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:54:23.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T16:54:54.260+0000] {processor.py:157} INFO - Started process (PID=4586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:54.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:54:54.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:54.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:54:54.305+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:54:54.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:54:54.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:54:54.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T16:55:24.711+0000] {processor.py:157} INFO - Started process (PID=4611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:24.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:55:24.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:24.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:24.740+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:55:24.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:24.751+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:55:24.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T16:55:55.116+0000] {processor.py:157} INFO - Started process (PID=4636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:55.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:55:55.120+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:55.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:55:55.146+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:55:55.160+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:55:55.160+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:55:55.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T16:56:25.582+0000] {processor.py:157} INFO - Started process (PID=4661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:25.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:56:25.588+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:25.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:25.615+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:56:25.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:25.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:56:25.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T16:56:56.024+0000] {processor.py:157} INFO - Started process (PID=4686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:56.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:56:56.026+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:56.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:56:56.053+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:56:56.063+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:56:56.063+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:56:56.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T16:57:26.488+0000] {processor.py:157} INFO - Started process (PID=4711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:26.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:57:26.493+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:26.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:26.555+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:57:26.566+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:26.566+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:57:26.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.094 seconds
[2024-07-28T16:57:56.956+0000] {processor.py:157} INFO - Started process (PID=4736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:56.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:57:56.959+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:56.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:56.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:57:56.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:56.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:57:57.000+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:57:57.000+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:57:57.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T16:58:27.366+0000] {processor.py:157} INFO - Started process (PID=4761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:27.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:58:27.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:27.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:27.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:58:27.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:27.423+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:58:27.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T16:58:57.858+0000] {processor.py:157} INFO - Started process (PID=4786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:57.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:58:57.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:57.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:58:57.893+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:58:57.904+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:58:57.904+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:58:57.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T16:59:28.287+0000] {processor.py:157} INFO - Started process (PID=4811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:28.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:59:28.292+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:28.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:28.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:59:28.330+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:28.330+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:59:28.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T16:59:58.764+0000] {processor.py:157} INFO - Started process (PID=4836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:58.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T16:59:58.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:58.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T16:59:58.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T16:59:58.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T16:59:58.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T16:59:58.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T17:00:29.185+0000] {processor.py:157} INFO - Started process (PID=4861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:29.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:00:29.189+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:29.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:29.217+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:00:29.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:29.227+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:00:29.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:00:59.613+0000] {processor.py:157} INFO - Started process (PID=4886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:59.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:00:59.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:59.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:00:59.649+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:00:59.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:00:59.659+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:00:59.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T17:01:30.029+0000] {processor.py:157} INFO - Started process (PID=4911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:01:30.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:01:30.032+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:01:30.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:01:30.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:01:30.071+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:01:30.070+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:01:30.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:02:00.416+0000] {processor.py:157} INFO - Started process (PID=4936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:00.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:02:00.419+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:00.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:00.444+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:02:00.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:00.456+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:02:00.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T17:02:30.817+0000] {processor.py:157} INFO - Started process (PID=4961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:30.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:02:30.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:30.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:02:30.853+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:02:30.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:02:30.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:02:30.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:03:01.284+0000] {processor.py:157} INFO - Started process (PID=4986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:01.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:03:01.291+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:01.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:01.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:03:01.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:01.339+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:03:01.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T17:03:31.757+0000] {processor.py:157} INFO - Started process (PID=5011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:31.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:03:31.760+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:31.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:03:31.789+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:03:31.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:03:31.799+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:03:31.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T17:04:02.196+0000] {processor.py:157} INFO - Started process (PID=5036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:02.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:04:02.200+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:02.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:02.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:04:02.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:02.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:04:02.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:04:32.657+0000] {processor.py:157} INFO - Started process (PID=5061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:32.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:04:32.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:32.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:04:32.688+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:04:32.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:04:32.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:04:32.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:05:03.143+0000] {processor.py:157} INFO - Started process (PID=5086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:03.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:05:03.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:03.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:03.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:05:03.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:03.208+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:05:03.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.081 seconds
[2024-07-28T17:05:33.622+0000] {processor.py:157} INFO - Started process (PID=5111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:33.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:05:33.628+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:33.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:05:33.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:05:33.668+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:05:33.668+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:05:33.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T17:06:04.034+0000] {processor.py:157} INFO - Started process (PID=5136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:04.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:06:04.038+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:04.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:04.073+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:06:04.086+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:04.086+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:06:04.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T17:06:34.448+0000] {processor.py:157} INFO - Started process (PID=5161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:34.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:06:34.457+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:34.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:06:34.487+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:06:34.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:06:34.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:06:34.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T17:07:04.928+0000] {processor.py:157} INFO - Started process (PID=5186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:04.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:07:04.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:04.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:04.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:07:04.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:04.982+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:07:04.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T17:07:35.361+0000] {processor.py:157} INFO - Started process (PID=5211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:35.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:07:35.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:35.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:07:35.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:07:35.404+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:07:35.404+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:07:35.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:08:05.822+0000] {processor.py:157} INFO - Started process (PID=5236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:05.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:08:05.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:05.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:05.852+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:08:05.862+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:05.862+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:08:05.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T17:08:36.274+0000] {processor.py:157} INFO - Started process (PID=5261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:36.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:08:36.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:36.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:08:36.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:08:36.320+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:08:36.320+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:08:36.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T17:09:06.702+0000] {processor.py:157} INFO - Started process (PID=5286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:06.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:09:06.707+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:06.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:06.738+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:09:06.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:06.749+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:09:06.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T17:09:37.128+0000] {processor.py:157} INFO - Started process (PID=5311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:37.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:09:37.132+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:37.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:09:37.159+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:09:37.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:09:37.170+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:09:37.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:10:07.502+0000] {processor.py:157} INFO - Started process (PID=5336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:07.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:10:07.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:07.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:07.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:10:07.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:07.548+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:10:07.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T17:10:37.927+0000] {processor.py:157} INFO - Started process (PID=5361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:37.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:10:37.933+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:37.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:10:37.961+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:10:37.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:10:37.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:10:37.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T17:11:08.323+0000] {processor.py:157} INFO - Started process (PID=5386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:08.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:11:08.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:08.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:08.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:11:08.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:08.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:11:08.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T17:11:38.783+0000] {processor.py:157} INFO - Started process (PID=5411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:38.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:11:38.787+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:38.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:11:38.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:11:38.824+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:11:38.824+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:11:38.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:12:09.198+0000] {processor.py:157} INFO - Started process (PID=5436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:09.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:12:09.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:09.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:09.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:12:09.241+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:09.240+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:12:09.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:12:39.610+0000] {processor.py:157} INFO - Started process (PID=5461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:39.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:12:39.613+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:39.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:12:39.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:12:39.646+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:12:39.646+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:12:39.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T17:13:10.092+0000] {processor.py:157} INFO - Started process (PID=5486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:10.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:13:10.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:10.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:10.135+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:13:10.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:10.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:13:10.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T17:13:40.558+0000] {processor.py:157} INFO - Started process (PID=5511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:40.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:13:40.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:40.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:13:40.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:13:40.599+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:13:40.599+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:13:40.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:14:10.993+0000] {processor.py:157} INFO - Started process (PID=5536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:10.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:14:10.997+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:10.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:11.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:11.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:11.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:14:11.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:11.033+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:14:11.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:14:41.476+0000] {processor.py:157} INFO - Started process (PID=5561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:41.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:14:41.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:41.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:14:41.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:14:41.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:14:41.515+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:14:41.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T17:15:11.828+0000] {processor.py:157} INFO - Started process (PID=5586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:11.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:15:11.830+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:11.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:11.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:15:11.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:11.864+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:15:11.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T17:15:42.276+0000] {processor.py:157} INFO - Started process (PID=5611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:42.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:15:42.279+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:42.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:15:42.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:15:42.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:15:42.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:15:42.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:16:12.693+0000] {processor.py:157} INFO - Started process (PID=5636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:12.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:16:12.696+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:12.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:12.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:16:12.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:12.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:16:12.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.040 seconds
[2024-07-28T17:16:43.140+0000] {processor.py:157} INFO - Started process (PID=5661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:43.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:16:43.144+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:43.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:16:43.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:16:43.180+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:16:43.179+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:16:43.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:17:13.611+0000] {processor.py:157} INFO - Started process (PID=5686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:13.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:17:13.614+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:13.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:13.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:17:13.652+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:13.652+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:17:13.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T17:17:44.089+0000] {processor.py:157} INFO - Started process (PID=5711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:44.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:17:44.097+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:44.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:17:44.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:17:44.146+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:17:44.146+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:17:44.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T17:18:14.570+0000] {processor.py:157} INFO - Started process (PID=5736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:14.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:18:14.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:14.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:14.605+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:18:14.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:14.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:18:14.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T17:18:44.991+0000] {processor.py:157} INFO - Started process (PID=5761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:44.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:18:44.995+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:44.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:45.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:18:45.025+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:45.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:18:45.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:18:45.035+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:18:45.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:19:15.475+0000] {processor.py:157} INFO - Started process (PID=5786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:15.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:19:15.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:15.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:19:15.519+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:15.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:19:15.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T17:19:45.919+0000] {processor.py:157} INFO - Started process (PID=5811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:45.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:19:45.922+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:45.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:19:45.950+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:19:45.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:19:45.960+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:19:45.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:20:16.372+0000] {processor.py:157} INFO - Started process (PID=5836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:16.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:20:16.378+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:16.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:16.424+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:20:16.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:16.440+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:20:16.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.084 seconds
[2024-07-28T17:20:46.792+0000] {processor.py:157} INFO - Started process (PID=5861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:46.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:20:46.797+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:46.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:20:46.827+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:20:46.836+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:20:46.836+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:20:46.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:21:17.236+0000] {processor.py:157} INFO - Started process (PID=5886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:17.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:21:17.240+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:17.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:17.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:21:17.277+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:17.277+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:21:17.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T17:21:47.709+0000] {processor.py:157} INFO - Started process (PID=5911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:47.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:21:47.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:47.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:21:47.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:21:47.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:21:47.759+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:21:47.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T17:22:18.073+0000] {processor.py:157} INFO - Started process (PID=5936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:18.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:22:18.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:18.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:18.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:22:18.117+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:18.116+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:22:18.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T17:22:48.558+0000] {processor.py:157} INFO - Started process (PID=5961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:48.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:22:48.565+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:48.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:22:48.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:22:48.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:22:48.616+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:22:48.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T17:23:19.016+0000] {processor.py:157} INFO - Started process (PID=5986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:19.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:23:19.018+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:19.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:19.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:23:19.052+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:19.052+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:23:19.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T17:23:49.433+0000] {processor.py:157} INFO - Started process (PID=6011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:49.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:23:49.437+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:49.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:23:49.461+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:23:49.472+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:23:49.472+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:23:49.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:24:19.859+0000] {processor.py:157} INFO - Started process (PID=6036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:19.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:24:19.864+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:19.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:19.889+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:24:19.899+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:19.899+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:24:19.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:24:50.318+0000] {processor.py:157} INFO - Started process (PID=6061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:50.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:24:50.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:50.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:24:50.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:24:50.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:24:50.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:24:50.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:25:20.794+0000] {processor.py:157} INFO - Started process (PID=6086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:20.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:25:20.800+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:20.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:20.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:25:20.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:20.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:25:20.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:25:51.179+0000] {processor.py:157} INFO - Started process (PID=6111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:51.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:25:51.185+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:51.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:25:51.221+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:25:51.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:25:51.233+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:25:51.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T17:26:21.651+0000] {processor.py:157} INFO - Started process (PID=6136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:21.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:26:21.655+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:21.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:21.684+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:26:21.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:21.693+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:26:21.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:26:52.010+0000] {processor.py:157} INFO - Started process (PID=6161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:52.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:26:52.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:52.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:26:52.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:26:52.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:26:52.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:26:52.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.048 seconds
[2024-07-28T17:27:22.449+0000] {processor.py:157} INFO - Started process (PID=6186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:27:22.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:22.480+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:27:22.490+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:22.490+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:27:22.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T17:27:52.949+0000] {processor.py:157} INFO - Started process (PID=6211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:52.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:27:52.952+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:52.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:27:52.980+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:27:52.991+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:27:52.990+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:27:53.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:28:23.355+0000] {processor.py:157} INFO - Started process (PID=6236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:23.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:28:23.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:23.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:23.385+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:28:23.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:23.397+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:28:23.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:28:53.821+0000] {processor.py:157} INFO - Started process (PID=6261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:53.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:28:53.825+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:53.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:28:53.854+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:28:53.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:28:53.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:28:53.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T17:29:24.226+0000] {processor.py:157} INFO - Started process (PID=6286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:24.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:29:24.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:24.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:24.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:29:24.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:24.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:29:24.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T17:29:54.709+0000] {processor.py:157} INFO - Started process (PID=6311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:54.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:29:54.712+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:54.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:29:54.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:29:54.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:29:54.752+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:29:54.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:30:25.191+0000] {processor.py:157} INFO - Started process (PID=6336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:25.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:30:25.195+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:25.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:25.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:30:25.224+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:25.224+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:30:25.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.041 seconds
[2024-07-28T17:30:55.627+0000] {processor.py:157} INFO - Started process (PID=6361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:55.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:30:55.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:55.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:30:55.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:30:55.673+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:30:55.673+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:30:55.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:31:26.116+0000] {processor.py:157} INFO - Started process (PID=6386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:26.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:31:26.122+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:26.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:26.148+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:31:26.158+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:26.158+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:31:26.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:31:56.599+0000] {processor.py:157} INFO - Started process (PID=6411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:56.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:31:56.604+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:56.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:31:56.633+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:31:56.642+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:31:56.641+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:31:56.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T17:32:27.107+0000] {processor.py:157} INFO - Started process (PID=6436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:27.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:32:27.111+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:27.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:27.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:32:27.149+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:27.149+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:32:27.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T17:32:57.514+0000] {processor.py:157} INFO - Started process (PID=6461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:57.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:32:57.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:57.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:32:57.584+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:32:57.610+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:32:57.610+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:32:57.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-28T17:33:28.053+0000] {processor.py:157} INFO - Started process (PID=6486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:28.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:33:28.058+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:28.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:28.091+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:33:28.102+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:28.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:33:28.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T17:33:58.433+0000] {processor.py:157} INFO - Started process (PID=6511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:58.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:33:58.436+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:58.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:33:58.465+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:33:58.477+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:33:58.477+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:33:58.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:34:28.892+0000] {processor.py:157} INFO - Started process (PID=6536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:28.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:34:28.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:28.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:28.926+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:34:28.936+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:28.936+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:34:28.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T17:34:59.377+0000] {processor.py:157} INFO - Started process (PID=6561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:59.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:34:59.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:59.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:34:59.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:34:59.434+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:34:59.433+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:34:59.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T17:35:29.834+0000] {processor.py:157} INFO - Started process (PID=6586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:35:29.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:35:29.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:35:29.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:35:29.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:35:29.883+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:35:29.883+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:35:29.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T17:36:00.332+0000] {processor.py:157} INFO - Started process (PID=6611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:00.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:36:00.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:00.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:00.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:36:00.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:00.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:36:00.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T17:36:30.879+0000] {processor.py:157} INFO - Started process (PID=6636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:30.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:36:30.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:30.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:36:30.949+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:36:30.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:36:30.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:36:30.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T17:37:01.372+0000] {processor.py:157} INFO - Started process (PID=6661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:01.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:37:01.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:01.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:01.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:37:01.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:01.410+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:37:01.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:37:31.791+0000] {processor.py:157} INFO - Started process (PID=6686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:31.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:37:31.796+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:31.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:37:31.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:37:31.844+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:37:31.844+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:37:31.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T17:38:02.305+0000] {processor.py:157} INFO - Started process (PID=6711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:02.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:38:02.310+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:02.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:02.348+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:38:02.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:02.360+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:38:02.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T17:38:32.806+0000] {processor.py:157} INFO - Started process (PID=6736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:32.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:38:32.818+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:32.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:38:32.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:38:32.872+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:38:32.872+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:38:32.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T17:39:03.325+0000] {processor.py:157} INFO - Started process (PID=6761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:03.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:39:03.331+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:03.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:03.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:39:03.387+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:03.387+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:39:03.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T17:39:33.801+0000] {processor.py:157} INFO - Started process (PID=6786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:33.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:39:33.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:33.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:39:33.840+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:39:33.851+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:39:33.851+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:39:33.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T17:40:04.271+0000] {processor.py:157} INFO - Started process (PID=6811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:04.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:40:04.275+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:04.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:04.339+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:40:04.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:04.354+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:40:04.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-28T17:40:34.710+0000] {processor.py:157} INFO - Started process (PID=6836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:34.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:40:34.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:34.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:40:34.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:40:34.757+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:40:34.757+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:40:34.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T17:41:05.150+0000] {processor.py:157} INFO - Started process (PID=6861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:05.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:41:05.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:05.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:05.190+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:41:05.205+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:05.205+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:41:05.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T17:41:35.600+0000] {processor.py:157} INFO - Started process (PID=6886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:35.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:41:35.603+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:35.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:41:35.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:41:35.648+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:41:35.648+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:41:35.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T17:42:05.996+0000] {processor.py:157} INFO - Started process (PID=6911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:05.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:42:06.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:06.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:06.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:42:06.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:06.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:42:06.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.069 seconds
[2024-07-28T17:42:36.477+0000] {processor.py:157} INFO - Started process (PID=6936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:36.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:42:36.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:36.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:42:36.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:42:36.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:42:36.521+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:42:36.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T17:43:06.903+0000] {processor.py:157} INFO - Started process (PID=6961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:06.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:43:06.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:06.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:06.943+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:43:06.955+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:06.954+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:43:06.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T17:43:37.388+0000] {processor.py:157} INFO - Started process (PID=6986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:37.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:43:37.392+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:37.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:43:37.420+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:43:37.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:43:37.429+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:43:37.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:44:07.771+0000] {processor.py:157} INFO - Started process (PID=7011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:07.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:44:07.773+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:07.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:07.798+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:44:07.808+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:07.807+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:44:07.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.049 seconds
[2024-07-28T17:44:38.898+0000] {processor.py:157} INFO - Started process (PID=7036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:38.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:44:38.938+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:38.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:38.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:44:39.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:39.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:44:39.074+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:44:39.073+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:44:39.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.225 seconds
[2024-07-28T17:45:09.579+0000] {processor.py:157} INFO - Started process (PID=7061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:09.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:45:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:09.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:09.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:45:09.638+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:09.638+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:45:09.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T17:45:40.090+0000] {processor.py:157} INFO - Started process (PID=7086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:40.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:45:40.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:40.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:45:40.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:45:40.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:45:40.182+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:45:40.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-28T17:46:10.672+0000] {processor.py:157} INFO - Started process (PID=7111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:10.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:46:10.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:10.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:10.733+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:46:10.747+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:10.747+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:46:10.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T17:46:41.168+0000] {processor.py:157} INFO - Started process (PID=7136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:41.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:46:41.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:41.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:46:41.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:46:41.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:46:41.208+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:46:41.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:47:11.634+0000] {processor.py:157} INFO - Started process (PID=7161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:11.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:47:11.640+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:11.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:11.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:47:11.679+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:11.678+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:47:11.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T17:47:42.236+0000] {processor.py:157} INFO - Started process (PID=7186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:42.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:47:42.250+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:42.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:47:42.317+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:47:42.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:47:42.336+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:47:42.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T17:48:12.687+0000] {processor.py:157} INFO - Started process (PID=7211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:12.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:48:12.691+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:12.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:12.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:48:12.734+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:12.734+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:48:12.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T17:48:43.092+0000] {processor.py:157} INFO - Started process (PID=7236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:43.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:48:43.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:43.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:48:43.151+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:48:43.164+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:48:43.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:48:43.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.089 seconds
[2024-07-28T17:49:13.581+0000] {processor.py:157} INFO - Started process (PID=7261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:13.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:49:13.586+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:13.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:13.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:49:13.626+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:13.626+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:49:13.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:49:43.938+0000] {processor.py:157} INFO - Started process (PID=7286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:43.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:49:43.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:43.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:49:43.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:49:43.973+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:49:43.973+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:49:43.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T17:50:14.353+0000] {processor.py:157} INFO - Started process (PID=7311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:14.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:50:14.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:14.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:14.397+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:50:14.409+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:14.409+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:50:14.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T17:50:44.824+0000] {processor.py:157} INFO - Started process (PID=7336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:44.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:50:44.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:44.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:50:44.851+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:50:44.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:50:44.863+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:50:44.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T17:51:15.254+0000] {processor.py:157} INFO - Started process (PID=7361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:15.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:51:15.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:15.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:15.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:51:15.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:15.353+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:51:15.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-28T17:51:45.853+0000] {processor.py:157} INFO - Started process (PID=7386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:45.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:51:45.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:45.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:51:45.918+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:51:45.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:51:45.932+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:51:45.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T17:52:16.421+0000] {processor.py:157} INFO - Started process (PID=7411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:16.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:52:16.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:16.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:16.481+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:52:16.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:16.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:52:16.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.104 seconds
[2024-07-28T17:52:46.864+0000] {processor.py:157} INFO - Started process (PID=7436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:46.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:52:46.868+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:46.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:52:46.895+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:52:46.905+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:52:46.905+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:52:46.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:53:17.245+0000] {processor.py:157} INFO - Started process (PID=7461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:17.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:53:17.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:17.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:17.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:53:17.315+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:17.315+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:53:17.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-28T17:53:47.749+0000] {processor.py:157} INFO - Started process (PID=7486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:47.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:53:47.754+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:47.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:53:47.779+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:53:47.788+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:53:47.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:53:47.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T17:54:18.162+0000] {processor.py:157} INFO - Started process (PID=7511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:18.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:54:18.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:18.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:18.208+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:54:18.222+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:18.222+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:54:18.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T17:54:48.683+0000] {processor.py:157} INFO - Started process (PID=7536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:48.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:54:48.687+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:48.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:54:48.732+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:54:48.746+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:54:48.746+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:54:48.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T17:55:19.090+0000] {processor.py:157} INFO - Started process (PID=7561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:19.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:55:19.098+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:19.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:19.142+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:55:19.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:19.154+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:55:19.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T17:55:49.587+0000] {processor.py:157} INFO - Started process (PID=7586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:49.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:55:49.591+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:49.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:55:49.622+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:55:49.631+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:55:49.631+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:55:49.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T17:56:19.985+0000] {processor.py:157} INFO - Started process (PID=7611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:19.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:56:19.989+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:19.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:20.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:20.022+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:20.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:56:20.034+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:20.034+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:56:20.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T17:56:50.527+0000] {processor.py:157} INFO - Started process (PID=7636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:50.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:56:50.534+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:50.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:56:50.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:56:50.587+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:56:50.586+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:56:50.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T17:57:21.076+0000] {processor.py:157} INFO - Started process (PID=7661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:21.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:57:21.081+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:21.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:21.108+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:57:21.118+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:21.118+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:57:21.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T17:57:51.550+0000] {processor.py:157} INFO - Started process (PID=7686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:51.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:57:51.563+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:51.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:57:51.617+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:57:51.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:57:51.647+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:57:51.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.114 seconds
[2024-07-28T17:58:22.073+0000] {processor.py:157} INFO - Started process (PID=7711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:22.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:58:22.079+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:22.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:22.121+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:58:22.132+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:22.132+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:58:22.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.077 seconds
[2024-07-28T17:58:52.507+0000] {processor.py:157} INFO - Started process (PID=7736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:52.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:58:52.512+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:52.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:58:52.547+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:58:52.559+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:58:52.559+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:58:52.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T17:59:23.089+0000] {processor.py:157} INFO - Started process (PID=7761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:23.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:59:23.096+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:23.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:23.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:59:23.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:23.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:59:23.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.100 seconds
[2024-07-28T17:59:53.571+0000] {processor.py:157} INFO - Started process (PID=7786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:53.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T17:59:53.575+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:53.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T17:59:53.606+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T17:59:53.618+0000] {logging_mixin.py:151} INFO - [2024-07-28T17:59:53.618+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T17:59:53.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T18:00:24.061+0000] {processor.py:157} INFO - Started process (PID=7811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:24.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:00:24.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:24.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:24.124+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:00:24.137+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:24.136+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:00:24.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.105 seconds
[2024-07-28T18:00:54.493+0000] {processor.py:157} INFO - Started process (PID=7836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:54.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:00:54.499+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:54.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:00:54.525+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:00:54.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:00:54.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:00:54.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T18:01:24.926+0000] {processor.py:157} INFO - Started process (PID=7861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:24.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:01:24.931+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:24.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:24.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:01:24.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:24.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:01:24.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T18:01:55.319+0000] {processor.py:157} INFO - Started process (PID=7886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:55.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:01:55.323+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:55.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:01:55.356+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:01:55.367+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:01:55.367+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:01:55.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T18:02:25.745+0000] {processor.py:157} INFO - Started process (PID=7911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:25.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:02:25.749+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:25.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:25.778+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:02:25.788+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:25.788+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:02:25.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T18:02:56.249+0000] {processor.py:157} INFO - Started process (PID=7936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:56.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:02:56.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:56.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:02:56.293+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:02:56.306+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:02:56.306+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:02:56.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T18:03:26.748+0000] {processor.py:157} INFO - Started process (PID=7961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:26.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:03:26.752+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:26.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:26.781+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:03:26.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:26.793+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:03:26.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T18:03:57.151+0000] {processor.py:157} INFO - Started process (PID=7986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:57.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:03:57.156+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:57.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:03:57.182+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:03:57.192+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:03:57.192+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:03:57.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T18:04:27.523+0000] {processor.py:157} INFO - Started process (PID=8011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:27.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:04:27.528+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:27.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:27.562+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:04:27.577+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:27.576+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:04:27.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T18:04:57.874+0000] {processor.py:157} INFO - Started process (PID=8036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:57.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:04:57.877+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:57.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:04:57.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:04:57.915+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:04:57.915+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:04:57.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T18:05:28.316+0000] {processor.py:157} INFO - Started process (PID=8061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:28.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:05:28.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:28.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:28.346+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:05:28.356+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:28.356+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:05:28.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T18:05:58.745+0000] {processor.py:157} INFO - Started process (PID=8086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:58.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:05:58.750+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:58.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:05:58.798+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:05:58.814+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:05:58.814+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:05:58.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-28T18:06:29.231+0000] {processor.py:157} INFO - Started process (PID=8111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:29.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:06:29.235+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:29.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:29.263+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:06:29.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:29.274+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:06:29.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T18:06:59.696+0000] {processor.py:157} INFO - Started process (PID=8136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:59.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:06:59.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:59.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:06:59.743+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:06:59.758+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:06:59.758+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:06:59.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T18:07:30.073+0000] {processor.py:157} INFO - Started process (PID=8161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:07:30.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:07:30.076+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:07:30.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:07:30.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:07:30.120+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:07:30.120+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:07:30.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T18:08:00.510+0000] {processor.py:157} INFO - Started process (PID=8186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:00.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:08:00.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:00.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:00.557+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:08:00.569+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:00.569+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:08:00.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T18:08:31.027+0000] {processor.py:157} INFO - Started process (PID=8211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:31.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:08:31.036+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:31.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:08:31.076+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:08:31.088+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:08:31.088+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:08:31.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T18:09:01.507+0000] {processor.py:157} INFO - Started process (PID=8236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:01.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:09:01.510+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:01.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:01.540+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:09:01.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:01.550+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:09:01.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T18:09:31.896+0000] {processor.py:157} INFO - Started process (PID=8261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:31.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:09:31.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:31.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:09:31.932+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:09:31.942+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:09:31.942+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:09:31.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.062 seconds
[2024-07-28T18:10:02.288+0000] {processor.py:157} INFO - Started process (PID=8286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:02.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:10:02.290+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:02.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:02.318+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:10:02.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:02.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:10:02.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:10:32.657+0000] {processor.py:157} INFO - Started process (PID=8311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:32.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:10:32.660+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:32.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:10:32.680+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:10:32.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:10:32.689+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:10:32.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.044 seconds
[2024-07-28T18:11:03.063+0000] {processor.py:157} INFO - Started process (PID=8336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:03.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:11:03.068+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:03.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:03.093+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:11:03.102+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:03.102+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:11:03.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T18:11:33.493+0000] {processor.py:157} INFO - Started process (PID=8361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:33.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:11:33.501+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:33.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:11:33.538+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:11:33.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:11:33.550+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:11:33.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.075 seconds
[2024-07-28T18:12:03.961+0000] {processor.py:157} INFO - Started process (PID=8386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:03.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:12:03.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:03.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:03.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:03.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:03.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:12:04.002+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:04.002+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:12:04.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:12:34.443+0000] {processor.py:157} INFO - Started process (PID=8411) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:34.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:12:34.446+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:34.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:12:34.471+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:12:34.485+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:12:34.485+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:12:34.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:13:04.830+0000] {processor.py:157} INFO - Started process (PID=8436) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:04.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:13:04.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:04.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:04.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:13:04.869+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:04.869+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:13:04.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:13:35.255+0000] {processor.py:157} INFO - Started process (PID=8461) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:35.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:13:35.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:35.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:13:35.287+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:13:35.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:13:35.297+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:13:35.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T18:14:05.719+0000] {processor.py:157} INFO - Started process (PID=8486) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:05.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:14:05.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:05.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:05.751+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:14:05.764+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:05.764+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:14:05.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T18:14:36.170+0000] {processor.py:157} INFO - Started process (PID=8511) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:36.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:14:36.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:36.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:14:36.205+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:14:36.215+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:14:36.215+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:14:36.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T18:15:06.583+0000] {processor.py:157} INFO - Started process (PID=8536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:06.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:15:06.589+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:06.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:06.616+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:15:06.625+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:06.625+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:15:06.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:15:36.964+0000] {processor.py:157} INFO - Started process (PID=8561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:36.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:15:36.967+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:36.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:36.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:15:36.993+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:36.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:15:37.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:15:37.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:15:37.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T18:16:07.416+0000] {processor.py:157} INFO - Started process (PID=8586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:07.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:16:07.423+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:07.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:07.451+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:16:07.462+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:07.462+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:16:07.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T18:16:37.848+0000] {processor.py:157} INFO - Started process (PID=8611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:37.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:16:37.855+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:37.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:16:37.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:16:37.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:16:37.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:16:37.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.064 seconds
[2024-07-28T18:17:08.341+0000] {processor.py:157} INFO - Started process (PID=8636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:08.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:17:08.344+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:08.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:08.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:17:08.381+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:08.380+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:17:08.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:17:38.772+0000] {processor.py:157} INFO - Started process (PID=8661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:38.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:17:38.777+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:38.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:17:38.819+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:17:38.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:17:38.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:17:38.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.076 seconds
[2024-07-28T18:18:09.131+0000] {processor.py:157} INFO - Started process (PID=8686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:09.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:18:09.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:09.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:09.159+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:18:09.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:09.171+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:18:09.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T18:18:39.543+0000] {processor.py:157} INFO - Started process (PID=8711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:39.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:18:39.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:39.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:18:39.576+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:18:39.585+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:18:39.585+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:18:39.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T18:19:09.977+0000] {processor.py:157} INFO - Started process (PID=8736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:09.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:19:09.982+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:09.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:09.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:10.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:10.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:19:10.021+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:10.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:19:10.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T18:19:40.435+0000] {processor.py:157} INFO - Started process (PID=8761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:40.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:19:40.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:40.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:19:40.467+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:19:40.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:19:40.476+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:19:40.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T18:20:10.925+0000] {processor.py:157} INFO - Started process (PID=8786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:10.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:20:10.928+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:10.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:10.960+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:20:10.969+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:10.969+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:20:10.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:20:41.335+0000] {processor.py:157} INFO - Started process (PID=8811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:41.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:20:41.337+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:41.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:20:41.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:20:41.377+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:20:41.377+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:20:41.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:21:11.778+0000] {processor.py:157} INFO - Started process (PID=8836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:11.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:21:11.784+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:11.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:11.809+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:21:11.821+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:11.820+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:21:11.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T18:21:42.250+0000] {processor.py:157} INFO - Started process (PID=8861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:42.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:21:42.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:42.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:21:42.283+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:21:42.294+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:21:42.294+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:21:42.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T18:22:12.710+0000] {processor.py:157} INFO - Started process (PID=8886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:12.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:22:12.718+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:12.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:12.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:22:12.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:12.767+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:22:12.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T18:22:43.105+0000] {processor.py:157} INFO - Started process (PID=8911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:43.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:22:43.110+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:43.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:22:43.138+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:22:43.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:22:43.147+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:22:43.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:23:13.516+0000] {processor.py:157} INFO - Started process (PID=8936) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:13.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:23:13.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:13.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:13.546+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:23:13.556+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:13.556+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:23:13.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:23:43.921+0000] {processor.py:157} INFO - Started process (PID=8961) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:43.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:23:43.925+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:43.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:23:43.953+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:23:43.962+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:23:43.962+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:23:43.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T18:24:14.342+0000] {processor.py:157} INFO - Started process (PID=8986) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:14.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:24:14.345+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:14.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:14.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:24:14.384+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:14.384+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:24:14.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:24:44.788+0000] {processor.py:157} INFO - Started process (PID=9011) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:44.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:24:44.793+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:44.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:24:44.821+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:24:44.831+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:24:44.831+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:24:44.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.056 seconds
[2024-07-28T18:25:15.232+0000] {processor.py:157} INFO - Started process (PID=9036) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:15.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:25:15.248+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:15.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:15.295+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:25:15.307+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:15.307+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:25:15.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T18:25:45.667+0000] {processor.py:157} INFO - Started process (PID=9061) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:45.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:25:45.670+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:45.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:25:45.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:25:45.704+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:25:45.704+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:25:45.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T18:26:16.050+0000] {processor.py:157} INFO - Started process (PID=9086) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:16.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:26:16.055+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:16.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:16.084+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:26:16.094+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:16.094+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:26:16.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T18:26:46.442+0000] {processor.py:157} INFO - Started process (PID=9111) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:46.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:26:46.448+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:46.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:26:46.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:26:46.489+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:26:46.489+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:26:46.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T18:27:16.916+0000] {processor.py:157} INFO - Started process (PID=9136) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:16.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:27:16.921+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:16.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:16.956+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:27:16.970+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:16.970+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:27:16.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T18:27:47.321+0000] {processor.py:157} INFO - Started process (PID=9161) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:47.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:27:47.324+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:47.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:27:47.362+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:27:47.373+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:27:47.373+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:27:47.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T18:28:17.833+0000] {processor.py:157} INFO - Started process (PID=9186) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:17.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:28:17.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:17.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:17.885+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:28:17.898+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:17.898+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:28:17.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.083 seconds
[2024-07-28T18:28:48.351+0000] {processor.py:157} INFO - Started process (PID=9211) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:48.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:28:48.360+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:48.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:28:48.421+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:28:48.435+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:28:48.435+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:28:48.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-28T18:29:18.952+0000] {processor.py:157} INFO - Started process (PID=9236) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:18.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:29:18.963+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:18.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:19.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:19.061+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:19.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:29:19.085+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:19.084+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:29:19.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.177 seconds
[2024-07-28T18:29:49.485+0000] {processor.py:157} INFO - Started process (PID=9261) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:49.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:29:49.497+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:49.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:29:49.551+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:29:49.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:29:49.574+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:29:49.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.111 seconds
[2024-07-28T18:30:20.072+0000] {processor.py:157} INFO - Started process (PID=9286) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:20.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:30:20.082+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:20.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:20.133+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:30:20.153+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:20.153+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:30:20.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.106 seconds
[2024-07-28T18:30:50.636+0000] {processor.py:157} INFO - Started process (PID=9311) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:50.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:30:50.647+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:50.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:30:50.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:30:50.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:30:50.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:30:50.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.102 seconds
[2024-07-28T18:31:21.272+0000] {processor.py:157} INFO - Started process (PID=9336) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:21.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:31:21.278+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:21.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:21.335+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:31:21.351+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:21.351+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:31:21.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.109 seconds
[2024-07-28T18:31:52.174+0000] {processor.py:157} INFO - Started process (PID=9361) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:52.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:31:52.178+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:52.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:31:52.204+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:31:52.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:31:52.214+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:31:52.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T18:47:51.808+0000] {processor.py:157} INFO - Started process (PID=9386) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:47:51.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:47:51.815+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:47:51.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:47:51.849+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:47:51.866+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:47:51.866+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:47:51.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.078 seconds
[2024-07-28T18:48:22.305+0000] {processor.py:157} INFO - Started process (PID=9413) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:48:22.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T18:48:22.311+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:48:22.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T18:48:22.352+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T18:48:22.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T18:48:22.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T18:48:22.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.544 seconds
[2024-07-28T19:04:09.905+0000] {processor.py:157} INFO - Started process (PID=9438) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:09.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:04:09.916+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:09.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:09.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:10.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:04:10.044+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:04:10.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.166 seconds
[2024-07-28T19:04:40.470+0000] {processor.py:157} INFO - Started process (PID=9463) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:40.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:04:40.476+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:40.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:04:40.526+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:04:40.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:04:40.541+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:04:40.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.090 seconds
[2024-07-28T19:05:10.966+0000] {processor.py:157} INFO - Started process (PID=9488) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:10.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:05:10.974+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:10.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:10.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:11.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:11.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:05:11.024+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:11.024+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:05:11.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T19:05:41.423+0000] {processor.py:157} INFO - Started process (PID=9513) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:41.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:05:41.428+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:41.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:05:41.456+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:05:41.466+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:05:41.466+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:05:41.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T19:06:11.876+0000] {processor.py:157} INFO - Started process (PID=9538) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:11.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:06:11.880+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:11.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:11.906+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:06:11.916+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:11.916+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:06:11.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T19:06:42.350+0000] {processor.py:157} INFO - Started process (PID=9563) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:42.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:06:42.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:42.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:06:42.386+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:06:42.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:06:42.398+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:06:42.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T19:07:12.836+0000] {processor.py:157} INFO - Started process (PID=9588) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:12.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:07:12.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:12.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:12.867+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:07:12.882+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:12.882+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:07:12.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T19:07:43.292+0000] {processor.py:157} INFO - Started process (PID=9613) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:43.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:07:43.298+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:43.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:07:43.336+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:07:43.349+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:07:43.349+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:07:43.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T19:08:13.770+0000] {processor.py:157} INFO - Started process (PID=9638) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:13.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:08:13.772+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:13.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:13.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:08:13.811+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:13.811+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:08:13.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T19:08:44.235+0000] {processor.py:157} INFO - Started process (PID=9663) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:44.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:08:44.239+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:44.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:08:44.266+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:08:44.276+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:08:44.276+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:08:44.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T19:09:14.662+0000] {processor.py:157} INFO - Started process (PID=9688) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:14.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:09:14.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:14.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:14.692+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:09:14.703+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:14.703+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:09:14.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T19:09:45.141+0000] {processor.py:157} INFO - Started process (PID=9713) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:45.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:09:45.147+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:45.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:09:45.175+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:09:45.184+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:09:45.184+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:09:45.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T19:10:15.633+0000] {processor.py:157} INFO - Started process (PID=9738) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:10:15.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:10:15.636+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:10:15.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:10:15.665+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:10:15.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:10:15.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:10:15.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T19:26:00.205+0000] {processor.py:157} INFO - Started process (PID=9765) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:00.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:26:00.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:00.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:00.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:26:00.297+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:00.296+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:26:00.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.121 seconds
[2024-07-28T19:26:30.780+0000] {processor.py:157} INFO - Started process (PID=9790) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:30.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:26:30.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:30.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:26:30.820+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:26:30.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:26:30.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:26:30.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.066 seconds
[2024-07-28T19:27:01.226+0000] {processor.py:157} INFO - Started process (PID=9815) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:01.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:27:01.229+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:01.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:01.257+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:27:01.267+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:01.267+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:27:01.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T19:27:31.634+0000] {processor.py:157} INFO - Started process (PID=9840) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:31.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:27:31.639+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:31.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:27:31.667+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:27:31.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:27:31.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:27:31.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.230 seconds
[2024-07-28T19:28:02.337+0000] {processor.py:157} INFO - Started process (PID=9865) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:28:02.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:28:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:28:02.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:28:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:28:02.383+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:28:02.383+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:28:02.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.061 seconds
[2024-07-28T19:43:44.582+0000] {processor.py:157} INFO - Started process (PID=9891) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:43:44.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:43:44.602+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:43:44.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:43:44.658+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:43:44.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:43:44.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:43:44.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.127 seconds
[2024-07-28T19:44:15.246+0000] {processor.py:157} INFO - Started process (PID=9917) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:15.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:44:15.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:15.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:15.289+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:44:15.302+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:15.302+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:44:15.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T19:44:45.677+0000] {processor.py:157} INFO - Started process (PID=9942) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:45.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:44:45.681+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:45.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:44:45.706+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:44:45.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:44:45.716+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:44:45.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T19:45:16.210+0000] {processor.py:157} INFO - Started process (PID=9967) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:16.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:45:16.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:16.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:16.239+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:45:16.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:16.252+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:45:16.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T19:45:46.621+0000] {processor.py:157} INFO - Started process (PID=9992) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:46.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:45:46.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:46.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:45:46.650+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:45:46.664+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:45:46.664+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:45:46.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.198 seconds
[2024-07-28T19:46:17.324+0000] {processor.py:157} INFO - Started process (PID=10017) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:46:17.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T19:46:17.327+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:46:17.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T19:46:17.353+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T19:46:17.364+0000] {logging_mixin.py:151} INFO - [2024-07-28T19:46:17.364+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T19:46:17.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T20:04:13.159+0000] {processor.py:157} INFO - Started process (PID=10044) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:13.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:04:13.170+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:13.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:13.233+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:04:13.260+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:13.260+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:04:13.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.130 seconds
[2024-07-28T20:04:43.857+0000] {processor.py:157} INFO - Started process (PID=10069) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:43.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:04:43.863+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:43.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:04:43.907+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:04:43.919+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:04:43.919+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:04:43.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.079 seconds
[2024-07-28T20:05:14.407+0000] {processor.py:157} INFO - Started process (PID=10094) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:14.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:05:14.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:14.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:14.440+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:05:14.453+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:14.453+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:05:14.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T20:05:44.802+0000] {processor.py:157} INFO - Started process (PID=10119) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:44.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:05:44.807+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:44.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:05:44.833+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:05:44.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:05:44.843+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:05:44.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T20:06:15.196+0000] {processor.py:157} INFO - Started process (PID=10144) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:06:15.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:06:15.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:06:15.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:06:15.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:06:15.238+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:06:15.238+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:06:15.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T20:21:59.714+0000] {processor.py:157} INFO - Started process (PID=10169) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:21:59.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:21:59.726+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:21:59.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:21:59.804+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:21:59.832+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:21:59.832+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:21:59.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.145 seconds
[2024-07-28T20:22:30.262+0000] {processor.py:157} INFO - Started process (PID=10196) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:22:30.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:22:30.268+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:22:30.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:22:30.304+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:22:30.318+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:22:30.318+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:22:30.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T20:23:00.724+0000] {processor.py:157} INFO - Started process (PID=10221) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:00.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:23:00.727+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:00.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:00.755+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:23:00.765+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:00.765+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:23:00.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T20:23:31.117+0000] {processor.py:157} INFO - Started process (PID=10246) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:31.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:23:31.123+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:31.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:23:31.154+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:23:31.163+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:23:31.163+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:23:31.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.060 seconds
[2024-07-28T20:24:01.500+0000] {processor.py:157} INFO - Started process (PID=10271) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:24:01.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:24:01.502+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:24:01.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:24:01.527+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:24:01.537+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:24:01.537+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:24:01.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.182 seconds
[2024-07-28T20:32:20.102+0000] {processor.py:157} INFO - Started process (PID=10298) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:20.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:32:20.106+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:20.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:20.143+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:32:20.157+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:20.157+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:32:20.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T20:32:50.569+0000] {processor.py:157} INFO - Started process (PID=10323) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:50.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:32:50.574+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:50.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:32:50.609+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:32:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:32:50.620+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:32:50.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.074 seconds
[2024-07-28T20:33:21.008+0000] {processor.py:157} INFO - Started process (PID=10348) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:21.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:33:21.014+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:21.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:21.048+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:33:21.060+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:21.060+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:33:21.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T20:33:51.424+0000] {processor.py:157} INFO - Started process (PID=10373) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:51.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:33:51.432+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:51.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:33:51.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:33:51.496+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:33:51.496+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:33:51.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.088 seconds
[2024-07-28T20:34:21.871+0000] {processor.py:157} INFO - Started process (PID=10398) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:34:21.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:34:21.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:34:21.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:34:21.902+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:34:21.912+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:34:21.912+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:34:21.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
[2024-07-28T20:50:13.352+0000] {processor.py:157} INFO - Started process (PID=10425) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:13.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:50:13.357+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:13.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:13.443+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:50:13.470+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:13.470+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:50:13.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.381 seconds
[2024-07-28T20:50:44.296+0000] {processor.py:157} INFO - Started process (PID=10450) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:44.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:50:44.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:44.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:50:44.358+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:50:44.371+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:50:44.371+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:50:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.091 seconds
[2024-07-28T20:51:14.728+0000] {processor.py:157} INFO - Started process (PID=10475) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:14.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:51:14.731+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:14.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:14.759+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:51:14.770+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:14.770+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:51:14.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T20:51:45.211+0000] {processor.py:157} INFO - Started process (PID=10500) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:45.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:51:45.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:45.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:51:45.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:51:45.256+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:51:45.256+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:51:45.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T20:52:15.680+0000] {processor.py:157} INFO - Started process (PID=10525) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:52:15.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T20:52:15.684+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:52:15.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T20:52:15.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T20:52:15.723+0000] {logging_mixin.py:151} INFO - [2024-07-28T20:52:15.723+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T20:52:15.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T21:10:04.473+0000] {processor.py:157} INFO - Started process (PID=10551) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:04.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:10:04.482+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:04.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:04.548+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:10:04.564+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:04.564+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:10:04.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-28T21:10:35.127+0000] {processor.py:157} INFO - Started process (PID=10576) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:35.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:10:35.134+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:35.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:10:35.181+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:10:35.328+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:10:35.328+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:10:35.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.222 seconds
[2024-07-28T21:11:05.809+0000] {processor.py:157} INFO - Started process (PID=10601) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:05.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:11:05.812+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:05.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:05.843+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:11:05.856+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:05.856+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:11:05.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T21:11:36.225+0000] {processor.py:157} INFO - Started process (PID=10626) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:36.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:11:36.227+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:36.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:11:36.251+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:11:36.261+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:11:36.261+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:11:36.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.047 seconds
[2024-07-28T21:12:06.717+0000] {processor.py:157} INFO - Started process (PID=10651) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:06.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:12:06.722+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:06.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:06.762+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:12:06.774+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:06.774+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:12:06.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T21:12:37.212+0000] {processor.py:157} INFO - Started process (PID=10676) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:37.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:12:37.218+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:37.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:12:37.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:12:37.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:12:37.270+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:12:37.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T21:29:20.341+0000] {processor.py:157} INFO - Started process (PID=10703) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:20.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:29:20.354+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:20.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:20.406+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:29:20.430+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:20.430+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:29:20.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.302 seconds
[2024-07-28T21:29:51.196+0000] {processor.py:157} INFO - Started process (PID=10728) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:51.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:29:51.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:51.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:29:51.230+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:29:51.350+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:29:51.350+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:29:51.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.168 seconds
[2024-07-28T21:30:21.831+0000] {processor.py:157} INFO - Started process (PID=10753) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:21.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:30:21.837+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:21.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:21.876+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:30:21.888+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:21.888+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:30:21.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.071 seconds
[2024-07-28T21:30:52.242+0000] {processor.py:157} INFO - Started process (PID=10778) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:52.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:30:52.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:52.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:30:52.274+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:30:52.284+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:30:52.284+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:30:52.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.054 seconds
[2024-07-28T21:31:22.739+0000] {processor.py:157} INFO - Started process (PID=10803) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:31:22.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:31:22.742+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:31:22.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:31:22.767+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:31:22.780+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:31:22.780+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:31:22.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T21:33:25.198+0000] {processor.py:157} INFO - Started process (PID=10830) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:25.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:33:25.219+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:25.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:25.301+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:33:25.329+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:25.329+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:33:25.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.172 seconds
[2024-07-28T21:33:55.959+0000] {processor.py:157} INFO - Started process (PID=10855) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:55.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:33:55.965+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:55.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:55.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:33:56.009+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:56.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:33:56.023+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:33:56.023+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:33:56.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.211 seconds
[2024-07-28T21:34:26.794+0000] {processor.py:157} INFO - Started process (PID=10880) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:26.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:34:26.801+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:26.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:26.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:34:26.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:26.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:34:26.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.059 seconds
[2024-07-28T21:34:57.216+0000] {processor.py:157} INFO - Started process (PID=10905) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:57.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:34:57.223+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:57.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:34:57.259+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:34:57.271+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:34:57.271+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:34:57.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.070 seconds
[2024-07-28T21:35:27.655+0000] {processor.py:157} INFO - Started process (PID=10930) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:35:27.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:35:27.659+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:35:27.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:35:27.689+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:35:27.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:35:27.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:35:27.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.058 seconds
[2024-07-28T21:51:03.193+0000] {processor.py:157} INFO - Started process (PID=10957) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:03.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:51:03.199+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:03.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:03.234+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:51:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:03.246+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:51:03.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.067 seconds
[2024-07-28T21:51:33.619+0000] {processor.py:157} INFO - Started process (PID=10982) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:33.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T21:51:33.623+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:33.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T21:51:33.662+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T21:51:33.675+0000] {logging_mixin.py:151} INFO - [2024-07-28T21:51:33.675+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T21:51:33.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.259 seconds
[2024-07-28T22:09:17.647+0000] {processor.py:157} INFO - Started process (PID=11007) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:17.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:09:17.658+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:17.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:17.716+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:09:17.957+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:17.957+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:09:17.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.328 seconds
[2024-07-28T22:09:48.679+0000] {processor.py:157} INFO - Started process (PID=11032) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:48.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:09:48.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:48.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:09:48.737+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:09:48.748+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:09:48.748+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:09:48.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.099 seconds
[2024-07-28T22:10:19.211+0000] {processor.py:157} INFO - Started process (PID=11057) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:19.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:10:19.214+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:19.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:19.244+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:10:19.254+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:19.254+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:10:19.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T22:10:49.648+0000] {processor.py:157} INFO - Started process (PID=11082) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:49.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:10:49.651+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:49.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:10:49.685+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:10:49.699+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:10:49.699+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:10:49.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.065 seconds
[2024-07-28T22:11:20.201+0000] {processor.py:157} INFO - Started process (PID=11107) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:20.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:11:20.207+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:20.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:20.232+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:11:20.242+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:20.241+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:11:20.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.050 seconds
[2024-07-28T22:11:50.653+0000] {processor.py:157} INFO - Started process (PID=11132) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:50.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:11:50.657+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:50.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:11:50.683+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:11:50.694+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:11:50.694+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:11:50.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.203 seconds
[2024-07-28T22:12:21.405+0000] {processor.py:157} INFO - Started process (PID=11157) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:12:21.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:12:21.410+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:12:21.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:12:21.461+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:12:21.583+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:12:21.583+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:12:21.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.210 seconds
[2024-07-28T22:28:01.465+0000] {processor.py:157} INFO - Started process (PID=11182) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:01.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:28:01.473+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:01.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:01.536+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:28:01.567+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:01.567+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:28:01.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.123 seconds
[2024-07-28T22:28:32.001+0000] {processor.py:157} INFO - Started process (PID=11207) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:32.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:28:32.006+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:32.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:28:32.033+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:28:32.043+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:28:32.043+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:28:32.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.053 seconds
[2024-07-28T22:29:02.502+0000] {processor.py:157} INFO - Started process (PID=11232) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:02.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:29:02.509+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:02.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:02.545+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:29:02.558+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:02.558+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:29:02.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.072 seconds
[2024-07-28T22:29:32.978+0000] {processor.py:157} INFO - Started process (PID=11257) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:32.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:29:32.984+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:32.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:32.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:29:33.011+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:33.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:29:33.021+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:29:33.021+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:29:33.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.057 seconds
[2024-07-28T22:30:03.471+0000] {processor.py:157} INFO - Started process (PID=11282) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:30:03.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:30:03.478+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:30:03.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:30:03.507+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:30:03.677+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:30:03.677+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:30:03.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.219 seconds
[2024-07-28T22:34:46.409+0000] {processor.py:157} INFO - Started process (PID=11307) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:34:46.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:34:46.416+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:34:46.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:34:46.501+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:34:46.769+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:34:46.769+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:34:46.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.379 seconds
[2024-07-28T22:50:46.351+0000] {processor.py:157} INFO - Started process (PID=11334) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:50:46.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:50:46.359+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:50:46.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:50:46.439+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:50:46.466+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:50:46.466+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:50:46.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.136 seconds
[2024-07-28T22:51:16.930+0000] {processor.py:157} INFO - Started process (PID=11359) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:51:16.935+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:16.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:16.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:16.988+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:16.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:51:17.003+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:17.003+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:51:17.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.113 seconds
[2024-07-28T22:51:47.511+0000] {processor.py:157} INFO - Started process (PID=11384) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:47.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:51:47.515+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:47.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:51:47.550+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:51:47.560+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:51:47.560+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:51:47.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T22:52:18.069+0000] {processor.py:157} INFO - Started process (PID=11409) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:18.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:52:18.075+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:18.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:18.101+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:52:18.114+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:18.114+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:52:18.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.210 seconds
[2024-07-28T22:52:48.824+0000] {processor.py:157} INFO - Started process (PID=11434) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:48.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:52:48.829+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:48.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:52:48.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:52:48.967+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:52:48.967+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:52:48.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.160 seconds
[2024-07-28T22:53:19.396+0000] {processor.py:157} INFO - Started process (PID=11459) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:19.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:53:19.398+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:19.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:19.422+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:53:19.431+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:19.431+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:53:19.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.045 seconds
[2024-07-28T22:53:49.817+0000] {processor.py:157} INFO - Started process (PID=11484) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:49.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:53:49.822+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:49.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:53:49.847+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:53:49.859+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:53:49.859+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:53:49.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T22:54:20.297+0000] {processor.py:157} INFO - Started process (PID=11509) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:54:20.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T22:54:20.303+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:54:20.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T22:54:20.338+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T22:54:20.347+0000] {logging_mixin.py:151} INFO - [2024-07-28T22:54:20.347+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T22:54:20.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.063 seconds
[2024-07-28T23:12:15.095+0000] {processor.py:157} INFO - Started process (PID=11536) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:15.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:12:15.103+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:15.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:15.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:12:15.167+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:15.167+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:12:15.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.093 seconds
[2024-07-28T23:12:45.664+0000] {processor.py:157} INFO - Started process (PID=11561) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:45.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:12:45.672+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:45.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:12:45.708+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:12:45.724+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:12:45.724+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:12:45.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.202 seconds
[2024-07-28T23:13:16.536+0000] {processor.py:157} INFO - Started process (PID=11586) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:16.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:13:16.541+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:16.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:16.573+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:13:16.669+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:16.669+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:13:16.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.147 seconds
[2024-07-28T23:13:47.120+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:47.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:13:47.124+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:47.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:13:47.150+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:13:47.162+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:13:47.162+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:13:47.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.055 seconds
[2024-07-28T23:14:17.661+0000] {processor.py:157} INFO - Started process (PID=11636) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:14:17.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:14:17.666+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:14:17.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:14:17.700+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:14:17.714+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:14:17.714+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:14:17.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.068 seconds
[2024-07-28T23:30:02.309+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:02.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:30:02.319+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:02.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:02.379+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:30:02.399+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:02.399+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:30:02.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.112 seconds
[2024-07-28T23:30:32.978+0000] {processor.py:157} INFO - Started process (PID=11686) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:32.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:30:32.983+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:32.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:32.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:30:33.025+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:33.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:30:33.037+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:30:33.037+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:30:33.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.082 seconds
[2024-07-28T23:31:03.475+0000] {processor.py:157} INFO - Started process (PID=11711) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:03.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:31:03.479+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:03.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:03.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:31:03.519+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:03.519+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:31:03.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.206 seconds
[2024-07-28T23:31:34.168+0000] {processor.py:157} INFO - Started process (PID=11736) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:34.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:31:34.171+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:34.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:31:34.201+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:31:34.285+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:31:34.285+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:31:34.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.133 seconds
[2024-07-28T23:32:04.860+0000] {processor.py:157} INFO - Started process (PID=11761) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:32:04.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:32:04.865+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:32:04.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:32:04.891+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:32:04.900+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:32:04.900+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:32:04.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.051 seconds
[2024-07-28T23:48:32.197+0000] {processor.py:157} INFO - Started process (PID=11786) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:48:32.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:48:32.203+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:48:32.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:48:32.252+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:48:32.270+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:48:32.270+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:48:32.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.095 seconds
[2024-07-28T23:49:02.781+0000] {processor.py:157} INFO - Started process (PID=11811) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:02.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:49:02.786+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:02.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:02.823+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:49:02.838+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:02.838+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:49:02.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.073 seconds
[2024-07-28T23:49:43.797+0000] {processor.py:157} INFO - Started process (PID=11836) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:43.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:49:43.799+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:43.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:49:43.828+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:49:43.839+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:49:43.839+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:49:44.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.218 seconds
[2024-07-28T23:50:14.389+0000] {processor.py:157} INFO - Started process (PID=11861) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:14.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:50:14.394+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:14.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:14.420+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:50:14.506+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:14.506+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:50:14.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.128 seconds
[2024-07-28T23:50:44.943+0000] {processor.py:157} INFO - Started process (PID=11886) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:44.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:50:44.946+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:44.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:44.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:50:44.971+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:44.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:50:45.049+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:50:45.048+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:50:45.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.117 seconds
[2024-07-28T23:51:15.491+0000] {processor.py:157} INFO - Started process (PID=11911) to work on /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:51:15.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs.py for tasks to queue
[2024-07-28T23:51:15.495+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:51:15.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['data_pipeline']) retrieved from /opt/airflow/dags/spark-jobs.py
[2024-07-28T23:51:15.521+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-28T23:51:15.531+0000] {logging_mixin.py:151} INFO - [2024-07-28T23:51:15.531+0000] {dag.py:3696} INFO - Setting next_dagrun for data_pipeline to 2024-07-28T00:30:00+00:00, run_after=2024-07-29T00:30:00+00:00
[2024-07-28T23:51:15.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs.py took 0.052 seconds
